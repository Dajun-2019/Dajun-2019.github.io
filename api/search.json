[{"id":"620525f1f9bec18e83cb8c46a0c73576","title":"Microservices","content":"1.微服务\n\nWhat：微服务（Microservices）是一种软件架构风格，将一个大型应用程序划分为一组小型、自治且松耦合的服务。每个微服务负责执行特定的业务功能，并通过轻量级通信机制（如HTTP）相互协作。每个微服务可以独立开发、部署和扩展，使得应用程序更加灵活、可伸缩和可维护。在微服务的架构演进中，一般可能会存在这样的演进方向：单体式–&gt;服务化–&gt;微服务\n\n单体服务（Monolithic Service）是一种传统的软件架构方式，将整个应用程序作为一个单一的、紧耦合的单元进行开发和部署。单体服务通常由多个模块组成，这些模块共享同一个数据库和代码库。然而，随着应用程序规模的增长，单体服务可能变得庞大且难以维护，且部署和扩展困难。\nSOA（Service-Oriented Architecture，面向服务的架构）是一种软件架构设计原则，强调将应用程序拆分为相互独立的服务，通过标准化的接口进行通信。SOA关注于服务的重用性和组合性，但并没有具体规定服务的大小。\n微服务是在SOA的基础上进一步发展而来，是一种特定规模下的服务拆分和部署方式。微服务架构强调将应用程序拆分为小型、自治且松耦合的服务，每个服务都专注于特定的业务功能。这种架构使得应用程序更加灵活、可伸缩和可维护。\n微服务是一种特定的架构风格，而SOA是一种设计原则。微服务可以看作是对SOA思想的一种具体实践方式，但并不等同于SOA。\n\n\n\n\n微服务带来的问题\n\n系统复杂性增加：一个服务拆成了多个服务，整体系统的复杂性增加，需要处理服务之间的通信、部署、监控和维护等方面的复杂性。\n服务间通信开销：微服务之间通过网络进行通信，传递数据需要额外的网络开销和序列化开销，可能导致性能瓶颈和增加系统延迟。\n数据一致性和事务管理：每个微服务都有自己的数据存储，数据一致性和跨服务的事务管理变得更加复杂，需要额外解决分布式事务和数据同步的问题。\n部署和运维复杂性：微服务架构涉及多个独立部署的服务，对于部署、监控和容错机制的要求更高，需要建立适当的部署管道和自动化工具，以简化部署和运维过程。\n团队沟通和协作成本：每个微服务都由专门的团队负责，可能增加团队之间的沟通和协作成本。需要有效的沟通渠道和协作机制，确保服务之间的协调和一致性。\n服务治理和版本管理：随着微服务数量的增加，服务的治理和版本管理变得更加复杂。需要考虑服务的注册发现、负载均衡、监控和故障处理等方面，以确保整个系统的可靠性和稳定性。\n分布式系统的复杂性：微服务架构涉及构建和管理分布式系统，而分布式系统本身具有一些固有的挑战，如网络延迟、分布式一致性和容错性。\n\n\n常见解决方案：Spring Cloud Alibaba（Nacos、Sentiel、Seata、RocketMQ、Dubbo）\n\n微服务有哪些组件\n\n\n注册中心：服务注册、服务发现、负载均衡、故障恢复、服务治理\n\nEureka和ZooKeeper的最大区别是一个支持AP，一个支持CP，Nacos既支持既支持AP，也支持CP。\n\n\n对比\n\n\n\n特性\nEureka\nZooKeeper\nNacos\n\n\n\n开发公司\nNetflix\nApache 基金会\n阿里巴巴\n\n\nCAP\nAP（可用性和分区容忍性）\nCP（一致性和分区容忍性）\n既支持AP，也支持CP\n\n\n功能\n服务注册与发现\n分布式协调、配置管理、分布式锁\n服务注册与发现、配置管理、服务管理\n\n\n定位\n适用于构建基于 HTTP 的微服务架构\n通用的分布式协调服务框架\n适用于微服务和云原生应用\n\n\n访问协议\nHTTP\nTCP\nHTTP/DNS\n\n\n自我保护\n支持\n-\n支持\n\n\n数据存储\n内嵌数据库、多个实例形成集群\nACID 特性的分布式文件系统 ZAB 协议\n内嵌数据库、MySQL 等\n\n\n健康检查\nClient Beat\nKeep Alive\nTCP/HTTP/MYSQL/Client Beat\n\n\n特点\n简单易用、自我保护机制\n高性能、强一致性\n动态配置管理、流量管理、灰度发布等\n\n\n\n\n\n配置中心：配置信息存储、注册配置信息、获取配置信息、监听配置变化\n\n微服务架构中的每个服务通常都需要一些配置信息，例如数据库连接地址、服务端口、日志级别等。这些配置可能因为不同环境、不同部署实例或者动态运行时需要进行调整和管理。微服务的实例一般非常多，如果每个实例都需要一个个地去做这些配置，那么运维成本将会非常大，这时候就需要一个集中化的配置中心，去管理这些配置。\n\n\n远程调用：见Feign\n\nHTTP和RPC的区别：一些RPC框架比如gRPC，底层传输协议其实也是用的HTTP2，包括Dubbo3，也兼容了gRPC，使用了HTTP2作为传输层的一层协议。\n\nHTTP（Hypertext Transfer Protocol）是一种应用层协议，主要强调的是网络通信；\n\nRPC（Remote Procedure Call，远程过程调用）是一种用于分布式系统之间通信的协议，强调的是服务之间的远程调用。\n\nHTTP和RPC对比\n\n\n\n\nHTTP\nRPC\n\n\n\n定义\nHTTP（超文本传输协议）是一种用于传输超文本的协议。\nRPC（远程过程调用）是一种用于实现分布式系统中不同节点之间通信的协议。\n\n\n通信方式\n基于请求-响应模型，客户端发送请求，服务器返回响应。\n基于方法调用模型，客户端调用远程方法并等待结果。\n\n\n传输协议\n基于TCP协议，可使用其他传输层协议如TLS/SSL进行安全加密。\n可以使用多种传输协议，如TCP、UDP等。\n\n\n数据格式\n基于文本，常用的数据格式有JSON、XML等。\n可以使用各种数据格式，如二进制、JSON、Protocol Buffers等。\n\n\n接口定义\n使用RESTful风格的接口进行定义，常用的方法有GET、POST、PUT、DELETE等。\n使用IDL（接口定义语言）进行接口定义，如Protocol Buffers、Thrift等。\n\n\n跨语言性\n支持跨语言通信，可以使用HTTP作为通信协议实现不同语言之间的通信。\n支持跨语言通信，可以使用IDL生成不同语言的客户端和服务端代码。\n\n\n灵活性\n更加灵活，适用于不同类型的应用场景，如Web开发、API调用等。\n更加高效，适用于需要高性能和低延迟的分布式系统。\n\n\n\n\n\n见Feign\n\n\n\n服务网关：API网关（API Gateway）是一种中间层服务器，用于集中管理、保护和路由对后端服务的访问。它充当了客户端与后端服务之间的入口点，提供了一组统一的接口来管理和控制API的访问。\n\n路由转发：API网关根据请求的URL路径或其他标识，将请求路由到相应的后端服务。通过配置路由规则，可以灵活地将请求分发给不同的后端服务。\n负载均衡：API网关可以在后端服务之间实现负载均衡，将请求平均分发到多个实例上，提高系统的吞吐量和可扩展性。\n安全认证与授权：API网关可以集中处理身份验证和授权，确保只有经过身份验证的客户端才能访问后端服务。它可以与身份提供者（如OAuth、OpenID Connect）集成，进行用户认证和授权操作。\n缓存：API网关可以缓存后端服务的响应，减少对后端服务的请求次数，提高系统性能和响应速度。\n监控与日志：API网关可以收集和记录请求的指标和日志，提供实时监控和分析，帮助开发人员和运维人员进行故障排查和性能优化。\n数据转换与协议转换：API网关可以在客户端和后端服务之间进行数据格式转换和协议转换，如将请求从HTTP转换为WebSocket，或将请求的参数进行格式转换，以满足后端服务的需求。\nAPI版本管理：API网关可以管理不同版本的API，允许同时存在多个API版本，并通过路由规则将请求正确地路由到相应的API版本上。\n\n\nSpring Cloud Gateway\n\n组件\n\nRoute（路由）：路由是Spring Cloud Gateway的基本构建块，它定义了请求的匹配规则和转发目标。通过配置路由，可以将请求映射到后端的服务实例或URL上。路由规则可以根据请求的路径、方法、请求头等条件进行匹配，并指定转发的目标URI。\nPredicate（断言）：断言用于匹配请求的条件，如果请求满足断言的条件，则会应用所配置的过滤器。Spring Cloud Gateway提供了多种内置的断言，如Path（路径匹配）、Method（请求方法匹配）、Header（请求头匹配）等，同时也支持自定义断言。\nFilter（过滤器）：过滤器用于对请求进行处理和转换，可以修改请求、响应以及执行其他自定义逻辑。Spring Cloud Gateway提供了多个内置的过滤器，如请求转发、请求重试、请求限流等。同时也支持自定义过滤器，可以根据需求编写自己的过滤器逻辑。\n\n\n重要概念\n\nGateway Handler（网关处理器）：网关处理器是Spring Cloud Gateway的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。\nGateway Filter Chain（网关过滤器链）：网关过滤器链由一系列过滤器组成，按照配置的顺序依次执行。每个过滤器可以在请求前、请求后或请求发生错误时进行处理。过滤器链的执行过程可以修改请求、响应以及执行其他自定义逻辑。\n\n\n工作流程\n\n\n\n\n链路追踪：见Sleuth\n\n分布式事务：见Seata\n\n运维\n\n服务监控：使用Prometheus和Grafana来实现整个微服务集群的监控和告警\n\nPrometheus：Prometheus 是一个开源的监控系统，具有灵活的数据模型和强大的查询语言，能够收集和存储时间序列数据。它可以通过HTTP协议定期拉取微服务的指标数据，并提供可扩展的存储和查询功能。\nGrafana：Grafana 是一个开源的可视化仪表板工具，可以与 Prometheus 结合使用，创建实时和历史数据的仪表板。Grafana 提供了丰富的图表和可视化选项，可以帮助用户更好地理解和分析微服务的性能和状态。\n\n\n日志收集：ELK，\nElasticsearch\n提供数据存储和检索能力，\nLogstash\n负责将日志收集到ES，\nKibana\n负责日志数据的可视化分析。\n\n组件\nElasticsearch：Elasticsearch是一个分布式搜索和分析引擎，用于存储和索引大量的日志数据。它提供了快速的搜索和聚合功能，可以高效地处理大规模的日志数据。\nLogstash：Logstash是一个用于收集、过滤和转发日志数据的工具。它可以从各种来源（如文件、网络、消息队列等）收集日志数据，并对数据进行处理和转换，然后将其发送到Elasticsearch进行存储和索引。\nKibana：Kibana是一个用于日志数据可视化和分析的工具。它提供了丰富的图表、仪表盘和搜索功能，可以帮助用户实时监控和分析日志数据，发现潜在的问题和趋势。\n\n\n收集流程\n在每个微服务中配置日志输出：将微服务的日志输出到标准输出（stdout）或日志文件。\n使用Logstash收集日志：配置Logstash收集器，通过配置输入插件（如文件输入、网络输入等）监听微服务的日志输出，并进行过滤和处理。\n将日志数据发送到Elasticsearch：配置Logstash的输出插件，将经过处理的日志数据发送到Elasticsearch进行存储和索引。\n使用Kibana进行可视化和分析：通过Kibana连接到Elasticsearch，创建仪表盘、图表和搜索查询，实时监控和分析微服务的日志数据。\n\n\n\n\n\n\n\n\n服务容灾\n\n服务雪崩：在微服务中，假如一个或者多个服务出现故障，如果这时候，依赖的服务还在不断发起请求，或者重试，那么这些请求的压力会不断在下游堆积，导致下游服务的负载急剧增加。不断累计之下，可能会导致故障的进一步加剧，可能会导致级联式的失败，甚至导致整个系统崩溃，这就叫服务雪崩。\n服务高可用部署：确保各个服务都具备高可用性，通过冗余部署、故障转移等方式来减少单点故障的影响。\n限流和熔断：对服务之间的请求进行限流和熔断，以防止过多的请求涌入导致后端服务不可用。\n缓存和降级：合理使用缓存来减轻后端服务的负载压力，并在必要时进行服务降级，保证核心功能的可用性。\n\n\n服务熔断：服务熔断是微服务架构中的容错机制，用于保护系统免受服务故障或异常的影响。当某个服务出现故障或异常时，服务熔断可以快速隔离该服务，确保系统稳定可用。它通过监控服务的调用情况，当错误率或响应时间超过阈值时，触发熔断机制，后续请求将返回默认值或错误信息，避免资源浪费和系统崩溃。服务熔断还支持自动恢复，重新尝试对故障服务的请求，确保服务恢复正常后继续使用。\nResilience4j：轻量级服务熔断库，提供类似于Hystrix的功能，具有更好的性能和更简洁的API，可与Spring Cloud其他组件无缝集成\n\n\n服务降级：服务降级是也是一种微服务架构中的容错机制，用于在系统资源紧张或服务故障时保证核心功能的可用性。当系统出现异常情况时，服务降级会主动屏蔽一些非核心或可选的功能，而只提供最基本的功能，以确保系统的稳定运行。通过减少对资源的依赖，服务降级可以保证系统的可用性和性能。它可以根据业务需求和系统状况来制定策略，例如替换耗时操作、返回默认响应、返回静态错误页面等。\nSentinel：阿里巴巴开源的流量控制和熔断降级组件，提供实时监控、流量控制、熔断降级等功能，与Spring Cloud Alibaba生态系统紧密集成\n\n\n\n\n短链系统：设定好映射规则，实现好解密流程，即可把请求的短链转发到对应的URI上\n\n怎么设计一个短链地址，要考虑跨机房部署问题\n你说要哈希算法生成短链，会存在什么问题（哈希冲突），该怎么解决？（可以用布隆过滤器，但是不好控制，而且仍存在hash冲突）\n有没有更好的方案？（自增序列算法，每次接收一个长链，就分配一个ID，转成62进制再拼到短域后面）\n存在的问题？（自增id方案如果用雪花算法，可能存在机器时钟回拨的问题，导致id重复，说到这里，我终于明白那家伙为什么说要考虑跨机房部署问题）\n该怎么解决？（用Redis做自增id生成器，性能高，但要考虑持久性的问题；或者改造雪花算法，通过改造workId解决时钟回拨的问题）\n\n\n\n2.Nacos\n注册中心对比\n\n常见问题\n\n消费者如何及时知道生产者的变更\n\n发布订阅模式（Zookeeper）：服务消费者能够实时监控服务更新状态，通常采用监听器以及回调机制\n主动拉取策略（Eureka）：服务的消费者定期调用注册中心提供的服务获取接口获取最新的服务列表并更新本地缓存\n\n\n负载均衡策略\n\n服务端的负载均衡典型代表是Nginx、客户端的负载均衡典型代表是Ribbon。服务端的负载均衡，给服务提供者更强的流量控制权，但是无法满足不同的消费者希望使用不同负载均衡策略的需求；客户端的负载均衡则提供了这种灵活性，并对用户扩展提供更加友好的支持。但是客户端负载均衡策略如果配置不当，可能会导致服务提供者出现热点，或者压根就拿不到任何服务提供者\n常见负载均衡算法：轮询法、随机法、哈希算法、加权轮询法、加权随机法、最小连接数法\n\n\nApollo与Nacos效率对比\n\n单机读场景：客户端测试程序通过部署多台机器，每台机器开启多个线程从配置中心读取不同的配置（3000个）。Nacos QPS可以达到15000，Apollo分为读内存缓存和从数据库中读两种方式，从数据库中读能达到7500，从内存读缓存性能可以达到9000QPS。Spring Cloud Config使用jGit读写Git，由于有客户端限制，单机读能力被限制在7QPS\n3节点读场景：将配置中心的压测节点数都部署成3个节点。Nacos QPS可以达到45000 QPS，Apollo读内存缓存可以达到27000 QPS。Nacos和Apollo由于读场景各个节点是独立的，基本就是单机读场景的3倍关系。Spring Cloud Config三个节点读能力可以到达21QPS\n单机写场景：同样的方式，多台机器同时在配置中心修改不同的配置。Nacos QPS可以达到1800，Apollo未使用默认的数据库连接池（10）QPS只能达到800 QPS（CPU未压满），调整连接池至100可以达到1100 QPS（CPU压满）。Git在提交同一个项目的时候会加锁，单机Git写能在5QPS左右，Spring Cloud Config在使用的时候以一个项目作为数据源，写能力受到Git限制\n3节点写场景：同样的方式，将配置中心的压测节点数都部署成3个节点。Nacos QPS可以达到6000，Apollo可以达到3300 QPS（CPU压满），此时MySQL数据库因为配置较高，未成为性能瓶颈。Spring Cloud Config三个节点时候，Git也是一个节点，写QPS为5\n\n\n\n\n\nApollo\nNacos\n\n\n\n单机读\n9000\n15000\n\n\n单机写\n1100\n1800\n\n\n3节点读\n27000\n45000\n\n\n3节点写\n3300\n5600\n\n\n\n\n\n常见注册中心\n\nZookeeper\n\n基础\n三种角色：Leader（同一时间只有一个，发起并维护与其它角色间的心跳，响应写操作并广播给其他服务器）、Follower（响应Leader心跳，可以处理读请求、有投票权）、Observer（与Follower类似，但无投票权）\n四种节点：PERSISTENT-持久节点（一直存在）、EPHEMERAL-临时节点（与客户端绑定）、PERSISTENT_SEQUENTIAL-持久顺序节点（增加了顺序属性，维护自增整形数字）、EPHEMERAL_SEQUENTIAL-临时顺序节点\n一种机制：Zookeeper的Watch机制（一种推拉结合的模式），一旦服务端感知主题变了，那么只会发送一个事件类型和节点信息给关注的客户端，而不会包括具体的变更内容，所以事件本身是轻量级的，这就是推的部分；然后，收到变更通知的客户端需要自己去拉变更的数据，这就是拉的部分\n\n\n如何实现注册中心：Zookeeper可以充当一个服务注册表（Service Registry），让多个服务提供者形成一个集群，让服务消费者通过服务注册表获取具体的服务访问地址（ip+端口）去访问具体的服务提供者\n每当一个服务提供者部署后都要将自己的服务注册到zookeeper的某一路径上: /{service}/{version}/{ip:port}\n进行服务注册，就是在Zookeeper中创建了一个Znode节点，该节点存储了该服务的IP、端口、调用方式(协议、序列化方式)等，由服务提供者创建，服务消费者通过获取节点信息定位到服务提供者真正IP，发起调用\n如果创建的是临时节点，那么当创建临时节点的客户端会话因超时或发生异常而关闭时，该节点也相应在 ZooKeeper 服务器上被删除，剔除或者上线的时候会触发Zookeeper的Watch机制，会发送消息给消费者，因此就做到消费者信息的及时更新\n\n\nZookeeper从设计上来说的话整体遵循的CP的原则，在任何时候对 Zookeeper 的访问请求能得到一致的数据结果，同时系统对网络分区具备容错性，在使用 Zookeeper 获取服务列表时，如果此时的 Zookeeper 集群中的 Leader 宕机了，该集群就要进行 Leader 的选举，又或者 Zookeeper 集群中半数以上服务器节点不可用（例如有三个节点，如果节点一检测到节点三挂了 ，节点二也检测到节点三挂了，那这个节点才算是真的挂了)，那么将无法处理该请求。所以说，Zookeeper 不能保证服务可用性\n\n\nConsul\n\n特点：服务注册和发现、健康检查、key/value存储、安全服务通信、多数据中心\n\n在单个数据中心中，Consul分为Client和Server两种节点（所有的节点也被称为Agent），Server节点保存数据，Client负责健康检查及转发数据请求到Server；Server节点有一个Leader和多个Follower，Leader节点会将数据同步到Follower，Server的数量推荐是3个或者5个，在Leader挂掉的时候会启动选举机制产生一个新的Leader\n\n集群内的Consul节点通过gossip协议（流言协议）维护成员关系，也就是说某个节点了解集群内现在还有哪些节点，这些节点是Client还是Server。单个数据中心的流言协议同时使用TCP和UDP通信，并且都使用8301端口。跨数据中心的流言协议也同时使用TCP和UDP通信，端口使用8302\n\n集群内数据的读写请求既可以直接发到Server，也可以通过Client使用RPC转发到Server，请求最终会到达Leader节点，在允许数据延时的情况下，读请求也可以在普通的Server节点完成，集群内数据的读写和复制都是通过TCP的8300端口完成\n\n应用外注册\n\nRegistrator：一个开源的第三方服务管理器项目，它通过监听服务部署的 Docker 实例是否存活，来负责服务提供者的注册和销毁\n\nConsul Template：定时从注册中心服务端获取最新的服务提供者节点列表并刷新 LB 配置（比如 Nginx 的 upstream），这样服务消费者就通过访问 Nginx 就可以获取最新的服务提供者信息,达到动态调节负载均衡的目的\n\n我们用Registrator来监控每个Server的状态。当有新的Server启动的时候，Registrator会把它注册到Consul这个注册中心上。由于Consul Template已经订阅了该注册中心上的服务消息，此时Consul注册中心会将新的Server信息推送给Consul Template，Consul Template则会去修改nginx.conf的配置文件，然后让Nginx重新载入配置以达到自动修改负载均衡的目的\n\n\n\n\n\n\nKubernetes\n\n在Kubernetes中，会将组成应用的容器组合成一个逻辑单元以更易管理和发现，通过Kubernetes能够进行应用的自动化部署和扩缩容\n特性：自动化装箱、自愈能力、水平扩容、服务发现和负载均衡、自动发布和回滚、保密和配置管理、存储编排\n架构组成\nMaster Node：作为控制节点，对集群进行调度管理，Master主要由三部分构成:\nApi Server相当于 K8S 的网关，所有的指令请求都必须经过 Api Server;\nKubernetes调度器，使用调度算法，把请求资源调度到某个 Node 节点;\nController控制器，维护 K8S 资源对象（CRUD：添加、删除、更新、修改）;\nETCD存储资源对象（可以服务注册、发现等等）;\n\n\nWorker Node：作为真正的工作节点，运行业务应用的容器；Worker Node主要包含五部分:\nDocker是运行容器的基础环境，容器引擎;\nKuberlet 执行在 Node 节点上的资源操作，Scheduler 把请求交给Api ，然后 Api Sever 再把信息指令数据存储在 ETCD 里，于是 Kuberlet 会扫描 ETCD 并获取指令请求，然后去执行;\nKube-proxy是代理服务，起到负载均衡作用；\nFluentd采集日志;\nPod：Kubernetes 管理的基本单元（最小单元)，Pod 内部是容器。Kubernetes 不直接管理容器，而是管理 Pod;\n\n\n\n\n\n\n\n\n\n\n主要功能：充当微服务的注册中心、服务配置、服务总线组件，\n\n架构图：provider对外暴露服务，consumer调用provider的服务，均需要使用@EnableDiscoveryClient来开启服务注册发现的功能\n\n\n服务注册与服务调用实现：可以使用Ribbon的负载均衡来调用provider\n\n创建RestTemplate，使用@LoadBalanced注解标注开启负载均衡\n\n\n直接使用注册到nacos的中的服务名作为访问地址调用服务，serviceUrl是配置文件中的serviceUrl.nacos-provider=http://nacos-provider，其中nacos-provider即provider在nacos注册的名字\n\n\n\n\n配置管理实现：可以使用命名空间（namespace）来解决多环境隔离问题、可以使用配置集（Group）来区分不同业务系统的相同配置、使用共享配置实现配置复用\n\n添加maven依赖、增加配置文件（指定当前环境、nacos地址和配置内容格式）\nspring:\n  application:\n    name: nacos-config\n    ## 当前环境，这个和dataId有关-&gt; $&#123;prefix&#125;-$&#123;spring.profiles.active&#125;.$&#123;file-extension&#125;\n  profiles:\n    active: dev\n  cloud:\n    nacos:\n      config:\n        ## nacos的地址，作为配置中心\n        server-addr: 127.0.0.1:8848\n        ## 配置内容的数据格式，目前只支持 properties 和 yaml 类型，这个和dataId有关-&gt; $&#123;prefix&#125;-$&#123;spring.profiles.active&#125;.$&#123;file-extension&#125;\n        file-extension: properties\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        ## yml文件中存在特殊字符，必须用单引号包含，否则启动报错\n        include: &#39;*&#39;\ndataId：一个配置的唯一标识，取值格式为$&#123;prefix&#125;-$&#123;spring.profiles.active&#125;.$&#123;file-extension&#125;\n\nprefix：前缀，默认为spring.application.name，也可以通过配置项 spring.cloud.nacos.config.prefix来配置\nspring.profiles.active：即为当前环境对应的 profile。当 spring.profiles.active为空时，对应的连接符-也将不存在，dataId 的拼接格式变成 $&#123;prefix&#125;.$&#123;file-extension&#125;\nspring.profiles.active=dev：本地开发环境\nspring.profiles.active=test：测试环境\nspring.profiles.active=prod：生产环境\n\n\nfile-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。\n\n\n添加配置：在Nacos页面，添加一个config.version的配置，发布之后就可以使用\n\n\n获取Nacos中的配置：使用原生注解@Value()直接读取即可\n\n\n使用Nacos自动刷新配置：添加原生注解@RefreshScope\n\n\n\n\n\n\nNacos集群\n\n集群架构图\n\n\n实现步骤\n\n修改端口号：application.properties中的server.port\n\n复制cluster.conf.example\n\n修改数据源：在MySQL中新建一个数据库，执行Nacos的SQL脚本（nacos-mysql.sql），修改application.properties中的数据源\n\n修改nginx的conf\nupstream nacos&#123;\n\t\tserver 172.16.1.84:8848;\n\t\tserver 172.16.1.84:8849;\n\t\tserver 172.16.1.84:8850;\n\t &#125;\n\t \n\t server&#123;\n\t\tlisten 80;\n\t\tlocation &#x2F; &#123;\n\t\t\tproxy_pass &lt;http:&#x2F;&#x2F;nacos&gt;;\n\t\t&#125;\n\t &#125;\n在项目中配置server-addr\n\n直连Nacos\nspring:\n  application:\n    ## 指定服务名称，在nacos中的名字\n    name: nacos-provider\n  cloud:\n    nacos:\n      discovery:\n        # nacos的服务地址，nacos-server中IP地址:端口号\n        server-addr: 172.16.1.84:8848,172.16.1.84:8849,172.16.1.84:8850\n通过Nginx\nspring:\n  application:\n    ## 指定服务名称，在nacos中的名字\n    name: nacos-provider\n  cloud:\n    nacos:\n      discovery:\n        # nacos的服务地址，nacos-server中IP地址:端口号\n        server-addr: 172.16.1.84:8848,172.16.1.84:8849,172.16.1.84:8850\n\n\n\n\nNacos是CP还是AP\n\nCAP的概念\n一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）\n可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）\n分区容错性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。\n\n\n一般分布式系统都是先保证P，剩下的C和A的取舍，不同的注册中心遵循的CAP也是不同的\nZookeeper：保证CP，放弃可用性；一旦zookeeper集群中master节点宕了，则会重新选举leader，这个过程可能非常漫长，在这过程中服务不可用\nEureka：保证AP，放弃一致性；Eureka集群中的各个节点都是平等的，一旦某个节点宕了，其他节点正常服务（一旦客户端发现注册失败，则将会连接集群中其他节点），虽然保证了可用性，但是每个节点的数据可能不是最新的\nNacos：同时支持CP和AP，默认是AP，可以切换；AP模式下以临时实例注册，CP模式下服务永久实例注册\n\n\n\n\n\n\n\n3.OpenFeign\nWhat：\n\nFeign是一个声明式的Web服务客户端，它简化了使用基于HTTP的远程服务的开发。Feign是在RestTemplate 和 Ribbon的基础上进一步封装，使用RestTemplate实现Http调用（不必手动使用RestTemplate调服务，而是定义一个接口并标注注解即可），使用Ribbon实现负载均衡。但已经停止迭代\nOpenFeign是springcloud在Feign的基础上支持了SpringMVC的注解，如@RequestMapping等等。OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务\n\n\n特点：\n\n声明式API：Feign允许开发者使用简单的注解来定义和描述对远程服务的访问。通过使用注解，开发者可以轻松地指定URL、HTTP方法、请求参数、请求头等信息，使得远程调用变得非常直观和易于理解\n@FeignClient(name &#x3D; &quot;example&quot;, url &#x3D; &quot;&lt;https:&#x2F;&#x2F;api.example.com&gt;&quot;)\npublic interface ExampleService &#123;\n    @GetMapping(&quot;&#x2F;endpoint&quot;)\n    String getEndpointData();\n&#125;\n集成负载均衡：Feign集成了Ribbon负载均衡器，可以自动实现客户端的负载均衡。它可以根据服务名和可用实例进行动态路由，并分发请求到不同的服务实例上，提高系统的可用性和可伸缩性\n\n容错机制：Feign支持集成Hystrix容错框架，可以在调用远程服务时提供容错和断路器功能。当远程服务不可用或响应时间过长时，Feign可以快速失败并返回预设的响应结果，避免对整个系统造成级联故障\n\n\n\n相关问题\n\n为什么Feign第一次调用耗时很长：主要原因是由于Ribbon的懒加载机制，当第一次调用发生时，Feign会触发Ribbon的加载过程，包括从服务注册中心获取服务列表、建立连接池等操作，这个加载过程会增加首次调用的耗时。可以在应用启动时预热Feign客户端，自动触发一次无关紧要的调用，来提前加载Ribbon和其他相关组件。这样，就相当于提前进行了第一次调用。\nFeign怎么做负载均衡：在Feign中，负载均衡是通过集成Ribbon来实现的。Ribbon通过从服务注册中心获取可用服务列表，并通过负载均衡算法选择合适的服务实例进行请求转发，实现客户端的负载均衡。\n\n\nFeign和Dubbo对比\n\n\n\n\nFeign\nDubbo\n\n\n\n定义\nFeign是一个声明式的Web服务客户端，用于简化HTTP API的调用。\nDubbo是一个分布式服务框架，用于构建面向服务的微服务架构。\n\n\n通信方式\n基于HTTP协议，使用RESTful风格的接口进行定义和调用。\n基于RPC协议，支持多种序列化协议如gRPC、Hessian等。\n\n\n服务发现\n通常结合服务注册中心（如Eureka、Consul）进行服务发现和负载均衡。\n通过ZooKeeper、Nacos等进行服务注册和发现，并提供负载均衡功能。\n\n\n服务治理\n不直接提供服务治理功能，需要结合其他组件或框架进行服务治理。\n提供服务注册与发现、负载均衡、容错机制、服务降级等服务治理功能。\n\n\n跨语言性\n支持跨语言通信，可以使用HTTP作为通信协议实现不同语言之间的通信。\n支持跨语言通信，通过Dubbo的IDL生成不同语言的客户端和服务端代码。\n\n\n生态系统\n集成了Spring Cloud生态系统，与Spring Boot无缝集成。\n拥有完整的生态系统，包括注册中心、配置中心、监控中心等组件。\n\n\n适用场景\n适用于构建RESTful风格的微服务架构，特别适合基于HTTP的微服务调用。\n适用于构建面向服务的微服务架构，提供更全面的服务治理和容错机制。\n\n\n\n实践\n\nhttps://mp.weixin.qq.com/s/YJu2oN-qxtpShrmHlyrByw\n\n\n\n4.Seata\nCAP定理：指的是在一个分布式系统中，不可能同时满足以下三点\n\n一致性（Consistency）：指强一致性，在写操作完成后开始的任何读操作都必须返回该值，或者后续写操作的结果。也就是说，在一致性系统中，一旦客户端将值写入任何一台服务器并获得响应，那么之后client从其他任何服务器读取的都是刚写入的数据。一致性保证了不管向哪台服务器写入数据，其他的服务器能实时同步数据\n可用性（Availability）：可用性（高可用）是指：每次向未崩溃的节点发送请求，总能保证收到响应数据（允许不是最新数据）\n分区容忍性（Partition tolerance）：分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，也就是说，服务器A和B发送给对方的任何消息都是可以放弃的，也就是说A和B可能因为各种意外情况，导致无法成功进行同步，分布式系统要能容忍这种情况。除非整个网络环境都发生了故障。\n\n\nBASE理论：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性\n\nBA(Basic Available)基本可用：整个系统在某些不可抗力的情况下，仍然能够保证“可用性”，即一定时间内仍然能够返回一个明确的结果。这里是属于基本可用。基本可用和高可用的区别：\n“一定时间”可以适当延长 当举行大促（比如秒杀）时，响应时间可以适当延长\n给部分用户返回一个降级页面，给部分用户直接返回一个降级页面，从而缓解服务器压力。但要注意，返回降级页面仍然是返回明确结果。\n\n\nS(Soft State)柔性状态：称为柔性状态，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统不同节点的数据副本之间进行数据同步的过程存在延时。\nE(Eventual Consisstency)最终一致性：同一数据的不同副本的状态，可以不需要实时一致，但一定要保证经过一定时间后仍然是一致的。\n\n\n一致性分类\n\n强一致性：系统中的某个数据被成功更新后，后续任何对该数据的读取操作都将得到更新后的值。也称为：原子一致性（Atomic Consistency）、线性一致性（Linearizable Consistency）。简言之，在任意时刻，所有节点中的数据是一样的。例如，对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。\n弱一致性：**系统中的某个数据被更新后，后续对该数据的读取操作**可能**得到更新后的值，也可能是更改前的值。但即使过了不一致时间窗口**这段时间后，后续对该数据的读取也不一定是最新值。所以说，可以理解为数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。例如12306买火车票，虽然最后看到还剩下几张余票，但是只要选择购买就会提示没票了，这就是弱一致性。\n**最终一致性：**是弱一致性的**特殊**形式，存储系统保证在没有新的更新的条件下，最终所有的访问都是最后更新的值。不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。\n\n\n分布式事务解决方案\n\n2PC：二阶段提交协议（Two-phase Commit，即 2PC）是常用的分布式事务解决方案，即将事务的提交过程分为两个阶段来进行处理。保证了数据的强一致，但是性能不好，都宕机会一直阻塞下去，无法保证数据一致（都宕机则失败），实现复杂\n\n准备阶段（投票阶段）：由事务的协调者（发起者）发起询问参与者（执行者）是否可以提交事务，但是这一阶段并未提交事务\n协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待答复\n各参与者执行事务操作，将 undo 和 redo 信息记入事务日志中（但不提交事务）\n如参与者执行成功，给协调者反馈同意，否则反馈中止\n\n\n提交阶段：协调者发起正式提交事务的请求，当所有参与者都回复同意时，则意味着完成事务\n协调者节点向所有参与者节点发出正式提交(commit)的请求。\n参与者节点正式完成操作，并释放在整个事务期间内占用的资源。\n参与者节点向协调者节点发送ack完成消息。\n协调者节点收到所有参与者节点反馈的ack完成消息后，完成事务。\n\n\n回滚阶段：如果任意一个参与者节点在第一阶段返回的消息为终止，或者协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时，那么这个事务将会被回滚\n协调者节点向所有参与者节点发出回滚操作(rollback)的请求。\n参与者节点利用阶段1写入的undo信息执行回滚，并释放在整个事务期间内占用的资源。\n参与者节点向协调者节点发送ack回滚完成消息。\n协调者节点受到所有参与者节点反馈的ack回滚完成消息后，取消事务。\n\n\n\n\n3PC：三阶段提交协议，是二阶段提交协议的改进版本，主要有两个改动点，一是在协调者和参与者中都引入超时机制，二是在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。相对于2PC，降低了阻塞范围，避免了协调者单点宕机问题，但是仍有数据不一致问题\n\nCanCommit阶段：3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求（事务询问），参与者如果可以提交就返回Yes响应，否则返回No响应（响应反馈）。\nPreCommit阶段：协调者根据参与者的反应情况来决定是否可以进行事务的PreCommit操作。根据响应情况，有以下两种可能。\n假如所有参与者均反馈 yes，协调者预执行事务。\n发送预提交请求 ：协调者向参与者发送PreCommit请求，并进入准备阶段\n事务预提交 ：参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中（但不提交事务）\n响应反馈 ：如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。\n\n\n假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。\n发送中断请求 ：协调者向所有参与者发送abort请求。\n中断事务 ：参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。\n\n\n\n\ndoCommit阶段：该阶段进行真正的事务提交，也可以分为以下两种情况。进入阶段 3 后，无论是协调者出现问题，或者协调者与参与者网络出现问题，都会导致参与者无法接收到协调者发出的 do Commit 请求或 abort 请求。此时，参与者都会在等待超时之后，继续执行事务提交\n执行提交\n发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。\n事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。\n响应反馈 事务提交完之后，向协调者发送ack响应。\n完成事务 协调者接收到所有参与者的ack响应之后，完成事务。\n\n\n中断事务：任何一个参与者反馈 no，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务\n发送中断请求 如果协调者处于工作状态，向所有参与者发出 abort 请求\n事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。\n反馈结果 参与者完成事务回滚之后，向协调者反馈ACK消息\n中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。\n\n\n\n\n\n\nTCC（事务补偿）：TCC（Try Confirm Cancel）方案是一种应用层面侵入业务的两阶段提交。是目前最火的一种柔性事务方案，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。相对于传统事务机制，在性能上有很大提升，并且保证数据的最终一致性，解决了单点故障问题提高了可靠性，但是需要侵入业务代码，耦合度较高\n\n第一阶段：Try（尝试），主要是对业务系统做检测及资源预留 (加锁，锁住资源)\n第二阶段：本阶段根据第一阶段的结果，决定是执行confirm还是cancel，Confirm 和 Cancel 操作满足幂等性，如果 Confirm 或 Cancel 操作执行失败，将会不断重试直到执行完成\nConfirm（确认）：执行真正的业务（执行业务，释放锁），Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的\nCancle（取消）：是预留资源的取消（出问题，释放锁）\n\n\n\n\n本地消息表：最初是由 eBay 提出，核心思路是将分布式事务拆分成本地事务进行处理。通过在事务主动发起方额外新建事务消息表，事务发起方处理业务和记录事务消息在本地事务中完成，轮询事务消息表的数据发送事务消息，事务被动方基于消息中间件消费事务消息表中的事务。方案轻量易实现，占用系统资源\n\n处理步骤\n事务主动方在同一个本地事务中处理业务和写消息表操作\n事务主动方通过消息中间件，通知事务被动方处理事务通知事务待消息。消息中间件可以基于 Kafka、RocketMQ 消息队列，事务主动方主动写消息到消息队列，事务消费方消费并处理消息队列中的消息。\n事务被动方通过消息中间件，通知事务主动方事务已处理的消息。\n事务主动方接收中间件的消息，更新消息表的状态为已处理。\n\n\n容错处理\n当步骤一处理出错，由于还在事务主动方的本地事务中，直接回滚即可\n当步骤二、三处理出错，由于事务主动方本地保存了消息，只需要轮询消息重新通过消息中间件发送，事务被动方重新读取消息处理业务即可。\n如果是业务上处理失败，事务被动方可以发消息给事务主动方回滚事务\n如果事务被动方已经消费了消息，事务主动方需要回滚事务的话，需要发消息通知事务主动方进行回滚事务。\n\n\n\n\nMQ事务方案（可靠消息事务）：基于 MQ 的分布式事务方案其实是对本地消息表的封装，将本地消息表基于 MQ 内部，其他方面的协议基本与本地消息表一致。耦合度较低，但是一次消息需要两次网络请求(half 消息 + commit/rollback 消息)\n\n整体流程\n\n\n正常情况：事务主动方发消息\n\n\n步骤①：发送方向 MQ 服务端(MQ Server)发送 half 消息。\n步骤②：MQ Server 将消息持久化成功之后，向发送方 ack 确认消息已经发送成功。\n步骤③：发送方开始执行本地事务逻辑。\n步骤④：发送方根据本地事务执行结果向 MQ Server 提交二次确认（commit 或是 rollback）。\n步骤⑤：MQ Server 收到 commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 rollback 状态则删除半消息，订阅方将不会接受该消息。\n\n\n异常情况：事务主动方消息恢复\n\n\n步骤⑤：MQ Server 对该消息发起消息回查。\n步骤⑥：发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。\n步骤⑦：发送方根据检查得到的本地事务的最终状态再次提交二次确认。\n步骤⑧：MQ Server基于 commit/rollback 对消息进行投递或者删除。\n\n\n\n\nSaga 事务\n\n\n\nSeata支持哪些模式的分布式事务\n\nAT（Atomikos）模式：AT模式是Seata默认支持的模式，也是最常用的模式之一。在AT模式下，Seata通过在业务代码中嵌入事务上下文，实现对分布式事务的管理。Seata会拦截并解析业务代码中的SQL语句，通过对数据库连接进行拦截和代理，实现事务的管理和协调。\n\n\nTCC（Try-Confirm-Cancel）模式：TCC模式是一种基于补偿机制的分布式事务模式。在TCC模式中，业务逻辑需要实现Try、Confirm和Cancel三个阶段的操作。Seata通过调用业务代码中的Try、Confirm和Cancel方法，并在每个阶段记录相关的操作日志，来实现分布式事务的一致性。\n\n\nSAGA模式：SAGA模式是一种基于事件驱动的分布式事务模式。在SAGA模式中，每个服务都可以发布和订阅事件，通过事件的传递和处理来实现分布式事务的一致性。Seata提供了与SAGA模式兼容的Saga框架，用于管理和协调分布式事务的各个阶段。\n\n\nXA模式：XA模式是一种基于两阶段提交（Two-Phase Commit）协议的分布式事务模式。在XA模式中，Seata通过与数据库的XA事务协议进行交互，实现对分布式事务的管理和协调。XA模式需要数据库本身支持XA事务，并且需要在应用程序中配置相应的XA数据源。\n\n\n\n\nSeata实现原理\n\n核心组件\n事务协调器（Transaction Coordinator）：事务协调器负责协调和管理分布式事务的整个过程。它接收事务的开始和结束请求，并根据事务的状态进行协调和处理。事务协调器还负责记录和管理事务的全局事务 ID（Global Transaction ID）和分支事务 ID（Branch Transaction ID）。\n事务管理器（Transaction Manager）：事务管理器负责全局事务的管理和控制。它协调各个分支事务的提交或回滚，并保证分布式事务的一致性和隔离性。事务管理器还负责与事务协调器进行通信，并将事务的状态变更进行持久化。\n资源管理器（Resource Manager）：资源管理器负责管理和控制各个参与者（Participant）的事务操作。它与事务管理器进行通信，并根据事务管理器的指令执行相应的事务操作，包括提交和回滚。\n\n\n两阶段提交（Two-Phase Commit）协议\n一阶段：在事务提交的过程中，首先进行预提交阶段。事务协调器向各个资源管理器发送预提交请求，资源管理器执行相应的事务操作并返回执行结果。在此阶段，业务数据和回滚日志记录在同一个本地事务中提交，并释放本地锁和连接资源。\n二阶段：在预提交阶段成功后，进入真正的提交阶段。此阶段主要包括提交异步化和回滚反向补偿两个步骤：\n提交异步化：事务协调器发出真正的提交请求，各个资源管理器执行最终的提交操作。这个阶段的操作是非常快速的，以确保事务的提交效率。\n回滚反向补偿：如果在预提交阶段中有任何一个资源管理器返回失败结果，事务协调器发出回滚请求，各个资源管理器执行回滚操作，利用一阶段的回滚日志进行反向补偿。\n\n\n\n\n事务执行流程\n事务发起方（Transaction Starter）发起全局事务：事务发起方是指发起分布式事务的应用程序或服务。它向Seata的事务协调器发送全局事务的开始请求，生成全局事务ID（Global Transaction ID）。\n事务协调器创建全局事务记录：事务协调器接收到全局事务的开始请求后，会为该事务创建相应的全局事务记录，并生成分支事务ID（Branch Transaction ID）。\n分支事务注册：事务发起方将全局事务ID和分支事务ID发送给各个参与者（Participant），即资源管理器。参与者将分支事务ID注册到本地事务管理器，并将事务的执行结果反馈给事务协调器。\n执行业务逻辑：在分布式事务的上下文中，各个参与者执行各自的本地事务，即执行业务逻辑和数据库操作。\n预提交阶段：事务发起方向事务协调器发送预提交请求，事务协调器将预提交请求发送给各个参与者。\n执行本地事务确认：参与者接收到预提交请求后，执行本地事务的确认操作，并将本地事务的执行结果反馈给事务协调器。\n全局事务提交或回滚：事务协调器根据参与者反馈的结果进行判断，如果所有参与者的本地事务都执行成功，事务协调器发送真正的提交请求给参与者，参与者执行最终的提交操作；如果有任何一个参与者的本地事务执行失败，事务协调器发送回滚请求给参与者，参与者执行回滚操作。\n完成全局事务：事务协调器接收到参与者的提交或回滚结果后，根据结果更新全局事务的状态，并通知事务发起方全局事务的最终结果。\n\n\n全局事务ID和分支事务ID是怎么传递的？：全局事务ID和分支事务ID在分布式事务中通过上下文传递的方式进行传递。常见的传递方式包括参数传递、线程上下文传递和消息中间件传递。具体的传递方式可以根据业务场景和技术选型进行选择和调整。\nSeata的事务回滚是怎么实现的？Seata的事务回滚是通过回滚日志实现的。每个参与者在执行本地事务期间生成回滚日志，记录了对数据的修改操作。当需要回滚事务时，事务协调器向参与者发送回滚请求，参与者根据回滚日志中的信息执行撤销操作，将数据恢复到事务开始前的状态。回滚日志的管理和存储是Seata的核心机制，可以选择将日志存储在不同的介质中。通过回滚日志的持久化和恢复，Seata确保了事务的一致性和恢复性。\n\n\n\n5.Sleuth+Zipkin\n链路追踪：在微服务中，有的山下游可能有十几个服务，如果某一环出了问题，排查起来非常困难，所以，就需要进行链路追踪，来帮助排查问题。通过链路追踪，可以可视化地追踪请求从一个微服务到另一个微服务的调用情况。除了排查问题，链路追踪黑还可以帮助优化性能，可视化依赖关系、服务监控和告警。常见链路追踪技术如下：\n\nZipkin：Zipkin 是一个开源的分布式实时追踪系统，由 Twitter 开发并贡献给开源社区。Spring Cloud Sleuth 提供了与 Zipkin 的集成，可以通过在微服务中添加相应的依赖和配置，将追踪信息发送到 Zipkin 服务器，并通过 Zipkin UI 进行可视化展示和查询。\nJaeger：Jaeger 是 Uber 开源的分布式追踪系统，也被纳入了 CNCF（云原生计算基金会）的维护。通过使用 Spring Cloud Sleuth 和 Jaeger 客户端库，可以将追踪信息发送到 Jaeger 并进行可视化展示和查询。\nSkyWalking：Apache SkyWalking 是一款开源的应用性能监控与分析系统，提供了对 Java、.NET 和 Node.js 等语言的支持。它可以与 Spring Cloud Sleuth 集成，将追踪数据发送到 SkyWalking 服务器进行可视化展示和分析。\n\n\nSpring Cloud Sleuth实现了一种分布式的服务链路跟踪解决方案，通过使用Sleuth可以让我们快速定位某个服务的问题。简单来说，Sleuth相当于调用链监控工具的客户端，集成在各个微服务上，负责产生调用链监控数据。\n\nSpan：基本的工作单元，相当于链表中的一个节点，通过一个唯一ID标记它的开始、具体过程和结束。我们可以通过其中存储的开始和结束的时间戳来统计服务调用的耗时。除此之外还可以获取事件的名称、请求信息等。\nTrace：一系列的Span串联形成的一个树状结构，当请求到达系统的入口时就会创建一个唯一ID（traceId），唯一标识一条链路。这个traceId始终在服务之间传递，直到请求的返回，那么就可以使用这个traceId将整个请求串联起来，形成一条完整的链路。\nAnnotation：一些核心注解用来标注微服务调用之间的事件，重要的几个注解如下：\n**cs(Client Send)**：客户端发出请求，开始一个请求的生命周期\nsr（Server Received）：服务端接受请求并处理；sr-cs = 网络延迟 = 服务调用的时间\nss（Server Send）：服务端处理完毕准备发送到客户端；ss - sr = 服务器上的请求处理时间\ncr（Client Reveived）：客户端接受到服务端的响应，请求结束；cr - sr = 请求的总时间\n\n\n\n\nZipkin：Twitter 的一个开源项目，基于Google Dapper实现，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现\n\n架构图\n\n\n核心组件\n\nCollector：收集器组件，它主要用于处理从外部系统发送过来的跟踪信息，将这些信息转换为Zipkin内部处理的 Span 格式，以支持后续的存储、分析、展示等功能\nStorage：存储组件，它主要对处理收集器接收到的跟踪信息，默认会将这些信息存储在内存中，我们也可以修改此存储策略，通过使用其他存储组件将跟踪信息存储到数据库中\nRESTful API：API 组件，它主要用来提供外部访问接口。比如给客户端展示跟踪信息，或是外接系统访问以实现监控等\nUI：基于API组件实现的上层应用。通过UI组件用户可以方便而有直观地查询和分析跟踪信息\n\n\nzipkin分为服务端和客户端，服务端主要用来收集跟踪数据并且展示，客户端主要功能是发送给服务端，微服务的应用也就是客户端，这样一旦发生调用，就会触发监听器将sleuth日志数据传输给服务端\n\nzipKin的数据传输方式如何切换？：zipkin默认的传输方式是HTTP，但是这里存在一个问题，一旦传输过程中客户端和服务端断掉了，那么这条跟踪日志信息将会丢失。当然zipkin还支持MQ方式的传输，支持消息中间件有如下几种：ActiveMQ、RabbitMQ、Kafka，使用MQ方式传输不仅能够保证消息丢失的问题，还能提高传输效率，生产中推荐MQ传输方式。\n\nzipkin如何持久化？：zipkin的信息默认是存储在内存中，服务端一旦重启信息将会丢失，但是zipkin提供了可插拔式的存储。zipkin支持以下四种存储方式：内存：服务重启将会失效，不推荐；MySQL：数据量越大性能较低；Elasticsearch：主流的解决方案，推荐使用；Cassandra：技术太牛批，用的人少，自己选择，不过官方推荐\n\n\n\n\n6.Sentinel\nSentinel怎么实现限流的：Sentinel通过动态管理限流规则，根据定义的规则对请求进行限流控制。具体实现步骤如下\n\n定义资源：在Sentinel中，资源可以是URL、方法等，用于标识需要进行限流的请求。\n&#x2F;&#x2F; 原本的业务方法.\n@SentinelResource(blockHandler &#x3D; &quot;blockHandlerForGetUser&quot;)\npublic User getUserById(String id) &#123;\n    throw new RuntimeException(&quot;getUserById command failed&quot;);\n&#125;\n\n&#x2F;&#x2F; blockHandler 函数，原方法调用被限流&#x2F;降级&#x2F;系统保护的时候调用\npublic User blockHandlerForGetUser(String id, BlockException ex) &#123;\n    return new User(&quot;admin&quot;);\n&#125;\n配置限流规则：在Sentinel的配置文件中定义资源的限流规则。规则可以包括资源名称、限流阈值、限流模式（令牌桶或漏桶）等。\nprivate static void initFlowQpsRule() &#123;\n    List&lt;FlowRule&gt; rules &#x3D; new ArrayList&lt;&gt;();\n    FlowRule rule1 &#x3D; new FlowRule();\n    rule1.setResource(resource);\n    &#x2F;&#x2F; Set max qps to 20\n    rule1.setCount(20);\n    rule1.setGrade(RuleConstant.FLOW_GRADE_QPS);\n    rule1.setLimitApp(&quot;default&quot;);\n    rules.add(rule1);\n    FlowRuleManager.loadRules(rules);\n&#125;\n监控流量：Sentinel会监控每个资源的流量情况，包括请求的QPS（每秒请求数）、线程数、响应时间等。\n\n\n限流控制：当请求到达时，Sentinel会根据资源的限流规则判断是否需要进行限流控制。如果请求超过了限流阈值，则可以进行限制、拒绝或进行其他降级处理。\n\n\n\n\nSentinel采用的是什么限流算法：Sentinel使用滑动窗口限流算法来实现限流。滑动窗口限流算法是一种基于时间窗口的限流算法。它将一段时间划分为多个时间窗口，并在每个时间窗口内统计请求的数量。通过动态地调整时间窗口的大小和滑动步长，可以更精确地控制请求的通过速率。\n\nSentinel怎么实现集群限流：Sentinel利用了Token Server和Token Client的机制来实现集群限流。开启集群限流后，Client向Token Server发送请求，Token Server根据配置的规则决定是否限流。\n\n\n\n","slug":"Microservices","date":"2023-09-26T01:20:25.000Z","categories_index":"","tags_index":"","author_index":"Dajunnnnnn"},{"id":"0ca9a116507ce2deadb100db49d2064a","title":"Dubbo","content":"Dubbo\nRPC\n\nRPC（Remote Procedure Call）全称为远程过程调用，用于解决不同服务器之间两个方法的互相调用问题，并且通过网络编程来传递方法调用所需要的参数，通过RPC来简化底层网络编程（如TCP连接的建立）、规划化参数序列化反序列化等问题，使得这个过程就像调用本地方法一样简单\n\n概念\n\n客户端（服务消费端） ：调用远程方法的一端\n\n客户端 Stub（桩） ： 这其实就是一代理类。把要调用的方法、类、方法参数等信息传递到服务端（序列化成RpcRequest）\n\n网络传输 ： 网络传输就是把要调用的方法的信息（参数、方法名、类等）传输到服务端，然后服务端执行完之后再把返回结果通过网络传输给你传输回来。网络传输的实现方式有Socket编程、Netty等\n\n服务端 Stub（桩） ：接收到客户端执行方法的请求后（反序列化RpcRequest），去指定对应的方法然后返回结果给客户端的类（序列化成RpcResponse）\n\n服务端（服务提供端） ：提供远程方法的一端\n\n\n\n\n常见RPC框架\n\nDubbo：为大规模微服务实践提供高性能 RPC 通信、流量治理、可观测性等解决方案， 涵盖 Java、Golang 等多种语言 SDK 实现。提供了从服务定义、服务发现、服务通信到流量管控等几乎所有的服务治理能力，支持 Triple 协议（基于 HTTP/2 之上定义的下一代 RPC 通信协议）、应用级服务发现、Dubbo Mesh （Dubbo3 赋予了很多云原生友好的新特性）等特性\ngRPC：Google 开源的一个高性能、通用的开源 RPC 框架。主要面向移动应用开发并基于 HTTP/2 协议标准而设计（支持双向流、消息头压缩等功能，更加节省带宽），基于 ProtoBuf 序列化协议开发，并且支持众多开发语言\nProtoBuf：一种更加灵活、高效的数据格式，可用于通讯协议、数据存储等领域，基本支持所有主流编程语言且与平台无关，但是接口和数据类型的定义比较繁琐\n\n\nThrift：Facebook 开源的跨语言的 RPC 通信框架，具有跨语言特性（比 gRPC 支持的语言多）和出色的性能，可以基于 Thrift 研发一套分布式服务框架，增加诸如服务注册、服务发现等功能\n\n\n\n\n分布式\n\nWhat：把整个系统拆分成不同的服务然后将这些服务放在不同的服务器上减轻单体服务的压力提高并发量和性能，比如电商系统可以简单地拆分成订单系统、商品系统、登录系统等等，拆分之后的每个服务可以部署在不同的机器上，如果某一个服务的访问量比较大的话也可以将这个服务同时部署在多台机器上\nWhy：每个团队可以负责一个服务的开发，这样提升了开发效率。另外，代码根据业务拆分之后更加便于维护和扩展\n\n\nDubbo\n\nWhat\n\n\nWhy：分布式架构下，不同微服务之间需要互相调用，Dubbo主要解决这种情况下产生的诸多问题，如下\n\n负载均衡 ： 同一个服务部署在不同的机器时该调用哪一台机器上的服务\n服务调用链路生成 ： 随着系统的发展，服务越来越多，服务间依赖关系变得错踪复杂，通过Dubbo 可以了解服务之间互相是如何调用的及先后顺序如何\n服务访问压力以及时长统计、资源调度和治理 ：基于访问压力实时管理集群容量，提高集群利用率\n\n\n\n\nDubbo架构\n\n核心角色\n\nContainer： 服务运行容器，负责加载、运行服务提供者\n\nProvider： 暴露服务的服务提供方，会向注册中心注册自己提供的服务\n\nConsumer： 调用远程服务的服务消费方，会向注册中心订阅自己所需的服务\n\nRegistry：服务注册与发现的注册中心。注册中心会返回服务提供者地址列表给消费者，非必须\n\n注册中心和监控中心都宕机的话，服务会挂掉吗？：不会。两者都宕机也不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表。注册中心和监控中心都是可选的，服务消费者可以直连服务提供者\n\n\nMonitor： 统计服务的调用次数和调用时间的监控中心。服务消费者和提供者会定时发送统计数据到监控中心，非必须\n\n\n\n\nInvoker：Dubbo 对远程调用的抽象，主要分为服务提供Invoker和服务消费Invoker两种，用来封装使用动态代理来屏蔽远程调用的细节的相关代码\n\n\n架构层次\n\nconfig 配置层：Dubbo相关的配置。支持代码配置，同时也支持基于 Spring 来做配置，以 ServiceConfig, ReferenceConfig 为中心\n\nproxy 服务代理层：调用远程方法像调用本地的方法一样简单的一个关键，真实调用过程依赖代理类，以 ServiceProxy 为中心。\n\nregistry 注册中心层：封装服务地址的注册与发现\n\n注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互\n服务提供者宕机后，注册中心会立即推送事件通知消费者\n\n\ncluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心\n\nmonitor 监控层：RPC 调用次数和调用时间监控，以Statistics为中心\n\n监控中心负责统计各服务调用次数，调用时间等\n\n\nprotocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心\n\nexchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心\n\ntransport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心\n\nserialize 数据序列化层 ：对需要在网络传输的数据进行序列化\n\n\n\n\nSPI机制\n\nWha&amp;Why：SPI（Service Provider Interface） 机制被大量用在开源项目中，帮助动态寻找服务/功能（比如负载均衡策略）的实现\nHow：首先将接口的实现类放在配置文件中，在程序运行过程中读取配置文件，通过反射加载实现类。这样，就可以在运行的时候，动态替换接口的实现类。和 IoC 的解耦思想是类似的\nJava本身实现了SPI机制，但是Dubbo做了增强，并提供多种扩展机制，只需要实现接口或抽象类并且将新的实现类写入到配置文件中\n\n\n微内核架构\n\n微内核架构：微内核架构模式（有时被称为插件架构模式）是实现基于产品应用程序的一种自然模式。基于产品的应用程序是已经打包好并且拥有不同版本，可作为第三方插件下载的。然后，很多公司也在开发、发布自己内部商业应用像有版本号、说明及可加载插件式的应用软件（这也是这种模式的特征）。微内核系统可让用户添加额外的应用如插件，到核心应用，继而提供了可扩展性和功能分离的用法（《软件架构模式》）\n通常情况下，微核心都会采用 Factory、IoC、OSGi 等方式管理插件生命周期。Dubbo 不想依赖 Spring 等 IoC 容器，也不想自己造一个小的 IoC 容器（过度设计），因此采用了一种最简单的 Factory 方式管理插件 ：JDK 标准的 SPI 扩展机制 （java.util.ServiceLoader）\n\n\n\n\nDubbo负载均衡策略\n\n负载均衡：负载均衡改善了跨多个计算资源（例如计算机，计算机集群，网络链接，中央处理单元或磁盘驱动）的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间，并避免任何单个资源的过载。使用具有负载平衡而不是单个组件的多个组件可以通过冗余提高可靠性和可用性。负载平衡通常涉及专用软件或硬件\n\n负载均衡策略：默认是random，所有策略继承自AbstractLoadBalance，该类实现了LoadBalance接口，并封装了一些公共的逻辑\n\n****RandomLoadBalance（对加权随机）****：根据权重所占比例来平均划分，生成随机数来确定对应的区间\n\n代码\npublic class RandomLoadBalance extends AbstractLoadBalance &#123;\n\n    public static final String NAME &#x3D; &quot;random&quot;;\n\n    @Override\n    protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123;\n\n        int length &#x3D; invokers.size();\n        boolean sameWeight &#x3D; true;\n        int[] weights &#x3D; new int[length]; \n        int totalWeight &#x3D; 0;\n        &#x2F;&#x2F; 下面这个for循环的主要作用就是计算所有该服务的提供者的权重之和 totalWeight（），除此之外，还会检测每个服务提供者的权重是否相同\n        for (int i &#x3D; 0; i &lt; length; i++) &#123;\n            int weight &#x3D; getWeight(invokers.get(i), invocation);\n            totalWeight +&#x3D; weight;\n            weights[i] &#x3D; totalWeight; &#x2F;&#x2F;序列\n            if (sameWeight &amp;&amp; totalWeight !&#x3D; weight * (i + 1)) &#123;\n                sameWeight &#x3D; false;\n            &#125;\n        &#125;\n        if (totalWeight &gt; 0 &amp;&amp; !sameWeight) &#123;\n            &#x2F;&#x2F; 随机生成一个 [0, totalWeight) 区间内的数字\n            int offset &#x3D; ThreadLocalRandom.current().nextInt(totalWeight);\n            &#x2F;&#x2F; 判断会落在哪个服务提供者的区间\n            for (int i &#x3D; 0; i &lt; length; i++) &#123;\n                if (offset &lt; weights[i]) &#123;\n                    return invokers.get(i);\n                &#125;\n            &#125;\n  \n        return invokers.get(ThreadLocalRandom.current().nextInt(length));\n    &#125;\n\n&#125;\n\n\n****LeastActiveLoadBalance（最小活跃数）****：初始状态下所有服务提供者的活跃数均为 0（每个服务提供者的中特定方法都对应一个活跃数），每收到一个请求后，对应的服务提供者的活跃数 +1，当这个请求处理完之后，活跃数 -1。因此，Dubbo 就认为谁的活跃数越少，谁的处理速度就越快，性能也越好，这样的话，就优先把请求给活跃数少的服务提供者处理。活跃数是通过 RpcStatus 中的一个 ConcurrentMap 保存的\n\n代码\npublic class LeastActiveLoadBalance extends AbstractLoadBalance &#123;\n\n    public static final String NAME &#x3D; &quot;leastactive&quot;;\n\n    @Override\n    protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123;\n        int length &#x3D; invokers.size();\n        int leastActive &#x3D; -1;\n        int leastCount &#x3D; 0;\n        int[] leastIndexes &#x3D; new int[length];\n        int[] weights &#x3D; new int[length];\n        int totalWeight &#x3D; 0;\n        int firstWeight &#x3D; 0;\n        boolean sameWeight &#x3D; true;\n        &#x2F;&#x2F; 这个 for 循环的主要作用是遍历 invokers 列表，找出活跃数最小的 Invoker\n        &#x2F;&#x2F; 如果有多个 Invoker 具有相同的最小活跃数，还会记录下这些 Invoker 在 invokers 集合中的下标，并累加它们的权重，比较它们的权重值是否相等\n        for (int i &#x3D; 0; i &lt; length; i++) &#123;\n            Invoker&lt;T&gt; invoker &#x3D; invokers.get(i);\n            &#x2F;&#x2F; 获取 invoker 对应的活跃(active)数\n            int active &#x3D; RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive();\n            int afterWarmup &#x3D; getWeight(invoker, invocation);\n            weights[i] &#x3D; afterWarmup;\n            if (leastActive &#x3D;&#x3D; -1 || active &lt; leastActive) &#123;\n                leastActive &#x3D; active;\n                leastCount &#x3D; 1;\n                leastIndexes[0] &#x3D; i;\n                totalWeight &#x3D; afterWarmup;\n                firstWeight &#x3D; afterWarmup;\n                sameWeight &#x3D; true;\n            &#125; else if (active &#x3D;&#x3D; leastActive) &#123;\n                leastIndexes[leastCount++] &#x3D; i;\n                totalWeight +&#x3D; afterWarmup;\n                if (sameWeight &amp;&amp; afterWarmup !&#x3D; firstWeight) &#123;\n                    sameWeight &#x3D; false;\n                &#125;\n            &#125;\n        &#125;\n       &#x2F;&#x2F; 如果只有一个 Invoker 具有最小的活跃数，此时直接返回该 Invoker 即可\n        if (leastCount &#x3D;&#x3D; 1) &#123;\n            return invokers.get(leastIndexes[0]);\n        &#125;\n        &#x2F;&#x2F; 如果有多个 Invoker 具有相同的最小活跃数，但它们之间的权重不同\n        &#x2F;&#x2F; 这里的处理方式就和  RandomLoadBalance 一致了\n        if (!sameWeight &amp;&amp; totalWeight &gt; 0) &#123;\n            int offsetWeight &#x3D; ThreadLocalRandom.current().nextInt(totalWeight);\n            for (int i &#x3D; 0; i &lt; leastCount; i++) &#123;\n                int leastIndex &#x3D; leastIndexes[i];\n                offsetWeight -&#x3D; weights[leastIndex];\n                if (offsetWeight &lt; 0) &#123;\n                    return invokers.get(leastIndex);\n                &#125;\n            &#125;\n        &#125;\n        return invokers.get(leastIndexes[ThreadLocalRandom.current().nextInt(leastCount)]);\n    &#125;\n&#125;\n\n\n****ConsistentHashLoadBalance（一致性Hash）****：没有权重的概念，具体是哪个服务提供者处理请求是由你的请求的参数决定的，也就是说相同参数的请求总是发到同一个服务提供者，并且引入虚拟节点，通过虚拟节点可以让节点更加分散，有效均衡各个节点的请求量\n\n****RoundRobinLoadBalance（加权轮询）****：轮询就是把请求依次分配给每个服务提供者。加权轮询就是在轮询的基础上，让更多的请求落到权重更大的服务提供者上\n\n\n\n\n\nDubbo序列化协议\n\nDubbo 支持多种序列化方式：JDK自带的序列化、hessian2、JSON、Kryo、FST、Protostuff，ProtoBuf等等，其中默认使用的序列化方式是 hessian2\n优缺点：官方推荐使用Kryo\nJDK自带的序列化不支持跨语言调用、JSON性能差\n像 Protostuff，ProtoBuf、hessian2这些都是跨语言的序列化方式，如果有跨语言需求的话可以考虑使用\nKryo和FST这两种序列化方式是 Dubbo 后来才引入的，性能非常好。不过，这两者都是专门针对 Java 语言的\n\n\n\n\n\nZookeeper\nWhat：是一个开源的，是用于维护配置信息，命名，提供分布式同步和提供组服务的集中式服务，可以基于 Zookeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能，比如Dubbo和Kafka都通过Zookeeper作为注册中心，有以下特性\n\n顺序一致性：leader会根据请求顺序生成 ZXID 来严格保证请求顺序的下发执行\n\n识别请求的先后顺序：Leader 收到请求之后，会将每个请求分配一个全局唯一递增的事务ID：zxid，然后把请求放入到一个 FIFO 的队列中，之后就会按照 FIFO 的策略发送给所有的 Follower\n\n\n原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，要么成功，要么就失败\n\n单一视图：无论客户端连到哪一个 ZooKeeper 服务器上，看到的数据都是一致的\n\n数据不一致情况还是会有的，因为 Zookeeper 采用的是过半写机制，意味着3台服务器只要有两台写成功就代表整个集群写成功，如果刚好有请求打在这台还未写的服务器上就查询不到该数据，就会有数据不一致的情况产生\n\n\n可靠性：一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来\n\n实时性：Zookeeper 仅仅能保证在段时间内客户端最终一定能够从服务端上读取到最新的数据状态\n\n\n\n数据结构\n\nZooKeeper 提供的名称空间与标准文件系统的名称空间非常相似。名称是由斜杠（“ /”）分隔的一系列路径元素。ZooKeeper 命名空间中的每个 znode 均由路径标识。每个 znode 都有一个父对象，其路径是 znode 的前缀，元素少一个（ root（“ /”）例外）。此外，与标准文件系统完全一样，如果 znode 有子节点，则无法删除它\n\nZooKeeper 与标准文件系统之间的主要区别在于，每个 znode 都可以具有与之关联的数据（每个文件也可以是目录，反之亦然），并且 znode 限于它们可以拥有的数据量。ZooKeeper 旨在存储协调数据：状态信息，配置，位置信息等。这种元信息通常以千字节来度量，最大支持1M的内置完整性检查\n\n\n\nznode\n\nznode分类\n\n三种类型\n持久节点（persistent node）节点会被持久化\n临时节点（ephemeral node）客户端断开连接后，ZooKeeper 会自动删除临时节点\n顺序节点（sequential node）每次创建顺序节点时，ZooKeeper 都会在路径后面自动添加上10位的数字，从1开始，最大是2147483647 （2^32-1）\n\n\n四种形式\n持久节点：如 create /test/a “hello”，通过 create参数指定为持久节点\n持久顺序节点：通过 create -s参数指定为顺序节点\n临时节点：通过 create -e参数指定为顺序节点\n临时顺序节点：通过 create -s -e参数指定为临时及顺序节点\n\n\n\n\nznode内部结构：包括存储数据（data）、访问权限（acl）、子节点引用（child）、节点状态信息（stat）\n\ndata:：znode存储的业务数据信息\nacl:：记录客户端对znode节点的访问权限，如IP等\nchild:：当前节点的子节点引用\nstat:：包含Znode节点的状态信息，比如事务id、版本号、时间戳等等。\n\n\n\n\n系统架构\n\nZooKeeper 分为服务器端（Server） 和客户端（Client），客户端可以连接到整个 ZooKeeper 服务的任意服务器上（除非 leaderServes 参数被显式设置，leader 不允许接受客户端连接），客户端使用并维护一个 TCP 连接，通过这个连接发送请求、接受响应、获取观察的事件以及发送信息，其中服务器主要分为以下三种角色\n\nLeader：负责投票的发起与决议，更新系统状态，写数据\n\nFollower：用于接收客户端请求并用来返回结果，在选主过程中参与投票\n\nObserver：**可以接受客户端连接，将**写请求转发给leader**节点，但是不参与投票过程，只同步leader状态，主要存在目的就是为了提高读取效率**\n\n\n\n\n组成 ZooKeeper 服务的服务器必须彼此了解。它们维护一个内存中的状态图像，以及持久存储中的事务日志和快照，只要大多数服务器可用（总数为奇数，超过半数正常即可），ZooKeeper 服务就可用\n\n将 server 分为三种是为了避免太多的从节点参与过半写的过程，导致影响性能，如果要横向扩展的话，只需要增加 Observer 节点即可\nZooKeeper 启动时，将从实例中选举一个 leader，Leader 负责处理数据更新等操作，每个Server都存储一份数据，大多数Server更新成功后即认为更新成功\nZookeeper 的数据一致性是依靠ZAB协议完成的\n\n\n\n\nZAB协议\n\nZAB协议（ZooKeeper Atomic Broadcast 原子广播） ：是为 ZooKeeper 设计的一种支持崩溃恢复的原子广播协议。在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性，主要包括两种模式\n\n崩溃恢复：当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。剩下未同步完成的机器会继续同步，直到同步完成并加入集群后该节点的服务才可用\n\n消息广播：当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进人消息广播模式（Leader 服务器在负责进行消息广播）了。ZooKeeper 设计成只允许唯一的一个 Leader 服务器来进行事务请求的处理。Leader 服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非 Leader 服务器会首先将这个事务请求转发给 Leader服务器\n\n当一台同样遵守 ZAB 协议的服务器启动后加人到集群中时，那么新加人的服务器就会自觉地进人数据恢复模式，找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去\n\n\n\n\n如何选举Leader：两台以上ZK启动发起leader选举\n\n发起投票：每个 Server 发出一个投票。初始选举 ZK1 和 ZK2 都会将自己作为 Leader 服务器来进行投票，每次投票会包含所推举的服务器的(myid, ZXID)，此时 ZK1 的投票为(1, 0)，ZK2 的投票为(2, 0)，然后各自将这个投票发给集群中其他机器\n\n收到投票：集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自 LOOKING 状态的服务器\n\n处理投票：每个发起投票的服务器需要将别人的投票和自己的投票进行比较，规则如下:\n\n优先检查 ZXID：ZXID 比较大的服务器优先作为 Leader\n其次检查myid：如果 ZXID 相同：那么就比较 myid。myid 较大的服务器作为Leader服务器\n\n\n统计投票：每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接收到相同的投票信息，对于 ZK1、ZK2 而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出 ZK2 作为Leader\n\n改变服务器状态：一旦确定了 Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为 FOLLOWING，如果是 Leader，就变更为 LEADING。当新的 Zookeeper 节点 ZK3 启动时，发现已经有 Leader 了，不再选举，直接将直接的状态从 LOOKING 改为 FOLLOWING\n\n\n\nLeader挂了进入崩溃恢复如何选举Leader\n\n变更状态。Leader 挂后，余下的非 Observer 服务器都会将自己的服务器状态变更为 LOOKING，然后开始进入 Leader 选举过程\n其余与启动时过程相同：发起投票、收到投票、处理投票、统计投票、改变服务器的状态\n\n\nleader选举后如何同步数据\n\nZXID：写数据由leader负责，leader会给每个请求分配一个zxid，放入到队列中依次执行，leader会记录执行完的请求的zxid。将队列中的最大的 ZXID 称为 maxZXID，最小的 ZXID 称为 minZXID，将 Observer 和 follower 中最新的 ZXID 称为lastSyncZXID，将请求中的一些信息如请求头，请求体以及 ZXID 等信息封装到 proposal对象当中\n\n差异化同步（触发条件:minZXID &lt; lastSyncZXID &lt; maxZXID）\n\nleader 向 Observer 和 follower 发送 DIFF 指令，之后就开始差异化同步\n然后把差异数据 提议 proposal 发送给 Observer 和 follower , Observer 和 follower 返回ACK表示已经完成了同步\n只要集群中过半的 Observer 和 follower 响应了 ACK 就发送一个 UPTODATE 命令\nleader 返回 ACK，同步流程结束\n\n\n回滚同步（触发条件maxZXID &lt; lastSyncZXID）\n\n直接回滚到 maxZXID\n举个例子：a，b，c三台服务服务器 a是leader，此时队列里面最大的 ZXID 为100，a 收到请求，该 ZXID 为101，还没来得及发送同步数据 a 就挂了，b 变为leader，然后 a 恢复了，此时就需要 a 先将之前 ZXID 为101的数据回滚\n\n\n回滚+差异化同步（触发条件:如果Leader刚生成一个proposal，还没有来得及发送出去，此时Leader宕机，重新选举之后作为Follower，但是新的Leader没有这个proposal数据）\n\nObserver 和 follower 将数据回滚\n进行差异化同步\n举个例子：a，b，c三台服务服务器 a是leader，此时队列里面最大的 ZXID 为100，a 收到请求，该 ZXID 为101，还没来得及发送同步数据 a 就挂了，b 变为leader，b 又处理了3个请求，则 b 队列中最大的 ZXID 为103，然后 a 恢复了，此时就需要 a 先将之前 ZXID 为101的数据回滚，再进行同步\n\n\n全量同步（触发条件lastSyncZXID &lt; minZXID）\n\nLeader服务器上没有缓存队列，并且lastSyncZXID!=maxZXID\n同步过程：leader 向 Observer 和 follower 发送SNAP命令，进行数据全量同步\n\n\n\n\n\n\nWather监听机制\n\nWhat：client 会对某个 znode 注册一个 watcher 事件，当该 znode 发生变化时，这些 client 会收到 ZooKeeper 的通知\nHow\n服务注册：Provider 启动时，会向 zookeeper 服务端注册服务信息，也就是创建一个节点\n服务发现：Consumer 启动时，根据自身配置的依赖服务信息，向 zookeeper 服务端获取注册的服务信息并设置 watch 监听，获取到注册的服务信息之后，将服务提供者的信息缓存在本地，并进行服务的调用\n服务通知：一旦服务提供者因某种原因宕机不再提供服务之后，客户端与 zookeeper 服务端断开连接，zookeeper 服务端上服务提供者对应服务节点会被删除，随后 zookeeper 服务端会异步向所有注册了该服务，且设置了 watch 监听的服务消费者发出节点被删除的通知，消费者根据收到的通知拉取最新服务列表，更新本地缓存的服务列表\n\n\n特性\n一次性：一旦一个Wather触发之后，Zookeeper就会将它从存储中移除，如果还要继续监听这个节点，就需要我们在客户端的监听回调中，再次对节点的监听watch事件设置为True。否则客户端只能接收到一次该节点的变更通知\n客户端串行：客户端的Wather回调处理是串行同步的过程，不会因为一个Wather的逻辑阻塞整个客户端\n轻量：Wather通知的单位是WathedEvent，只包含通知状态、事件类型和节点路径，不包含具体的事件内容，具体的时间内容需要客户端主动去重新获取数据\n异步: Zookeeper服务器发送watcher的通知事件到客户端是异步的，不能期望能够监控到节点每次的变化，Zookeeper只能保证最终的一致性，而无法保证强一致性\n\n\n\n\n\nNetty\nNetty：基于NIO实现的高性能、异步事件驱动的网络编程框架，Dubbo和RocketMQ都基于Netty实现，其高性能体现在如下方面\n\n异步非阻塞 I/O 模型：Netty 使用基于NIO的异步非阻塞 I/O 模型，可以大大提高网络通信效率，减少线程的阻塞等待时间，从而提高应用程序的响应速度和吞吐量\n\n零拷贝技术：Netty 支持零拷贝技术，可以避免数据在内核和用户空间之间的多次复制，减少了数据拷贝的次数，从而提高了数据传输的效率和性能\n\n线程模型优化：Netty的线程模型非常灵活，可以根据不同的业务场景选择不同的线程模型。例如，对于低延迟和高吞吐量的场景，可以选择 Reactor线程模型，对于 I/O操作比较简单的场景，可以选择单线程模型\n\n\n\n内存池技术：Netty提供了一套基于内存池技术的 ByteBuf缓冲区，可以重用已经分配的内存空间，减少内存的分配和回收次数，提高内存使用效率\n\n堆内存：ByteBuf以普通的字节数组为基础，在 JVM堆上分配内存。这种方式适用于小型数据的传输，如传输的是文本、XML等数据\n\n采用了类似于JVM 的分代内存管理机制，将缓冲区分为三种类型：堆缓冲区、直接缓冲区、复合缓冲区。Netty 会根据不同的使用场景和内存需求来决定使用哪种类型的缓冲区，从而提高内存利用率\n直接内存：ByteBuf 使用操作系统的堆外内存，由操作系统分配和回收内存。这种方式适用于大型数据的传输，如传输的是音视频、大型图片等数据\n\n\n处理器链式调用：Netty 的 ChannelHandler 可以按照一定的顺序组成一个处理器链，当事件发生时，会按照处理器链的顺序依次调用处理器，从而实现对事件的处理。这种处理方式比传统的多线程处理方式更加高效，减少了线程上下文切换和锁竞争等问题\n\n\n\n核心组件\n\nChannel：用于网络通信的通道，可以理解为Java NIO中的SocketChannel\n\n每个Channel都与一个EventLoop关联，而一个EventLoop可以关联多个Channel，Channel上有事件发生（数据可读/可写）时，加入到EventLoop的任务队列，通过异步I/O和事件驱动的方式处理，保证在处理每个Channel的事件时不会被阻塞\n每个Channel都有一个与之关联的ChannelPipeline，用于处理该Channel上的事件和请求。ChannelPipeline是一种基于事件驱动的处理机制，它由多个处理器（Handler）组成，每个处理器负责处理一个或多个事件类型，将事件转换为下一个处理器所需的数据格式，直到到达最后一个处理器或者被中途拦截（异常）\n\n\nChannelFuture：异步操作的结果，可以添加监听器以便在操作完成时得到通知\n\nChannelFuture用于在异步操作完成后通知应用程序结果。在异步操作执行后，Netty将一个ChannelFuture对象返回给调用方。调用方可以通过添加一个回调（ChannelFutureListener）来处理结果\nChannelFuture还提供了许多有用的方法，如检查操作是否成功、等待操作完成、添加监听器等\n\n\nEventLoop：事件循环器，用于处理一个或多个Channel的I/O事件和请求，是一个不断循环的I/O线程。Netty的I/O操作都是异步非阻塞的，它们由EventLoop处理并以事件的方式触发回调函数\n\nEventLoopGroup：由一个或多个EventLoop组成的组，用于处理所有的Channel的I/O操作，可以将其看作是一个线程池\n\nChannelHandler：用于处理Channel上的I/O事件和请求（用于处理入站和出站数据流），包括编码、解码、业务逻辑等，为了将网络协议的细节与应用程序的逻辑分离开，可以理解为NIO中的ChannelHandler，通过实现ChannelHandler接口的以下方法来实现\n\nchannelRead(ChannelHandlerContext ctx, Object msg): 处理接收到的数据，这个方法通常会被用于解码数据并将其转换为实际的业务对象\nchannelReadComplete(ChannelHandlerContext ctx): 读取数据完成时被调用，可以用于向远程节点发送数据\nexceptionCaught(ChannelHandlerContext ctx, Throwable cause): 发生异常时被调用，可以在这个方法中处理异常或关闭连接\nchannelActive(ChannelHandlerContext ctx): 当连接建立时被调用\nchannelInactive(ChannelHandlerContext ctx): 当连接关闭时被调用\n\n\nChannelPipeline：由一组ChannelHandler组成的管道，用于处理Channel上的所有I/O 事件和请求，Netty中的数据处理通常是通过将一个数据包装成一个ByteBuf对象，并且通过一个 ChannelPipeline来传递处理，以达到业务逻辑与网络通信的解耦，工作方式如下：\n\n入站（Inbound）事件：由Channel接收到的事件，例如读取到新的数据、连接建立完成等等。入站事件将从ChannelPipeline的第一个InboundHandler开始流动，直到最后一个InboundHandler\n出站（Outbound）事件：由Channel发送出去的事件，例如向对端发送数据、关闭连接等等。出站事件将从ChannelPipeline的最后一个OutboundHandler开始流动，直到第一个OutboundHandler\nChannelHandlerContext：表示处理器和ChannelPipeline之间的关联关系。每个ChannelHandler都有一个ChannelHandlerContext，通过该对象可以实现在ChannelPipeline中的事件流中向前或向后传递事件，也可以通过该对象访问所属的Channel、所在的ChannelPipeline和其他ChannelHandler等。在处理I/O事件时，Netty会将I/O事件转发给与该事件相应的ChannelHandlerContext，该上下文对象可以使Handler访问与该事件相关的任何信息，也可以在管道中转发事件\n\n\nByteBuf：Netty提供的字节容器，可以对字节进行高效操作，包括读写、查找等，与 Java NIO 的 ByteBuffer 相比有以下优势\n\n容量可扩展：ByteBuf的容量可以动态扩展，而 ByteBuffer 的容量是固定的\n\n内存分配：ByteBuf 内部采用了内存池的方式，可以有效地减少内存分配和释放的开销\n\n读写操作：ByteBuf 提供了多个读写指针，可以方便地读写字节数据\n\n零拷贝：ByteBuf 支持零拷贝技术，可以减少数据复制的次数\n\n使用示例\nByteBuf buffer &#x3D; Unpooled.buffer(10);\nbuffer.writeBytes(&quot;hello&quot;.getBytes());\n\nwhile (buffer.isReadable()) &#123;\n  System.out.print((char) buffer.readByte());\n&#125;\n\n\nCodec：用于在ChannelPipeline中进行数据编码和解码的组件，如字符串编解码器、对象序列化编解码器等，将二进制数据与 Java 对象之间进行编码和解码的组件，常用的Codec如下\n\nByteToMessageCodec：将字节流解码为 Java 对象，同时也可以将 Java 对象编码为字节流。可以用于处理自定义协议的消息解析和封装。\nMessageToByteEncoder：将 Java 对象编码为字节流。通常用于发送消息时将消息转换为二进制数据。\nByteToMessageDecoder：将字节流解码为 Java 对象。通常用于接收到数据后进行解码。\nStringEncoder 和 StringDecoder：分别将字符串编码为字节流和将字节流解码为字符串。\nLengthFieldPrepender 和 LengthFieldBasedFrameDecoder：用于处理 TCP 粘包和拆包问题。\nObjectDecoder和ObjectEncoder：将Java对象序列化为字节数据，并将字节数据反序列化为Java对象。\n\n\n\n\n线程模型（基于事件驱动的Reactor模型）\n\nReactor模型\n\n单线程模型：所有IO操作都由同一个NIO线程处理，虽然这种方式并不适合高并发的场景，但是它具有简单、快速的优点，适用于处理I/O操作非常快速的场景，例如传输小文件等\n\n\n多线程模型：所有的I/O操作都由一组线程来执行，其中一个线程负责监听客户端的连接请求，其他NIO线程负责处理I/O操作。这种方式可以支持高并发，但是线程上下文切换的开销较大，适用于处理I/O操作较为耗时的场景\n\n\n主从多线程模型：，所有的I/O操作都由一组NIO线程来执行，其中一组NIO线程负责接受请求，一组NIO线程负责处理IO操作。这种方式将接受连接和处理I/O操作分开，避免了线程上下文切换的开销，同时又能支持高并发，适用于处理I/O操作耗时较长的场景\n\n\n\n\n为每个连接都分配了一个单独的EventLoop线程，负责处理所有与该连接相关的事件，包括数据传输、握手和关闭等。多个连接还可以共享同一个EventLoop线程，从而减少线程的创建和销毁开销，提高资源利用率\n\n可以使用不同的EventLoopGroup实现不同的线程模型，如单线程模型、多线程模型和主从线程模型等。同时，还可以设置不同的线程池参数，如线程数、任务队列大小、线程优先级等，以调整线程池的工作负载和性能表现\n\n单线程模型\n&#x2F;&#x2F;eventGroup 既负责处理客户端连接，又负责具体的处理\nEventLoopGroup eventGroup &#x3D; new NioEventLoopGroup(1);\n多线程模型\n&#x2F;&#x2F; bossGroup处理客户端连接, workerGroup负责具体的处理\nEventLoopGroup bossGroup &#x3D; new NioEventLoopGroup(1);\nEventLoopGroup workerGroup &#x3D; new NioEventLoopGroup();\n主从多线程模型\n&#x2F;&#x2F; bossGroup接收客户端连接, workerGroup负责具体的处理\nEventLoopGroup bossGroup &#x3D; new NioEventLoopGroup();\nEventLoopGroup workerGroup &#x3D; new NioEventLoopGroup();\n\n\n在实际使用中，还可以通过优化网络协议、数据结构、业务逻辑等方面来提高Netty的性能。例如，可以使用零拷贝技术避免数据拷贝，使用内存池减少内存分配和回收的开销，避免使用阻塞IO和同步操作等，从而提高应用的吞吐量和性能表现\n\n\n\n零拷贝\n\n可以避免在数据传输过程中对数据的多次拷贝操作，如数据在内核空间和用户空间之间的拷贝次数，从而提高数据传输的效率和性能\n实现：Netty 通过使用 Direct Memory 和 FileChannel 的方式实现零拷贝。当应用程序将数据写入 Channel 时，Netty 会将数据直接写入到内存缓冲区中，然后通过操作系统提供的 sendfile 或者 writev 等零拷贝技术，将数据从内存缓冲区中传输到网络中，从而避免了中间的多次拷贝操作\n\n\n客户端与服务端之间的网络连接机制\n\n长连接：通过 Channel 的 keepalive 选项来保持连接的状态。当启用了 keepalive 选项后，客户端和服务器之间的连接将会自动保持一段时间，如果在这段时间内没有数据交换，客户端和服务器之间的连接将会被关闭，通过以下四种方式来实现\n\n心跳机制：心跳机制可以通过定期向对方发送心跳消息，来检测连接是否正常。如果在一段时间内没有收到心跳消息，就认为连接已经断开，并进行重新连接。Netty提供了一个 IdleStateHandler类，可以用来实现心跳机制。IdleStateHandler可以设置多个超时时间，当连接空闲时间超过设定的时间时，会触发一个事件，可以在事件处理方法中进行相应的处理，比如发送心跳消息\n\n定义心跳消息的类型\npublic class HeartbeatMessage implements Serializable &#123;\n    &#x2F;&#x2F; ...\n&#125;\n在客户端和服务端的ChannelPipeline中添加IdleStateHandler，用于触发定时任务\npipeline.addLast(new IdleStateHandler(0, 0, 60, TimeUnit.SECONDS));\n在客户端和服务端的业务逻辑处理器中，重写userEventTriggered方法，在触发定时任务时发送心跳包\npublic class MyServerHandler extends SimpleChannelInboundHandler&lt;Object&gt; &#123;\n    @Override\n public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123;\n        if (evt instanceof IdleStateEvent) &#123;\n         IdleStateEvent event &#x3D; (IdleStateEvent) evt;\n            if (event.state() &#x3D;&#x3D; IdleState.READER_IDLE) &#123;\n             &#x2F;&#x2F; 读空闲，发送心跳包\n                ctx.writeAndFlush(new HeartbeatMessage());\n            &#125;\n        &#125; else &#123;\n            super.userEventTriggered(ctx, evt);\n        &#125;\n &#125;\n&#125;\n在客户端和服务端的业务逻辑处理器中，重写channelRead方法，接收并处理心跳包\n        public class MyClientHandler extends SimpleChannelInboundHandler&lt;Object&gt; &#123;\n            @Override\n               protected void channelRead0(ChannelHandlerContext ctx, Object msg) throws Exception &#123;\n                   if (msg instanceof HeartbeatMessage) &#123;\n                       &#x2F;&#x2F; 收到心跳包，不做处理\n                       return;\n                   &#125;\n                   &#x2F;&#x2F; 处理其他消息\n                   &#x2F;&#x2F; ...\n               &#125;\n           &#125;\n     \n   - **断线重连机制**：在网络不稳定的情况下，连接可能会不可避免地断开。为了避免因为网络异常导致应用程序不能正常工作，可以实现断线重连机制，定期检查连接状态，并在连接断开时尝试重新连接。&#96;Netty&#96;提供了&#96;ChannelFutureListener&#96;接口和&#96;ChannelFuture&#96;对象，可以方便地实现断线重连机制\n   \n   - **基于HTTP&#x2F;1.1协议的长连接**：&#96;HTTP&#x2F;1.1&#96;协议支持长连接，可以在一个&#96;TCP&#96;连接上多次发送请求和响应。在&#96;Netty&#96;中，可以使用&#96;HttpClientCodec&#96;和&#96;HttpObjectAggregator&#96;处理器，实现基于&#96;HTTP&#x2F;1.1&#96;协议的长连接\n   \n   - **WebSocket协议**：&#96;WebSocket&#96;协议也支持长连接，可以在一个&#96;TCP&#96;连接上双向通信，实现实时数据交换。在&#96;Netty&#96;中，可以使用&#96;WebSocketServerProtocolHandler&#96;和&#96;WebSocketClientProtocolHandler&#96;处理器，实现&#96;WebSocket&#96;协议的长连接\n   \n6. **服务端和客户端的启动过程**\n\n   1. 创建 &#96;EventLoopGroup&#96; 对象。&#96;EventLoopGroup&#96; 是&#96;Netty&#96;的核心组件之一，它用于管理和调度事件的处理。&#96;Netty&#96; 通过&#96;EventLoopGroup&#96;来创建多个&#96;EventLoop&#96;对象，并将每个 &#96;EventLoop&#96; 与一个线程绑定。在服务端中，一般会创建两个 &#96;EventLoopGroup&#96; 对象，分别用于接收客户端的连接请求和处理客户端的数据\n\n   2. 创建 &#96;ServerBootstrap&#96; 或 &#96;Bootstrap&#96; 对象。&#96;ServerBootstrap&#96; 和 &#96;Bootstrap&#96; 是 &#96;Netty&#96; 提供的服务端和客户端启动器，它们封装了启动过程中的各种参数和配置，方便使用者进行设置。在创建 &#96;ServerBootstrap&#96; 或 &#96;Bootstrap&#96; 对象时，需要指定相应的 &#96;EventLoopGroup&#96; 对象，并进行一些基本的配置，比如传输协议、端口号、处理器等\n\n      - Bootstrap是一个用于启动和配置Netty客户端和服务器的工具类。它提供了一组简单易用的方法，用于设置服务器或客户端的选项和属性，以及为ChannelPipeline配置handler，以处理传入或传出的数据，使得创建和配置Netty应用程序变得更加容易。主要有两个作用\n        - 作为&#96;Netty&#96;服务器启动的入口点：通过&#96;Bootstrap&#96;启动一个&#96;Netty&#96;服务器，可以在指定的端口上监听传入的连接，并且可以设置服务器的选项和属性\n        - 作为&#96;Netty&#96;客户端启动的入口点：通过&#96;Bootstrap&#96;启动一个&#96;Netty&#96;客户端，可以连接到远程服务器，并且可以设置客户端的选项和属性\n\n   3. 配置&#96;Channel&#96;的参数。&#96;Channel&#96; 是&#96;Netty&#96;中的一个抽象概念，它代表了一个网络连接。在启动过程中，需要对 &#96;Channel&#96; 的一些参数进行配置，比如传输协议、缓冲区大小、心跳检测等\n\n   4. 绑定 &#96;ChannelHandler&#96;。&#96;ChannelHandler&#96; 是 &#96;Netty&#96; 中用于处理事件的组件，它可以处理客户端的连接请求、接收客户端的数据、发送数据给客户端等。在启动过程中，需要将 &#96;ChannelHandler&#96; 绑定到相应的 &#96;Channel&#96; 上，以便处理相应的事件\n   \n   5. 启动服务端或客户端。在完成以上配置后，就可以启动服务端或客户端了。在启动过程中，会创建相应的 &#96;Channel&#96;，并对其进行一些基本的初始化，比如注册监听器、绑定端口等。启动完成后，就可以开始接收客户端的请求或向服务器发送数据了\n\n   6. 服务端代码\n\n      ![image-20230902110031766](https:&#x2F;&#x2F;macro---oss2.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;image-20230902110031766.png)\n   \n   7. 客户端代码\n\n      ![image-20230902110047958](https:&#x2F;&#x2F;macro---oss2.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;image-20230902110047958.png)\n\n7. IO模型（基于异步的NIO）：一个线程可以处理多个连接的读写事件，Netty的NIO与传统NIO相比有以下不同点\n\n   - &#96;Netty&#96;使用了&#96;Reactor&#96;模式，将&#96;IO&#96;事件分发给对应的&#96;Handler&#96;处理，使得应用程序可以更方便地处理网络事件\n   - &#96;Netty&#96;使用了多线程模型，将&#96;Handler&#96;的处理逻辑和&#96;IO&#96;线程分离，避免了&#96;IO&#96;线程被阻塞的情况\n   - &#96;Netty&#96;支持多种&#96;Channel&#96;类型，可以根据应用场景选择不同的&#96;Channel&#96;类型，如&#96;NIO、EPoll、OIO&#96;等\n\n8. **TCP粘包&#x2F;拆包：**在&#96;TCP&#96;传输过程中，由于&#96;TCP&#96;并不了解上层应用协议的消息边界，**会将多个小消息组合成一个大消息，或者将一个大消息拆分成多个小消息发送**\n\n   1. 解决方式一（**消息定长）**：将消息固定长度发送，例如每个消息都是固定的&#96;100&#96;字节。在接收端，根据固定长度对消息进行拆分\n\n      &#96;&#96;&#96;java\n      &#x2F;&#x2F; 编码器，将消息的长度固定为100字节\n      pipeline.addLast(&quot;frameEncoder&quot;, new LengthFieldPrepender(2));\n      pipeline.addLast(&quot;messageEncoder&quot;, new StringEncoder(CharsetUtil.UTF_8));\n      &#x2F;&#x2F; 解码器，根据固定长度对消息进行拆分\n      pipeline.addLast(&quot;frameDecoder&quot;, new LengthFieldBasedFrameDecoder(100, 0, 2, 0, 2));\n      pipeline.addLast(&quot;messageDecoder&quot;, new StringDecoder(CharsetUtil.UTF_8));\n\n\n\n\n解决方式二（消息分隔符）：将消息以特定的分隔符分隔开，例如以”\\\\r\\\\n“作为分隔符。在接收端，根据分隔符对消息进行拆分\n&#x2F;&#x2F; 编码器，以&quot;\\\\r\\\\n&quot;作为消息分隔符\npipeline.addLast(&quot;frameEncoder&quot;, new DelimiterBasedFrameEncoder(&quot;\\\\r\\\\n&quot;));\npipeline.addLast(&quot;messageEncoder&quot;, new StringEncoder(CharsetUtil.UTF_8));\n&#x2F;&#x2F; 解码器，根据&quot;\\\\r\\\\n&quot;对消息进行拆分\npipeline.addLast(&quot;frameDecoder&quot;, new DelimiterBasedFrameDecoder(1024, Delimiters.lineDelimiter()));\npipeline.addLast(&quot;messageDecoder&quot;, new StringDecoder(CharsetUtil.UTF_8));\n解决方式三（消息头部加长度字段）：在消息的头部加上表示消息长度的字段，在发送端发送消息时先发送消息长度，再发送消息内容。在接收端，先读取消息头部的长度字段，再根据长度读取消息内容\n&#x2F;&#x2F; 编码器，将消息的长度加入消息头部\npipeline.addLast(&quot;frameEncoder&quot;, new LengthFieldPrepender(2));\npipeline.addLast(&quot;messageEncoder&quot;, new StringEncoder(CharsetUtil.UTF_8));\n&#x2F;&#x2F; 解码器，先读取消息头部的长度字段，再根据长度读取消息内容\npipeline.addLast(&quot;frameDecoder&quot;, new LengthFieldBasedFrameDecoder(1024, 0, 2, 0, 2));\npipeline.addLast(&quot;messageDecoder&quot;, new StringDecoder(CharsetUtil.UTF_8));\n\n\n常用Handler\n\n实现WebSocket协议：WebSocketServerProtocolHandler 是一个 ChannelHandler，可以将 HTTP 升级为 WebSocket 并处理 WebSocket 帧\n大文件传输：ChunkedWriteHandler是一个编码器，可以将大文件切分成多个Chunk，并将它们以ChunkedData的形式写入管道，这样就可以避免一次性将整个文件读入内存，降低内存占用\nSSL/TLS加密传输：通过 SSLHandler来进行处理。通常情况下，SSLHandler 需要在 ChannelPipeline 中作为最后一个handler添加\n\n\nNetty和Tomcat的区别\n\n底层网络通信模型不同：Tomcat 是基于阻塞的 BIO（Blocking I/O）模型实现的，而 Netty 是基于 NIO（Non-Blocking I/O）模型实现的\n线程模型不同：Tomcat 使用传统的多线程模型，每个请求都会分配一个线程，而 Netty 使用 EventLoop 线程模型，每个 EventLoop 负责处理多个连接，通过线程池管理 EventLoop\n协议支持不同：Tomcat 内置支持 HTTP 和 HTTPS 协议，而 Netty 不仅支持 HTTP 和 HTTPS 协议，还支持 TCP、UDP 和 WebSocket 等多种协议\n代码复杂度不同：由于Tomcat支持的功能比较全面，所以其代码相对较为复杂，而 Netty 的代码相对比较简洁、精简\n应用场景不同：Tomcat适合于处理比较传统的 Web 应用程序，如传统的 MVC 模式Web应用程序；而 Netty更适合于高性能、低延迟的网络应用程序，如游戏服务器、即时通讯服务器等\n\n\n为什么不直接用NIO：NIO编程复杂、不能简单的解决断点重连、包丢失、粘包等问题\n\nNetty自带编码、解码器用来解决粘包、拆包问题\n自带各种协议栈，支持多种协议，如FTP、HTTP、SSL/TLS以及二进制和基于文本的传统协议\n比直接用Java的核心API有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制\n\n\n\n","slug":"Dubbo","date":"2023-09-02T02:38:57.000Z","categories_index":"","tags_index":"","author_index":"Dajunnnnnn"},{"id":"f8ef4e10e9f952ff4ed3590ecc45cea3","title":"MQ","content":"MQ\n\n\n\n\n\n\n\n\n中间件（Middleware）：是一类提供系统软件和应用软件之间连接、便于软件各部件之间的沟通的软件，应用软件可以借助中间件在不同的技术架构之间共享信息与资源。常用中间件有消息队列、RPC 框架、分布式组件（分布式事务、分布式Session、分布式Id）、HTTP 服务器（Tomcat、Nginx）、缓存服务、任务调度框架（xxl-job）、配置中心、数据库层的分库分表和数据迁移工具\n1.MQ基础\n消息队列的优缺点\n\n优点\n异步处理\n减少响应时间：虽然可以减少处理时间，但是需要业务配合，在数据校验并写入数据库后才能返回业务处理成功的消息\n降低系统耦合：生产者（客户端）发送消息到消息队列中去，接受者（服务端）处理消息，需要消费的系统直接去消息队列取消息进行消费即可而不需要和其他系统有耦合\n\n\n流量削峰：先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉\n\n\n缺点\n系统可用性降低： 需要额外考虑消息丢失或MQ宕机的情况\n系统复杂性提高： 需要保证消息无重复消费、无丢失、消息传递的顺序合理\n一致性问题： 如果消费者并没有正确消费消息就会导致数据不一致的情况\n\n\n\n\nJMS和AMQP\n\nJMS：Java消息队列服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输，JMS API 是一个消息服务的标准或者说是规范\n消息类型：StreamMessage（Java 原始值的数据流）、MapMessage（键-值对）、TextMessage（字符串对象）、ObjectMessage（一个序列化的 Java 对象）、BytesMessage（一个字节的数据流）\n消息模型：点到点（P2P）模型、发布/订阅（Pub/Sub）模型\n应用：ActiveMQ\n\n\nAMQP：高级消息队列协议（Advanced Message Queuing Protocol）是一个提供统一消息服务的应用层标准，兼容JMS，仅支持byte[]（二进制）消息类型\n消息类型：direct exchange；fanout exchange；topic change；headers exchange；system exchange（本质来讲，后四种和 JMS 的 pub/sub 模型没有太大差别，仅是在路由机制上做了更详细的划分）\n应用：RabbitMQ\n\n\n\n\nRPC与MQ的区别\n\n从用途来看：RPC将调用远程服务方法简化成调用本地方法，MQ主要用来降低系统耦合性、实现任务异步、有效地进行流量削峰\n从通信方式来看：RPC 是双向直接网络通讯，MQ是单向引入中间载体的网络通讯\n从架构上来看：MQ需要把消息存储起来，RPC 则没有这个要求\n从请求处理的时效性来看：通过 RPC 发出的调用一般会立即被处理，存放在MQ中的消息并不一定会立即被处理\n\n\n消息模型\n\n生产者-消费者模型与发布订阅模型：生产者-消费者模型适用于单消费者的环境，当有多个消费者的时候就会产生消费者的竞争关系，所以出现了发布订阅模型，发布者将消息发送到主题（Topic，即消息容器）中，然后订阅该主题的订阅者就可以收到发送者发送的消息了\n\nRabbitMQ消息模型：RabbitMQ新增了一个交换器组件（主要有4种），生产者发送消息的时候会指定一个 RoutingKey ,当 RoutingKey 和 BindingKey一样的时候就会被发送的对应的队列中去\n\n\nKafka消息模型\n\n\n\n\n技术选型\n\n按照不同的业务诉求进行选择，如消息挤压、消费重试、延迟消息、顺序消息、消息归档、预发消息等场景\n\n\n\n\n\nKafka\nRabbitMQ\nRocketMQ\n\n\n\n资料文档\n中等\n多\n少\n\n\n开发语言\nScala\nErlang\nJava\n\n\n支持的协议\n自定义（基于TCP）\nAMQP\n自定义\n\n\n消息存储\n内存、磁盘、数据库；支持大量堆积\n内存、磁盘；支持少量堆积\n磁盘；支持大量堆积\n\n\n消息事务\n支持\n支持\n支持\n\n\n负载均衡\n支持\n支持的不好\n支持\n\n\n集群方式\n天然的‘Leader-Slave’无状态集群\n支持简单集群 对高级集群模式支持不好\n常用 多对’Master-Slave’ 模式\n\n\n管理界面\n一般\n好\n有管理后台\n\n\n可用性\n非常高（分布式）\n高（主从）\n非常高（分布式）\n\n\n消息重复\n支持at least once、at most once\n支持at least once、at most once\n支持at least once\n\n\n吞吐量TPS\n极大\n比较大\n大\n\n\n订阅形式和消息分发\n发布订阅模式\ndirect、topic、Headers和fanout\n发布订阅模式\n\n\n顺序消息\n支持\n不支持\n支持\n\n\n消息确认\n支持\n支持\n支持\n\n\n消息回溯\n支持指定分区offset位置的回溯\n不支持\n支持指定时间点的回溯\n\n\n消息重试\n不支持\n不支持\n支持\n\n\n并发度\n并发度高\n并发度极高\n并发度高\n\n\n\n\n2.Kafka\n\n\n\n\n\n\n\n\nLinkedIn 开源的一个分布式流式处理平台，已经成为 Apache 顶级项目，早期被用来用于处理海量的日志，后面才慢慢发展成了一款功能全面的高性能消息队列\n\n基础\n\n优势：极致的性能（每秒处理千万级别的消息）、生态系统兼容性（大数据和流计算）\n主要功能：消息队列（发布和订阅消息流）、容错的持久方式存储记录消息流（把消息持久化到磁盘）、流式处理平台（流式处理类库，在消息发布的时候进行处理）\n架构模式：Kafka 是一个分布式系统，由通过高性能 TCP 网络协议进行通信的服务器和客户端组成，可以部署在在本地和云环境中的裸机硬件、虚拟机和容器上\n重大改进：在 Kafka 2.8 之前，Kafka 最被大家诟病的就是其重度依赖于 Zookeeper 做元数据管理和集群的高可用。在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构\n\n\n消息模型\n\n最开始使用的是队列模型：一对一模式，生产者需要知道具体消费者个数然后去复制对应数量的消息队列，但是违背了解耦这一原则\n\n\n发布-订阅模型：使用主题（Topic） 作为消息通信载体，类似于广播模式。发布者发布一条消息，该消息通过主题传递给所有的订阅者（广播后订阅的用户收不到该条消息）\n\n名词：Producer（生产者）、Consumer（消费者）\n\nBroker（代理） ：可以看做一个独立的Kafka实例，多个可以组成Kafka Cluster\nTopic（主题）：Producer 将消息发送到特定的Topic(主题)，Consumer 通过订阅特定的 Topic(主题) 来消费消息\nPartition（分区）：Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker\n\n\n模型图\n\n\n\n\n\n\n多副本机制\n\nPartition中的多个副本之间有一个leader、和若干follower。发送的消息会被发送到leader，然后follower才从leader中拉去信息进行同步\nproducer和consumer只与leader交互，其它follower只是leader的拷贝，follower的存在只是为了保证消息存储的安全性，在旧leader宕机时被选举为新leader（与leader同步程度达不到要求的无法参加leader的竞选）\n优势：一个Topic可以有多个Partition，各个Partition可以分布在不同的Broker上（并发能力），每个Partition可以指定对应的Replica数（容灾能力）\n\n\n消息的顺序性保证\n\nPartition内部有序保证：消息存储在Topic的Partition中，每次消息添加都会使用尾加法，所以Kafka可以保证Partition内部的消息有序\n消息参数：Kafka 中发送 1 条消息的时候，可以指定 topic、partition、key、data 4 个参数\nPartition外部顺序保证：1个 Topic 只对应1个 Partition；或者发送消息的时候指定 key/Partition（同一个key的消息可以保证只发送到同一个 partition）\n\n\n保证信息不丢失：增加异步的回调方法感知消息是否丢失、利用Producer的重试机制\n\nKafka防止消息丢失的方式\n\n消息持久化：Kafka将消息持久化到磁盘，确保消息的可靠性和持久性。在消息写入磁盘之前会先写入缓存中，如果有故障，可以从缓存或磁盘中恢复数据避免消息的丢失。另外可以创建一个单独的Task表，表中专门写MQ消息记录，用于发送失败重试等，这样可以统一管理\n\n同步副本机制：Kafka基于分布式的同步副本机制，能够通过给每个副本分配分区的方式来防止消息丢失。这种方式可以避免某个分区的副本所在的节点宕机或者网络故障等情况，还能够确保消费者所有副本都被读取到，从而避免消息的丢失\n\nReplication factor：在Kafka集群中，可以配置副本的数量。如果要求高可靠性，可以提高副本数量，这样即使某个Broker出现故障，也可以使用其他Broker上的副本进行恢复，从而避免消息丢失\n\n消费者接收确认（consumer ACKs）：消费者可以通过在读取完消息后发送反馈确认信息，告诉Kafka消息已经被成功读取。如果消费者没有确认信息，则在消息超时后，Kafka将重新推送一次消息给消费者。这种方式可以防止消息在消费者读取之前被错误地删除\n\n日志压缩：Kafka支持对日志进行压缩操作，可以节省磁盘空间并提高处理性能，同时也可以防止消息丢失\n\n\n\n解决\n\n异步回调方法\nListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future &#x3D; \n  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tkafkaTemplate.send(topic, o);\nfuture.addCallback(\n  result -&gt; logger.info(&quot;生产者成功发送消息到topic:&#123;&#125; partition:&#123;&#125;的消息&quot;, \n  result.getRecordMetadata().topic(),       \t  \t\n  result.getRecordMetadata().partition()),\n  ex -&gt; logger.error(&quot;生产者发送消失败，原因：&#123;&#125;&quot;,\n  ex.getMessage())\n); \n\n\n\n\n重试机制；为 Producer 的retries（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次 3 次一下子就重试完了\n补偿消息\n数据库记录MQ状态，所有超时n分钟的消息将状态更改为发送失败状态，基于落库记录添加worker扫描补偿MQ消息，对于库存扣减的MQ也可以通过二次记录缓存，worker定时批量更新数据库，避免较高MQ给数据库带来压力\n具体SQL语句：使用set value = value - 1而不是set value = xxx，后续的MQ会把库存更新的更小；或者使用set value = xxx where value &gt; xxx，只有更新的值比原有的值小，才更新，否则不更新，防止MQ是乱序消费的\n\n\n\n\n\n3.RocketMQ\n\n\n\n\n\n\n\n\nalibaba开源的一款云原生“消息、事件、流”实时数据处理平台，借鉴了 Kafka，已经成为 Apache 顶级项目。\n\n基础\n\n在传统的分布式计算环境中，常常会出现由于某个单机节点的性能瓶颈，消息队列本质上是提供了一种非常合理的任务分配策略，通过将任务分给消费者实现异步和分布式处理，提高整个集群的性能\n消息队列有着经典的三大应用场景：解耦（消息订阅）、异步（流程耗时）和削峰填谷（流量激增）\n核心特性：云原生（K8s 友好）、高吞吐（万亿级吞吐保证）、流处理（提供轻量、高扩展、高性能和丰富功能的流计算引擎）、金融级稳定性、架构极简（零外部依赖，Shared-nothing 架构）、生态友好\n\n\n消息模型\n\nNameServer（注册中心）：Broker将自己的信息注册到NameServer中，消费者和生产者通过查询NameServer获取Broker信息（定期更新），并与对应的Broker进行通信\n\n在每个NameServer节点内部都维护着所有 Broker 的地址列表，所有 Topic 和 Topic 对应 Queue 的信息等\n路由信息管理：通过去中心化的方式进行集群部署，单个 Broker 和所有 NameServer 保持长连接 ，并且在每隔 30 秒 Broker 会向所有 Nameserver 发送心跳，心跳包含了自身的 Topic 配置信息\n\n\nTopic （主题）：代表一类消息，比如订单消息，物流消息等等\n\n主题中存在多个队列（提高并发能力），生产者每次生产消息之后是指定主题中的某个队列发送消息的\n一个队列只会被一个消费组的一个消费者消费，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费\n不同消费组可以同时消费同一个队列中的消息，只需要每个消费组在每个队列上维护一个消费位置，用来记录消费过的信息，消费完后不删除消息\n\n\nBroker（消息队列服务器）：负责消息的存储、投递和查询，保证服务的高可用，生产者生产消息并传送到Broker，消费者从Broker拉去消息并消费\n\n一个Topic分布在多个Broker上，一个Broker可以配置多个Topic，是多对多的关系\n\n提供了主从部署模式，slave定期从master同步数据（同步刷盘或异步刷盘），如果master宕机，则slave提供消费服务，但是不能写入消息\n\n在 master 宕机时，同步副本集中的其余节点会自动选举出新的 master 代替工作（==Raft 协议==）\nBroker 默认采用的是==同步双写==的方式，消息写入 master 成功后，master 会等待 slave 同步数据成功后才向 Producer 返回成功 ACK ，即 Master 与 Slave 都要写入成功后才会返回成功 ACK\nbroker 节点可以按照处理的数据相同划分成副本组，同一组 master 和 slave 的关系可以通过指定相同 brokerName，不同的 ==brokerId== 来定义，brokerId 为 0 标识 master，非 0 是 slave\n\n\n每个broker服务器会与每一个NameServer服务器建立长连接，并注册topic信息到NameServer中\n\n\n\nProducer Group （生产者组）：代表某一类的生产者，比如我们有多个秒杀系统作为生产者，这多个合在一起就是一个 Producer Group 生产者组，它们一般生产相同的消息\n\nProducer支持分布式集群方式部署，与NameServer随机一个节点建立长连接，定时从NameServer获取topic路由信息，与master broker建立长连接，定时发送心跳，不与slave建立连接\nProducer需要向Broker发送消息的时候，需要先从NameServer获取关于Broker的路由信息，然后通过轮询的方式向每个队列中生产数据（负载均衡）\n查询本地缓存是否存储了 TopicPublishInfo ，否则从 NameServer 获取\n根据负载均衡选择策略获取待发送队列并轮训访问\n获取消息队列对应的 broker 实际 IP\n设置消息 Unique ID ，zip 压缩消息\n消息校验（长度等），发送消息\n\n\n消息发送时如果出现失败，默认会重试 2 次，在重试时会尽量避开刚刚接收失败的 Broker，而是选择其它 Broker 上的队列进行发送，从而提高消息发送的成功率\n\n\nConsumer Group （消费者组）：代表某一类的消费者，比如我们有多个短信系统作为消费者，这多个合在一起就是一个 Consumer Group 消费者组，它们一般消费相同的消息\n\nConsumer支持分布式集群方式部署，支持push推、pull拉两种模式对消息进行消费，同时也支持集群方式和广播方式的消费，提供了实时订阅机制\n广播消费：Producer 向一些队列轮流发送消息，队列集合称为 Topic，每一个 Consumer 实例消费这个 Topic 对应的所有队列\n集群消费：多个 Consumer 实例平均消费这个 Topic 对应的队列集合\n广播模式下一条消息会发送给同一消费组的所有消费者；集群模式下只会发送给一个消费者\n\n\nConsumer通过NameServer获取所有Broker的路由信息后，向Broker发送pull请求来获取消息\n集群模式下有一点需要注意：消费队列负载机制遵循一个通用的思想，一个消息队列同时只允许被一个消费者消费，一个消费者可以消费多个消费队列。因此当 Consumer 的数量大于队列的数量，会有部分 Consumer 分配不到队列，这些分配不到队列的 Consumer 机器不会有消息到达\n\n\n\n\n\n相关问题\n\n消息顺序：通过Hash取模将需要有序的消息发送到同一个队列中\n\n重复消费\n\n出现的时机\n发送时消息重复【消息 Message ID 不同】：MQ Producer 发送消息时，消息已成功发送到服务端并完成持久化，此时网络闪断或者客户端宕机导致服务端应答给客户端失败。如果此时 MQ Producer 意识到消息发送失败并尝试再次发送消息，MQ 消费者后续会收到两条内容相同但是 Message ID 不同的消息\n投递时消息重复【消息 Message ID 相同】：MQ Consumer 消费消息场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。为了保证消息至少被消费一次，MQ 服务端将在网络恢复后再次尝试投递之前已被处理过的消息，MQ 消费者后续会收到两条内容相同并且 Message ID 也相同的消息\n\n\n解决办法\n写入Redis：因为Redis的key和value天然支持幂等\n插入MySQL：通过数据库的唯一键来保证重复数据不会被插入多条\n\n\n\n\n消息丢失：RocketMQ避免消息丢失的机制主要包括重试、冗余消息存储。在生产者的消息投递失败时，默认会重试两次。消费者消费失败时，广播模式下，消费失败仅返回 ConsumeConcurrentlyStatus.RECONSUME_LATER ，而不会重试。在未指定顺序消息的集群模式下，消费失败的消息会进入重试队列自动重试，默认最大重试次数为 16 。在顺序消费的集群模式下，消费失败会使得当前队列暂停消费，并重试到成功为止\n\n消息堆积：限流降级、检查是否消费者出现了大量的消费错误、增加消费者实例的同时增加每个主题的队列数量（因为消费者和队列一一对应）\n\n消息回溯（Consumer重新消费已消费成功的消息）：因为在RocketMQ中，已经消费过的消息仍然需要保留，支持按照时间回溯消费，并且时间维度精确到毫秒\n\n消费失败：当出现消费失败的消息时，Broker 会为每个消费者组设置一个重试队列。当一条消息初次消费失败，消息队列会自动进行消费重试。达到最大重试次数后，若消费仍然失败，此时会将该消息发送到死信队列。对于死信消息，通常需要开发人员进行手动处理\n\n\n\n消息链路\n\nproducer 指定 broker 和 queue 发送消息 msg \nbroker 接收消息，并完成缓存、刷盘和生成摘要（同时根据 tag 和 user properties 对 msg 进行打标）等操作\nconsumer 每隔一段时间（ pullInterval ）从 broker 端的（根据服务端消息过滤模式 tag 或 sql 过滤后）获取一定量的消息到本地消息队列中（单线程）\nconsumer 按照配置并发分配上述队列消息并执行消费方法；\nconsumer 返回 broker 消费结果并重置消费位点；\n\n\n消息种类\n\n普通消息：可选择同步、异步或单向发送\n\n同步：Producer 发出一条消息后，会在收到 MQ 返回的 ACK 之后再发送下一条消息\n异步：Producer 发出消息后无需等待 MQ 返回 ACK ，直接发送下一条消息\n单向： Producer 仅负责发送消息，不等待，MQ 也不返回 ACK\n\n\n顺序消息：只支持同一个queue的顺序消息，且同一个queue只能被一台机器的一个线程消费，如果想要支持全局消息，那需要将该 topic 的 queue 的数量设置为 1，牺牲了可用性\n\n全局顺序：对于指定的一个 Topic ，所有消息按照严格的先入先出的顺序进行发布和消费 （同一个 queue）\n分区顺序：对于一个指定的 Topic ，所有消息根据 sharding key 进行分区，同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费，分区之间彼此独立\n\n\n消息事务：事务消息加上事务反查机制\n\n\n发送方向 MQ 服务端发送消息\nMQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功，此时消息为半消息\n发送方开始执行本地事务逻辑\n发送方根据本地事务执行结果向 MQ Server 提交二次确认（Commit 或是 Rollback），MQ Server 收到 Commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 Rollback 状态则删除半消息，订阅方将不会接受该消息\n在断网或者是应用重启的特殊情况下，上一步骤中提交的二次确认最终未到达 MQ Server，经过固定时间后 MQ Server 将对该消息发起消息回查\n反查机制：如果消息是 half 消息，将备份原消息的主题与消息消费队列，然后改变主题为 RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费 half 类型的消息，然后 RocketMQ 会开启一个定时任务，从 Topic 为 RMQ_SYS_TRANS_HALF_TOPIC 中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息\n\n\n发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果\n发送方根据检查得到的本地事务的最终状态再次提交二次确认，MQ Server 仍按照步骤 4 对半消息进行操作\n\n\n\n\n刷盘机制\n\n同步刷盘和异步刷盘（设置 Broker 的参数 FlushDiskType 为ASYNC_FLUSH 或SYNC_FLUSH）\n\n同步刷盘对 MQ 消息可靠性来说是一种不错的保障，但是 性能上会有较大影响 ，一般地适用于金融等特定业务场景\n\n异步刷盘往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟 ，提高了MQ的性能和吞吐量，一般适用于发验证码等对于消息保证要求不太高的业务场景，只有在 Broker 意外宕机的时候会丢失部分数据\n\n\n\n同步复制和异步复制：同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的 Borker 主从模式下，主节点返回消息给客户端的时候是否需要同步从节点\n\n同步复制：也叫 “同步双写”，也就是说，只有消息同步双写到主从节点上时才返回写入成功\n异步复制：消息写入主节点之后就直接返回写入成功 ，主节点挂掉后，消费者可以自动切换到从节点进行消费（仅消费，不只是生产）\n主节点同步消息到从节点过程中，如果主节点宕机，就会少一部分消息，可以切换到从节点进行消费（仅能消费），但是会出现短暂的消息不一致的情况，在主节点重启后，会继续复制中断未复制的消息\n\n\n\n\n存储机制：消息存储在生产者和消费者之间的一个消息代理（Message Broker）上\n\n不同的消息存储方式对比\n\nAcviveMQ使用队列表来存储消息，依靠轮训和加锁的方式检查和处理信息，QPS高的时候会导致B+树索引层级深，影响查询效率\nKV数据库使用LSM树作为索引结构，对读性能有较大牺牲，消息队列常常会因为失败重试，所以不适合\n﻿RocketMQ/Kafka/RabbitMQ 等消息队列会采用顺序写的日志结构，将消息刷盘至文件系统作持久化。顺序写日志文件可以避免频繁的随机访问而导致的性能问题，而且利于延迟写入等优化手段，能够快速保存日志\n\n\nCommitLog：消息主体以及元数据的存储主体，存储 Producer 端写入的消息主体内容，消息内容不是定长的。\n\n单个文件大小默认 1G ，文件名长度为 20 位，左边补零，剩余为起始偏移量，比如 00000000000000000000 代表了第一个文件，起始偏移量为 0，文件大小为 1G=1073741824；当第一个文件写满了，第二个文件为 00000000001073741824，起始偏移量为 1073741824，以此类推\n\n\n消息主要是顺序写入日志文件，当文件满了，写入下一个文件\n\n内存映射机制：CommitLog 文件要设计成固定大小的长度\n\n\n\nConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能\n\n由于RocketMQ 是基于主题 Topic 的订阅模式，消息消费是针对主题进行的，如果要遍历 commitlog 文件中根据 Topic 检索消息是非常低效的。Consumer 即可根据 ConsumeQueue 来查找待消费的消息，RocketMQ会启动一个ReputMessageService每隔1ms生成一次Consume queue和其它索引文件\n\nConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定 Topic 下的队列消息在 CommitLog 中的起始物理偏移量 offset ，消息大小 size 和消息 Tag 的 HashCode 值。ConsumeQueue 文件可以看成是基于 topic 的 commitlog 索引文件\n\nconsumequeue 文件夹的组织方式如下：topic/queue/file 三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样 consumequeue 文件采取定长设计，每一个条目共 20 个字节，分别为 8 字节的 commitlog 物理偏移量、4 字节的消息长度、8 字节 tag hashcode，单个文件由 30W 个条目组成，可以像数组一样随机访问每一个条目，每个 ConsumeQueue文件大小约 5.72M；\n\n\n\n\nIndexFile：IndexFile（索引文件）提供了一种可以通过 key 或时间区间来查询消息的方法\n\n查找时，可以根据消息的 key 计算 hash 槽的位置，hash 槽中存储着 Index 条目的位置，可以根据这个 index 条目获得一个链表（尾），每个 index 条目包含在 CommitLog 上的消息主体的物理偏移量\n\n\n\nRocketMQ与Kafka对比\n\nRocketMQ 采用的是 混合型的存储结构 ，即为 Broker 单个实例下所有的队列共用一个日志数据文件来存储消息\n\n\nKafka 会为每个 topic (事件的组织和存储单位，一个 topic 可以对应多个生产者和多个消费者) 划分出一个分区日志，便于根据 topic 顺序消费，消息被读取后不会立刻删除，可以持久存储，但 topic 数量增加的时候，broker 的分区文件数量增大，会使得本来速度很快的顺序写变成随机写（不同文件之间移动），性能大幅下降。\n\nRocketMQ不分 Topic 意味着有更大的几率获取 成批 的消息进行数据写入，但也会带来一个麻烦就是读取消息的时候需要遍历整个大文件，这是非常耗时的，所以，在RocketMQ中又使用了ConsumeQueue作为每个队列的索引文件来提升读取消息的效率。可以直接根据队列的消息序号，计算出索引的全局位置（索引序号*索引固定⻓度 20），然后直接读取这条索引，再根据索引中记录的消息的全局位置，找到消息\n\n\n\n\n\n\n\n\n\n4.RabbitMQ\n\n\n\n\n\n\n\n\n采用 Erlang 语言实现 AMQP(Advanced Message Queuing Protocol，高级消息队列协议）的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息\n\n架构模型\n\nProducer(生产者) 、Consumer(消费者) \n\n**Exchange(交换器)**：RabbitMQ收到的消息首先会经过Exchange，由Exchange决定消息被分配到哪个对应的Queue中，如果路由失败则会返回给Producer或者直接丢弃\n\nExchange有4种不同的类型并分别对应四种不同的路由策略（direct、fanout、topic、headers）\ndirect（默认）：把消息路由到那些 BindingKey 与 RoutingKey 完全匹配的 Queue 中，常用在处理有优先级的任务，给优先级高的任务分配更多的资源\nfanout：把所有发送到该Exchange的消息路由到所有与他绑定的Queue中，不做任何判断，处理速度最快，常用来广播消息\ntopic：扩展了direct类型，将BindingKey和RoutingKey规定为”.”分割的字符串，并提供“*”（1个）和“#”（0个或多个）用作模糊匹配\nheaders（不推荐）：根据发送的消息内容中的headers属性进行匹配，性能很差\n\n\nRoutingKey(路由键)：生产者将消息发给交换器的时候，会指定一个RoutingKey，用来指定这个消息的路由规则（RoutingKey需要结合Exchange类型和BindingKey来使用）\n**BindingKey(绑定建)**：通过BindingKey来将Exchange和Queue关联起来，当BindingKey与RoutindKey相匹配时，消息会被路由到对应的队列中（需要交换器类型支持此机制）\n\n\n**Queue(消息队列)**：用来保存消息直到发送给消费者，一个消息可投入一个或多个队列，并且一直保存在队列里面等待消费者取走，多个消费者可以订阅同一个队列（使用轮询方式平分，每个消费者一个，避免重复消费）\n\nBroker（消息中间件的服务节点）：RabbitMQ服务节点或者服务实例，可以看作一台RabbitMQ服务器\n\n模型架构图示例：\n\n\n\n\n消息传输方式：\n\nTCP与信道：由于 TCP 链接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈，所以 RabbitMQ 使用信道的方式来传输数据\n信道（Channel）：生产者、消费者与 RabbitMQ 通信的渠道，建立在 TCP 链接上的虚拟链接，且每条 TCP 链接上的信道数量没有限制。可以在一条 TCP 链接上建立成百上千个信道来达到多个线程处理，这个 TCP 被多个线程共享，每个信道在 RabbitMQ 都有唯一的 ID，保证了信道私有性，每个信道对应一个线程使用\n\n\n部署方式\n\n单机模式：Demo 级别\n普通集群模式：在每台机器上启动1个RabbitMQ实例，创建的Queue只会放在一个RabbitMQ实例上，但是每个实例都同步Queue的元数据用于查找每个Queue所在实例。消费的时候，如果连接到了另外一个实例，则此实例会从Queue所在实例拉去数据过来，使用多个节点进行读写操作，提高吞吐量\n镜像集群模式：高可用模式，创建的Queue无论元数据还是Queue里的消息都会存在多个实例上，每个RabbitMQ节点都有这个Queue的一个完整镜像。每次写信息到Queue中，都会自动把消息同步到多个实例的Queue上，可以通过管理控制台指定要求数据同步到所有节点或者同步到指定数量的节点。当任何一个机器宕机了，Consumer还可以去其它节点上消费数据，但是性能开销很大，导致网络带宽压力很重\n\n\n进阶使用\n\n死信队列：DLX，全称为Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列\n\n产生的原因：消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false；消息 TTL 过期；队列满了无法再添加\n\n\n延迟队列：存储对应的延迟消息，消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费，有以下两种实现方式\n\n使用 RabbitMQ 的死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）\n在 RabbitMQ 3.5.7 及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能（插件依赖 Erlang/OPT 18.0 及以上）\n\n\n优先级队列：通过x-max-priority参数来实现优先级队列。不过，当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义\n\n\n\n消息相关问题\n\n消息的可靠性：\n\n生产者到 RabbitMQ：事务机制和 Confirm 机制（两者是互斥的）\nRabbitMQ 自身：持久化、集群、普通模式、镜像模式\nRabbitMQ 到消费者：basicAck 机制、死信队列、消息补偿机制\n\n\n消息顺序性：\n\n拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点\n或者一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理\n\n\n消息队列的延时以及过期失效：设置过期时间、临时丢失后续批量重新导入\n\n\n\n\n5.MQ进阶\n为什么使用消息队列：结合自己的系统里类似的场景来叙述，一个模块调用了多个模块\n\n解耦：多个下游系统使用一个核心系统的数据时，使用消息队列可以在增减下游系统时不用更改核心系统的代码，直接消费消息队列里的A输入的数据\n异步：核心系统调用不同存储系统存储数据时，不用等待存储操作完成，可以将数据输入到消息队列中，然后直接返回响应，由消息队列与存储系统继续协调\n削峰：MySQL最多响应2k个请求，可以把过多的请求存储在消息队列中，然后MySQL每秒拉去2k个请求，防止MySQL因为请求过多而崩溃\n\n\n如何保证消息队列组件的高可用\n\nRabbitMQ：镜像集群模式（高可用性）\n无论是元数据还是queue里的消息都会存放在多个实例上并且都是完整镜像， 每次写消息到queue的时候，都会自动把消息同步到多个实例的queue上\n通过后台的管理控制台，新增一个策略（镜像集群模式），指定的时候可以要求数据同步到所有节点，也可以要求同步到指定数量的节点，再次创建queue的时候就会自动将数据同步到其他节点上\n缺点：通信的性能开销很大；扩展性不好，对于负载大的queue新的机器也会包含这个queue的所有数据，没办法平衡负载\n\n\nKafka：由多个broker组成，每个broker是一个节点；每创建一个topic，这个topic可以被划分为多个partition，每个partition可以存在于不同的broker上，每个partition存放一部分数据\nKafka0.8之后的HA机制：每个partition的数据都会同步到其它机器上，形成自己的repllica副本，所有replica副本会选举出一个leader出来，其它replica就是follower，所有生产者和消费者都跟这个leader交互。不能随意读写每个follower，因为需要保证数据一致性问题，但是Kafka会均匀地将一个partition的所有replica分布在不同的机器上，提高容错性\n写的时候，leader会负责把数据同步到所有follower上（leader直接写盘，然后其它follower主动从follower来pull数据，同步好数据后向leader发送ack，leader收到所有follower的ack后返回写成功的消息给生产者）；读的时候直接读leader上的数据（当leader读取到所有follower的ack后才会向消费者返回消息）\n如果某个broker宕机了，此时会从follower中重新选举一个新的leader出来\n\n\n\n\n消息的重复消费问题（幂等）\n\n问题示例：Kafka使用offset来表示当前consumer消费完的消息的序号，consumer会定期提交自己消费过的offset，保证重启的时候会从上次消费到的offset来继续消费，但是异常宕机时会丢失这一段时间消费了但未提交offset的消息消费记录，导致重启的时候会再次消费一次，如果下游系统没有考虑到重复消费问题就无法保证幂等姓，导致数据出错\n\n保证幂等性的方法（结合业务）\n\n写入有主键的数据库（MySQL）时，可以先根据主键查询一下，如果数据都有了就不insert而是进行update\n\n写Redis时，因为每次都是set，有天然的幂等性\n\n向队列中的每条信息加一个全局唯一的id，在收到信息后，先查询是否消费过再决定是否处理\n\n将 enable.auto.commit参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：什么时候提交 offset 合适？\n\n处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样\n拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底\n\n\n使用Redis缓存MQ的消费记录（记录12h），消费前如果缓存没有记录，可以查询数据库，消费后进行缓存记录，对于金融、订单、支付等场景，必须使用数据库防重字段做强一致性拦截处理（双重保证）\n\n\n\n\n\n消息的丢失问题\n\nRabbitMQ\n\n生产者：事务机制（吞吐量会下降）、confirm模式（队列处理了会返回ack，否则调用nack接口的回调函数告知失败），前者是同步的后者是异步的，并且两种模式并不共存\n\nconfirm实现代码，一共三种：普通、批量、异步\n&#x2F;&#x2F;普通confirm\nchannel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\nif (!channel.waitForConfirms()) &#123;\n    &#x2F;&#x2F; 消息发送失败\n    &#x2F;&#x2F; ...\n&#125;\n&#x2F;&#x2F;批量confirm\nchannel.confirmSelect();\nfor (int i &#x3D; 0; i &lt; batchCount; ++i) &#123;\n    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\n&#125;\nif (!channel.waitForConfirms()) &#123;\n    &#x2F;&#x2F; 消息发送失败\n    &#x2F;&#x2F; ...\n&#125;\n&#x2F;&#x2F;异步confirm\nSortedSet&lt;Long&gt; confirmSet &#x3D; Collections.synchronizedSortedSet(new TreeSet&lt;Long&gt;());\nchannel.confirmSelect();\nchannel.addConfirmListener(new ConfirmListener() &#123;\n    public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123;\n        if (multiple) &#123;\n            confirmSet.headSet(deliveryTag + 1).clear();\n        &#125; else &#123;\n            confirmSet.remove(deliveryTag);\n        &#125;\n    &#125;\n\n    public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123;\n        System.out.println(&quot;Nack, SeqNo: &quot; + deliveryTag + &quot;, multiple: &quot; + multiple);\n        if (multiple) &#123;\n            confirmSet.headSet(deliveryTag + 1).clear();\n        &#125; else &#123;\n            confirmSet.remove(deliveryTag);\n        &#125;\n    &#125;\n&#125;);\n\nwhile (true) &#123;\n    long nextSeqNo &#x3D; channel.getNextPublishSeqNo();\n    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\n    confirmSet.add(nextSeqNo);\n&#125;\n\n\n消息队列：开启Rabbit的持久化（也会有小概率丢失，还没持久化到磁盘上消息就丢失了），首先在创建queue时将其设置为持久化，保证RabbitMQ持久化queue的元数据；然后在发送消息的时候将消息的deliveryMode设置为2，保证消息也被持久化到磁盘上\n\n消费者：关闭RabbitMQ的自动ack，在消费者消费完消息后再通过api来返回ack。消费者在声明队列时可以指定noAck参数，当noAck=false时，RabbitMQ 会等待消费者显式发回 ack 信号后，才从内存（和磁盘，如果是持久化消息）中移去消息。否则，一旦消息被消费者消费，RabbitMQ 会在队列中立即删除它\n\n\n\nKafka\n\n消费者：可能因为自动提及offset机制提前提交了还未处理的消息的offset，所以可以关闭自动提交机制；但如果提交offset前系统崩溃会导致重复消费，则可以通过幂等性相关的方法来处理\n消息队列：某个broker宕机会重新选举partition的leader，新旧leader会有数据处理不一致的情况，造成数据丢失。可以设置如下四个参数来解决，保证leader切换时数据不会丢失\n给 topic 设置 replication.factor 参数：这个值必须大于 3，要求每个 partition 必须有至少 2 个副本\n在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower，一般推荐设置成 replication.factor = min.insync.replicas + 1\n在 producer 端设置 acks=all ：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了\n在 producer 端设置 retries=MAX （很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。\n\n\n生产者：设置了acks=all后，一定不会丢失，因为所有follower都确定收到了消息\n\n\n\n\n消息的顺序性\n\nRabbitMQ\n数据错乱的场景：一个queue多个consumer时，不同consumer同时消费有顺序的消息，无法保证哪个consumer先执行完成\n解决：拆分多个queue，每个queue一个consumer，会造成吞吐量下降\n\n\nKafka\n数据错乱的场景：一个topic和三个partition时，生产者写的时候可以指定一个key，相同key的数据会被分到同一个partition中，并且是有序的；但是当消费者是多线程的模式来并发处理消息时，消费消息的顺序就无法保证了\n解决：写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。\n\n\n\n\n消息积压\n\n大量消息在 mq 里积压了几个小时了还没解决（紧急扩容）\n先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉\n新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量\n然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue\n接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据\n等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息\n\n\nmq 中的消息过期失效了\n直接丢弃数据，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了\n\n\nmq 都快写满了\n如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧\n\n\n\n\n消费失败\n\n原因：消息被拒绝后并且消息没有重新入队、消息超时未消费、达到最大队列长度\nRabbitMQ：当普通队列中有死信时，RabbitMQ就会自动将这个消息重新发不到设置的死信交换机去，然后被路由到死信队列，可以监听死信队列中的消息做相应的处理\nKafka：\nKafka提供了一种称为“消费组”的机制来处理消息的消费，每个消费者组都有一个唯一的组ID，Kafka会将一个主题下的消息分发给该主题的每个消费组（每个消费组对应一个消费组内的多个消费者）中的一个消费者进行消费，这样每个消费组内的所有消费者都会收到相同主题下的全部信息\n在消费组中，只有一个消费者能消费同一分区的消息，如果消费者在消费消息是失败，Kafka会将该分区的消息再次分配给同一组中的其它消费者。这样的机制保证了消息的可靠性和可重试性\n除了重试，Kafka还提供了一些其它的机制来处理信息消费失败的情况。例如，可以开启自动提交消费进度或手动提交消费进度，这样在消费者再次运行时，可以从上次消费的进度开始继续消费。另外，Kafka也有死信队列，可以将消费失败的信息发送到专门的队列中进行处理，避免消息的丢失\n\n\n\n\n怎么解决消息队列上的消息堆压？\n\n自身场景下，消息堆压是暂时的，消息堆压只是突发状况，就算不额外处理，随着时间流逝也可消费完毕。 \n假如存在持续性消息堆压，可以考虑临时增加消费者的数量，提升消费者的消费能力。 \n如果是线上突发问题，要临时扩容，增加消费端的数量，与此同时，降级一些非核心的业务。通过扩容和降级承担流量，这是为了表明你对应急问题的处理能力。其次，才是排查解决异常问题，如通过监控，日志等手段分析是否消费端的业务逻辑代码出现了问题，优化消费端的业务处理逻辑。\n\n\n\n","slug":"MQ","date":"2023-08-07T05:45:26.000Z","categories_index":"","tags_index":"","author_index":"Dajunnnnnn"},{"id":"f00c07cb09e8c5144602456ae7f0f75a","title":"Internet","content":"Internet1.网络层\nIP\n\n查看IP地址：ifconfig、ip addr\n\nscope：如果是global，则此张网卡是可以对外开放的，可以接受各个地方的包；对于lo来说事host，说明这张网卡仅仅可以供本机相互通信\n\nlo全称是loopback，又称环回接口，往往会被分配到127.0.0.1这个地址，用于本机通信，经过内核处理后直接返回，不会再任何网络中出现。\n\nMAC地址：在 IP 地址的上一行是 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff，这个被称为 MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示。因为MAC没有定位功能，所以需要IP地址来寻路\n\n\n网络设备的状态标识（net_device flags）：例如&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; ，UP 表示网卡处于启动的状态；BROADCAST 表示这个网卡有广播地址，可以发送广播包；MULTICAST 表示网卡可以发送多播包；LOWER_UP 表示 L1 是启动的，也即网线插着呢。MTU1500 是指最大传输单元 MTU 为 1500，这是以太网的默认值。\n\n排队规则（qdisc pfifo_fast）：qdisc 全称是 queueing discipline，中文叫排队规则。内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的 qdisc（排队规则）把数据包加入队列。最简单的 qdisc 是 pfifo，它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。pfifo_fast 稍微复杂一些，它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。\n\n\n\nIP地址分类方式（ 无类型域间选路（CIDR）：10.100.122.2/24 ，网络号+主机号组成，通过与掩码进行与运算来求值）\n\nA类地址：1.0.0.0 到126.0.0.0（私有地址10.0.0.0～10.255.255.255）\nB类地址：128.0.0.0到191.255.255.255（私有地址172.16.0.0～172.31.255.255）\nC类地址：192.0.0.0到223.255.255.255（私有地址192.168.0.0～192.168.255.255）\nD类组播地址用于VXLAN协议，E类留待后用\n0.0.0.0对应于当前主机，255.255.255.255对应于当前子网的广播地址，127.0.0.1用于环回测试（loopback test）本主机\n\n\n数据报格式\n\n\n版本 : 有 4（IPv4）和 6（IPv6）两个值；\n首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。\n区分服务 : 是一个框架和一组标准，用于支持RFC2474,RFC2475,RFC3260上不同类型的服务（即不只是尽力而为的服务，而是更好的服务）\n总长度 : 包括首部长度和数据部分长度，以字节为单位（最大为MTU一般为1500字节）\n生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。\n协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP（6）、UDP（17） 等。\n首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。\n标识 : 避免数据报分片的混淆，在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。\n片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。\n选项字段：很多选项已经被淘汰，只有一部分被留下来放在了IPv6的扩展头部中\n\n\n\n\n路由协议：ODPF、RIP\n\n配置路由\n\n路由表：决定如何转发流量，通常称为路由表，主要包含以下三项信息，目的网络、出口设备、下一跳网关。可以通过route命令和ip route命令进行查询或者配置。例如，我们设置ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0，就说明要去 10.176.48.0/20 这个目标网络，要从 eth0 端口出去，经过 10.173.32.1。\n\n策略路由配置示例：\n$ ip rule add from 192.168.1.0&#x2F;24 table 10\n$ ip rule add from 192.168.2.0&#x2F;24 table 20\n#表示从 192.168.1.10&#x2F;24 这个网段来的，使用 table 10 中的路由表，\n#而从 192.168.2.0&#x2F;24 网段来的，使用 table20 的路由表\n$ ip route add default scope global nexthop via 100.100.100.1 weight 1 nexthop via 200.200.200.1 weight 2\n#下一跳有两个地方，分别是 100.100.100.1 和 200.200.200.1，权重分别为 1 比 2。\n\n\n动态路由算法：如何在网络拓扑中找到两个节点的最短路径，主要有Bellman-Ford和Dijkstra算法\n\n距离矢量路由算法（distance vector routing）：基于Bellman-Ford算法，算法思想是每个路由器都保存一个路由表，从哪出和距离，每个路由器都保存全局信息，每过一段时间将已知信息告知邻居。存在两个问题\n\n好消息（新加入路由器）传的块，坏消息（下线的路由器）传的慢\n\n每次发送的时候，要发送整个全局路由表\n\n\n\n链路状态路由算法（link state routing），基于Dijkstra算法，算法思想是当一个路由器启动的时候，首先是发现邻居，向邻居 say hello，邻居都回复。然后计算和邻居的距离，发送一个 echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径\n\n\n\n动态路由协议\n\n基于链路状态路由算法的OSPF（Open Shortest Path First，开放式最短路径优先）：主要用于数据中心内部，又称内部网关协议（Interior Gateway Protocol IGP）。内部网关协议的重点就是找到最短路径，可以在多个路径中进行负载均衡，常被称为等价路由。常配合接入层的负载均衡LVS\n\n基于距离矢量路由算法的BGP（Border Gateway Protocol，外网路由协议）：因为每个数据中心都有自己的Policy，所以有些路可以走，有些不可以走。这一个个数据中心称为自治系统AS（Autonomous System），通过边界路由器与外面世界建立联系。BGP有两类：\n\neBGP：边界路由器之间使用eBGP广播路由\n\niBGP：使得内部路由器能够找到到达外网目的地的最好的边界路由器\n\n\n\n\n\n\n\n数据链路层：ARP（将IP解析为MAC）\n\n\n\n\n\n\n\n\n\n如果说互联网中每一个资源都有IP地址唯一标识，那么一些网络设备都有MAC地址唯一标识，MAC类似于身份证号，IP地址类似于住址\n\nMAC地址：6字节，地址空间约280万亿，由IEEE统一管理与分配，FF-FF-FF-FF-FF-FF为广播地址\n\n\n类型字段用于确定协议类型：\nIPv4为0x0800\nIPv6为0x86DD\n\n\nFCS为帧校验序列：为待检查的消息追加n为0，除以一个n+1位的生成多项式，将余数取反放到FCS中\n链路层MTU为1500字节\n\n\nARP协议原理：ARP表，广播问讯，单播响应\n\n\n\n\n\n\n\n\n\n全称为地址解析协议，它解决的是网络层地址和链路层地址之间的转换问题，因为一个IP数据报在物理上传输的过程中，总需要知道下一跳（物理上的下一目的地）该去往何处，但IP地址属于逻辑地址，而MAC地址才是物理地址，ARP协议解决了IP地址转MAC地址的一些问题\n\nARP表：在一个局域网内，每个网络设备都自己维护了一个ARP表，ARP表记录了某些网络设备的IP地址和MAC地址的映射关系（&lt;IP, MAC, TTL&gt;），其中TTL为该映射关系的生存周期（通常为20min），超时即丢弃此条目\n\n什么时候不用查ARP表：\n当设备要与目标设备进行通信时，它首先会检查自己的ARP缓存表，如果已经有了目标IP地址的映射，就不需要再发送ARP请求，直接使用缓存的MAC地址。\n如果ARP缓存表中没有目标IP地址的映射，设备需要发送ARP请求以获取目标MAC地址。\n\n\n\n\n同一个局域网内的MAC寻址（A「137.196.7.23」，B「137.196.7.14」）\n\n\nA检索自己的ARP表，发现ARP表中无B的IP地址对应的条目，无法知道B的MAC地址\nA构造一个ARP查询分组，将其广播到所在的局域网中\nARP分组主要有两种，ARP查询分组和ARP响应分组，他们具有相同的格式，均包含了发送和接收的IP地址，发送和接收的MAC地址\n查询分组发送的IP地址为A的IP地址，接收的IP地址为B的IP地址；发送的MAC地址为A的MAC地址，接收的MAC地址为FF-FF-FF-FF-FF-FF\n响应分组IP地址与查询分组相反，MAC地址也相反，但是目的MAC地址为查询分组的发送者的MAC，源MAC地址为B的MAC地址\n\n\n\n\n主机A构造的查询分组将在局域网内广播，每一个设备都会收到该分组，设备通过核查IP地址是否与本地相同来确定是否响应\n主机B收到了查询分组，构造一个ARP响应分组，该分组只有一个目的地（主机A），主机B提取IP和MAC信息，插入到ARP表中\n主机A收到主机B的响应分组，提取出该分组的IP地址和MAC地址，插入到ARP表中\n\n\n从一个局域网到另一个局域网中的网络设备的寻址\n\n\n\n\n\n\n\n\n\n路由器的每一个接口都各自维护一个ARP表\n\n主机A查询ARP表，期望寻找到目标路由器（根据B的IP分析出B的子网，转发报文到该子网）的本子网接口的MAC地址\n主机A未能找到目标路由器的本子网接口的MAC地址，采用ARP协议，问询到该 MAC 地址，由于目标接口与主机 A 在同一个子网内，该过程与同一局域网内的 MAC 寻址相同\n主机 A 获取到目标接口的 MAC 地址，先构造 IP 数据报，其中源 IP 是 A 的 IP 地址，目的 IP 地址是 B 的 IP 地址，再构造链路层帧，其中源 MAC 地址是 A 的 MAC 地址，目的 MAC 地址是本子网内与路由器连接的接口的 MAC 地址。主机 A 将把这个链路层帧，以单播的方式，发送给目标接口\n目标接口接收到了链路层帧，解析，根据目的IP地址，查询转发表，将该IP数据报转发到B所在的子网相连的接口上\n路由接口查询ARP表，寻找主机B的MAC地址，如果没找到，则采用ARP查询分组，广播问询，单播响应，获取到主机B的MAC地址，路由器接口对IP数据报重新封装成链路层帧，目标MAC地址为主机B的MAC地址，单播发送，直到目的地\n\n\n\n\n\n\n应用层：DNS（由域名查IP，负载均衡技术，DNS解析过程如下）\n\n首先查缓存\n浏览器缓存检查：浏览器首先搜索自身的DNS缓存（大概1000条左右），看自身缓存是否命中，或已过期\n操作系统缓存检查 + hosts 解析：查询操作系统的DNS缓存是否命中，可以通过/etc/hosts文件来设置，将任何域名解析到任何能够访问的IP地址\n\n\n然后进行dns解析\n第一步：发送域名到本地DNS服务器，查询其缓存，如果有则返回，如果没有则本地DNS服务器发送请求给根DNS服务器进行查询\n第二步：根域名服务器没有记录对应关系时，返回顶级域名服务器的IP；顶级域名服务器向根DNS服务器返回二级域名服务器的IP；二级域名服务器将自己缓存表中的域名和IP地址的对应关系返回给本地DNS服务器\n第三步：本地 DNS 服务器将获取到与域名对应的 IP 地址返回给客户端，并且将域名和 IP 地址的对应关系保存在缓存中，以备下次别的用户查询时使用\n\n\n\n\n应用层：DHCP（已有MAC，获取IP）\n\n格式\n\n\n原理\n\n手动配置IP相当于自己买房装修，DHCP协议相当于租房\n\n新到一个城市要先找中介（DHCP服务器）租个房（IP）-Discover\n\n\n中介（DHCP）会带你看房，可能会有多个中介带你看多个房-Offer\n\n\n你看上其中一个房，愿意租下来-Request\n\n\n中介说没问题，咱们签合同，租约达成-Ack\n\n\n租约达成要广播，防止中介之间跳单\n\n租约快到之前，记得续租\n\n\n\n\n\nNAT：内网复用IP，NAT网关将私有IP改为公网IP\n\n内网穿透，也即 NAT 穿透，进行 NAT 穿透是为了使具有某一个特定源 IP 地址和源端口号的数据包不被 NAT 设备屏蔽而正确路由到内网主机\n允许多个范围内中的同一地址可以复用。专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP，内部原理就是重写通过路由器的数据包的识别信息\n一共有三个IPv4地址范围作为私有地址范围使用（常作为DHCP地址池）：10.0.0.0/8、172.16.0.0/12、192.168.0.0/16\n在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把传输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。\n\n\nNAT工作方式：网络地址转换（Network Address Translation，NAT）机制的问题在于，NAT设备自动屏蔽了非内网主机主动发起的连接，也就是说，从外网发往内网的数据包将被NAT设备丢弃，这使得位于不同NAT设备之后的主机之间无法直接交换信息。这一方面保护了内网主机免于来自外部网络的攻击，另一方面也为P2P通信带来了一定困难。Internet上的NAT设备大多是地址限制圆锥形NAT或端口限制圆锥形 NAT，外部主机要与内网主机相互通信，必须由内网主机主动发起连接，使NAT设备产生一个映射条目\nNAT穿透的原理：NAT设备（或软件）维护一个状态表，用来把内部网络的私有IP地址映射到外部网络的合法IP地址上去。每个包头中的IP地址和端口信息在NAT设备（或软件）中都 被修改并翻译成一正确的IP地址发往下一级。当一个内网主机通过NAT打开一个“外出”的TCP或UDP会话时，NAPT分配给这个会话一个公网IP和端口，用来接收外网 的响应的数据包，并经过转换通知内部网的主机。这样，NAPT在[私有IP：私有端口]和[公网IP：公网端口]之间建立了一个端口绑定\n\n\nICMP（ping的底层实现）\n\n帧格式\n\n查询报文类型：一种主动请求并且获得主动应答的ICMP协议，在网络抓包时，称为ICMP ECHO REQUEST和CMP ECHO REPLY，比原生ICMP多个标识符和序号字段\n\n差错报文类型：主要有终点不可达（3）、源抑制（4）、超时（11）、重定向（5）等\n\n\n\n\nping原理\n\n\nICMP是哪个路由器回的，什么地方用了ICMP：\n\nICMP消息通常由目标设备或中间路由器回复，以响应请求或报告错误。例如，ping工具发送ICMP Echo请求到目标主机，然后目标主机回复ICMP Echo响应。\nICMP还用于路由器和网络设备之间的通信，用于报告网络错误和状态信息。例如，当路由器无法路由数据包时，它可以发送ICMP不可达消息给源设备。\n\n\ntraceroute的工作原理：\n\ntraceroute是一种用于追踪数据包在网络中的路径的工具。它通过向目标主机发送一系列数据包，每个数据包具有不同的生存时间（TTL），从而导致数据包在网络中的不同路由器上生成ICMP Time Exceeded消息。\n当一个路由器收到生存时间（TTL）为0的数据包时，它会向源设备发送ICMP Time Exceeded消息，然后数据包被丢弃。traceroute工具根据接收到的ICMP消息来确定数据包的路径，逐步增加TTL并记录下每一跳的路由器。\n这样，traceroute可以生成一份包含数据包路径的报告，帮助用户诊断网络问题和了解数据包在网络中的传输路径。\n\n\n\n\n\n2.传输层\nTCP\n\n\n\n\n\n\n\n\n\nTCP的连接：用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接\n\n特点：可靠性（丢失重传）、面向连接、流量控制、拥塞控制、顺序性、字节流传输、长连接\n\n头格式\n\n序号：给包编号，用来解决乱序问题（将应用层的数据分块「TCP segment」，最大为MSS、MTU除去IP头和TCP头）\n确认序号：发出去的包应该有确认，来确定是否已经收到相应包\n状态位：\nSYN：发起一个连接\nACK：回复\nRST：重新连接\nFIN：结束连接\n\n\n窗口大小：TCP要做流浪控制，通信双方动态约定一个窗口，保证双方都在高效处理数据\n\n\n\n三次握手：保证双方都有发送和接收的能力\n\n握手次数：一次的话，请求方不知道响应方是否已经成功接受请求；两次的话，接收方不知道发送方是否成功接受相应；三次的话，刚好双方都知晓；四次以及更多的话，已经没有特殊的意义了，所以再多的数据包都不能保证真的可靠，后续通过数据包和探活包来解决相关问题\n\n防止旧的重复连接初始化造成混乱：旧连接的同步客户端会返回RST报文来解决\n同步双方初始序列号：同步双方的序列号\n避免资源浪费\n\n\n\nTCP包的序号问题：为了防止连接之间数据包序号的相互影响，所以序号是随时间变化的，通过数据包的序号，双方都可以知道应收的包和应发的包都是哪个\n\nSocket编程\n\n连接建立过程\n\n\n没有 accept，能建立 TCP 连接吗：accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了\n\n\n\n\n\n\n四次挥手：确保了双方在关闭连接之前完成了所有的数据传输，防止数据的丢失或不完整，最后的ACK表示对方的关闭请求已经被确认，连接可以正常关闭。\n\n等待2MSL：MSL是报文最大生存时间，虽然序号是重新生成的，但是为了防止左端提前结束后收到右端之前连接的数据包，所以需要等待2MSL时间。时间截止后，对于右端旧连接发送的数据包，左端将会直接发送RST，这样右端就知道左端已退出\n\n防止历史连接中的数据，被后面相同四元组的连接错误的接收\n确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭\n\n\n\nTIME_WAIT 状态是主动关闭连接方才会出现的状态\n\n服务器出现大量 TIME_WAIT 状态的原因：服务端主动断开大量TCP连接，有可能是HTTP 没有使用长连接、HTTP 长连接超时（nginx 提供的 keepalive_timeout）、HTTP 长连接的请求数量达到上限（nginx 的 keepalive_requests）\n\n\nCLOSE_WAIT 状态是「被动关闭方」才会有的状态，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接，通过如下TCP服务流程查看具体原因\n\n创建服务端 socket，bind 绑定端口、listen 监听端口\n\n将服务端 socket 注册到 epoll\n\n没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了\n\n\nepoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket\n\n没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了\n\n\n将已连接的 socket 注册到 epoll\n\n通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了\n\n\nepoll_wait 等待事件发生\n\n对方连接关闭时，我方调用 close\n\n当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等\n\n\n\n\n\n\n\n滑动窗口\n\n发送端\n\n第一部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的\n第二部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉\n第三部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的\n第四部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。（区分三和四是为了流量控制）\n\n\n\n接收端\n\n第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的\n第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量\n第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。\n\n\n\n问题\n\n流量控制：在对包的确认中，同时会携带一个窗口的大小。当发送方窗口已经全发送过了，但是接受端还没接收，此时每接受到一个应答，窗口大小就减一，直到为0\n丢包问题\n超时重传：对每一个发送了，但是没有 ACK 的包，都有设一个定时器，超过了一定的时间，就重新尝试。超时时间依靠自适应重传算法（Adaptive Retransmission Algorithm，比RTT多一点）\n超时间隔加倍：每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送\n快速重传机制：当接收方收到一个序号大于下一个所期望的报文段时，就会检测到数据流中的一个间隔，于是它就会发送冗余的 ACK，仍然 ACK 的是期望接收的报文段。而当客户端收到三个冗余的 ACK 后，就会在定时器过期之前，重传丢失的报文段\nSACK：解决快速重传机制不确定传输是否需要传输丢失报文后续的报文问题，这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据\nDuplicate SACK：又称 D-SACK，主要使用了 SACK 来告诉发送方有哪些数据被重复接收了\n\n\n流量控制使用什么数据结构\nTCP传输协议中，流量控制是使用滑动窗口（Sliding Window）来实现的。滑动窗口是一种基于数据流的、动态调整的、可变大小的窗口，它通过协商双方的接收窗口和发送窗口大小，控制数据的传输速率。\n在TCP协议中，每个数据包都有一个序号，接收方通过序号来确认是否收到了正确的数据包。发送方将数据分成若干个数据段，每个数据段的大小不超过发送窗口的大小，然后将这些数据段发送给接收方。接收方会确认已经收到的数据，同时告诉发送方自己的接收窗口大小。发送方根据接收方的窗口大小，动态调整自己的发送窗口大小，从而控制数据的传输速率。\n滑动窗口的大小是可以动态调整的，它可以根据网络状况和双方的能力来自适应地调整，从而实现流量控制的功能。如果接收方的接收窗口变小，发送方会相应地减小自己的发送窗口，以避免过多的数据堆积在网络中导致拥塞。如果接收方的接收窗口变大，发送方会相应地增加自己的发送窗口，以提高数据传输速率。\n\n\nTCP如何保证可靠传输\ntcp的序列号可以避免乱序的问题，保证收到的tcp报文都是有序的。\n在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。\nTCP 针对数据包丢失的情况，会用重传机制解决。\n用快重传解决个别报文段的丢失问题。\n使用滑动窗口实现流量控制。使用接收方确认报文中的窗口字段来控制发送方发送窗口大小，进而控制发送方的发送速率，使得接收方来得及接收。\n使用基于窗口的拥塞控制，来尽量避免避免网络拥塞。\n\n\nLInux的TCP连接数量最大为多少：Linux的TCP连接数量最大不能超过65535是一个常见的误解。实际上，一个TCP连接由一个五元组（协议、本地IP、本地端口、远程IP、远程端口）唯一确定12。对于服务器来说，本地端口一般是固定的，比如HTTP (80），但是远程IP和远程端口没有限制。因此，理论上服务器可以支持的TCP连接数是2的32次方（IP数）x2的16次方（端口数）x2的16次方（服多器端口数）个2\n\n\n\n\n==拥塞窗口==\n\n慢启动拥塞避免\n\n\n快重传快恢复\n\n\n\n\nTCP粘包分析与处理\n\n概念\n\nTCP粘包现象：发送方发送的多个数据包，到接收方后粘连在一起，导致数据包不能完整的体现发送的数据（UDP有消息边界，所以不会出现粘包问题）\n如果一次发送的消息太小，没达到缓冲区大小，TCP会讲多个请求合并为同一个请求来发送，这就形成了粘包问题；如果一次发送的消息过大，超过了缓冲区的大小，TCP就会将其拆分为多次发送，这就是拆包问题\n\n\n\n原因：可能是发送方的原因也可能是接收方的原因\n\n发送方：由于TCP需要尽可能高效和可靠，所以TCP默认采用Nagle算法，以合并相连的小数据包，再一次性发送，以达到提升网络传输效率的目的。但是接收方并不晓得发送方合并数据包，而且数据包的合并在TCP协议中是没有分界线的，所以这就导致接收方不能还原其本来的数据包\n接收方：TCP是基于“流”的，网络传输数据的速度可能会快过接收方处理数据的速度，这时就会导致接收方在读取缓冲区时，缓冲区存在多个数据包。在TCP协议中接收方是一次读取缓冲区中的所有内容，所以不能反映原本的数据信息\nTCP协议是基于字节流的传输层协议，没有固定的分包边界。发送方将数据分成多个小的数据包进行传输，接收方再将这些数据包组合成完整的数据。在这个过程中，可能会出现拆包和沾包现象\n网络传输中的延迟和拥塞会影响数据包发送的速度和到达接收方的顺序。这可能导致数据包的拆分和组合不规律，从而出现拆包和沾包现象\n接收方的缓冲区大小限制。当接收方的缓冲区不足以容纳一个完整的数据包时，可能会将数据包拆分成多个部分，导致拆包现象\n\n\n解决办法\n\n其他办法\n禁用Negel算法：只能解决发送方的问题，但是TCP的传输效率变低了\nPUSH标志：在发送时可以设置这个标志位，通知接收方将收到的数据提交给接收进程，并不能完全解决，只能降低发生粘包的可能性\n发送端将每个包都封装成固定的长度、发送端在每个包的末尾使用固定的分隔符、将消息分为头部和消息体其中头部包含消息长度\n在应用层实现数据包的边界识别，例如通过添加包头，包头中包含数据包长度等信息，使得接收方能够准确地将数据包进行拼接\n使用固定长度的数据包或者特殊的分隔符，以便于接收方识别数据包的边界\n使用更高级的传输层协议，如WebSocket，它在TCP基础上增加了数据帧的概念，可以更好地解决拆包和沾包问题\n\n\nNetty对粘包和拆包的处理，提供了一些解码器（Decoder）来解决粘包和吃啊包的问题\nLineBasedFrameDecoder：以行为单位进行数据包的解码；\nDelimiterBasedFrameDecoder：以特殊的符号作为分隔来进行数据包的解码；\nFixedLengthFrameDecoder：以固定长度进行数据包的解码；\nLenghtFieldBasedFrameDecode：适用于消息头包含消息长度的协议（最常用）\n\n\n\n\n\n\n\n\nUDP\n\n头格式\n\n\n使用场景\n\n需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用\n不需要一对一沟通，建立连接，而是可以广播的应用\n需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候\n基于UDP的协议：DHCP、HTTP3、云网络中的VXLAN、操作系统镜像的下载使用的 TFTP\n一些新兴改进\nQUIC是Google提出的一种基于UDP改进的通信协议，在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制。主要用在网页和APP的访问\n直播协议多使用RTMP，丢包时会影响直播效果，所以很多直播应用都基于UDP实现了视频传输协议\n实时游戏领域，在异步IO机制引入之前，常采用自定义UDP来解决对海量客户端连接的策略\n物联网领域终端资源少，维护TCP协议代价太大，而且物联网对实时性要求也很高。Google 旗下的 Nest 建立 Thread Group，推出了物联网通信协议 Thread，就是基于 UDP 协议的\n在 4G 网络里，移动流量上网的数据面对的协议 GTP-U 是基于 UDP 的\n\n\n\n\n\n\n其它\n\nTCP和UDP的区别\n连接：TCP 是面向连接的传输层协议，传输数据前先要建立连接；UDP 是不需要连接，即刻传输数据\n服务对象：TCP 是一对一的两点服务，即一条连接只有两个端点；UDP 支持一对一、一对多、多对多的交互通信\n可靠性：TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达；UDP 是尽最大努力交付，不保证可靠交付数据\n拥塞控制、流量控制：TCP 有拥塞控制和流量控制机制，保证数据传输的安全性；UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。\n首部开销：TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的；UDP 首部只有 8 个字节，并且是固定不变的，开销较小。\n传输方式：TCP 是流式传输，没有边界，但保证顺序和可靠；UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序\n分片不同\nTCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。\nUDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。\n\n\n使用场景：\nTCP：可靠性传输（文件传输、电子邮件传输）、顺序性（视频流、Web页面加载）、流量控制和拥塞控制、长连接（Web浏览、远程桌面）\nUDP：低延迟（音频/视频流、在线游戏）、广播和多播（多人在线游戏、流媒体广播）、轻量级、不可靠但快速的数据传输（实时传感数据采集）\n\n\n\n\nTCP如何保证可靠的\ntcp的序列号可以避免乱序的问题，保证收到的tcp报文都是有序的。\n在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。\nTCP 针对数据包丢失的情况，会用重传机制解决。\n用快重传解决个别报文段的丢失问题。\n使用滑动窗口实现流量控制。使用接收方确认报文中的窗口字段来控制发送方发送窗口大小，进而控制发送方的发送速率，使得接收方来得及接收。\n使用基于窗口的拥塞控制，来尽量避免避免网络拥塞。\n\n\n\n\n\n\n3.应用层\nHTTP：HyperText Transfer Protocol（超文本传输协议）\n\nHTTP/1.1：无状态（cookie）、明文传输（SSL/TLS）、\n\nmethod\nGET（SELECT）：从服务器获取指定的资源，通过URL以ASCII格式传递参数，是安全且幂等的\n\nRFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。\n\n\nPOST（CREATE）：在服务器新建一个资源，创建成功返回201并且新资源的URI包含在响应的Location标头中，未创建新资源但成功处理则返回200并在响应正文中包含操作的结果，如果是无效数据则返回400（错误的请求），不是幂等的\n\nURL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的\n\n\nPUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源），与POST方法类似\n\nPATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性），对PUT方法的补充用来对已知资源进行局部更新\n\nDELETE（DELETE）：从服务器删除资源\n\n\n\n方法\n是否安全\n是否幂等性\n\n\n\nGET\nTRUE\nTrue\n\n\nPUT\nFALSE\nTrue\n\n\nDELETE\nFALSE\nTrue\n\n\nPOST\nFALSE\nFalse\n\n\nPATCH\nFALSE\nFalse\n\n\n\n\n\nstatus codes\n1xx：表示目前是协议处理的中间状态，还需要后续操作\n2xx：表示成功状态，报文已收到并正确处理\n204：没有响应体、206：响应体不全\n\n\n3xx：重定向状态，资源位置发生变动，需要重新请求\n301：永久重定向、302：暂时重定向\n304：内容未更改，重定向到客户端的缓存资源\n\n\n4xx：客户端错误，请求报文有误服务器无法处理\n403：禁止访问资源、404资源未找到\n\n\n5xx：服务端错误，服务器在处理请求时内部发生了错误\n501 Not Implemented：表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思\n502 Bad Gateway：通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误\n503 Service Unavailable：表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思\n\n\n\n\nheader fields\nHost：客户端发送请求时，用来指定服务器的域名，可以将请求发往同一台服务器上的不同网站\nContent-Length ：表明本次回应的数据长度，HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题\nConnection：客户端要求服务器使用HTTP 长连接机制（Keep-Alive），任意一端没有明确提出断开连接，则保持 TCP 连接状态\nContent-Type：用于服务器回应时，告诉客户端，本次数据是什么格式Content-Type: text/html; Charset=utf-8\nAccept：客户端请求的时候，声明自己可以接受哪些数据格式Accept: */*\nContent-Encoding：表示服务器返回的数据使用了什么压缩格式；Accept-Encodin：说明客户端可以接受哪些压缩方法\n\n\n\n\n报文\n\nHTTP请求报文：\n请求行（Request Line）： 请求行包含了请求的方法（如GET、POST、PUT、DELETE等）、请求的URL路径和HTTP协议的版本。\n请求头部（Request Headers）： 请求头部包含了关于请求的元数据信息，例如Host、User-Agent、Content-Type等。这些信息通常用于描述请求的特性和需要的处理。\n空行（Blank Line）： 请求头部之后必须有一个空行，表示请求头部的结束。\n请求体（Request Body）： 请求体包含了实际的请求数据，例如在POST请求中的表单数据、JSON数据等。对于GET请求等没有主体的请求，请求体通常为空。\n\n\nHTTP响应报文：\n状态行（Status Line）： 状态行包含了响应的HTTP协议版本、状态码和状态消息。状态码表示请求的处理结果，如200表示成功，404表示未找到，500表示服务器内部错误等。\n响应头部（Response Headers）： 响应头部包含了关于响应的元数据信息，例如Content-Type、Content-Length、Server等。这些信息用于描述响应的特性和响应数据的属性。\n空行（Blank Line）： 响应头部之后必须有一个空行，表示响应头部的结束。\n响应体（Response Body）： 响应体包含了实际的响应数据，例如HTML页面、JSON数据、图像文件等。响应体的内容取决于服务器对请求的处理。\n\n\n\n\nHTTP缓存：通过将不变的请求-响应数据缓存在本地提升性能\n\n强制缓存：只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边\n实现：Cache-Control（一个相对时间）、Expires（一个绝对时间），建议使用Cache-Control\n当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；\n浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器；\n服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。\n\n\n\n\n协商缓存：与服务端协商之后，通过协商结果来判断是否使用本地缓存\n实现：使用请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段或 Last-Modified两种方式来实现，ETag用来唯一标识资源，Last-Modified用来记录修改时间，由于时间粒度大并且会被恶意修改，所以推荐使用ETag\n服务器再次收到请求后，会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：\n如果值相等，则返回 304 Not Modified，不会返回资源；\n如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；\n\n\n\n\n\n\n性能优化\n\n尽量避免发送 HTTP 请求：缓存\n在需要发送 HTTP 请求时，考虑如何减少请求次数\n使用代理服务器减少重定向请求次数\n合并请求：使用CSS Image Sprites技术；使用 webpack 等打包工具将 js、css 等资源合并打包\n延迟发送请求：请求网页的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的页面资源，当用户向下滑动页面的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果\n\n\n减少服务器的 HTTP 响应的数据大小：无损压缩（gzip）、有损压缩（WebP）\n\n\nsession&amp;cookie\n\ncookie：客户端保存用户信息的一种机制，将服务器发送到浏览器的数据保存在本地，下次向同一服务器再发起请求时被携带发送，解决HTTP无状态的问题，可以保持用户登录状态\nsession：Session是一种在服务器端保存数据的机制，用来跟踪用户状态的数据结构，可以保存在文件、数据库或者集群中。客户端关闭会话，或者Session超时失效时会话结束\n目前大多数的应用都是用Cookie实现Session跟踪的。第一次创建Session时，服务端会通过在HTTP协议中返回给客户端，在Cookie中记录SessionID，后续请求时传递SessionID给服务，以便后续每次请求时都可分辨你是谁\n区别\n作用范围不同，Cookie 保存在客户端(浏览器)，Session 保存在服务器端。\n存取方式的不同，Cookie只能保存 ASCII，Session可以存任意数据类型，比如UserId等。\n有效期不同，Cookie可设置为长时间保持，比如默认登录功能功能，Session一般有效时间较短，客户端关闭或者Session超时都会失效。\n隐私策略不同，Cookie存储在客户端，信息容易被窃取；Session存储在服务端，相对安全一些。\n存储大小不同， 单个Cookie 保存的数据不能超过 4K，Session可存储数据远高于Cookie。\n\n\n分布式系统中的Session：会有多个服务器处理同一业务，Session存在不同服务器上会登录失败，解决方法如下\n方案一：请求精确定位。也就是通过负载均衡器让来自同一IP的用户请求始终分配到同一服务上。比如，Nginx的ip_hash策略，就可以做到\n方案二：Session复制共享。该方案的目标就是确保所有的服务器的Session是一致的。像Tomcat等多数主流web服务器都采用了Session复制实现Session的共享\n方案三：基于共享缓存。该方案是通过将Session放在一个公共地方，各个服务器使用时去取即可。比如，存放在Redis、Memcached等缓存中间件中\n\n\n同源策略与跨域请求\n同源：协议相同、域名相同、端口相同，主要是为了保证用户信息的安全，防止恶意的网站窃取数据\n恶意网站会使用用户的Cookie来伪装成用户，窃取用户信息\n\n\n跨域请求：请求一个与自身资源不同源的资源，浏览器设置了同源策略，但是有的时候网页中需要有跨域访问，所以W3C提供了一个解决方法（跨域资源共享CORS），浏览器将CORS请求分为两部分\n简单请求：浏览器直接处理\n预检请求：不符合简单请求条件的请求，会在正式通信之前触发一个 **OPTIONS**请求进行预检。服务端收到预检请求后，会根据上述附带的信息判断是否允许跨域，浏览器会根据返回的 CORS 信息判断是否继续发送真实的请求（确认后才发实际的HTTP请求）\n\n\n\n\n\n\n\n\nSSL/TLS\n\n在HTTP和TCP之间，HTTPS在进行三次握手之后还要进行SSL/TLS 的握手过程，才能进行加密报文传输。解决HTTP协议明文传输导致的：窃听信息（混合加密）、篡改响应（摘要算法）、冒充网站（数字证书）\n\n混合加密：对称加密和非对称加密结合，在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。\n\n对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。\n非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。\n\n\n摘要算法：用摘要算法（哈希函数）来计算出内容的哈希值\n\n\n数字证书：将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的\n\n\n\nSSL/TLS 协议基本流程\n\n客户端向服务器索要并验证服务器的公钥，双方协商生产「会话秘钥」\n即 SSL/TLS 的建立过程，也就是 TLS 握手阶段。TLS 的「握手阶段」涉及四次通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：RSA 算法和 ECDHE 算法。\nTLS 在实现上分为握手协议和记录协议两层：\nTLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；\nTLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证\n\n\n\n\n双方采用「会话秘钥」进行加密通信\nSSL与TLS：SSL 是洋文 “Secure Sockets Layer” 的缩写，中文叫做「安全套接层」。它是在上世纪 90 年代中期，由网景公司设计的。到了1999年，SSL 因为应用广泛，已经成为互联网上的事实标准。IETF 就在那年把 SSL 标准化。标准化之后的名称改为 TLS（是 “Transport Layer Security” 的缩写），中文叫做 「传输层安全协议」。很多相关的文章都把这两者并列称呼（SSL/TLS），因为这两者可以视作同一个东西的不同阶段。\n\n\n网络攻击常见手段\n\nIP欺骗：伪造某台主机的IP地址的技术，通过IP地址的伪装使得某台主机能够伪装另一台主机，而这台主机往往具有某种特权或者被另外的主机所信任\n\n示例：攻击者构造TCP数据，伪装自己的IP地址，并向服务器发送一个带有RSI位的TCP数据段，服务器接收到这样的数据后，认为该IP地址发送的连接有误，会清空缓冲区中建立好的连接。这时合法用户再发送合法数据，服务器就已经没有这样的连接了，使得服务器无法对合法用户服务\n缓解1：入口过滤是一种数据包过滤形式，通常在网络边缘设备上实施，用于检查传入的IP数据包并确定其源标头。如果这些数据包的源标头与其来源不匹配或者看上去很可疑，则拒绝这些数据包\n缓解2：一些网络还实施出口过滤，检查退出网络的 IP 数据包，确保这些数据包具有合法源标头，以防止网络内部用户使用 IP 欺骗技术发起出站恶意攻击\n\n\n洪泛攻击：DDoS、SYN Flood、UDP Flood、HTTP Flood、DNS Flood\n\n\n\n\n\n\n\n\n\nDDoS（Distributed Denial of Service，分布式拒绝服务）\n\nDDOS\n\nDDos 全名 Distributed Denial of Service，翻译成中文就是分布式拒绝服务。指的是处于不同位置的多个攻击者同时向一个或数个目标发动攻击，是一种分布的、协同的大规模攻击方式。单一的 DoS 攻击一般是采用一对一方式的，它利用网络协议和操作系统的一些缺陷，采用欺骗和伪装的策略来进行网络攻击，使网站服务器充斥大量要求回复的信息，消耗网络带宽或系统资源，导致网络或系统不胜负荷以至于瘫痪而停止提供正常的网络服务\n如何应对\n高防服务器：能独立硬防御50Gbps以上的服务器，能够帮助网站拒绝服务攻击，定期扫描网络主节点，唯一缺点就是贵\n黑名单：设置黑名单，但是会封锁正常流量，影响正常业务\nDDoS清洗：会对用户请求数据进行实时监控，及时发现 DOS攻击等异常流量，在不影响正常业务开展的情况下清洗掉这些异常流量\nCDN加速：将网站访问流量分配到了各个节点中，这样一方面隐藏网站的真实 IP，另一方面即使遭遇 DDoS 攻击，也可以将流量分散到各个节点中，防止源站崩溃\n\n\n\n\nSYN Flood\n\n互联网上最原始最经典的DDoS攻击，旨在耗尽可用服务器资源，致使服务器无法传输合法流量\n利用三次握手机制，通过工具或僵尸网络主机向服务器发送海量的不同源IP/不同源端口的TCP SYN报文，服务器响应了这些报文之后就会返回SYN-ACK报文，并生成大量的半连接，当系统资源被耗尽后，服务器将无法提供正常的服务\n常见形式\n直接攻击：不伪造IP地址\n欺骗攻击：恶意用户伪造其发送的各个SYN数据包的IP地址\n分布式DDoS：通过僵尸网络，令每台分布式设备伪造其发送数据包的IP地址\n\n\n服务器在返回SYN-ACK报文后，会有一个计时器Timer，如果超过时间还没有收到A的ACK消息，则重新发送一次SYN-ACK消息，直到重试超过一定次数才会放弃\n在短时面临海量连接时，SYN Flood攻击就形成了\n\n\n解决办法主要是判断哪些连接请求来自于真实源，屏蔽非真实源的请求以保障正常的业务请求能得到服务\n扩展积压工作队列：增加操作系统允许的最大半开连接数目，但需额外预留内存资源以处理各类新请求\n回收最先创建的 TCP 半开连接：在填充积压工作后覆盖最先创建的半开连接，这项策略要求完全建立合法连接的时间低于恶意 SYN 数据包填充积压工作的时间。当攻击量增加或积压工作规模小于实际需求时，这项特定的防御措施将不奏效\nSYN Cookie：此策略要求服务器创建 Cookie。为避免在填充积压工作时断开连接，服务器使用 SYN-ACK 数据包响应每一项连接请求，而后从积压工作中删除 SYN 请求，同时从内存中删除请求，保证端口保持打开状态并做好重新建立连接的准备。如果连接是合法请求并且已将最后一个 ACK 数据包从客户端机器发回服务器，服务器将重建（存在一些限制）SYN 积压工作队列条目。虽然这项缓解措施势必会丢失一些 TCP 连接信息，但好过因此导致对合法用户发起拒绝服务攻击\n\n\n\n\nUDP Flood\n\nUDP Flood也是一种拒绝服务攻击，将大量的用户数据报协议（UDP）数据包发送到目标服务器，目的是压倒该设备的处理和响应能力。防火墙保护目标服务器也可能因UDP泛滥而耗尽，从而导致对合法流量的拒绝服务\n\n攻击原理：当服务器在特定端口接收到 \nUDP\n 数据包时，会经过两个步骤：\n\n服务器首先检查是否正在运行正在侦听指定端口的请求的程序\n如果没有程序在该端口接收数据包，则服务器使用 ICMP（ping）数据包进行响应，以通知发送方目的地不可达\n\n\n如何缓解：大多数操作系统部分限制了ICMP报文的响应速率，以中断需要 ICMP 响应的DDoS攻击。这种缓解的一个缺点是在攻击过程中，合法的数据包也可能被过滤。如果UDP Flood的容量足够高以使目标服务器的防火墙的状态表饱和，则在服务器级别发生的任何缓解都将不足以应对目标设备上游的瓶颈\n\n\n\nHTTP Flood\n\nHTTP Flood 是一种大规模的 DDoS（Distributed Denial of Service，分布式拒绝服务）攻击，旨在利用 HTTP 请求使目标服务器不堪重负。目标因请求而达到饱和，且无法响应正常流量后，将出现拒绝服务，拒绝来自实际用户的其他请求\nHTTP Flood攻击有两种：\nHTTP GET 攻击 ：在这种攻击形式下，多台计算机或其他设备相互协调，向目标服务器发送对图像、文件或其他资产的多个请求。当目标被传入的请求和响应所淹没时，来自正常流量源的其他请求将被拒绝服务\nHTTP POST 攻击 ： 一般而言，在网站上提交表单时，服务器必须处理传入的请求并将数据推送到持久层（通常是数据库）。与发送 POST 请求所需的处理能力和带宽相比，处理表单数据和运行必要数据库命令的过程相对密集。这种攻击利用相对资源消耗的差异，直接向目标服务器发送许多 POST 请求，直到目标服务器的容量饱和并拒绝服务为止\n\n\n防护办法\n对发出请求的设备实施质询，以测试它是否是机器人，这与在线创建帐户时常用的 CAPTCHA 测试非常相似。通过提出 JavaScript 计算挑战之类的要求，可以缓解许多攻击\nWeb 应用程序防火墙 (WAF)、管理 IP 信誉数据库以跟踪和有选择地阻止恶意流量，以及由工程师进行动态分析\n\n\n\n\nDNS Flood\n\n攻击者用大量流量淹没某个域的 DNS 服务器，以尝试中断该域的 DNS 解析。通过中断 DNS 解析，DNS Flood攻击将破坏网站、API 或 Web 应用程序响应合法流量的能力。很难将 DNS Flood攻击与正常的大流量区分开来，因为这些大规模流量往往来自多个唯一地址，查询该域的真实记录，模仿合法流量\n如何防护：DNS Flood 对传统上基于放大的攻击方法做出了改变。借助轻易获得的高带宽僵尸网络，攻击者现能针对大型组织发动攻击。除非被破坏的 IoT 设备得以更新或替换，否则抵御这些攻击的唯一方法是使用一个超大型、高度分布式的 DNS 系统，以便实时监测、吸收和阻止攻击流量\n\n\n\n\n其他攻击\n\nTCP重置攻击\n在 TCP重置攻击中，攻击者通过向通信的一方或双方发送伪造的消息，告诉它们立即断开连接，从而使通信双方连接中断\n一般客户端发现到达的报文对于相关连接不正确时，就会发送一个重置报文段，从而导致TCP连接的快速拆卸\n\n\n一般只对长连接有效果，对于短连接而言，你还没攻击呢，人家已经完成了信息交换\n\n\n中间人攻击\n\n\n\n\n\n\nHTTP协议的演变\n\n\nHTTP/1.1 相比 HTTP/1.0 性能上的改进：\n长连接：只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载\n如果要关闭 HTTP Keep-Alive，需要在 HTTP 请求或者响应的 header 里添加 Connection:close 信息，也就是说，只要客户端和服务端任意一方的 HTTP header 中有 Connection:close 信息，那么就无法使用 HTTP 长连接的机制\n\n\n管道网络传输：即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间，但不是默认开启的\n对头堵塞问题：如果服务端在处理某个请求时耗时比较长，那么后续的请求的处理都会被阻塞住\nHTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞，可以同时发多个请求但是需要响应等待服务器\n\n\n\n\n那 HTTP/2 相比 HTTP/1.1 性能上的改进：\n安全传输：基于HTTPS，HTTPS与HTTP的区别如下\nHTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输\nHTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输\n两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443\nHTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的\n\n\n头部压缩（HPACK算法）：通过在客户端和服务器同时维护一张头信息表，只传输索引号而不是重复传相同的头部\n二进制格式：不再是纯文本形式的报文，头信息和数据体都是二进制，并且统称为帧（frame），头信息帧（Headers Frame）和数据帧（Data Frame）\n并发传输：1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）\n针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的\n\n\n服务器主动推送资源：服务端不再是被动地响应，可以主动向客户端发送消息。客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。\n\n\nHTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP\n使用基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输\nQUIC协议\n无队头阻塞：当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题\n更快的连接建立：三次握手（ QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商）\n连接迁移：TCP通过四元组标识，Wi-Fi切换到4G时需要重新建立连接，而QUIC通过连接 ID 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能\n\n\n\n\n队头阻塞问题\nHTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是没有解决响应的队头阻塞，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞\nHTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时（丢包），后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题\nHTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP，UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输\n\n\n分块传输：分块传输感觉是说http协议里的chunk传输。它允许将数据分成多个块（Chunk）进行传输，每个块都包含一段数据和该块数据的长度。在传输数据时，先发送一个块的长度，然后发送该块的数据，接着发送下一个块的长度和数据，以此类推，直到所有的数据都传输完毕。\n\n\nWeb页面请求过程\n\n概览 ：HTTP解析URL（服务器名+路径名）并生成HTTP请求消息（Get/Post报文），通过DNS查询服务器名对应的IP地址（DNS请求-本地-根-顶级-权威），通过Socket委托Linux协议栈进行层层处理（TCP-IP-网卡驱动-物理网卡）；TCP协议填充头信息（端口、序号、确认号、状态位）进行三次握手、流量控制、拥塞控制，IP协议通过ip地址来确定路由方向，通过ARP协议根据ip地址得到MAC地址再通过MAC地址在以太网中传输数据；通过网卡驱动程序增加数据（报头、帧分节符、校验符）并将二进制数据转换成电信号，通过二层设备交换机通过MAC地址决定走哪个端口，通过三层设备路由器路由表来查询走哪个端口\n在发送数据包时，如果目标主机不是本地局域网，填入的 MAC 地址是路由器，也就是把数据包转发给路由器，路由器一直转发下一个路由器，直到转发到目标主机的路由器，发现目标 IP 地址是自己局域网内的主机，就会 ARP 请求获取目标主机的 MAC 地址，从而转发到这个服务器主机\n\nHTTP调度如下\n\n\n\n\nDHCP 配置主机信息\n假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。\n主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。\n该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。\n该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。\n连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。\n该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。\n主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。\n\n\nARP 解析 MAC 地址\n主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。\n主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。\n该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。\n该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。\nDHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。\n主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。\n网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。\n\n\nDNS 解析域名\n知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。\n网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。\n因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。\n到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。\n找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。\n\n\nHTTP 请求页面\n有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。\n在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。\nHTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。\n连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。\nHTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。\n浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。\n\n\n\n\n网络分层\n\nTCP/IP四层协议：网络接口层、网络层、传输层、应用层\n\n网络接口层：MAC地址\n物理层\n物理信道：单工通信（无线电广播）、半双工通信（对讲机）、全双工通信（手机打电话）\n物理设备：交换机（连接多段网线）、调制解调器（将数字信号转换成电话线的模拟信号或光信号）\n\n\n数据链路层\n在一条链路上传输数据时，需要有对应的通信协议来控制数据的传输\n广播信道：CSMA/CD协议，如同轴电缆、集线器等组成的网络\n点对点信道：PPP协议，如2个路由器之间的信道\n\n\n数据链路层的3个基本问题\n封装成帧：帧的数据部分就是网络层传递下来的数据包，帧的最大长度为MTU（1500字节）\n透明传输：完整的数据使用SOH作为开始，使用EOT作为结束，与标志相同的数据会被转义传输，到达后被还原\n差错检验：帧尾部有一个FCS字段，是根据数据部分和数据链路层首部计算得出的，可以用来检验接收到的消息对错\n\n\nCSMA/CD：载波侦听多路访问/冲突检测，用来支持单用通信和半双工通信\n\n\n\n\n网络层：IP、ARP（IP解析为MAC）、DHCP（获取IP）、ICMP（ping的底层实现）、NAT（网关内复用IP，将私有IP转换为公网IP）、OSPF和BGP（动态路由协议，确定走哪个路由器）\n传输层：TCP（流量控制、超时重传、拥塞控制）、UDP（实时性好传输效率高）、Socket编程\n应用层：HTTP协议（超文本传输协议）、FTP（文件传输协议）、DNS（将域名转换为IP地址）、SMTP（邮件传输协议）、Telnet（使用命令行与服务器通信）\n\n\nOSI七层：（物理层、数据链路层）；网络层；传输层；（会话层、表示层、应用层）\n\n\n\n\n\n附录1.Sockets\nsocket 是什么？\n\nsock（或 socket）是操作系统内核提供的一种数据结构，用于实现网络传输功能\n基于不同的网络协议以及应用场景，衍生了各种类型的 sock。每个网络层协议都有相应的 sock 结构体来管理该层协议的连接状态和数据传输。各类 sock 操作硬件网卡，就实现了网络传输的功能\n为了将这些功能让处在用户态的应用程序使用，不但引入了 socket 层，还将各类功能的实现方式抽象成了 API 接口，供应用程序调用\n同时将 sock 封装成文件，应用程序就可以在用户层通过文件句柄（socket fd）来操作内核中 sock 的网络传输功能。这个 socket fd 是一个 int 类型的数字，而 socket 中文翻译叫做套接字，结合这个 socket fd，你是不是可以将其理解成：一套用于连接的数字\n而 socket 分 Internet socket 和 UNIX Domain socket，两者都可以用于不同主机进程间的通信和本机进程间的通信。只是前者采用的是基于 IP 协议的网络通信方式，而后者采用的是基于本地文件系统的通信方式\n\n\n网络包接收流程\n\n网卡会将收到的网络数据帧通过DMA的方式放到环形缓冲区RingBuffer（环形缓冲区，满了就丢弃）中（可通过ifconfig命令查看网卡收发数据的情况），DMA操作完后网卡会向CPU发起一个硬中断，对应中断处理程序为网络数据帧创建内核数据结构sk_buffer（sk_buffer是双向链表，每一个元素是一个网络帧，网络各层之间操作相关指针而不是复制数据）并拷贝收到的网络数据帧，然后向kernel发起软中断请求（软中断和硬中断在同一个CPU核上）\n\n为了解决频繁中断带来的性能开销，Linux 2.6 版本引入了 NAPI 机制，它是混合「中断和轮询」的方式来接收网络包，它的核心概念就是不采用中断的方式读取数据，而是首先采用中断唤醒数据接收的服务程序，然后 poll 的方法来轮询数据\n硬中断：先暂时屏蔽中断，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。接着，发起软中断，然后恢复刚才屏蔽的中断。\n\n\n内核线程ksoftirqd（一个CPU一个）响应软中断请求，调用网卡驱动注册的poll函数，poll函数将sk_buffer中的网络数据包送到内核协议栈中注册的ip_rcv函数\n\nip_rcv函数处在网络层，该函数取出IP头并判断下一跳走向，如果是本机则取出传输层协议类型（TCP或UDP），并去掉数据包的IP头，将数据包交给传输层处理（TCP协议使用tcp_rcv函数，UDP协议使用udp_rcv函数）\n\ntcp_rcv函数会去掉TCP头，根据四元组（源IP、源端口、目的IP，目的端口）查找对应的Socket，如果找到则将数据包中的数据拷贝到Socket中的接收缓冲区，否则发送一个目标不可达的icmp包\n\n当程序调用read读取Socket接收缓冲区的数据时，如果接收缓冲区没有数据则会阻塞在系统调用上，知道Socket接收缓冲区有数据。然后CPU将内核空间（Socket接收缓冲区）的数据拷贝到用户空间，最后系统调用read返回，应用程序读取数据\n\n\n\n\n网络包发送流程\n\n应用程序调用send发送数据，kernel首先根据fd找到对应的socket（包含各种协议栈的函数地址），然后构造msghdr对象封装用户要发送的数据。调用内核函数inet_sendmsg发送流程进入内核协议栈来处理，找到socket上具体协议的发送函数（TCP协议发送函数tcp_sendmsg，UDP协议发送函数udp_sendmsg）\n\ntcp_sendmsg函数内部创建内核数据结构sk_buffer将msghdr中的数据拷贝到sk_buffer中，调用tcp_write_queue_tail函数获取Socket发送队列中的队尾元素，将sk_buffer添加到socket发送队列（双向链表）的尾部\n此时数据已经被拷贝到内核，但是因为TCP的流量控制和拥塞控制，所以数据并不会被马上发送，需要符合TCP协议的发送条件。如果没有达到发送条件则本次send系统调用就会直接返回，如果符合发送条件，则调用tcp_write_xmit内核函数，循环获取socket发送队列中待发送的sk_buffer，然后进行拥塞控制和滑动窗口管理\n发送网络数据的时候，涉及几次内存拷贝操作？\n第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。\n第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。\n第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。\n\n\n\n\n将从socket发送队列中获取到的sk_buffer重新拷贝一份，并设置sk_buffer副本中的TCP HEADER\n\nsk_buffer 内部其实包含了网络协议中所有的 header。在设置 TCP HEADER的时候，只是把指针指向 sk_buffer的合适位置。后面再设置 IP HEADER的时候，在把指针移动一下就行，避免频繁的内存申请和拷贝，效率很高\n\n\n为什么不直接使用Socket发送队列中的sk_buffer而是需要拷贝一份呢？因为TCP协议是支持丢包重传的，在没有收到对端的ACK之前，这个sk_buffer是不能删除的。内核每次调用网卡发送数据的时候，实际上传递的是sk_buffer的拷贝副本，当网卡把数据发送出去后，sk_buffer拷贝副本会被释放。当收到对端的ACK之后，Socket发送队列中的sk_buffer才会被真正删除\n\n为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包：sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame，通过调整 sk_buff 中 data 的指针来实现\n\n\n\n\n调用ip_queue_xmit内核函数进行网络层的处理\n\n将sk_buffer中的指针移动到IP头位置上，设置IP头\n执行netfilters过滤。过滤通过之后，如果数据大于 MTU的话，则执行分片\n检查Socket中是否有缓存路由表，如果没有的话，则查找路由项，并缓存到Socket中。接着在把路由表设置到sk_buffer中\n\n\n邻居子系统\n\n邻居子系统位于内核协议栈中的网络层和网络接口层之间，用于发送ARP请求获取MAC地址，然后将sk_buffer中的指针移动到MAC头位置，填充MAC头，此时sk_buffer中已经封装了一个完整的数据帧\n\n\n网络设备子系统\n\n选择发送队列（RingBuffer），因为网卡拥有多个发送队列，所以在发送前需要选择一个发送队列\n\n将sk_buffer添加到发送队列中\n\n循环从发送队列（RingBuffer）中取出sk_buffer，调用内核函数sch_direct_xmit发送数据，其中会调用网卡驱动程序来发送数据\n\n\n\n无论是用户线程的内核态还是触发NET_TX_SOFTIRQ类型的软中断在发送数据的时候最终会调用到网卡的驱动程序函数dev_hard_start_xmit来发送数据。在网卡驱动程序函数dev_hard_start_xmit中会将sk_buffer映射到网卡可访问的内存 DMA 区域，最终网卡驱动程序通过DMA的方式将数据帧通过物理网卡发送出去\n\n前文a-e是用户线程的内核态在执行，占用的CPU时间是系统态时间(sy)，当分配给用户线程的CPU quota用完的时候，会触发NET_TX_SOFTIRQ类型的软中断，内核线程ksoftirqd会响应这个软中断，并执行NET_TX_SOFTIRQ类型的软中断注册的回调函数net_tx_action，在回调函数中会执行到驱动程序函数 dev_hard_start_xmit来发送数据\n从这里可以看到网络包的发送过程和接受过程是不同的，在介绍网络包的接受过程时，通过触发NET_RX_SOFTIRQ类型的软中断在内核线程ksoftirqd中执行内核网络协议栈接受数据。而在网络数据包的发送过程中是用户线程的内核态在执行内核网络协议栈，只有当线程的CPU quota用尽时，才触发NET_TX_SOFTIRQ软中断来发送数据\n在整个网络包的发送和接受过程中，NET_TX_SOFTIRQ类型的软中断只会在发送网络包时并且当用户线程的CPU quota用尽时，才会触发。剩下的接受过程中触发的软中断类型以及发送完数据触发的软中断类型均为NET_RX_SOFTIRQ。所以这就是在服务器上查看 /proc/softirqs，一般 NET_RX都要比 NET_TX大很多的的原因\n\n\n当数据发送完毕后，还有最后一项重要的工作，就是清理工作。数据发送完毕后，网卡设备会向CPU发送一个硬中断，CPU调用网卡驱动程序注册的硬中断响应程序，在硬中断响应中触发NET_RX_SOFTIRQ类型的软中断，在软中断的回调函数igb_poll中清理释放 sk_buffer，清理网卡发送队列（RingBuffer），解除DMA映射\n\n无论硬中断是因为有数据要接收，还是说发送完成通知，从硬中断触发的软中断都是 NET_RX_SOFTIRQ\n这里释放清理的只是sk_buffer的副本，真正的sk_buffer现在还是存放在Socket的发送队列中。前面在传输层处理的时候我们提到过，因为传输层需要保证可靠性，所以 sk_buffer其实还没有删除。它得等收到对方的 ACK 之后才会真正删除\n\n\n\n\n补充问题：\n\n假设这样一个场景，客户端在和服务端进行TCP的三次握手的过程中，突然间客户端宕机了，那么这个socket怎么处理？可以删除吗？是怎么删除的？\n因为它尚未确认客户端的连接请求，服务端会继续保持等待状态，可以通过操作系统的TCP/IP协议栈中的一些机制来最终释放未完成的连接，如下：\n超时机制： TCP协议栈通常会启用一个超时机制，等待一段时间来确保客户端在握手过程中宕机后仍然不可用。一旦超过一定时间（通常几分钟），TCP协议栈将放弃等待，并关闭连接。\nTCP状态管理： TCP连接具有不同的状态，包括CLOSE_WAIT、TIME_WAIT等。如果服务端在等待客户端完成连接时检测到客户端宕机，它将尝试将连接状态设置为CLOSE_WAIT（表示等待关闭），然后等待一段时间，最终将连接状态设置为CLOSED。\n资源释放： 一旦连接状态变为CLOSED，相关资源（包括文件描述符、内存等）将被释放，从而完成连接的清理。\n\n\n\n\n在服务端调用accept()之后,socket就是一直可读的吗？就是调用read()函数就一直可以读吗？会阻塞吗？\n在服务端调用accept()函数之后，返回的新套接字（socket）是可读的，但并不意味着它一直可以读取数据，也不会一直阻塞\nread()可能阻塞： 调用read()函数时，如果没有可用的数据，它会阻塞，等待数据到达。这意味着如果没有数据可读，read()将一直阻塞，直到有以下情况之一发生（可以设置套接字为非阻塞模式，以确保read()不会无限阻塞）\n客户端重新连接并发送数据：如果客户端重新连接到服务端并发送数据，服务端的read()函数将解除阻塞，并开始读取新的数据。\n超时或错误：如果服务端设置了超时选项或发生了错误条件，read()函数可能会返回一个错误，指示连接已关闭或发生了其他问题。\n\n\n\n\n\n\n\n2.网络设备\n路由器和交换机的区别\n工作层次不同：\n交换机主要工作在数据链路层（第二层）\n路由器工作在网络层（第三层）\n\n\n转发依据不同：\n交换机转发所依据的对象时：MAC地址。（物理地址）\n路由转发所依据的对象是：IP地址。（网络地址），因为只处理MAC地址匹配路由器的网络爆\n\n\n主要功能不同：（交换机能做的，路由都能做。）\n交换机主要用于组建局域网，不能分割广播域\n而路由主要功能是将由交换机组好的局域网相互连接起来，或者接入Internet，可以提供防火墙功能\n\n\n\n\n\n3.命令行\nping：\n\nnetstat -napt：查看TCP的连接状态\n\n\nroute -n：查看当前系统的路由表，将目的IP与掩码与操作得到的结果与Destination比较，相同则走对应的iface（网卡）\n\n第三条是默认网关：如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器（Gateway即对应路由器的IP地址）\n\n\n\narp -a 查看 ARP 缓存的内容，记录IP与MAC的映射关系\n\n\n\n4.RPC\n为什么有HTTP协议了?还要用RPC?\nRPC 本质上不算是协议，而是一种调用方式，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，不一定非得基于 TCP 协议。\n从发展历史来说，HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。\nRPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP/1.1 性能要更好，所以大部分公司内部都还在使用 RPC。\nHTTP/2.0在 HTTP/1.1的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。\n返回的信息：HTTP所蕴含的信息不够丰富，通信双方的执行状态只能够通过状态码来描述，但RPC框架可以返回完整的异常信息\nHTTP的编码冗余，需要定义一大堆的状态码来定义当前的状态，对于不同的服务，这些编码还有不同的含义\nHTTP通常用于前端和后端的通信，包含大量浏览器跳转状态定义，这些定义对于后端服务器之间的联调没有意义；但RPC自定义的协议可以去除这些冗余的状态，更加定制化地进行后端联调\n\n\n\n5.CDN\nCDN 将内容资源分发到位于多个地理位置机房中的服务器上，这样我们在访问内容资源的时候，不用访问源服务器。而是直接访问离我们最近的 CDN 节点 ，这样一来就省去了长途跋涉的时间成本，从而实现了网络加速\n\n找到离用户最近的 CDN 节点是由 CDN 的全局负载均衡器（*Global Sever Load Balance，GSLB*）负责的。\n\n在没有 CDN 的情况下，访问域名时，通过DNS 服务器返回源服务器的地址\n\n在有CDN的情况下会在 xiaolin.com 这个 DNS 服务器上，设置一个 CNAME 别名，指向另外一个域名 www.xiaolin.cdn.com，返回给本地 DNS 服务器。\n\n接着继续解析该域名，这个时候访问的就是 xiaolin.cdn.com 这台 CDN 专用的 DNS 服务器，在这个服务器上，又会设置一个 CNAME，指向另外一个域名，这次指向的就是 CDN 的 GSLB。\n\n接着，本地 DNS 服务器去请求 CDN 的 GSLB 的域名，GSLB 就会为用户选择一台合适的 CDN 节点提供服务，选择的依据主要有以下几点：\n\n看用户的 IP 地址，查表得知地理位置，找相对最近的 CDN 节点；\n看用户所在的运营商网络，找相同网络的 CDN 节点；\n看用户请求 URL，判断哪一台服务器上有用户所请求的资源；\n查询 CDN 节点的负载情况，找负载较轻的节点；\n\n\nGSLB 会基于以上的条件进行综合分析后，找出一台最合适的 CDN 节点，并返回该 CDN 节点的 IP 地址给本地 DNS 服务器，然后本地 DNS 服务器缓存该 IP 地址，并将 IP 返回给客户端，客户端去访问这个 CDN 节点，下载资源\n\n\n\n\n\n6.Restful API\n过滤信息：如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果\n\n?limit=10：指定返回记录的数量\n?offset=10：指定返回记录的开始位置\n?page=2&amp;per_page=100：指定第几页，以及每页的记录数\n?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序\n?animal_type_id=1：指定筛选条件\n\n\nURL路径：避免层级过深、不能有动词、首选小写字母\n\nURI和URL的区别\n\nURI（统一资源标识符）： URI是一个通用的标识符，用于唯一标识资源。它可以标识任何资源，包括但不限于互联网上的资源。URI分为两种主要子集：URL和URN（Uniform Resource Name）。\nURL（统一资源定位符）： URL是URI的一个子集，它不仅标识资源，还提供了如何定位和访问这些资源的信息。URL包括协议（例如http、https、ftp）、主机名、端口号、路径和查询参数等信息，用于精确定位资源的位置和访问方式。URL通常用于访问互联网上的资源，如网页、图片、文件等。\nURN（统一资源名称）： URN也是URI的一个子集，它用于标识资源的名称，而不提供关于如何访问资源的信息。URN通常用于命名资源，而不是定位和访问资源。例如，ISBN（国际标准书号）就是一种URN，用于唯一标识图书。\n\n\n\n","slug":"Internet","date":"2023-08-02T14:26:24.000Z","categories_index":"","tags_index":"","author_index":"Dajunnnnnn"},{"id":"0b1381c4a63c09e41167c5168339035a","title":"JVM","content":"JVM1.编译执行\n\n\n\n\n\n\n\n\n如何实现跨平台：通过不同平台的JVM实现来将相同的一个Class文件翻译成适配不同机器的机器语言用于执行，即使打包成可还行文件仍需要JVM的支持\n\nJava程序的执行过程\n\nJAVA源代码编译成字节码；字节码校验并把JAVA程序通过类加载器加载到JVM内存中，在加载到内存后针对每个类创建Class对象并放到方法区；字节码指令和数据初始化到内存中；\n找到main方法，并创建栈帧；初始化程序计数器内部的值为main方法的内存地址；\n程序计数器不断递增，逐条执行JAVA字节码指令，把指令执行过程的数据存放到操作数栈中（入栈），执行完成后从操作数栈取出后放到局部变量表中，遇到创建对象，则在堆内存中分配一段连续的空间存储对象，栈内存中的局部变量表存放指向堆内存的引用；遇到方法调用则再创建一个栈帧，压到当前栈帧的上面。\n\n\n编译链接：前端编译、类加载、解释执行、JIT编译执行\n\n\n前端编译：将.java文件编译成.class文件，由javac编译器来完成，通过词法分析、语法分析、语义分析等方法将源代码翻译成字节码，并且还包括特有的注解处理、解语法糖操作\n\n注解处理：JDK6开始，可以开发注解插件，前端编译会调用注解插件如Lombok根据@getter、@setter为类的变量生成方法\n\n解语法糖：Java一开始就注重开发效率，所以Java很适合做业务系统开发，C/C++更适合做底层的系统级开发，为了提高效率，通过对基本语法进行二次封装，来提高易用性，在前端编译的时候会还原为基本语法\n\n泛型：类型擦除，只用于编译时的类型检查\n\n自动拆装箱：方便基本类型和包装类的互相转换，底层使用valueof、xxxvalue实现\n\nfor-each循环：底层依赖迭代器遍历\n\n匿名内部类：单独生成一个class文件，名字由JVM指定如下\npublic class A&#123;&#x2F;&#x2F;A.class\n  public class B&#123;&#125;&#x2F;&#x2F;内部类，编译为A$B.class\n  public void f()&#123;\n    Thread t1 &#x3D; new Thread(new Runnable()&#123;&#x2F;&#x2F;匿名内部类，编译为A$1.class\n      @Override\n      public void run()&#123;\n        System.out.println(&quot;anonymous inner class.&quot;);\n      &#125;\n    &#125;);\n  &#125;\n&#125;\n\n\n\n\n类加载\n\n在Java应用中，类的字节码是按需加载到内存中的，当第一次创建某个类的对象，或调用某个类的方法时，会将这个类加载到内存中，之后便一直保存在内存中\n类加载过程包括验证、准备、解析、初始化等步骤，类的加载遵从双亲委派机制，不同的类有不同的classLoader加载器来加载\n\n\n解释执行\n\n对于C/C++，代码会被事先编译出机器指令（可执行文件），然后再交由CPU来执行；对于Java来说，编译出的.class文件，需要由JVM逐条取出，边解释为机器码，边交由CPU执行\n比如说在使用Demo类对象的创建语句时，如果内存中没有Demo类的字节码信息，会通过类加载器在classpath对应的路径下查找Demo.class，并将其加载到内存中，后续虚拟机根据对象demo中的类指针，找到内存中的Demo类，然后在类的方法中找函数对应的字节码，逐句解释执行\n\n\nJIT编译执行\n\n解释执行的效率比较低，所以引入JIT（Just-In-Time）编译执行，对于一些热点代码，可以将其编译为机器码并存储下来，跳过解释执行\nAOT（Ahead Of Time Compile）编译，运行前编译，类似于C/C++的编译（移植性由程序员来运行），但是仍支持一次编写，到处运行的特点，代码的可移植性有AOT编译器来负责\n\n\n\n\nJIT编译：JIT编译器及JVM运行模式（Client、Server）、分层编译（解释执行、不带/部分/所有编译优化的Client、Server）、热点探测（优化的对象是方法方法，调用计数器、回边计数器、阈值、调用计数器的热度衰减机制）\n\nJIT编译器\nHotSpot支持两种JIT编译器\nClient编译器（C1编译器）：只进行局部的编译优化，编译时间短，编译优化程度低\nServer编译器（C2编译器）：进行局部和全局优化，编译时间长，编译优化程度高\n\n\n有两种JIT编译器引出JVM有两种运行模式，Client模式和Server模式，对于长时间运行的服务器程序，可以使用Server模式\n\n\n分层编译\nJava7之前只能通过参数指定，但是Java7引入了分层编译的技术，JVM可以根据代码、运行情况来选择不同的编译类型，主要分为5个层级（见下），Java8开始默认开启分层编译技术，关闭时直接使用Server编译器\n解释执行\n使用不带编译优化的Client编译器\n使用仅带部分编译优化的Client编译器\n使用带有所有编译优化的Client编译器\n使用Server编译器\n\n\n\n\n热点探测\n热点代码：主要包括被多次执行的方法和被多次执行的循环，JIT编译的对象是方法，对循环的编译是循环编译循环所在方法\n计数器：HotSpot使用计数器来统计方法或循环的执行次数，分别为方法调用计数器（方法的执行次数）和回边计数器（方法内循环的执行次数）\n阈值：调用计数器和回边计数器的总和超过阈值，JVM就会进行JIT编译\nClient编译器：1500\nServer编译器：10000\n分层编译：动态阈值，根据当前编译方法数以及编译线程数动态计算得到\n\n\n热度衰减机制：防止因为运行时间长而超过阈值的代码被判定为成热点代码，此机制（通过-XX:-UseCounterDecay开关）在超过一定的时间（通过-XX:CounterHalfLifeTIme设置）限制之后，如果某个方法没有达到触发JIT编译的阈值要求，那么这个方法的方法计数器的值就减半，回边计数器不存在此机制\n\n\n\n\n编译优化：JIT编译优化策略（方法内联、逃逸分析、无用代码消除、循环展开、消除公共子表达式、范围检查消除、空值检查消除）\n\n减少无效、冗余代码，以便生成高效的机器码\nJIT编译优化策略\n方法内联：达到阈值的方法嵌入、final方法触发内联\n将短小的函数嵌入到函数调用处，通过内存的增加减少时间的消耗\n内联要求：\n函数短小（字节码小于325字节）+调用次数（大于等于100次）\n字节码（小于35字节）+方法调用次数（少于100次）\n\n\nfinal：final方法会触发方法内联，特别是多态的情况下，因为final声明的函数不会被重载，所以可以直接通过类的方法来内联，而不用分析是否有重载变化函数的情况\n\n\n逃逸分析：栈上分配（将对象分配到栈上）、标量替换（使用基本类型替换对象的成员变量）、锁消除（去掉无多线程并发访问的代码）\nJIT编译器通过分析对象的使用范围来优化对象的内存存储方式和访问方式，针对不同的逃逸分析结果，有三种策略\n栈上分配：编译器分析完，发现某个对象使用范围仅限于某个函数内部（没有逃逸到方法外），就可以启动栈上分配编译优化，将对象作为局部变量直接分配在栈上\n标量替换：如果某个对象只在某个函数内使用，并且函数内只访问对象的基本类型成员变量等标量数据，就可以使用基本类型变量替代对象\n锁消除：对不存在多线程并发访问的代码（逃逸到线程外），编译器会去掉其中保证线程安全的加锁逻辑\n\n\n\n\n\n\n\n\n类文件（class文件）结构详解\n\nclass文件由ClassFile结构定义，类似于C语言的结构体\nClassFile &#123;\n    u4             magic; &#x2F;&#x2F;Class 文件的标志，确定这个文件是否是一个能被虚拟机接收的class文件\n    u2             minor_version;&#x2F;&#x2F;Class 的小版本号\n    u2             major_version;&#x2F;&#x2F;Class 的大版本号\n    u2             constant_pool_count;&#x2F;&#x2F;常量池的数量\n    cp_info        constant_pool[constant_pool_count-1];&#x2F;&#x2F;常量池，计数器从1开始，0项代表不引用任何一个常量池选项\n    u2             access_flags;&#x2F;&#x2F;Class 的访问标记，标识class是类还是接口，是否为public或者abstract，是否声明final\n    u2             this_class;&#x2F;&#x2F;当前类\n    u2             super_class;&#x2F;&#x2F;父类 Object的父类索引为0\n    u2             interfaces_count;&#x2F;&#x2F;接口\n    u2             interfaces[interfaces_count];&#x2F;&#x2F;一个类可以实现多个接口\n    u2             fields_count;&#x2F;&#x2F;Class 文件的字段属性\n\n\t\t&#x2F;&#x2F;字段作用域、字段的名称、字段和方法的描述符、字段的额外属性、具体属性具体内容\n    field_info     fields[fields_count];&#x2F;&#x2F;一个类可以有多个字段，用于描述接口或类中声明的变量\n    u2             methods_count;&#x2F;&#x2F;Class 文件的方法数量\n\n\t\t&#x2F;&#x2F;方法表的结构如同字段表一样，依次包括了访问标志、名称索引、描述符索引、属性表集合几项\n    method_info    methods[methods_count];&#x2F;&#x2F;一个类可以有个多个方法\n    u2             attributes_count;&#x2F;&#x2F;此类的属性表中的属性数\n    attribute_info attributes[attributes_count];&#x2F;&#x2F;属性表集合\n&#125;\n示例\n\n\n\n\nnew一个对象的过程\n\n类加载：首先，JVM会检查并加载该类的字节码文件。如果该类还没有被加载，它将被加载到内存中。\n分配内存：一旦类被加载，JVM会为对象分配内存空间。这通常发生在堆内存中，但也可能在某些情况下发生在栈上\n初始化：在分配内存后，JVM会调用类的构造函数（构造方法）来初始化对象。构造函数负责为对象的属性设置初始值，也可以执行其他初始化任务。这个过程可能涉及到其他对象的创建和初始化。\n对象创建完成：一旦构造函数执行完毕，对象就被认为是完全创建好的，可以在程序中使用。\n对象使用：你可以在程序中使用该对象，访问其属性和方法。\n对象不再被引用：当对象不再被任何引用变量引用时，它就成为不可达对象。这时，该对象就变得可被垃圾收集器回收。\n垃圾回收：JVM的垃圾收集器会定期扫描堆内存，找出不可达对象，并释放其占用的内存。这个过程被称为垃圾回收。\n\n\n类卸载\n\n卸载类需要满足 3 个要求：\n该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象\n该类没有在其他任何地方被引用\n该类的类加载器的实例已被 GC\n\n\n所以，在 JVM 生命周期内，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的\nJDK 自带的BootstrapClassLoader、ExtClassLoader、AppClassLoader负责加载 JDK 提供的类，所以它们(类加载器的实例)肯定不会被回收。而我们自定义的类加载器的实例是可以被回收的，所以使用我们自定义加载器加载的类是可以被卸载掉的\n\n\n\n2.类加载器\n类加载：类加载过程（验证、准备、解析、初始化）、类加载器（启动类加载器、扩展类加载器、应用程序类加载器）\n\n类加载过程：JVM将类的二进制字节码加载到内存中，以便创建类的对象或者执行类上的方法\n\n验证：验证所加载的类字节码格式是否符合JVM规范，防止被恶意篡改，由四个检验阶段组成\n\n\n准备：虚拟机为类的静态变量分配内存，并初始化为默认值\n\n对于static final修饰的静态常量，直接初始化指定值\n对于只有static修饰的变量，初始化为默认值（0、null、false等）而不是代码指定值，指定值会在下面的初始化阶段赋予\n\n\n解析：解析类似C++中的链接，把类字节码的常量池中的符号引用（间接引用）转换为直接引用\n\n解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符 7 类符号引用进行\n\n\n初始化：虚拟机执行静态变量的初始化代码，包括初始化语句（private static int a = 25;）、静态代码块（static &#123; a = 13; &#125;），这一步JVM才开始真正执行类中定义的Java程序代码，只有以下5种情况必须对类进行初始化\n\n当遇到 new、 getstatic、putstatic 或 invokestatic这 4 条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。\n当 jvm 执行 new 指令时会初始化类。即当程序创建一个类的实例对象。\n当 jvm 执行 getstatic 指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。\n当 jvm 执行 putstatic 指令时会初始化类。即程序给类的静态变量赋值。\n当 jvm 执行 invokestatic 指令时会初始化类。即程序调用类的静态方法。\n\n\n使用 java.lang.reflect 包的方法对类进行反射调用时如 Class.forname(&quot;...&quot;), newInstance() 等等。如果类没初始化，需要触发其初始化。\n初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。\n当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。\nMethodHandle 和 VarHandle 可以看作是轻量级的反射调用机制，而要想使用这 2 个调用， 就必须先使用 findStaticVarHandle 来初始化要调用的类。\n补充：当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化\n\n\n\n\n类加载机制：启动类加载器、扩展类加载器、应用程序类加载器、双亲委派机制\n\nJVM定义的类加载器\n启动类加载器（BootStrap ClassLoader）：负责加载$JAVA_HOME/jre/lib/rt.jar包中的类\n扩展类加载器（Extension ClassLoader）：负责加载$JAVA_HOME/jre/lib/ext目录下的jar包中的类\n应用程序类加载器（Application ClassLoader）：负责加载classpath所指定路径下的其余类\n\n\n双亲委派机制：见下2\n\n\n自定义类加载器：继承自ClassLoader类的子类，重写findClass函数，可以指定父类加载器\n\n定义继承自ClassLoader类的子类，重写findClas函数（loadClass方法可以加载指定二进制名称的类）\n&#x2F;&#x2F;从文件系统的绝对路径下读取类的二进制字节码，通过调用CLassLoader的defineClass函数将二进制的\n&#x2F;&#x2F;字节码转化成Class对象，以此来实现一个加载特定路径下的类的加载器\npublic class FileSystemClassLoader extends ClassLoader&#123;\n  private String rootDir;\n\t&#x2F;&#x2F;通过构造函数指定父类加载器\n  public FileSystemClassLoader(String rootDir)&#123;\n    this.rootDir &#x3D; rootDir;\n  &#125;\n\n  @Override\n  protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException&#123;\n\t\t&#x2F;&#x2F;绝对路径\n    String path &#x3D; rootDir + File.separatorChar + name.replace(&#39;.&#39;, File.separatorChar) + &quot;.class&quot;;\n    byte[] bytecode &#x3D; null;\n\t\t\n    try(InputStream input &#x3D; new FileInputStream(path))&#123;\n      ByteArrayOutputStream byteStream &#x3D; new ByteArrayOutputStream();\n      byte[] buffer &#x3D; new byte[4096];\n      int readSize &#x3D; 0;\n\t\t\t&#x2F;&#x2F;读入二进制字节码\n      while((readSize &#x3D; input.read(buffer)) !&#x3D; -1)&#123;\n\t\t\t\t&#x2F;&#x2F;写出到流中\n        byteStream.write(buffer, 0, readSize);\n      &#125;\n\t\t\t&#x2F;&#x2F;写入到字节数组\n      bytecode &#x3D; byteStream.toByteArray();\n    &#125;catch(FileNotFoundException | IOException e)&#123;\n      e.printStackTrace();\n    &#125;\n    if(bytecode &#x3D;&#x3D; null)&#123;\n      throw new ClassNotFoundException(&quot;class name:&quot; + name);\n    &#125;else&#123;\n\t\t\t&#x2F;&#x2F;生成class对象\n      return defineClass(name, bytecode, 0, bytecode.length);\n    &#125;\n  &#125;\n&#125;\npublic class Demo&#123;\n  public static void main(Stringp[] args) throws ClassNotFoundException&#123;\n    ClassLoader classLoader &#x3D; new FileSystemClassLoader(&quot;&#x2F;Users&#x2F;dajunnnnnn&quot;);\n    Class&lt;?&gt; clazz &#x3D; classLoader.loadCLass(&quot;com.code.hello&quot;);\n    System.out.println(clazz.getClassLoader());&#x2F;&#x2F;打印SystemFileClassLoader对象信息\n  &#125;\n&#125;\nClassLoader是一个模版方法模式类，其中的loadClass函数是模版方法，里面包含类加载的整个逻辑，比如双亲委派机制的实现逻辑，findClass函数为模版方法模式中的抽象方法，被loadClass函数使用，用来根据类名查找类\nprotected Class&lt;?&gt; loadClass(String name, boolean resolve)\n  throws ClassNotFoundException\n&#123;\n  synchronized (getClassLoadingLock(name)) &#123;\n    &#x2F;&#x2F; First, check if the class has already been loaded\n    Class&lt;?&gt; c &#x3D; findLoadedClass(name);\n    if (c &#x3D;&#x3D; null) &#123;\n      long t0 &#x3D; System.nanoTime();\n      try &#123;\n        if (parent !&#x3D; null) &#123;\n          c &#x3D; parent.loadClass(name, false);\n        &#125; else &#123;\n          c &#x3D; findBootstrapClassOrNull(name);\n        &#125;\n      &#125; catch (ClassNotFoundException e) &#123;\n        &#x2F;&#x2F; ClassNotFoundException thrown if class not found\n        &#x2F;&#x2F; from the non-null parent class loader\n      &#125;\n\n      if (c &#x3D;&#x3D; null) &#123;\n        &#x2F;&#x2F; If still not found, then invoke findClass in order\n        &#x2F;&#x2F; to find the class.\n        long t1 &#x3D; System.nanoTime();\n        c &#x3D; findClass(name);\n\n        &#x2F;&#x2F; this is the defining class loader; record the stats\n        sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);\n        sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);\n        sun.misc.PerfCounter.getFindClasses().increment();\n      &#125;\n    &#125;\n    if (resolve) &#123;\n      resolveClass(c);\n    &#125;\n    return c;\n  &#125;\n&#125;\n默认情况下自定义类加载器的父类为应用程序类加载器，可以在构造函数中指定自定义类加载器的父类加载器\n\n\n\n\n\n双亲委派机制：用来确定类加载器，定义了类加载器之间的父子关系，从子类找到父类再从父类开始向下搜索\n\n当JVM无法根据全限定名（java.lang.StringUtils）找到路径和对应的类加载器时，虚拟机需要通过在各个类加载器所负责的路径下查找这个类，当有重复的时候，需要机制来确定加载哪一个类，所以虚拟机设计了双亲委派机制\n\n双亲委派机制：定义了类加载器之间的父子关系\n\nClassLoaderB的父类加载器为ClassloaderA（B继承自A）\nClassLoaderA的父类加载器为AppClassloader\nAppClassLoader的父类加载器为ExtClassLoader\nExtClassLoader的父类加载器为null,实际为BootrapClassLoader\n由于其由C++代码实现，因此无法在打印结果中显示\n\n\n\n在某个类加载器接收到某个类的加载请求时（使用new或反射创建类的对象时，默认为请求应用程序类加载器加载对应的类），如果这个类加载器之前没有加载过这个类，那么他便委托父类加载器加载这个类，如果父类没有加载过则继续向上委托直到有类加载器加载了这个类，如果达到最顶层父类加载器还没有的话，就从上往下请求各个类加载器在自己负责的路径下查找并加载这个类\n\n\n双亲委派机制可以有效防止对核心类的恶意修改，比如在自己的路径下定义一个新的java.util.String类，请求应用程序类加载器来加载，意图覆盖核心类库中的String类，但是，基于双亲委派机制，应用程序类加载器会委托父类加载器来加载java.util.String类，最终仍然会由启动类加载器加载核心类库中的String类（因为是从上往下搜索）\n\n结合Tomcat说一下双亲委派机制\n\nTomcat中的类加载器\nBootstrap 类加载器：它是 Java 虚拟机的一部分，用于加载核心 Java 类库，例如 java.lang 包下的类。Tomcat 不会干预 Bootstrap 类加载器的工作。\nCatalina 类加载器：Catalina 是 Tomcat 的核心组件，它使用自定义的类加载器来加载 Tomcat 内部的类和核心库。\nShared 类加载器：Tomcat 的 Shared 类加载器用于加载位于 $CATALINA_BASE/lib 目录下的共享库（JAR 文件），这些库可以被不同的 Web 应用程序共享。\nWeb 应用程序类加载器：每个 Web 应用程序在 Tomcat 中都有自己的类加载器。这个类加载器负责加载特定 Web 应用程序的类和资源，位于该应用程序的 WEB-INF/classes 和 WEB-INF/lib 目录下的类和 JAR 文件。\n\n\n在 Tomcat 中，双亲委派机制有助于隔离不同 Web 应用程序之间的类加载，确保它们不会相互干扰或冲突。这意味着每个 Web 应用程序都有自己的类加载器，它们首先尝试委派给父加载器加载类，只有在父加载器找不到类的情况下才会尝试自己加载。这种隔离性和优先级机制有助于确保各个 Web 应用程序在运行时能够安全地共存，不会因为类冲突而导致问题\n\n\n\n\n\n3.Java内存区域\n内存分区：方法区（一些不变的信息）、堆（对象，垃圾回收器管理）、程序计数器、虚拟机栈和本地方法栈、直接内存（操作系统管理）\n\n\n方法区：类信息、方法信息、静态变量、运行时常量池、字符串常量池、JIT编译代码缓存\n\n存储内容：类信息（类的全限定名、访问修饰符、符类、接口列表）、方法信息（方法名、修饰符、入参、返回值、访问标志）、静态变量（隶属于类，存在方法区）、运行时常量池（类字节码中的常量池，存储字面量和符号引用）、字符串常量池、JIT编译代码缓存\n\n常量池中每一项常量都是一个表，这 14 种表有一个共同的特点：开始的第一位是一个 u1 类型的标志位 -tag 来标识常量的类型，代表当前这个常量属于哪种常量类型（.class文件可以通过javap -v class名，来查看常量池中的信息（temp.txt））\n\n\n运行时常量池：存放编译器生成的各种字面量和符号引用\n\n字面量：源代码中的固定值的表示法，包括整数、浮点数、字符串字面量\n符号引用：类/接口符号引用（全限定名）、字符符号引用（名称和描述符）、方法符号引用（名称和描述符）\n符号引用：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时无歧义地定位到目标即可，与虚拟机内存布局无关，引用他的目标不一定是已经加载到虚拟机内存中的内容\n直接引用：是可以指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄，与虚拟机内存布局直接相关\n\n\n运行时常量池的功能类似于传统编程语言的符号表，但它包含了比典型符号表更广泛的数据。既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。\n\n\n字符串常量池：\n\nHotSpot 虚拟机中字符串常量池的实现是src/hotspot/share/classfile/stringTable.cpp，StringTable本质上是一个HashSet&lt;String&gt;，容量为StringTableSize，可以通过-XX:StringTableSize参数来设置\nStringTable中保存的是字符串对象的引用，字符串对象的引用指向堆中的字符串对象\nJDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中\n原因：主要是因为永久代（方法区实现）的 GC 回收效率太低，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时地回收字符串内存\n\n\n\n\n\n\n方法区是一种抽象分区，不同JVM可以有不同的实现方式\n\nJava7之前实现为永久代\nJava7方法区的字符串常量池和静态变量从永久代中移除，放入堆中\nJava7之后永久代被元空间（Metaspace）取代，但字符串常量池和静态常量仍存储在堆中\n整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整，而元空间使用的是本地内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小，可以使用 -XX：MaxMetaspaceSize标志设置最大元空间大小\n元空间里面存放的是类的元数据，这样加载多少类的元数据就不由MaxPermSize控制了, 而由系统的实际可用空间来控制，这样能加载的类就更多了\n\n\n\n\n方法区常用JVM参数\n\nJDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小\n-XX:PermSize&#x3D;N &#x2F;&#x2F;方法区 (永久代) 初始大小\n-XX:MaxPermSize&#x3D;N &#x2F;&#x2F;方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen\nJDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是本地内存。下面是一些常用参数\n-XX:MetaspaceSize&#x3D;N &#x2F;&#x2F;设置 Metaspace 的初始（和最小大小）\n-XX:MaxMetaspaceSize&#x3D;N &#x2F;&#x2F;设置 Metaspace 的最大大小\n\n\n\n\n程序计数器：线程私有的，PC寄存器是线程共享的\n\n虚拟机相当于一个抽象的计算机，也有自己的指令集（字节码集），因此也需要一个存储单元（程序计数器）用来存储下一条要执行的字节码的地址\n与PC寄存器不同的地方在于：PC寄存器是线程共享的，PC寄存器会随着线程的切换而进行保存和恢复，程序计数器是线程私有的，每个线程都会分配一个独立的程序计数器，记录当前线程执行到哪一行字节码（因为程序计数器位于内存而不是CPU，资源丰富，线程独享能减少线程上下文切换的信息量，有利于提高线程切换的速度）\n\n\n堆：用来存储Java对象，在Java中对象的回收是有虚拟机中的垃圾收集器自动完成的，堆是垃圾收集器的主要工作分区\n\n新生代（Young Generation）：主要用于存放新创建的对象实例，进一步可以分为以下三个区域，垃圾回收主要采用标记-复制算法\n\nEden 区：这是对象的初始分配区域，大多数新创建的对象都会被分配到这里\nSurvivor 区（通常有两个，分别称为 From 和 To 区）：Eden 区中的对象经过一次垃圾回收后，仍然存活的对象会被移动到 Survivor 区\n\n\n老年代（Tenured/Old Generation）：主要用于存储长时间存活的对象实例，当对象在新生代经过多次垃圾回收后仍然存活就会晋升到老年代，垃圾回收主要采用标记-清除和标记-整理算法\n\n\n\n虚拟机栈：函数调用中，主要用栈存储函数的局部变量、参数、返回地址等信息。栈是线程私有的，每个线程会有一个栈，因此也叫线程栈。Java中的栈叫做虚拟机栈\n\n栈帧中主要有以下几方面\n局部变量表：存放了编译器可知的各种数据类型、对象引用，分为若干slot，第一个slot存this，其余先是方法参数列表，然后是方法内创建的变量（int、boolean、char、Object这种都只占一个slot，如果遇到long或者double类型的，则占用两个slot来存储）\n操作数栈：主要作为方法调用的中转站使用，用于存放方法执行过程中产生的中间结算结果或临时变量\n动态链接：主要服务一个方法需要调用其他方法的场景，常量池中保存了大量的符号引用（方法引用的符号引用），当一个方法调用其他方法时，需要将常量池中指向方法的符号引用转化为其内存地址的直接引用，这个过程就是动态链接\n方法返回地址\n\n\nreturn和抛出异常都会导致栈帧被弹出\n程序运行中栈可能会出现的两种错误\nStackOverFlowError： 若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误\nOutOfMemoryError： 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常\n\n\n\n\n本地方法栈：服务于native方法（C/C++）的栈，HotSpot中，两个栈被合并为一个栈\n\nJava提供了很多使用C/C++实现的native方法，在JVM规范中，Java将服务于Java方法调用的栈，跟服务于native方法调用的栈做了区分，服务于Java方法调用的栈称为虚拟机栈，服务于native方法调用的栈称为本地方法栈\n两个栈的功能相同，在具体的虚拟机实现中，如HotSpot中，把两栈合并为一个栈，同时存储Java方法调用的栈帧和native方法调用的栈帧\n默认线程栈的大小：不同平台下有区别，HotSpot默认的每个线程的栈大小为1MB（可更改）\n\n\n直接内存：在本地内存分配，直接受操作系统管理，减少垃圾回收对程序的影响，用于NIO基于通道和缓存区的I/O方式，\n\n直接内存是一种特殊的内存缓冲区，并不在 Java 堆或方法区中分配的，而是通过 JNI 的方式在本地内存上分配的。不是虚拟机运行的一部分，但是也会导致OutOfMemoryError错误出现\nJDK1.4 中新加入的NIO(New Input/Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据\n堆外内存就是把内存对象分配在堆（新生代+老年代+永久代）以外的内存，这些内存直接受操作系统管理（而不是虚拟机），这样做的结果就是能够在一定程度上减少垃圾回收对应用程序造成的影响\n\n\n\n栈内存\n\n堆内存\n\n在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分：新生代内存(Young Generation)、老生代(Old Generation)、永久代(Permanent Generation)；JDK8版本之后，PermGen（永久）已被Metaspace（元空间）取代，元空间使用的是本地内存\n\n\n\n\n\n\nJava内存模型\n\n工作内存和主内存：Java 内存模型规定所有的变量都存储在主内存中，每个线程都有自己独立的工作内存，工作内存保存了对应该线程使用的变量的主内存副本拷贝。线程对这些变量的操作都在自己的工作内存中进行，不能直接操作主内存和其他工作内存中存储的变量或者变量副本。线程间的变量传递需通过主内存来完成，并且定义了定义了 8 种操作来完成主内存和工作内存的变量访问，三者的关系如下图所示。\n\n\nJava内存模型的三大特性\n\n原子性：Java 内存模型直接保证的原子性操作包括 read、load、use、assign、store、write、lock、unlock\n可见性：可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改\n实现方式：通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式\nvolatile：volatile 的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新，但是它并不能保证互斥性，也就是说多个线程并发修改某个变量时，依旧会产生多线程问题，一般用在一个线程写，其他线程读的场景\nsynchronized：由 “对一个变量执行 unlock 操作 之前，必须先把此变量同步回主内存中（执行 store、write 操作）” 这条规则获得\n\n\n有序性：单线程没有问题，多线程下由于指令重排，并发执行的正确性会受到影响（通过volatile和synchronized解决）\nvolatile 通过加入内存屏障指令来禁止内存的重排序，\nsynchronized 通过加锁，保证同一时刻只有一个线程来执行同步代码\n\n\n\n\n\n\n\n4.垃圾回收\n\n\n\n\n\n\n\n\nGC是JVM的一项重要功能，用于自动管理内存，回收不再使用的对象，以避免内存泄漏和OOM（Out of Memory）错误。流程主要有标记、清除、整理，即它通过标记不再被引用的对象，然后清除这些对象占用的内存。在某些情况下，还会对堆内存进行整理，以减少内存碎片\n\n可达性分析：判断哪些对象可以被回收，引用计数、STW、安全点、安全区\n\n引用计数：同可达性分析类似的判断对象是否可以被回收的算法，但是存在问题（无法检测循环引用，都为null计数不为0）不被JVM采用\n\n可达性分析：GC Roots、遍历（BFS、DFS）\n\n\n用有向图表示对象之间的引用关系，图中定点表示对象，有向边表示引用\nGC Roots：堆外变量所直接引用的堆内对象，包括虚拟机栈、本地方法栈中的局部变量所直接引用的对象，方法区中静态变量所直接引用的对象等\n虚拟机以GC Roots为起点，遍历（BFS或DFS）整个图，可以遍历到的对象为可达对象，遍历不到的对象被虚拟机当作垃圾回收\n\n\nSTW：运行在虚拟机上的用户线程和垃圾回收线程是并行的，垃圾回收是对象会被用户线程更改，可达性分析结果会有误报/漏报的情况\n\n误报：非存活对象误报为存活对象，等待再次垃圾回收\n漏报：漏报存活对象，从而将其判定为死亡对象。会产生严重的问题，导致本不该被回收的对象被回收，从而导致程序出错，解决此问题最简单的方法就是STW（Stop The World），即停止所有用户线程的执行，知道垃圾回收结束，因此会影响程序性能\n\n\n安全点：使用OopMap动态更新GC Roots，JVM为某个指令记录OopMap，这个指令就叫～\n\nGC Roots的获得方式：遍历栈中的局部变量和方法区中的静态变量，找出引用类型变量，然后，再将引用类型变量所引用的对象放入GC Roots中\n\n虚拟机使用OopMap来存储当前的GC Roots并动态更新，减少遍历耗时\n\n遍历查找GC Roots，初始化OopMap，在代码执行过程中，变量更新引用时，同步更新OopMap\n因为JIT编译后的机器码直接交由CPU执行，所以需要在编译成机器码之前静态分析指令，存储指令执行后的OopMap，浪费内存\n\n\n安全点：为了节约空间，虚拟机采用了时间换空间的策略，将为每个指令存储一个OopMap，改为只选取部分指令存储OopMap。这些被选取的指令称为安全点，当虚拟机启动垃圾回收并需要STW时，会向用户线程发送暂停的中断请求，此时，用户线程并不能立刻停止，而是需要运行到安全点之后才能停止，因为只有安全点处才记录了OopMap，只有所有线程都运行到安全点之后，虚拟机才能得到完整的GC Roots\n\n\n\n\n安全区：不会改变对象引用关系的一段连续的代码区间，安全区代码可以和垃圾回收线程并行执行\n\n大部分情况，用户线程在接收到暂停的中断请求之后，都可以在较短的时间内达到最近的安全点，但是在少数情况下，如果用户线程处于阻塞状态（如等待I/O读写就绪），就无法在较短的时间内达到最近的安全点，为了解决这个问题，虚拟机引入了一个新的概念：安全区，即不会改变对象引用关系的一段连续的代码区间\n当虚拟机执行垃圾回收并发起STW请求时，如果某个线程处于安全区，那么，这个线程并不需要停止执行，而是可以跟垃圾回收线程并行执行。但是，当用户线程离开安全区时，他需要检查虚拟机是否处于STW状态，如果是，用户线程需要阻塞等待STW结束，才能继续往下执行，以免用户线程跳出安全区之后，执行非安全代码导致对象引用关系的改变\n\n\n\n\n垃圾回收算法：基础垃圾回收算法（标记-清除、标记-整理、标记-复制）、分代垃圾回收算法（年轻代和YoungGC、老年代和FullGC）\n\n概念：用于回收死亡对象，主流算法为分代垃圾回收算法，JVM将堆空间分为年轻代和老年代，针对不同的分代单独进行垃圾回收（YoungGC、FullGC）\n针对年轻代的垃圾回收叫做YoungGC\n针对老年代的垃圾回收叫做FullGC，FullGC比YoungGC慢很多\n\n\n基础垃圾回收：标记使用可达性分析找出需要回收的死亡对象，主要有标记-清除、标记-整理、标记-复制\n标记-清除：虚拟机将死亡对象占用的内存空间释放，放入到空闲链表中，创建对象时，JVM从空闲链表中查找合适的空闲空间分配给对象，会出现内存碎片问题，标记-清除后的空闲空间不连续，查找耗时，大对象无法分配\n标记-整理：有叫做标记-压缩，在标记-清除的基础上，增加了整理的环节，先使用可达性分析标记存活对象所占用的内存空间，然后顺序遍历，将存活对象移动到内存的一端，从而解决内存碎片的问题，只需记录空闲空间的起始地址\n标记-复制：将内存分为轮流使用的两块内存，一块内存为对象分配内存空间（工作内存），另一块内存作为复制时备用（备用内存），当工作内存使用完之后，将这块内存的存活对象复制到备用内存中，然后交换两块内存角色，缺点是内存只用了一半，长时间存活的对象会被来回复制多次\n\n\n分代垃圾回收算法\n不需回收：程序计数器内存小，随着线程创建和销毁，不需要回收；虚拟机栈和本地方法栈存储的是方法的栈帧，随着方法退出而销毁，因此这三部分会随着生命周期的结束而立刻被回收，不需要经过虚拟机的垃圾回收线程的处理\n需要回收\n堆中存储的是对象，需要所有线程共享，作用域范围大，生命周期长，使用完不会立即回收，所以堆是进行垃圾回收的重点\n方法区也会涉及垃圾回收，比如方法区中的一些无用的类（类所有对象被回收、类class对象未被引用、类加载器已卸载）、无用的String常量对象（存储在字符串常量池，却没有变量引用的String对象）\n\n\n对堆的垃圾回收：堆中存储的是对象，对生命周期短的希望以较高频率进行回收；对生命周期长的希望以较低频率进行回收\n分代的垃圾回收：JVM将堆分为年轻代（Young Genereation）和老年代（Old Generation）两个分区，年轻代存储生命周期短的对象，老年来存储生命周期长的对象。JVM针对不同的分代使用不同的基础垃圾回收算法\n\n\n年轻代和YoungGC\n新创建的对象会分配在年轻代，选择标记-复制算法进行回收，因为生命周期短所以只需要复制少量存活对象\n为提高内存利用率，将年轻代分为不均等的三个分区：一个Eden区和两个Survivor区（From Survivor区、To Survivor区）\nEden满了之后，会触发Minor GC，存入survivor0中，如果触发MinorGC时survivor0也是满的，则s0和Eden一起进行可达性分析，找出活跃对象复制到s1区（标记-复制算法），请空Eden和s0，并将s0和s1交换\n对象在第一次进入Survivor，年龄初始化为1，在survivor中每熬过一次MinorGC，年龄就增加1\nEden区和Survivor区会被动态调整，或通过参数-XX:SurvivorRatio来设置比例（Eden区：1个Survivor区）\n\n\n空间分配担保机制：ToSurvivor区存不下的时候，会借用老年代的部分空间（老年代也不够时会执行FullGC，仍不够会抛出OOM），缺点是部分生命周期短的对象存储在老年代，等待很长时间才会被回收\n\n\n老年代和FullGC\n新生代存不下的对象、大对象、长期存活的对象都会进入老年代\n如果设置了JVM参数-XX:PretenureSizeThreshold，当对象大小超过这个阈值，对象会直接在老年代创建\n长期存活的对象指的是经过多次年轻代垃圾回收仍然存活的对象，虚拟机在对象的对象头中记录对象的GC年龄，每经过一次GC，GC年龄就增一，当GC年龄超过一定阈值（默认15，或通过-XX:PretenureSizeThreshold设置）之后，对象便从年轻代移动到老年代，但是人工设置的不准需要动态年龄判断机制\n动态年龄判断机制：统计YoungGC后，处于每个GC年龄值的对象占To Survivor区的比例，如果GC年龄&gt;=X（X取最大值）的对象占To Survivor区的比例超过50%（比例通过-XX:TargetSurvivorRatio来设置），那么GC年龄&gt;=X的对象都将直接进入老年代，不等GC年龄大于15\n\n\n老年代的垃圾回收\n因为老年代中的对象生命周期较长，每次垃圾回收之后，存活对象比较多，所以采用标记-整理算法进行回收（标记-清楚有内存碎片，永久代也使用标记-整理）\n老年代的垃圾回收叫做OldGC，但是在HotSpotJVM中，对老年代进行垃圾回收的同时，虚拟机会一并对年轻代和永久代进行垃圾回收，整个过程叫做FullGC\nYoungGC只对年轻代进行垃圾回收，速度快（可达性分析遍历的对象少，需要复制的对象较少），因此也称为MinorGC，而FullGC针对整个堆进行垃圾回收，速度慢（可达性分析遍历的对象多，垃圾回收处理的对象也多），因此也称为MajorGC\n\n\n\n\n增量（Incremental）算法：是一种渐进式的垃圾收集算法，它将垃圾收集的工作分为多个小部分分别执行，不需要一次性完成所有的垃圾收集工作，从而减少了垃圾收集时程序的暂停时间\n\n\n垃圾回收器：垃圾回收算法的具体实现，同一种算法可以有不同的实现\n\n性能指标：吞吐量（业务运行时间/总运行时间）、停顿时间（STW）、资源消耗（CPU资源、内存资源）、回收延迟、回收频率\n\n四大类常用的垃圾回收器：Serial、Parallel、CMS、G1\n\nSerial垃圾回收器：使用单线程进行垃圾回收，回收时需要STW、针对工作分区有以下两类\n\nSerial New：用于年轻代的垃圾回收，基于标记-清楚算法实现\nSerial Old：用于老年代的垃圾回收，基于标记-整理算法实现\n\n\nParallel垃圾回收器：使用多线程进行垃圾回收，回收是需要暂停程序运行，针对工作分区有以下三类\n\nParallel Scavenge（简称PS）：用于年轻代，基于标记-复制算法，与ParOld配合使用\nParallel New（简称ParNew）：用于年轻代，基于标记-复制算法，与CMS配合使用\nParallel Old（简称ParOld）：用于老年代，基于标记-整理算法\n\n\nCMS垃圾回收器：全称Concurrent Mark Sweep，采用多线程，不暂停应用程序，但不能用于年轻代的垃圾回收（Parallel New）\n\n\n垃圾回收过程（见后）：初始标记（需暂停应用程序）、并发标记、重新标记（需暂停应用程序）、并发清理\nCMS垃圾回收器在应用程序并行执行的过程中会争抢CPU资源，因此CMS使用的并发线程数等于（CPU内核数+3）/ 4，并且需要在老年代未满的时候进行垃圾回收，为并发程序预留内存空间\n预留内存通过JVM参数-XX:CMSInitiatingOccupancyFraction来指定已用内存占老年代的比值，超过此阈值就会触发CMS垃圾回收器的执行\n预留内存空间不够时，转而使用SerialOld垃圾回收器执行本次垃圾回收\n\n\n为了减少STW时间，CMS采用标记-清除算法来实现，相对于标记-整理算法，节省了整理空闲空间的时间，并且CMS针对内存碎片问题进行了改进，即在多次垃圾回收之后进行一次内存碎片的整理\n\n\nG1垃圾回收器：全称Garbage First，是一个应用于堆上的垃圾回收器，借鉴分代的处理思路，将整个堆分为2048个小的Region，并进一步分为年轻代（Eden区、Survivor区）、老年代\n\n\n之前的垃圾回收器都是针对整个分代进行垃圾回收，当分代被划分为更小的区域后，每次垃圾回收时，虚拟机可以只回收分代中的部分区域，进一步缩短STW时间\nG1同CMS类似，都是多线程进行垃圾回收，并且回收的过程与应用程序并发执行，不同的地方是G1垃圾回收器整体使用标记-整理算法、局部（每个Region）使用标记-复制\n因为G1的STW时间可以预测，所以可以通过-XX:MaxGCPauseMillis设置可允许的最大STW时间，G1根据这个时间决定每次对多少个区域进行垃圾回收\n\n\nZGC垃圾回收器\n\n与 CMS 中的 ParNew 和 G1 类似，ZGC 也采用标记-复制算法，不过 ZGC 对该算法做了重大改进。在 ZGC 中出现 Stop The World 的情况会更少\n\n\n\n\n垃圾回收器的对比与选择\n\n默认Java7、Java8采用Parallel垃圾回收器，Java9采用G1垃圾回收器，可以通过设置JVM参数来指定项目使用的垃圾回收器\n\n\n实战建议\n\nSerial：单核系统，多个应用程序争用CPU资源的环境下，需要刻意限制虚拟机所占用资源的环境，比如运行在移动端的客户端程序\nParallel与CMS相比，前者吞吐量更大，后者停顿时间更少，对于离线服务，首选吞吐量达的Parallel垃圾回收器，对于实时服务，特别是对响应时间敏感的服务，首选停顿时间更少的CMS垃圾回收器\nJava9中，CMS被标记为Deprecated，使用G1取代，针对比较大的堆（大于6GB），首选停顿时间可控的G1垃圾回收器\n老年代使用CMS（Concurrent Mark-Sweep）或G1（Garbage First），减少停顿时间\n\n\n\n\n并发垃圾回收\n\n并发：并非完全并发，而是大部分时间不需要暂停应用程序，并发垃圾回收整个过程分为4个阶段，分别是：初始标记、并发标记、重新标记、并发清理，其中并发标记和并发清理这两个比较耗时的阶段可以与应用程序并发执行，而其余两个阶段仍需要暂停应用程序的执行\n回收过程：初始标记指的是标记GC Roots。并发标记指的是在应用程序不暂停的情况下，以GC Roots为起点，广度或深度优先遍历所有可达对象（存活对象），在并发标记的过程中，应用程序有可能修改对象之间的引用关系，导致并行标记过程出现误标或漏标的情况，重新标记所做的工作就是对误标和漏标进行修正。并发清理指的是在不暂停应用情况下，对标记出来的垃圾对象进行清理\n并发清理：前面三个阶段属于可达性分析，即标记-清除算法中的标记环节，并发清理是标记-清除算法中的清除环节。在并发清理过程中，如果存活对象变为死亡对象，只需要在下一次垃圾回收中被回收即可；而死亡对象不会再变成存活对象，因为死亡对象不再有变量（局部变量或静态变量）的直接或间接引用，因此应用程序是无法在代码中使用这些死亡对象（比如局部变量在函数执行结束后就被销毁了）\n\n\n三色标记算法\n\n用于可达性分析，将遍历过程中的对象分为白色、灰色、黑色三种\n白色：对象没有遍历过，遍历开始时，所有对象都初始化白色，遍历结束后，仍为白表示对象不可达\n灰色：对象已经被遍历，但是对象所直接引用的对象还没有完全被遍历\n黑色：对象已经被遍历，并且对象所直接引用的对象都已经被遍历\n\n\n可达性分析基于图的广度和深度遍历\n初始化GC Roots为灰色，其余为白色\n从灰色集合中取出一个灰色对象，标记为黑色，将此对象直接引用的所有白色对象标记为灰色\n重复第二步，直到灰色集合中没有对象为止。此时黑色集合存放的是可达对象，也就是存活对象；白色集合中存在的是不可达对象，也就是死亡对象\n\n\n误标（白的标成黑的）和漏标（黑的标成白的）\n误标：灰色对象的引用变为0，应该变成白的，但是最后变成黑的了\n漏标：白色对象的灰色对象引用断开，新增了黑色对象引用，应该被标成黑的，但是只能被标成白的\n\n\n\n\n增量更新和原始快照\n\n并发标记的误标和漏标问题会在重新标记中解决，其中误标问题不大，是可以接受的，只会导致垃圾对象延迟回收，但是漏标问题会导致应用程序运行出错，回收不该回收的对象，漏标产生的原因主要有以下两点，两者缺一不可\n新增引用：新增一个黑色对象对一个白色对象的引用\n删除引用：删除所有灰色对象到此白色对象的直接或间接引用\n\n\n针对以上两点，Java发明了两种漏标解决方案，针对第一点新增引用的漏标解决方案叫做增量更新，是CMS垃圾回收器所使用的方案；针对第二点删除引用的漏标解决方案叫做原始快照，是G1垃圾回收器所使用的方案，方案具体如下：\n增量更新：在并发标记的过程中，如果应用程序新增了一个黑色对象对一个白色对象的引用，虚拟机会将这个白色对象记录下来，在并发标记完成之后，重新标记阶段会以这些记录下的白色对象为起点，重新进行可达性分析，这样漏标的白色对象会被重新标记为黑色对象\n原始快照：在并发标记的过程中，如果应用程序删除了一个灰色对象对一个白色对象的直接/间接引用，那么虚拟机会将这个白色对象记录下来，在并发标记完成之后，重新标记阶段会以这些记录下来的白色对象为起点，重新进行可达性分析，这就相当于虚拟机对引用关系改变之前的原始快照进行可达性分析。不过，这些记录下的白色对象有可能是死亡对象，而重新标记阶段会将这些死亡对象重新标记为存活对象，因此，原始快照这种解决方案会导致误标问题，会导致垃圾对象延迟回收\n\n\n\n\n\n\n\n5.实战调优\nJVM性能优化\n\n性能指标：GC频率、GC时间，印象以上两项的内部性能指标\n年轻代中对象的增长速率\n每次YoungGC之后存活对象大小\n每次YoungGC之后进入老年代的对象大小\n老年代对象的增长速率\n\n\nJVM参数类别：参数稳定性依次下降\n-标准参数\n-X参数\n-XX参数\n\n\n常用参数：堆大小、年轻代和老年代大小、永久代和元空间大小、Eden区和Survivor区大小、线程栈大小、垃圾回收器类别\n设置堆的大小：一般设置为相同的值，避免堆大小的调整而引起的性能损耗\nXms：Java堆内存的初始大小\nXmx：Java堆内存的最大大小\n\n\n设置年轻代和老年代的大小：设置年轻代大小的方法有三种，但是对于老年代的大小只需要通过堆大小减去年轻代大小即可得到\nXmn：年轻代的大小\nXX:NewSize：年轻代的初始大小\nXX:MaXNewSize：年轻代的最大大小\nXX:NewRatio：年轻代与老年的大小比值，值为老年代/年轻代\n\n\n设置永久代或元空间的大小\nXX:PermSize：永久代的初始大小\nXX:MaxPermSize：永久代的最大大小，这两个参数只在1.7之前有效\nXX:MetaspaceSize：元空间的初始大小\nXX:MaxMetaspaceSize：元空间的最大大小，这两个参数只在1.8之后有效\n\n\n设置Eden区和survivor区的大小\nXX:SurvivorRatio：一个Survivor区跟Eden区的大小比例，值为Eden区/Survivor区，注意：一共有两个Survivor区\n\n\n设置线程栈的大小\nXss：每个线程的栈大小，HotSpot JVM不区分虚拟机栈和本地方法栈，使用一个栈同时存储Java方法和本地方法的栈帧，因此这里只有一个栈大小的设置参数，线程栈大小默认为512KB或1MB，除非系统在运行的过程中，出现非代码因素导致的StackOverflow，才需要调整线程栈的大小，否则默认即可\n\n\n设置垃圾回收器\nXX:+UseSerialGC：用Serial垃圾回收器\nXX:+UseParallelGC：用Parallel垃圾回收器\nXX:+UseConcMarkSweepGC：用CMS垃圾回收器\nXX:+UseG1GC：用G1垃圾回收器\n\n\n\n\n\n\nJVM问题排查\n\n常见工具\n\njps (JVM Process Status）: 类似 UNIX 的 ps 命令。用于查看所有 Java 进程的启动类、传入参数和 Java 虚拟机参数等信息；\n**jstat**（JVM Statistics Monitoring Tool）: 用于收集 HotSpot 虚拟机各方面的运行数据;\njinfo (Configuration Info for Java) : Configuration Info for Java,显示虚拟机配置信息;\njmap (Memory Map for Java) : 生成堆转储快照;\njhat (JVM Heap Dump Browser) : 用于分析 heapdump 文件，它会建立一个 HTTP/HTML 服务器，让用户可以在浏览器上查看分析结果;\njstack (Stack Trace for Java) : 生成虚拟机当前时刻的线程快照，线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合\n\n\nJVM性能调优\n\n线上通过jstat得到JVM性能统计数据，JVM调优主要方向是减少FullGC频率和FullGC时间\n增大年轻代的大小，增大Survivor区大小，让对象尽量在年轻代就被回收掉，减少老年代中对象的增长速率，从而降低FullGC频率\n增加老年代的大小也会降低FullGC的频率，但会增大FullGC的时间\n\n\n一般来说，如果堆不是很大，没有长期存活的大对象和内存泄漏，那么应用CMS垃圾回收器并调节年轻代、老年代、Survivor区等内存分配，完全可以将FullGC时间优化到合适的范围，否则可以选择GC时间可控的G1垃圾回收器\n大部分情况，不需要刻意的进行调优，只有当通过监控发现GC严重影响系统性能时，才有必要对JVM参数进行调优\n\n\nJVM性能监控和分析工具\n\njstat：通过jps命令查找到要监控的JVM进程ID，然后执行jstat -gcutil [vmid] [time-interval]即可\n\nS0：表示Survivor0的内存使用率；S1：表示Survivor1的内存使用率；E：表示Eden区的内存使用率；O：表示老年代的内存使用率；M：表示Metaspace的内存使用率；YGC：YoungGC的次数；YGCT：YoungGC的总耗时；FGC：FullGC的次数； FGCT：FullGC的总耗时；GCT：GC的总耗时\n\n\n\nGC详细日志分析\n\n-XX:+PrintGCDetails 打印详细GC日志\n-Xloggc:./logs/gc.log 详细GC日志存储的位置\n以上日志可以粗略的分为两类：ParNew日志和CMS日志\nParNew日志：记录GC触发原因、GC发生时间、GC前后年轻代大小变化、GC具体耗时等信息\nCMS日志示例：CMS日志包含的信息比ParNew日志要多很多，其中，CMS Initial Mark、CMS-cocurrent-mark、CMS Final Remark、CMS-concurrent-sweep分别对应并发垃圾回收的四个阶段：初始标记、并发标记、重新标记、并发清理\n\n\n\n\nJVM内存快照获取和分析：jmap\n\n当JVM出现问题时，比如OOM、频繁GC，我们希望得知当前堆中存储的对象情况，比如哪些对象占据了大量堆内存，我们就需要将当下的内存快照dump出来，然后利用工具来查看和分析\n\n常用的dump堆内存快照的方法有两种，一种是使用JVM参数，另一种是使用jmap命令行工具。具体如下所示。dump出来的堆内存快照为二进制文件，我们需要通过工具来查看，常用的查看工具有MAT、jhat等\n方法一：使用JVM参数\n-XX:+HeapDumpBeforeFullGC\n-XX:HeapDumpOnOutOfMemoryError\n-XX:HeapDumpPath&#x3D;目录\n\n方法二：使用jmap命令行工具\njmap -dump:format&#x3D;b,file&#x3D;文件名 [pid]\n\n\n\n\n\n\nJVM常见问题\n\nOOM：应用程序使用完成的对象没有被及时释放，导致对应的内存无法被回收，长期积累，便会导致内存耗尽\n当程序申请不到足够的内存空间，并且JVM通过GC也无法释放出足够的内存空间时，JVM便会抛出OOM\nList&lt;Object&gt; list &#x3D; new ArrayList&lt;&gt;();\nwhile (true) &#123;\n    list.add(new byte[1_000_000]); &#x2F;&#x2F; 每次添加1MB的对象\n&#125;\n\n导致内存溢出的常见的原因有如下几种\n\n堆内存（Heap）：OOM最常见的场景之一是堆内存不足，通常由于创建了太多对象（SQL查询全表数据）或者每个对象太大。这在处理大数据量、内存泄漏或者没有合理限制对象创建时可能发生\n永久代/元空间（PermGen/Metaspace）：在Java 8之前，类的元数据和静态字符串池存储在永久代（PermGen），而在Java 8及以后，它们存储在元空间（Metaspace）。如果永久代或元空间太小，则OOM可能发生在这些区域，尤其是在动态生成类或加载大量类的应用中\n栈内存（Stack）：虽然栈内存通常较小，但如果递归调用层次太深，也可能导致栈溢出（StackOverflowError）\n\n\n如何排查OOM问题\n\n当JVM出现OOM问题时，应用程序的对应表现一般是无法继续执行，如果应用程序是接口系统，那么接口将出现大量503错误。这时，我们通过查看日志，便会发现大量java.lang.OutOfMemoryError错误信息。为了排查出到底哪些对象长期存在并大量占用内存，我们需要通过jmap或JVM参数获取堆内存快照，并通过MAT等工具来查看和分析\n使用MAT工具可以得知内存泄漏的数据可能集中在哪些代码，然后就可以去分析源代码，看是否代码存在内存泄漏，又或者创建了太多长期存在的对象，最后可以尝试调大堆内存的大小\n确保资源的正确关闭和对象引用的释放\n特别关注长时间存活的对象和数据结构\n\n\n\n\n\n\n频繁GC\n一般OOM前会出现频繁GC，主要有两种：频繁YoungGC和频繁FullGC，单纯的频繁YoungGC往往是由年轻代空间太小导致的，只需要适当增大年轻代的大小即可解决这个问题，因为YoungGC只与存活对象的数量有关，与年轻代大小无关\n相对于频繁YoungGC，频繁FullGC会引发更加严重的问题，且解决起来更加复杂。因为FullGC更加消耗CPU资源并且STW停顿时间较长，所以，在发生频繁FullGC时，CPU利用率一般会飙升，并且会出现应用程序变慢的情况（比如接口请求处理速度变慢甚至大量超时）\n触发FullGC的主要原因是老年代空间不足。前面我们已经总结过，老年代的对象一般来源于长期存活的对象、大对象、空间分配担保。接下来，我们从这3个对象来源来分析频繁GC发生的原因。\n长期存活的对象：如果应用程序创建的长期存活的对象比较多，那么，我们可以适当调大老年代的大小，以减少FullGC的频率。不过，这种情况并不常见，大部分应用程序并不会创建太多的长期存活的对象。实际上，内存泄露往往才是导致对象长期存活无法回收的主要原因。如果每次FullGC回收率很低，释放出来的空间很少，那么就说明是存在内存泄露了。频繁FullGC一段时间之后，JVM便会出现OOM\n大对象：前面讲到，大对象会直接进入老年代。过多的大对象是引起频繁FullGC的最常见的原因之一。比如，在某个接口中执行了未分页SQL，一次性加载过多数据到内存中，当高并发下，接口大量被调用，就会导致大量大对象被创建，从而导致老年代空间不足，引发频繁FullGC。定位此种频繁FullGC发生的原因，我们需要在FullGC前（设置JVM参数-XX:+HeapDumpBeforeFullGC）dump内存快照，分析占用堆内存比较多的是哪个对象，以此来定位问题代码\n空间分配担保：前面讲到，在执行YoungGC时，如果To Survivor空间不足，JVM会触发空间分配担保，将对象存储到老年代。因此，如果每次YoungGC，To Survivor都被占满，那么，我们就要考虑增大To Survivor区，避免空间分配担保，减少进入老年代的对象数量\n\n\n\n\nGC时间过长\n堆内存过大：前面讲到，年轻代使用标记-复制垃圾回收算法，并且，年轻代空间增大并不会导致存活对象增多，因此，YoungGC时间跟年轻代的大小无关，但是，老年代使用标记-整理或标记-清除垃圾回收算法，并且，老年代空间增大会导致存活对象增多，因此，FullGC时间跟老年代的大小有关。老年代过大会导致FullGC时间过长。针对比较大的堆内存，我们应该选择GC时间可控的G1垃圾回收器，或者在一台大物理内存的机器上部署多个JVM，以减小单个堆内存的大小\nConcurrent Mode Failure：前面讲到，CMS垃圾回收器采用并发垃圾回收算法，在垃圾回收的某些阶段，应用程序可以与之并发执行。应用程序的执行需要堆内存，因此，JVM在执行垃圾回收前，会预留一定的堆内存空间。但是，在执行垃圾回收的的过程中，如果预留空间不足，应用程序无法继续执行，那么，JVM便会抛出Concurrent Mode Failure错误，并且，暂停CMS垃圾回收器的执行，改为STW停顿时间更长的Serial Old垃圾回收器。垃圾回收器的中止和切换势必会增长FullGC时间。如果我们在GC详细日志中（通过设置JVM参数-XX:+PrintGCDetails得到）发现大量Concurrent Mode Failre字样，那么，我们就需要通过减小JVM参数-XX:CMSInitialOccupancyFraction的值来调大预留空间的大小\n操作系统swap：swap是操作系统中的概念。当物理内存不足时，操作系统会将物理内存中的部分不活跃的数据放入磁盘，当这部分数据重新被使用时，再从磁盘加载到物理内存中。这种数据在物理内存和磁盘之间换入换出的机制，就叫作swap。swap涉及磁盘I/O操作，非常影响进程的性能。如果设置的JVM堆内存大小超过物理内存大小，或者多个应用程序争用有限的物理内存，那么，就有可能触发swap而导致GC时间增长。解决这个问题的方法也很简单，尽量保证JVM堆大小不要超过物理内存的大小，并且为操作系统或者其他软件预留充足的物理内存，比如物理内存有8GB，我们设置JVM堆大小为6GB，预留2GB给操作系统和其他并发运行的软件\n\n\n\n\n\n附录\n如何判断一个常量是废弃常量\n\nJDK1.8 hotspot 移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace)\n假如在字符串常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池了\n\n\n怎么释放一个用完的大对象的内存空间\n\n不再使用对象后，确保将其所有引用设置为==null==。这有助于加速对象变为不可达的过程\n如果你知道某个大对象的生命周期非常短暂，可以考虑==手动调用System.gc()或Runtime.getRuntime().gc()==来建议垃圾收集器执行垃圾回收。请注意，这只是建议，垃圾收集器是否真正执行垃圾回收还取决于具体的实现\n如果你的应用程序经常创建和销毁大量的大对象，可以考虑==使用对象池或其他内存管理技术来重用对象==，以减少垃圾收集的开销。\n\n\nJVM 判定两个 Java 类是否相同的具体规则\n\nJVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。只有两者都相同的情况，才认为两个类是相同的。即使两个类来源于同一个Clas文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相同\n\n\n打破双亲委派模型方法\n\n自定义加载器的话，需要继承ClassLoader。如果我们不想打破双亲委派模型，就重写ClassLoader类中的findClass()方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写loadClass()方法\nTomcat 服务器为了能够优先加载 Web 应用目录下的类，然后再加载其他目录下的类，就自定义了类加载器WebAppClassLoader来打破双亲委托机制。这也是 Tomcat 下 Web 应用之间的类实现隔离的具体原理（详见深入拆解Tomcat&amp;Jetty）\n\n\nJVM内存模型运行原理\n\n当 Java 程序启动时，JVM 会初始化内存模型中的各个区域。\n程序代码被加载并编译成字节码，并由类加载器加载到方法区。\n线程开始执行，每个线程都有自己的程序计数器、虚拟机栈等区域。\n当方法被调用时，在虚拟机栈上创建栈帧，用于存储方法的局部变量和操作数栈。\n对象实例被分配到 Java 堆上，并由垃圾回收器负责回收不再被引用的对象。\n类的元数据信息存储在方法区（或元空间）中，包括字段、方法、方法字节码等。\n运行时常量池用于存储符号引用和字面量常量。\nJVM 运行时会执行字节码指令，操作数据、调用方法等。\n垃圾回收器定期检查和回收不再被引用的对象，释放内存。\n\n\nHotSpot虚拟机对象探秘\n\n对象的创建\n\n类加载检查：虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程\n分配内存：在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有“指针碰撞”和“空闲列表”两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定\n指针碰撞 ：堆内存没有内存碎片的情况下，使用该分配方式的 GC 收集器有Serial, ParNew\n空闲列表 ：堆内存有内存碎片的情况下，虚拟机有一个空闲链表记录哪些内存块是可用的，使用该分配方式的 GC 收集器有CMS\n内存并发问题：创建对象是很频繁的，必须保证线程安全，有以下几种方法\nCAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性\nTLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配\n\n\n\n\n初始化零值：内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值\n设置对象头：初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式\n执行init方法：在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来\n\n\n对象的内存布局\n\n对象头\n用于存储对象自身的运行时数据：哈希码、GC分代年龄、锁状态标志等\n类型指针：对象指向他的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例\n\n\n实例数据：对象真正存储的有效信息，程序中所定义的各种类型的字段内容\n对齐填充：仅仅起占位作用，因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全\n\n\n对象的内存访问：通过栈上的reference数据来操作堆上的具体对象，对象的访问方式有虚拟机实现而定，主要有以下几种\n\n句柄：如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息（reference中存储的是稳定的句柄地址，对象被移动只会改变句柄中的实例数据指针，reference本身不需要修改）\n\n\n直接指针：如果使用直接指针访问，reference 中存储的直接就是对象的地址（速度快，节省了一次指针定位的时间开销）\n\n\n\n\nHostSpot VM的实现，里面的GC主要有两类\n\nPartial GC：并不收集整个GC堆的模式\n新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集\n老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集，知有CMS和concurrent collection有这个模式\n混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集，只有G1有这个模式\n\n\n整堆收集 (Full GC)：收集整个 Java 堆和方法区\n\n\n\n\n\n\n","slug":"JVM","date":"2023-07-30T02:35:00.000Z","categories_index":"","tags_index":"","author_index":"Dajunnnnnn"},{"id":"3fe1ee3f3830128bf539e5f4ed9fbbe9","title":"Linux","content":"Linux1.进程管理\n概念\n\nfd在系统中有限制吗？可以无限申请吗：通过ulimit -n来显示当前进程的文件描述符限制数量，通过编辑或创建/etc/security/limits.conf文件来调整文件描述符限制，不可以无限申请而是需要满足系统资源限制\n\n进程：进程是资源调度的基本单位，启动main函数就是启动一个JVM进程，main函数所在的线程是这个进程的主线程\n\n进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态\n\n一个进程切换到另一个进程运行，称为进程的上下文切换，其中上下文包括CPU 寄存器、程序计数器，切换时保存在进程的 PCB（进程存在的唯一标识）中，切换的时机主要有时间片耗尽、资源不足、高优先级进程调度、主动Sleep、硬件中断\n\n进程切换涉及到更多的内容，包括整个进程的地址空间、全局变量、文件描述符等。因此，进程切换的开销通常比线程切换大\n线程切换只涉及到线程的堆栈、寄存器和程序计数器等，不涉及进程级别的资源，因此线程切换的开销较小\n\n\n分配给进程的资源：虚拟内存、文件描述符、信号\n\n\n\n\n线程：线程是CPU调度的基本单位，线程间共享堆和方法区（代码段、数据段）资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈\n\n线程共享进程的资源在Linux中怎么实现\n\n内存空间：所有线程都共享同一个进程的地址空间，这意味着它们可以访问相同的内存区域，包括代码段、数据段和堆栈\n所有线程可以访问相同的全局变量和静态变量\n\n\n文件描述符：所有线程共享相同的文件描述符表，这使得它们可以同时访问文件和套接字等文件系统资源\n所有线程共享相同的进程ID（PID）和用户ID（UID）\n\n\n信号处理：信号可以被发送到进程，然后由任何一个线程处理。这意味着任何线程都可以捕获和处理信号\n\n\nlinux进程创建线程的流程是怎么样的？\n\n包含线程库头文件： 要在程序中使用线程相关函数，首先需要包含适当的头文件。在C语言中，可以包含&lt;pthread.h&gt;头文件。\n\n初始化线程库： 在创建线程之前，需要调用pthread_init()或pthread_create()函数来初始化线程库。通常情况下，不需要手动调用pthread_init()，因为它会在第一个线程创建时自动初始化。\n\n创建线程： 使用pthread_create()函数创建新线程。这个函数接受多个参数，包括指向线程标识符的指针、线程属性、线程入口函数和传递给线程入口函数的参数。例如：\npthread_t thread_id;\npthread_create(&amp;thread_id, NULL, thread_function, (void*)arg);\n\n其中，thread_id是用于存储新线程的标识符，thread_function是线程的入口函数，(void*)arg是传递给入口函数的参数。\n\n执行线程入口函数： 新线程开始执行指定的入口函数，也就是thread_function。在这个函数内部，线程可以执行任意操作。\n\n等待线程结束： 如果主线程需要等待新线程完成，可以使用pthread_join()函数。这个函数将阻塞主线程，直到指定的线程执行完毕。\npthread_join(thread_id, NULL);\n释放线程资源： 当线程完成其任务后，可以使用pthread_exit()函数来退出线程。这会释放线程所占用的资源，并将线程的退出状态传递给父线程。\n\n清理线程库： 当所有线程都完成后，可以使用pthread_exit()或pthread_cleanup()等函数来清理线程库。通常情况下，不需要显式调用这些函数，因为它们会在程序结束时自动清理。\n\n\n\n分类\n\n用户线程（*User Thread*）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；\n内核线程（*Kernel Thread*）：在内核中实现的线程，是由内核操作系统管理的线程，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责；\n轻量级进程（*LightWeight Process*）：在内核中来支持用户线程；\n\n\n\n\n协程：由编程语言创建，又称为用户态线程；协程是异步非抢占式的，需要用户自己释放使用权来切换协程；线程数量在千万级别，而协程可以达到上万级别，因为线程是多核上并行，而协程是用来实现高并发的\n\n调度方式：线程是由操作系统调度的，而协程则是由程序员控制的。当一个线程被调度时，它会被操作系统挂起，等待下一次调度。而协程则是由程序员在代码中主动调用的，可以在不同的任务之间切换，而不需要等待操作系统的调度\n资源占用：线程是操作系统管理的实体，它占用系统资源比较大，包括内存、线程栈、CPU 时间片等。而协程则是在用户空间中实现的，不需要操作系统的支持，因此占用的资源比较少\n切换成本：线程的切换需要保存和恢复线程上下文，需要耗费一定的时间和资源。而协程的切换只需要保存和恢复栈帧等少量数据，因此切换成本比线程低\n\n\n\n\n通信方式\n\n进程通信的方式：匿名管道、命名管道、信号、消息队列、共享内存、内存映射、套接字、信号量\n\n管道\n匿名管道：Unix系统最古老的通信方式，通过在内核中维护一块内核缓冲区来实现通信，Linux系统中通过pipi()函数创建管道，会生成两个文件描述符，分别对应读端和写端，只能用于具有亲缘关系的进程间通信\n命名管道：为了解决匿名管道只能在具有亲缘关系的进程间通信的问题，通过将管道和一个路径名相关联，以FIFO的文件形式存在于文件系统中，没有亲缘关系的进程也可以像操作文件一样通过命名管道进行数据交换\n\n\n信号：Linux系统最古老的通信方式，是一种异步通信的方式，信号可以导致一个正在运行的进程被另一个正在运行的进程中断，转而处理突发事件，是事件发生时对进程的通知机制\n消息队列：一个消息的链表，链表中的消息有特性格式和优先级，有对应权限的进程可以对其进行读写\n共享内存：允许两个或多个进程共享物理内存的同一块区域（称为段），由于一个共享内存段会成为一个进程用户空间的一部分，因此这种IPC机制无需内核介入，只需要一个进程将数据复制进共享内存中即可\n共享内存：不同进程间共享的一段物理内存，所有进程都可以访问共享内存中的地址，改动对所有进程可见。优点是可以直接访问速度更快；缺点是需要额外的同步机制来互斥访问\n\n\n内存映射：将磁盘文件的数据映射到内存，用户通过修改内存就能修改磁盘文件\n信号量：用于解决进程或线程之间并发执行是的同步问题，对信号量的操作主要有P操作和V操作\nSocket：对网络中不同主机上的应用进程之间进行双向通信的段点的抽象，提供了应用层进程利用网络协议交换数据的机制，用于网络中不同主机上的进程之间进行通信\n\n\n线程通信方式：Monitor、Condition\n\n在Java中,常用的线程通信方式有两种,分别是利用Monitor实现线程通信、利用Condition实现线程通信。线程同步是线程通信的前提,所以究竟采用哪种方式实现通信,取决于线程同步的方式。\n如果是采用synchronized关键字进行同步,则需要依赖Monitor（同步监视器）实现线程通信，Monitor就是锁对象。在synchronized同步模式下,锁对象可以是任意的类型,所以通信方法自然就被定义在Object类中了,这些方法包括：wait()、notify()、notifyAll()。一个线程通过Monitor调用wait()时,它就会释放锁并在此等待。当其他线程通过Monitor调用notify()时,则会唤醒在此等待的一个线程。当其他线程通过Monitor调用notifyAll()时,则会唤醒在此等待的所有线程。\nJDK 1.5新增了Lock接口及其实现类,提供了更为灵活的同步方式。如果是采用Lock对象进行同步,则需要依赖Condition实现线程通信，Condition对象是由Lock对象创建出来的,它依赖于Lock对象。Condition对象中定义的通信方法,与Object类中的通信方法类似,它包括await()、signal()、signalAll()。通过名字就能看出它们的含义了,当通过Condition调用await()时当前线程释放锁并等待,当通过Condition调用signal()时唤醒一个等待的线程,当通过Condition调用signalAll()时则唤醒所有等待的线程。\n线程同步是基于同步队列实现的,而线程通信是基于等待队列实现的。当调用等待方法时，即将当前线程加入等待队列。当调用通知方法时,即将等待队列中的一个或多个线程转移回同步队列。因为synchronized只有一个Monitor，所以它就只有一个等待队列。而Lock对象可以创建出多个Condition，所以它拥有多个等待队列。多个等待队列带来了极大的灵活性,所以基于Condition的通信方式更为推荐\n比如，在实现生产消费模型时，生产者要通知消费者、消费者要通知生产者。相反，不应该出现生产者通知生产者、消费者通知消费者这样的情况。如果使用synchronized实现这个模型，由于它只有一个等待队列,所以只能把生产者和消费者加入同一个队列,这就会导致生产者通知生产者、消费者通知消费者的情况出现。采用Lock实现这个模型时，由于它有多个等待队列，可以有效地将这两个角色区分开，就能避免出现这样的问题。\n\n\n协程的的通讯有哪些方式：\n\n共享内存：协程通过共享内存来交换数据，这种方式简单直接，但需要考虑同步和互斥问题，否则会出现数据竞争等问题。 \n消息传递：协程通过消息队列等方式来传递数据，这种方式可以避免数据竞争等问题，但需要考虑消息的发送和接收顺序等问题。 \n信号量：协程通过信号量等方式来实现同步和互斥，这种方式需要考虑好信号量的数量和使用顺序，否则会出现死锁等问题。\n\n\n\n\n进程调度\n\n算法\n先来先服务（FCFS）：选最早\n短作业/进程优先（SJF/SPF）：选最短（平均等待时间、平均周转时间最少）\n优先级调度：选优先级最高（净：sys&gt;users、交互&gt;非交互、I/O&gt;CPU）\n高相应比优先（HRRN）：响应比最高（等待时间+需服务时间）/需服务时间\n时间片轮转（RR）：分时OS、绝对可抢占\n多级反馈队列：1+3+5、“UNIX”、优先级高到低、时间片小到大（上无才执行下\n\n\n不能调度（处理中断、临界区、屏蔽中断）；剥夺与非剥夺调度（早期批处理）【在进程处于临界区时，只要不破坏临界区资源使用规则就不影响处理机调度】\n评估指标：CPU利用率（忙碌时间/总时间）、系统吞吐量（完成作业数/总时间）、平均周转时间（提交到完成/n=（等待+执行）/n）、带权周转时间（作业周转时间/实际运行时间，越小越好必然大于1）、等待时间（等处理机状态）、响应时间（提交请求到首次响应）\n\n\n死锁：并发执行线程需要加锁主要是为了保护共享数据，防止出现”竞态条件”\n\n死锁定义：多个进程因竞争资源而造成的一种僵局（互相等待）若无外力作用，这些进程都将无法向前推进\n互斥：保证一个线程在临界区执行时，其他线程应该被阻止进入临界区\n同步：并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步\n\n\n产生原因：竞争资源、进程推进非法\n必要条件：互斥访问临界区资源、请求和保持、不剥夺、环路等待（等待的进程成环）\n预防死锁：破坏互斥（资源共享使用）、破坏不剥夺、破坏请求和保持（预先静态分配）、破坏循环等待（顺序资源分配）（必要条件）\n避免死锁：安全状态（不一定是死锁状态）、银行家算法（必须知道将来的资源请求）、安全性算法\n检测死锁：利用死锁定理化简资源分配图（圆圈代表进程，框代表一类资源，一个圆代表一个该类资源，进程到资源为请求边，资源到进程为分配边）把圈都变成孤点\n解除死锁：资源剥夺、撤销进程、进程回退\n死锁检测：银行家算法\nMax、Allocation、Need\nWork、Need、Allocation、W+A（分配一个写一行，一行一行写）\n\n\n\n\n同步\n\n信号量：操作系统提供的一种协调共享资源访问的方法，通常信号量表示资源的数量，对应的变量是一个整型（sem）变量，使用一个阻塞队列保存阻塞的线程，还有两个原子操作的系统调用函数来控制信号量的，分别是：\n\nP 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；\nV 操作：将 sem 加 1，相加后，如果 sem &lt;= 0（多个线程同时P后，即使有V，sem也会是负的），唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；\n\n\n操作系统实现\n&#x2F;&#x2F;信号量数据结构\ntype struct sem_t&#123;\n\tint sem; &#x2F;&#x2F;资源个数\n\tqueue_t *q; &#x2F;&#x2F;等待队列\n&#125;\n&#x2F;&#x2F;初始化信号量\nvoid init(sem_t *s, int sem)&#123;\n\ts-&gt;sem &#x3D; sem;\n\tqueue_init(s-&gt;q);\n&#125;\n&#x2F;&#x2F;P操作\nvoid P(sem_t *s)&#123;\n\ts-&gt;sem--;\n\tif(s-&gt;sem &lt; 0)&#123;\n\t\t&#x2F;&#x2F;保留调用线程CPU现场\n\t\t&#x2F;&#x2F;将该线程的TCB插入到s的等待队列\n\t\t&#x2F;&#x2F;设置该线程为等待状态\n\t\t&#x2F;&#x2F;执行调度程序\n\t&#125;\n&#125;\n&#x2F;&#x2F;V操作\nvoid V(sem_t* s)&#123;\n\ts-&gt;sem++;\n\tif(s-&gt;sem &lt;&#x3D; 0)&#123;\n\t\t&#x2F;&#x2F;移出S等待队列首元素\n\t\t&#x2F;&#x2F;将该线程的TCB插入就绪队列\n\t\t&#x2F;&#x2F;设置该线程为就绪状态\n\t&#125;\n&#125;\n\n\n读写模型\n\n读者-写者模型：一个请求队列有读者有写者线程同时操作这个共享的请求队列\n读者优先模型：在这种模型下，允许多个读者同时访问共享数据，但当有写者在访问时，其他读者和写者都必须等待。读者线程可以并发读取请求队列；写者线程等待读者完成后，才能进行写操作。\n写者优先模型：在这种模型下，写者线程具有优先权，一旦有写者等待，读者将被阻塞，直到写者完成操作。写者线程可以随时写入请求队列；读者线程必须等待写者完成后才能读取。\n\n\n一写多读模型的情况下怎么解决读写冲突的问题：读写锁、无锁数据结构、分段锁、基于版本的并发控制（MVCC）、CAS算法\n\n\n\n2.内存管理\nCPU寻址\n\n寻址：CPU通过内存地址来访问计算机内存中的数据和指令\n虚拟地址空间：虚拟地址空间是一种抽象概念，它将进程（应用程序）视为拥有自己独立的内存地址空间。每个进程都有自己的虚拟地址空间，这使得每个进程可以独立运行，不受其他进程的影响。虚拟地址空间的大小通常大于物理内存的大小，使用页表或段表等数据结构将进程的虚拟地址映射到物理内存中的实际位置。这种映射允许操作系统将进程的数据加载到RAM中，并在需要时将其移入和移出，以实现内存的有效使用\n虚拟内存：允许操作系统将部分数据从RAM中移到磁盘上，以扩展可用内存，从而提高系统的整体性能\n\n\n虚拟地址与物理地址映射方式\n\n分段：将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息，段与段之间可以不相邻接。主要是为了程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护，反应程序的逻辑结构有利于段的共享\n\n会有外部内存碎片，可以通过内存交换（写入磁盘swap区再重新写回），但是因为磁盘读写速度所以效率很低\n\n\n分页：用户程序的地址空间划分为若干个固定大小的页，内存空间分成若干个物理块，页和快的大小相等，可以将任一页放在任一块中。主要用于实现虚拟内存，从而获得更大的地址空间，可以解决内存碎片，提高内存利用率\n\n换入换出\n当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行\n如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）\n\n\n多级页表：\nTLB：专门存放程序最常访问的页表项的 Cache，又称快表\n\n\n段页式：段页式存储管理方式即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。系统同时配置段表和页表，每个进程一张段表，没个分段一张页表，利用段表和页表进行用户地址空间到物理内存空间的映射。\n\n段表项包括段号、页表长度、页表起始地址；页表项包括页号、块号。在进行地址转换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最终形成物理地址。\n\n\nLinux实现：页式内存管理（由段式内存管理所映射而成的地址上再加上一层地址映射）\n\nLinux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。\n\n\n32位系统内存空间划分\n\n上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞\n在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存\n保留区：因为在大多数的系统里，认为比较小数值的地址不是一个合法地址，所以空出来不使用\n代码段，包括二进制可执行代码；\n数据段，包括已初始化的静态常量和全局变量；\nBSS 段，包括未初始化的静态变量和全局变量；\n堆段，包括动态分配的内存，从低地址开始向上增长；\n文件映射段，包括动态库、共享内存等，从低地址开始向上增长。\n栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB，增长顺序为从高到低\n内核空间：\n\n\n\n\n\n\n\n虚拟内存和物理内存\n\n物理内存：使用物理地址进行寻址，寻址的范围取决于CPU的地址线条数（如32位平台下寻址范围为2^32即4G），每次开启一个线程都要给4G物理内存，资源不够时没分配到资源的进程只能等待，并且资源不隔离导致数据不安全\n虚拟内存：让应用程序以为自己拥有连续的可用内存（连续完整的地址空间），实际上被分割成多个物理内存分片，还有部分存储在外部磁盘存储器上，在需要时进行数据交换\n\n\n页面置换算法：\n\n最佳(Optimal)页面置换算法：这是一种理论上的算法，它总是选择未来最长时间内不会被访问的页面进行替换。虽然它具有最佳性能，但实际上很难实现，因为需要预测未来的页面访问模式。\n先进先出(FIFO)页面置换算法：这是一种简单的算法，它选择最早进入内存的页面进行替换。它的实现简单，但有时可能会导致”抖动”现象，即最近使用频繁的页面被频繁地替换。\n最近最少使用(LRU)页面置换算法：LRU算法选择最近最久未被使用的页面进行替换。为了实现LRU，需要维护一个页面访问历史记录，以跟踪哪些页面最近被访问。这是一种比较复杂的算法，但通常效果很好。\n最不经常使用(LFU)页面置换算法：LFU算法选择最不经常被使用的页面进行替换。它根据页面的使用频率来做决策。这种算法适用于需要考虑页面访问频率的情况。\n时钟(Clock)页面置换算法：时钟算法使用一个类似于时钟的数据结构，按照页面的访问顺序进行替换。当页面被访问时，它的”使用位”被设置，当需要替换页面时，算法选择第一个”使用位”为0的页面进行替换。\n最近未使用(NRU)页面置换算法：NRU算法将页面分为四个类别，根据页面的访问历史和”修改位”来分类。然后它选择一个类别中的页面进行替换。这种算法相对简单，但不够精细。\n二次机会(Second-Chance)页面置换算法：二次机会算法是时钟算法的一种变体，它使用”使用位”和”修改位”来做出替换决策。如果页面的”使用位”为1，它将被清零并获得第二次机会。\n工作集(Working Set)页面置换算法：工作集算法尝试维护一个动态的工作集，其中包含了最近一段时间内被进程访问的页面。它优先保留工作集中的页面，以减少页面失效率。\n\n\n内存泄漏\n\n程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果\n避免内存泄漏：动态开辟内存空间、及时释放内存、使用智能指针，采用静态分析技术（LCLink、ccmalloc、Dmalloc、Electric Fence、Leaky、LeakTracer、MEMWATCH、Valgrind、KCachegrind）来进行检测\n\n\n堆和栈的区别\n\n管理方式：堆手动控制，栈由编译器自动管理\n空间大小：栈小于堆，栈会出现OOM问题\n碎片问题：堆频繁的分配和释放会造成空间不连续，利用率低，栈不会\n增长方向：堆是向上的（内存地址增加），栈是向下的（内存地址减小）\n分配方式：堆都是动态分配的，没有静态分配的堆。栈有两种分配方式：静态分配和动态分配，静态分配是编译器完成的，比如局部变量的分配；动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，它的动态分配是由编译器实现的，无需我们手工实现\n分配效率：栈有寄存器、底层指令的支持，堆是由C/C++来提供的，根据算法在内存中找可用空间，所以堆的效率要比栈低的多\n\n\nmalloc\n\nCPU Cache的数据写入\n\n写直达（Write Through）：把数据同时写入内存和 Cache 中，写入前会先判断数据是否已经在 CPU Cache 里面了\n如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；\n如果数据没有在 Cache 里面，就直接把数据更新到内存里面。\n\n\n写回（Write Back）：当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率\n\n\n缓存一致性\n\n第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为写传播（*Write Propagation*）；\n\n第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串行化（*Transaction Serialization*）。\n\n实现\n\n总线嗅探：当 A 号 CPU 核心修改了 L1 Cache 中 i 变量的值，通过总线把这个事件广播通知给其他所有的核心，然后每个 CPU 核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的 L1 Cache 里面，如果 B 号 CPU 核心的 L1 Cache 中有该数据，那么也需要把该数据更新到自己的 L1 Cache\n\nMESI协议：\n\n状态：Modified（已修改）、Exclusive（独占）、Shared（共享）、Invalidated（已失效）\n\n状态流转\n\n\n示例\n\n当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的；\n然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的；\n当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。\n如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。\n如果 A 号 CPU 核心的 Cache 里的 i 变量对应的 Cache Line 要被「替换」，发现 Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。\n\n\n\n\n\n\n\n\n\n\n3.网络系统\nIO模型\n\n同步阻塞IO（BIO）「jdk1.4之前支持」：服务端采用单线程，当accept一个请求后，在recv或send调用阻塞时，将无法accept其他请求，必须等待上一个请求被处理完；服务端采用多线程，当accept一个请求后，开启线程进行recv，通过多个线程可以完成并发处理，但是大量的线程占用大量的内存空间，并且线程切换会带来巨大的开销\n\n阻塞和非阻塞：数据未准备好时请求数据，等待数据就是阻塞，直接返回多次请求就是非阻塞\n同步与异步：同步模式由用户线程的内核态执行内核空间到用户空间的数据拷贝，异步模式由内核来执行数据拷贝执行完通知用户线程并将数据回调给用户线程\n阻塞读/写：执行read或send系统调用时，用户线程从用户态切换到内核态，执行用户空间拷贝到内核空间的Socket发送缓冲区之间的数据拷贝。读时如果没有数据则线程进入阻塞状态，直到有数据后唤醒线程；写时如果无法一次容纳所有的数据，则让出CPU，直到空间够用时执行写流程\n\n\n同步非阻塞IO（NIO）「jdk1.4之后的java.nio包」：服务器accept一个请求后，加入文件描述符集合，每次轮询一遍文件描述符集合来recv数据，没有数据立即返回错误，每次轮询所有文件描述符很浪费时间\n\n阻塞IO的问题是一个线程只能处理一个连接，非阻塞IO就是为了解决这样的问题\n非阻塞读：当无数据时，系统调用立刻返回并带一个EWOULDBLOCK 或 EAGAIN错误，这个阶段用户线程不会阻塞也不会让出CPU，而是会继续轮训直到socket接收缓冲区中有数据为止\n非阻塞写：能写多少写多少，不用一次写完，写不下了返回已经写入的字节数，方便下一次轮训来写剩下的数据\n\n\nIO多路复用（select、poll、epoll、aio、libevent、libuv）：见下\n\n在阻塞IO模型中一个连接就需要分配一个独立的线程去专门处理这个连接上的读写，到了IO多路复用模型中，多个连接可以复用这一个独立的线程去处理这多个连接上的读写，通过使用操作系统内核来执行轮训操作，减少系统调用和内核切换的次数\n\nselect：将轮询的操作交给了内核来完成，调用并阻塞在select系统调用上，并通过select将文件描述符fd数组（BitMap，1表示该fd上有读写事件）通过select系统调用传递给内核。select通过内核来轮询遍历fd数组，有数据来就设置为1否则设置为0，如果有新的数据来就将修改后的fd数组返回给用户线程。用户线程接触阻塞，开始遍历fd数组对值为1的scoket文件描述符发起系统调用。仍需要上下文切换和数据拷贝，还需要遍历结果，所以只能处理1000个左右的并发连接\n&#x2F;&#x2F;select系统调用是在规定的超时时间内，监听（轮询）用户感兴趣的文件描述符集合上的可读,可写,异常三类事件\n&#x2F;&#x2F;这里的fd_set就是前边提到的fd数组，是一个BitMap结构\nint select(int maxfdp1,fd_set *readset,fd_set *writeset,fd_set *exceptset,const struct timeval *timeout)\n&#x2F;&#x2F;用户线程中重新遍历fd数组的过程中，需要用到的API\nvoid FD_ZERO(fd_set *fdset)  &#x2F;&#x2F;清空指定的文件描述符集合，即让fd_set中不在包含任何文件描述符\nvoid FD_SET(int fd, fd_set *fdset)  &#x2F;&#x2F;将一个给定的文件描述符加入集合之中\nint FD_ISSET(int fd, fd_set *fdset)  &#x2F;&#x2F;检查集合中指定的文件描述符是否可以读写。用户线程遍历文件描述符集合,调用该方法检查相应的文件描述符是否IO就绪\nvoid FD_CLR(int fd, fd_set *fdset)  &#x2F;&#x2F;将一个给定的文件描述符从集合中删除\npoll：poll相当于是改进版的select，但是工作原理基本和select没有本质的区别\nint poll(struct pollfd *fds, unsigned int nfds, int timeout)\nstruct pollfd &#123;\n    int   fd;         &#x2F;* 文件描述符 *&#x2F;\n    short events;     &#x2F;* 需要监听的事件 *&#x2F;\n    short revents;    &#x2F;* 实际发生的事件 由内核修改设置 *&#x2F;\n&#125;;  &#x2F;&#x2F;将BitMap结构改成pollfd，即没有固定长度的数组，这样就没有最大描述符数量的限制，只受限于系统文件描述符最大数量\n\n\n信号驱动的IO（SIGIO）\n\n异步IO（POSIX的aio_functions）\n\n异步非阻塞IO，在进行IO操作时，不需要等待操作完成就可以进行其他操作，当操作完成后自动回调通知，jdk1.7之后java.nio包下的java.nio.channels.AsynchronousSocketChannel等。但是linux下AIO支持并不好并且相比NIO性能提升不明显，所以Netty在4.x舍弃了AIO\n\n\n\n\nReactor模式和Proactor模式\n\nReactor模式：要求主线程只负责监听文件描述符上是否有事件发生，有的话立即将该事件通知工作线程，将socket可读可写事件方去请求队列，交给工作线程来处理，使用epoll实现的工作流程如下：\n主线程向epoll内核事件表中注册socket上的读就绪事件\n可读\n主线程调用epoll_wait等待socket上有数据可读\n当socket上有数据可读时，epoll_wait通知主线程，主线程将socket可读事件放入请求队列\n睡眠在请求队列上的某个工作线程被唤醒，它从socket读取数据，并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件\n\n\n可写\n当主线程调用epoll_wait等待socket可写\n当socket可写时，epoll_wait通知主线程。主线程将socket可写事件放入请求队列\n睡眠在请求队列上的某个工作线程被唤醒，它往 socket上写入服务器处理客户请求的结果\n\n\n\n\nProactor模式\n\n\nIO多路复用技术\n\nselect模型：采用轮询和遍历的方式，在客户端操作服务器时，会创建三种文件描述符（写描述符、读描述符、异常描述符），select会阻塞这三种文件描述符，等有数据可读、可写、异常或超时都会返回。然后通过遍历文件描述符集合来找到就绪的文件描述符，进行IO操作。由于每次都需要遍历所有文件描述符，所以性能随着描述符的增多而减小\n\n使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符\n\n\n\n\n\n int main()&#123;\n\t&#x2F;&#x2F;socket 建立、地址设置\n\tfd_set read_fs,write_set;\n\tstruct timeval timeout;\n\tint max &#x3D; 0;&#x2F;&#x2F;用于记录最大的fd，在轮询中时刻更新\n\t&#x2F;&#x2F;初始化比特位\n\tFD_ZERO（&amp;read_fs);\n\tFD_ZERO(&amp;write_fs);\n\t\n\tint nfds &#x3D; 0;&#x2F;&#x2F;记录就绪的事件，可以减少遍历的次数\n\twhile(1）&#123;\n\t&#x2F;&#x2F;阻塞获取，每次需要把fd从用户态拷贝到内核态\n\tnfds &#x3D; select(max+1, &amp;read_fd, &amp;write_fd, NULL, &amp;timeout);\n\t&#x2F;&#x2F;每次需要遍历所有fd，判断有无读写事件发生\n\tfor(int i &#x3D; 0; i &lt;&#x3D; max &amp;&amp; nfds; ++i)&#123;\n\t\tif(i &#x3D;&#x3D; listenfd)&#123;\n\t\t\t--nfds;\n\t\t\t&#x2F;&#x2F;处理accept事件\n\t\t\tFD_SET(i, &amp;read_fd);&#x2F;&#x2F;将客户端socket加入到集合中\n\t\t&#125;\n\t\tif(FD_ISSET(i, &amp;read_fd))&#123;\n\t\t\t--nfds;\n\t\t\t&#x2F;&#x2F;处理read事件\n\t\t&#125;\n\t\tif (FD_ISSET(i, &amp;write_fd)) &#123;\n\t\t\t --nfds;\n\t     &#x2F;&#x2F; 这里处理write事件\n    &#125;\n  &#125;\n&#125;\n\n\npoll模型：poll模型的原理与select模型基本一致，也是轮询+遍历，区别在于poll采用链表的方式来存储文件描述符，同select一样，性能随着描述符的增多而减小\n#include &lt;poll.h&gt;\n&#x2F;&#x2F; 数据结构\nstruct pollfd &#123;\n    int fd;                         &#x2F;&#x2F; 需要监视的文件描述符\n    short events;                   &#x2F;&#x2F; 需要内核监视的事件\n    short revents;                  &#x2F;&#x2F; 实际发生的事件\n&#125;;\n\n&#x2F;&#x2F; API\nint poll(struct pollfd fds[], nfds_t nfds, int timeout);\nepoll模型：采用时间通知机制来触发相关的IO操作，没有文件描述符个数的限制，从用户态拷贝到内核态只需要一次。它主要通过系统底层的函数来注册、激活文件描述符，从而触发相关的IO操作，这样大大提高了提高性能（Redis、Nginx等，1G内存大概支持10万个句柄）\n\n特点\n\n将轮询改成了回调，提高了CPU执行效率、没有文件描述符数量限制、性能不会随文件描述符的增加而减小，内存拷贝（利用mmap文件映射内存加速与内核空间的消息传递，减少复制开销）\n\n在内核里使用红黑树来关注进程所有待检测的 Socket，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。\n\n解释io特别密集时 epoll 效率不高\n\n连接密集（短连接特别多），使用epoll的话，每一次连接需要发生epoll_wait-&gt;accpet-&gt;epoll_ctl调用，而使用select只需要select-&gt;accpet，减少了一次系统调用\n读写密集的话，如果收到数据，我们需要响应数据的话，使用epoll的情况下， read 完后也需要epoll_ctl 加入写事件，相比select多了一次系统调用\n\n\n\n\nSocket创建\n\n服务端线程调用accept后阻塞，在客户端连接并完成TCP三次握手之后，kernel创建一个对应的socket作为服务端与内核端通信的内核接口，并将socket保存在当前进程打开的文件列表（Linux内核中一切皆是文件）中管理起来\nsocket()函数的返回值是一个非负整数，称为文件描述符（File Descriptor），它用于标识和操作这个socket，如果创建失败，它会返回-1，表示错误\n\n\n进程中管理的文件列表结构：内核通过fd_array来进行组织管理，数组下标为文件描述符，数据中存放的是文件数据结构file。进程中打开的文件列表fd_array定义在内核数据结构struct files_struct中，在struct fdtable结构中有一个指针struct file **fd指向fd_array\n用于封装文件元信息的内核数据结构struct file中的private_data指针指向具体的Socket结构。struct file中的file_operations属性定义了文件的操作函数，不同的文件类型，对应的file_operations是不同的，针对Socket文件类型，这里的file_operations指向socket_file_ops。在用户空间对Socket发起的读写等系统调用，进入内核首先会调用的是Socket对应的struct file中指向的socket_file_ops，如对Socket发起write写操作，在内核中首先被调用的就是socket_file_ops中定义的sock_write_iter\nSocket内核结构：最先创建的是监听socket，之后另外创建新的socket专门用于客户端之间的网络通信，并将监听Socket中的Socket操作函数集合（inet_stream_ops）ops赋值到新的Socket的ops属性中。接着kernel会为已连接的socket创建file结构体并初始化，并把Socket文件操作函数集合（socket_file_ops）赋值给file中的f_ops指针。然后将struct socket中的file指针指向这个新分配申请的file结构体。然后调用socket-&gt;ops-&gt;accept，即inet_accept函数，该函数会在icsk_accept_queue（已完成三次握手）中查找是否有已经建立好的连接，如果有的话，直接从icsk_accept_queue中获取已经创建好的struct sock。并将这个struct sock对象赋值给struct socket中的sock指针（sock对象中定义了接收队列，发送队列，等待队列，数据就绪回调函数指针，内核协议栈操作函数集合）\ninet_stream_ops函数集合中存储给用户提供的接口，socket与内核协议栈之间的接口定义在struct sock中的sk_port指针上\nstruct sock中的等待队列中存放的是系统IO调用发生阻塞的进程fd，以及相应的回调函数\n对Socket发起的系统IO调用，在内核中首先会调用Socket的文件结构struct file中的file_operations文件操作集合，然后调用struct socket中的ops指向的inet_stream_opssocket操作函数，最终调用到struct sock中sk_prot指针指向的tcp_prot内核协议栈操作函数接口集合\n\n\n当struct file，struct socket，struct sock这些核心的内核对象创建好之后，最后就是把socket对象对应的struct file放到进程打开的文件列表fd_array中。随后系统调用accept返回socket的文件描述符fd给用户程序。\n\n\n阻塞IO中用户进程阻塞以及唤醒原理\n\n阻塞\n首先我们在用户进程中对Socket进行read系统调用时，用户进程会从用户态转为内核态\n在进程的struct task_struct结构找到fd_array，并根据Socket的文件描述符fd找到对应的struct file，调用struct file中的文件操作函数结合file_operations，read系统调用对应的是sock_read_iter\n在sock_read_iter函数中找到struct file指向的struct socket，并调用socket-&gt;ops-&gt;recvmsg，这里我们知道调用的是inet_stream_ops集合中定义的inet_recvmsg\n在inet_recvmsg中会找到struct sock，并调用sock-&gt;skprot-&gt;recvmsg,这里调用的是tcp_prot集合中定义的tcp_recvmsg函数\n\n\n唤醒：\n当软中断将sk_buffer放到Socket的接收队列上时，接着就会调用数据就绪函数回调指针sk_data_ready，前边我们提到，这个函数指针在初始化的时候指向了sock_def_readable函数\n在sock_def_readable函数中会去获取socket-&gt;sock-&gt;sk_wq等待队列。在wake_up_common函数中从等待队列sk_wq中找出一个等待项wait_queue_t，回调注册在该等待项上的func回调函数（wait_queue_t-&gt;func）,创建等待项wait_queue_t是我们提到，这里注册的回调函数是autoremove_wake_function，即epoll的回调函数\n在autoremove_wake_function函数中，根据等待项wait_queue_t上的private关联的阻塞进程fd调用try_to_wake_up唤醒阻塞在该Socket上的进程\n\n\n\n\n相关的系统调用\n\nepoll_create：系统启动的时候，在Linux内核里面申请一个B+树结构的文件系统，然后返回epoll对象（一个文件描述符）用来后续使用\n\nepoll_ctl：每新建一个连接的时候，会同步更新epoll对象中的文件描述符，并且绑定一个callback函数，通过此调用向epoll对象中添加、删除、修改感兴趣的事件，返回0表示成功\n\nepoll_wait：轮询所有的callback集合（红黑树），并触发相应的IO操作，通过此调用收集在epoll监控中已发生的事件\n\n工作流程\n\n通过epoll_create创建epoll对象，此时epoll对象的内核结构包含就绪链表和红黑树，就绪队列是用于保存所有读写事件到来的socket。红黑树用于保存所有待检测的socket\n通过 epoll_crt 将待检测的socket，加入到红黑树中，并注册一个事件回调函数，当有事件到来的之后，会调用这个回调函数，进而通知到 epoll 对象\n调用 epoll_wait 等待事件的发生，当内核检测到事件发生后，调用该socket注册的回调函数，执行回调函数就能找到socket对应的epoll对象，然后会将事件加入到epoll对象的绪队列中，最后将就绪队列返回给应用层\n\n\n示意图\n\n\n\n\nepoll水平触发（LT）和边缘触发（ET）的区别\n\nLevel Triggered（LT）水平触发：只要有数据就会触发，只要这个 fd 还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作\n使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；\n如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作\n\n\nEdge Triggered（ET）边缘触发：只有数据到来，才触发，只会提示一次，直到下次数据流入\n使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；\n如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I/O 搭配使用，程序会一直执行 I/O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。\n\n\n\n\n代码示例\n#include &lt;sys&#x2F;epoll.h&gt;\n\n&#x2F;&#x2F; 每一个epoll对象都有一个独立的eventpoll结构体\n&#x2F;&#x2F; 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件\n&#x2F;&#x2F; epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可\nstruct eventpoll &#123;\n    &#x2F;*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*&#x2F;\n    struct rb_root  rbr;\n    &#x2F;*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*&#x2F;\n    struct list_head rdlist;\n&#125;;\n\n&#x2F;&#x2F;在epoll中，对于每一个事件，都会建立一个epitem结构体\nstruct epitem&#123;\n    struct rb_node  rbn;&#x2F;&#x2F;红黑树节点\n    struct list_head    rdllink;&#x2F;&#x2F;双向链表节点\n    struct epoll_filefd  ffd;  &#x2F;&#x2F;事件句柄信息\n    struct eventpoll *ep;    &#x2F;&#x2F;指向其所属的eventpoll对象\n    struct epoll_event event; &#x2F;&#x2F;期待发生的事件类型\n&#125;\n\n&#x2F;&#x2F; API\nint epoll_create(int size); &#x2F;&#x2F; 内核中间加一个 eventpoll 对象，把所有需要监听的 socket 都放到 ep 对象中\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); &#x2F;&#x2F; epoll_ctl 负责把 socket 增加、删除到内核红黑树\n&#x2F;&#x2F; 当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可\nint epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);&#x2F;&#x2F; epoll_wait 负责检测可读队列，没有可读 socket 则阻塞进程\n\n\n\n\nNginx的IO模型：支持多种并发模型，自动选择最高效的模型，也可以使用use指令在配置文件中显示指定某个并发模型，如下所示\n\nselect：编译时，所用平台没有更高效的并发模型时，select被自动编译\npoll：标准并发模型，同select一样，所用平台没有更高效的并发模型时，pol被自动编译\nepoll：IO多路复用，高效并发模型，Linux2.6+可以使用\nkequeue：IO多路复用，高效并发模型，可在 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0, and Mac OS X 平台中使用\n/dev/poll：高效并发模型，可在 Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+, and Tru64 UNIX 5.1A+ 平台使用\neventport：建议 使用/dev/poll替代\n\n\nRedis的IO模型：Redis跑在单线程中，所有操作都是按照顺序线性执行的，为了防止IO阻塞整个Redis进程，所以使用IO多路复用技术。Redis的IO复用技术基于epoll实现，另外提供了select和kqueue的实现\n\n补充\n\n一个服务端进程最多可以和多少个客户端进行连接？和fd的数量有关吗？\n在Linux系统中，每个进程都有一个限制的文件描述符数量，这个限制通常由操作系统的配置和资源决定\n服务端进程与客户端的连接通常会使用文件描述符，每个连接至少需要一个文件描述符。因此，文件描述符的数量会限制服务端进程能够同时处理的客户端连接数量\n要增加服务端进程能够处理的客户端连接数量，可以通过更改系统配置来增加文件描述符限制、使用事件驱动的I/O模型（epoll或select）、优化服务端代码（多线程、异步编程）、合理使用连接池复用连接\n\n\n\n\n\n\n附录\n\n\n\n\n\n\n\n\nShell/Python脚本、网络编程、多线程编程\n1.Termianl\n目录结构：/bin：命令、/etc：系统管理所需要的配置文件和子目录、/home：用户的主目录、/lib：系统最基本的动态连接共享库、/opt：额外安装软件所摆放的目录、/root：管理员主目录、/sbin：管理员使用的命令、/tmp：存放临时文件、/usr：用户的应用程序和文件、/var：存不断扩充的文件，如日志文件\n命令\n文件管理：ls、ll、cd、pwd、mkdir、rmdir、rm、cp、mv、touch、chown、chmod、tar、\n\n文档编辑：cat、tac、nl、more、less、head、tail、grep（文本搜索）、awk（自定义函数或正则表达式）、sed（批量编辑文本文件）\n\n进程监控：su、sudo、kill（kill -9 pid）、管道命令、ps（ps -ef | more进程信息）、top（实时显示进程信息）、lsof（查看某一文件的进程信息）、free（查看内存使用情况，如进程、CPU占用率、内存信息）、df（磁盘使用量）、iostat（I/O设备状态）、vmstat（虚拟内存状态）、du（磁盘使用情况）\n\n\n网络监控：iperf（查看带宽和网络）、netstat（查看所有占用端口的进程）、traceroute（数据包路径）、ping（测试与主机的连通性）、lsof（查看占用某端口号的进程sudo lsof -i :80）\n\n其它：strace、dtrace、systemtap、uname、history\n\n\n\nShell脚本\nVim编辑器\n常见系统调用\n文件管理：creat、open、close、lseek（定位）、read、write\n进程管理：fork、execve（执行新二进制文件）、waitpid（等待子进程结束）、clone、exit\n内存管理：brk、mmap（内存映射）\n进程间通信：\n消息队列：msgget（创建队列）、msgsnd（发送消息）、msgrcv（接收消息）\n共享内存：shmget（创建共享内存）、shmat（将共享内存映射到内存空间）\n信号量：sem_wait(抢占信号量)、sem_post（释放信号量）\n\n\n网络通信：socket、bind、connect、listen、accept\n信号处理：kill、signaction\n\n\n\n2.系统调用\nmalloc：通过两种系统调用申请堆内存（虚拟内存），malloc()本身不是系统调用\n\n方式一（用户分配的内存小于 128 KB）：通过 brk() 系统调用将堆顶指针向高地址移动，获得新的内存空间\n\n频繁通过 mmap 分配的内存，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大，所以通过brk系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中，等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了\n频繁使用brk，会导致堆内产生越来越多不可用的碎片，导致“内存泄露”，这种“泄露”现象使用 valgrind 是无法检测出来的\n\n\n\n方式二（用户分配的内存大于 128 KB）：通过 mmap() 系统调用在文件映射区域分配内存（私有匿名映射，从文件映射区“偷”了一块内存）\n\nmalloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节，保存了该内存块的描述信息，当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小，从而知道释放多大的内存\n\n\n\n其它\n\nmalloc() 在分配内存的时候，并不按用户预期申请的字节数来分配内存空间大小，而是会预分配更大的空间作为内存池\nfree()\nmalloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用；\nmalloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。\n\n\n\n\n\n\nread()\n- \n\n\n3.实战\n操作系统保护模式和实模式\n\n实模式将整个物理内存看成分段的区域，程序代码和数据位于不同区域，系统程序和用户程序并没有区别对待，而且每一个指针都是指向实际的物理地址。这样一来，用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并修改了内容，那么对于这个被修改的系统程序或用户程序，其后果就很可能是灾难性的。再者，随着软件的发展，1M的寻址空间已经远远不能满足实际的需求了。最后，对处理器多任务支持需求也日益紧迫，所有这些都促使新技术的出现\n为了克服实模式下的内存非法访问问题，并满足飞速发展的内存寻址和多任务需求，处理器厂商开发出保护模式。在保护模式中，除了内存寻址空间大大提高；提供了硬件对多任务的支持；物理内存地址也不能直接被程序访问，程序内部的地址(虚拟地址)要由操作系统转化为物理地址去访问，程序对此一无所知。至此，进程(程序的运行态)有了严格的边界，任何其他进程根本没有办法访问不属于自己的物理内存区域，甚至在自己的虚拟地址范围内也不是可以任意访问的，因为有一些虚拟区域已经被放进一些公共系统运行库。这些区域也不能随便修改，若修改就会有出现linux中的段错误，或Windows中的非法内存访问对话框\n\n\n内存回收：系统内存紧张时会进行内存回收，主要回收以下两类\n\n文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存\n匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了\n文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。\nactive_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；\ninactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；\n\n\n\n\n从 a 文件 copy 到另外一个目录， b 作为一个从 a 目录 copy 到一个 b 目录这样的一个文件，操作过程中间包含了哪些系统调用？这里面执行了多少次拷贝的动作？\n\n\n第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。\n第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。\n第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核缓冲区里，这个过程依然还是由 CPU 搬运的。\n第四次拷贝，把内核缓冲区里的数据，拷贝到磁盘，这个过程又是由 DMA 搬运的。\n\n\nPageCache\n\n缓存一些比较常访问的文件到缓存中，这样子的话它就能减少两次从内核空间拷贝的过程，就是来减少查询这个内容的时间\n当用户对文件进行读写时，实际上是对文件的 页缓存 进行读写。所以对文件进行读写操作时，会分以下两种情况进行处理：\n当从文件中读取数据时，如果要读取的数据所在的页缓存已经存在，那么就直接把页缓存的数据拷贝给用户即可。否则，内核首先会申请一个空闲的内存页（页缓存），然后从文件中读取数据到页缓存，并且把页缓存的数据拷贝给用户。\n当向文件中写入数据时，如果要写入的数据所在的页缓存已经存在，那么直接把新数据写入到页缓存即可。否则，内核首先会申请一个空闲的内存页（页缓存），然后从文件中读取数据到页缓存，并且把新数据写入到页缓存中。对于被修改的页缓存，内核会定时把这些页缓存刷新到文件中。\n\n\n\n\nfd\n- \n\n\n","slug":"Linux","date":"2023-05-11T11:26:21.000Z","categories_index":"","tags_index":"tools","author_index":"Dajunnnnnn"},{"id":"0eecce2180060832c1ffa34a76f3eb3b","title":"Spring Family","content":"Spring\n\n\n\n\n\n\n\n\nSpring框架是一个开源的Java应用程序框架，用于简化企业级Java应用程序的开发。它提供了广泛的基础设施支持，包括依赖注入（Dependency Injection）、面向切面编程（Aspect-Oriented Programming）、事务管理、数据访问、消息传递等功能，以帮助开发者构建可维护、可扩展、松散耦合的应用程序\n1.IOC1.基础知识\nIOC（Inversion of Control，IoC）是一种设计原则，它将应用程序的控制权从应用程序代码中转移到外部容器或框架。在IoC中，对象的创建、组装和管理不再由应用程序本身负责，而是由IoC容器或框架来完成，原理如下：\n\n配置元数据： 应用程序的对象及其依赖关系通常通过XML配置文件或Java注解来描述\n容器初始化及对象的管理： 应用程序启动时通过读取配置信息来初始化IOC容器。IOC容器负责实例化对象，管理对象的生命周期（初始化@PostConstruct、使用和销毁@PreDestroy），在使用时从IOC容器中获取所需要的对象（容器返回已创建和配置好的对象实例）\n依赖注入：IOC容器负责注入对象之间的依赖关系，根据配置信息自动将依赖注入到对象中\n\n\n容器启动过程：\n\n加载配置文件或配置类： Spring容器会首先加载配置文件（如XML配置文件）或配置类（如使用Java配置的方式）。这些配置文件或类包含了Spring应用程序的配置信息，定义了需要被容器管理的Bean以及它们之间的依赖关系。\n创建容器： 根据加载的配置信息，Spring容器会创建一个容器对象，通常是ApplicationContext的实例。容器的类型可以根据配置来选择，常见的包括ClassPathXmlApplicationContext、AnnotationConfigApplicationContext等。\n扫描和注册Bean定义： Spring容器会扫描配置文件或配置类中的Bean定义，然后将这些Bean定义注册到容器中。Bean定义包括Bean的类型、作用域、初始化方法、销毁方法等信息。\n实例化Bean： 容器根据Bean定义，实例化应用程序中所有需要被管理的Bean。这通常涉及到创建Bean的Java对象实例，并将其存储在容器的Bean工厂中。\n依赖注入： Spring容器会处理Bean之间的依赖关系。它会查找需要注入的属性或构造函数参数，然后根据配置找到相应的Bean，将其注入到目标Bean中。\n初始化Bean： 在Bean的生命周期中，Spring容器会调用初始化方法。这可以是通过@PostConstruct注解标记的方法，或者是配置中指定的初始化方法。初始化方法可以包括一些必要的配置和资源初始化。\n应用程序运行： Spring容器启动后，应用程序可以开始运行。开发者可以通过容器获取需要的Bean，并调用它们的方法执行业务逻辑。\n关闭容器： 当应用程序需要关闭时，开发者可以显式地关闭Spring容器。容器会执行销毁Bean的操作，包括调用@PreDestroy注解标记的销毁方法。\n资源释放： 在容器关闭过程中，容器会释放占用的资源，如数据库连接、线程池等。这确保资源得到正确释放，防止资源泄漏。\n\n\nBeanFactory：提供了一种高级配置，能够管理任何类型对象，BeanFactory是ApplicationContext的父接口，ApplicationContext接口的实现类主要有ClassPathXmlApplicationContext、FileSystemXmlApplicationContext、WebApplicationContext、AnnotationConfigApplicationContext等，主要负责Bean的实例化、配置、组装\n\n安装容器：ApplicationContext context = new ClassPathXmlApplicationContext(&quot;services.xml&quot;, &quot;daos.xml&quot;);\n\n\nBean：由Spring的IOC容器实例化、组装和管理的对象，一个Bean有全局唯一的name，其它的只能指定别名\n\nbean定义：Class、Name（全局唯一）、Scope、Constructor arguments、Properties、Autowiring mode、Lazy initialization mode、Lazy initialization mode、\n\n==生命周期（作用域）==\n\n\n\nScope\nDescription\n\n\n\nsingleton\n(Default) Scopes a single bean definition to a single object instance for each Spring IoC container.\n\n\nprototype\nScopes a single bean definition to any number of object instances.\n\n\nrequest\nScopes a single bean definition to the lifecycle of a single HTTP request. That is, each HTTP request has its own instance of a bean created off the back of a single bean definition.\n\n\nsession\nScopes a single bean definition to the lifecycle of an HTTP Session.\n\n\napplication\nScopes a single bean definition to the lifecycle of a ServletContext.\n\n\nwebsocket\nScopes a single bean definition to the lifecycle of a WebSocket.\n\n\n\n实例化：bean定义本质上是创建一个或多个对象的方法，当被访问到时，容器会查看bean的命名和定义来创建实际对象\n\n通过构造方法实例化：所有普通类（默认空参构造+getter+setter）都可以被Spring使用并兼容，只需要指定bean类\n通过静态工厂方法实例化：使用class属性来指定包含静态工厂方法的类，并使用factory-method的属性来指定工厂方法本身的名称，主要用于在遗留代码中调用静态工厂来实例化bean\n通过实例工厂方法实例化：使用实例工厂中的非静态方法来创建新bean，使用factory-bean指定工厂类对应的bean，使用factory-method的属性来指定工厂方法\n\n\n\n\n容器扩展点\n\nBeanPostProcessor：通过实现其提供的回调方法，来提供定制的实例化逻辑、依赖解析逻辑，BeanPostProcessor的两个方法分别在Bean的初始化前后执行（postProcessBeforeInitialization和postProcessAfterInitialization）\n\nAOP自动代理类：DefaultAdvisorAutoProxyCreator，可以实现自动生效所有的advisor\n\nSpring自动装配的实现类：AutowiredAnnotationBeanPostProcessor\n         public interface BeanPostProcessor &#123;\n             @Nullable\n             default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;return bean;&#125;\n             @Nullable\n             default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;return bean;&#125;\n         &#125;\n\n\nBeanFactoryPostProcessor：与BeanPostProcessor的区别是BeanFactoryPostProcessor对bean的配置元数据进行操作，并可以在容器实例化除BeanFactoryPostProcessor实例之外的任何bean之前更改它\n\n\n\n从外部jdbc.properties文件导入DataSource的某些属性的元数据：PropertySourcesPlaceholderConfigurer\n        &lt;!--加载properties文件--&gt;\n        &lt;context:property-placeholder location&#x3D;&quot;classpath*:jdbc.properties&quot;&#x2F;&gt;\n        &lt;!--数据源--&gt;\n        &lt;bean id&#x3D;&quot;dataSource&quot; class&#x3D;&quot;com.alibaba.druid.pool.DruidDataSource&quot;&gt;\n            &lt;property name&#x3D;&quot;driverClassName&quot; value&#x3D;&quot;$&#123;jdbc.driver&#125;&quot;&#x2F;&gt;\n            &lt;property name&#x3D;&quot;url&quot; value&#x3D;&quot;$&#123;jdbc.url&#125;&quot;&#x2F;&gt;\n            &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;$&#123;jdbc.username&#125;&quot;&#x2F;&gt;\n            &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;$&#123;jdbc.password&#125;&quot;&#x2F;&gt;\n        &lt;&#x2F;bean&gt;\n\n\nFactoryBean\n\n\n依赖注入：通过定义需要的依赖，并将这些依赖注入到bean中，可以使得代码更简洁，更方便测试。对强制依赖项使用构造函数，对可选依赖使用setter方法\n\n依赖注入处理流程\n\n通过所有bean的元数据的描述构造并初始化ApplicationContext\n对每一个bean，它的依赖关系以属性、构造函数或静态工厂方法的参数的形式表示，并在实际创建bean时提供给bean\n每个属性或构造函数参数都是要设置的值的实际定义，或是对容器中另一个bean的引用\n作为值的每个属性或构造函数参数都从其指定格式转换为该属性或构造函数参数的实际类型\n\n\n自动装配的四种模式：？\n\nno：不自动装配，bean引用必须有ref元素定义\nbyName：按属性名自动装配，Spring寻找与需要自动装配的属性同名的bean，例如有setMaster()方法的bean会去找名为master的bean定义\nbyType：如果容器中恰好存在一个属性类型的bean，则让属性自动装配；如果存在多个，则需要使用byType自动装配\nconstructor：与byType类似，但适用于构造函数参数，如果容器中没有一个构造函数参数类型的bean，则会引发错误\n\n\n延迟初始化bean：单例bean常常会很早初始化，当不需要提前初始化bean来验证错误时，可以将bean定义标记为延迟初始化来防止单例bean的预实例化。lazy bean不会被太早实例化，not.lazy bean会被很早实例化\n&lt;bean id&#x3D;&quot;lazy&quot; class&#x3D;&quot;com.something.ExpensiveToCreateBean&quot; lazy-init&#x3D;&quot;true&quot;&#x2F;&gt;\n&lt;bean name&#x3D;&quot;not.lazy&quot; class&#x3D;&quot;com.something.AnotherBean&quot;&#x2F;&gt;\n\n\n自动装配原理（条件注解+依赖注入）\n\n首先，Spring Boot会根据classpath下的依赖以及配置文件中的设置，自动扫描并加载相应的自动配置类\n其次，自动配置类中使用了条件注解，根据条件判断是否要进行自动装配。条件注解可以根据一些特定的条件，如某个类是否在classpath中、某个配置是否存在等，来决定是否要进行自动装配\n最后，当条件满足时，自动配置类会自动注册和配置相应的Bean，将它们添加到Spring容器中。这样，在应用程序启动时，Spring Boot就会自动完成大部分配置工作，开发者无需手动配置\n\n\n依赖注入\n\n注入方式\n\nField Injection：通过Java的反射机制实现，所以private的成员也可以被注入具体的对象\n\n@Autowired 根据类型来注入，Spring框架提供的注解，支持自动装配、按类型查找、按名称查找\n@Resource 根据名字来注入，是Java EE规范中的注解由标准库提供\n\n@Controller\npublic class UserController &#123;\n\n    @Autowired\n    private UserService userService;\n\n&#125;\nConstructor Injection：这种注入方式很直接，通过对象构建的时候建立关系，所以这种方式对对象创建的顺序会有要求，当然Spring会为你搞定这样的先后顺序，除非你出现循环依赖，然后就会抛出异常。\n@Controller\npublic class UserController &#123;\n\n    private final UserService userService;\n\n    public UserController(UserService userService)&#123;\n        this.userService &#x3D; userService;\n    &#125;\n\n&#125;\nSetter Injection：Setter Injection也会用到@Autowired注解，但使用方式与Field Injection有所不同，Field Injection是用在成员变量上，而Setter Injection的时候，是用在成员变量的Setter函数上。\n@Controller\npublic class UserController &#123;\n\n    private UserService userService;\n\n    @Autowired\n    public void setUserService(UserService userService)&#123;\n        this.userService &#x3D; userService;\n    &#125;\n&#125;\n\n\n注入方式对比\n\n\n推荐使用方式\n\nConstructor Injection在很多方面都是优于其他两种方式的，所以Constructor Injection通常都是首选方案！而Setter Injection比起Field Injection来说，大部分都一样，但因为可测试性更好，所以当你要用@Autowired的时候，推荐使用Setter Injection的方式，这样IDEA也不会给出警告了。同时，也侧面反映了，可测试性的重要地位啊！\n依赖注入的使用上，Constructor Injection是首选。\n使用@Autowired注解的时候，要使用Setter Injection方式，这样代码更容易编写单元测试。\n\n\n\n\n\n2.设计模式\n单例模式：一个类在同一进程内只允许创建一个对象（或实例），通过将构造函数声明为private，并在内部以static final的方式创建对象并返回的方式实现，具体实现如下：\n\n模版代码\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;不支持延迟加载&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic class IdGenerator&#123;\n  private AtomicLong id &#x3D; new AtomicLong(10);\n  private static final IdGenerator instance &#x3D; new IdGenerator();\n  private IdGenerator()&#123;&#125;\n  private static IdGenerator getInstance()&#123;return instance;&#125;\n  public long getId()&#123;return id.incrementAndGet();&#125;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;支持延迟加载（需要解决线程安全问题）&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic class IdGenerator&#123;\n  private AtomicLong id &#x3D; new AtomicLong(10);\n  private static final IdGenerator instance;\n  private IdGenerator()&#123;&#125;\n  private static IdGenerator getInstance()&#123;\n    if(instance &#x3D;&#x3D; null)&#123;\n      synchronized(IdGenerator.class)&#123;\n        if(instance &#x3D;&#x3D; null)&#123;\n          instance &#x3D; new IdGenerator();\n        &#125;\n      &#125;\n    &#125;&#x2F;&#x2F;if(instance &#x3D;&#x3D; null)\n    return instance;\n  &#125;\n  public long getId()&#123;return id.incrementAndGet();&#125;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;有参构造&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic synchronized static Singleton getInstance(int param) &#123; \n    if (instance &#x3D;&#x3D; null) &#123; \n        instance &#x3D; new Singleton(param); \n    &#125; else if (instance.param &#x3D;&#x3D; param) &#123;\n        return instance;\n    &#125; else &#123;\n        instance &#x3D; new Singleton(paramA, paramB);\n    &#125;\n    return instance; \n&#125;\nSingleton singleton &#x3D; Singleton.getInstance(10);\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;利用静态内部类在被调用时才加载（与外部类加载时间无关）的特性来实现&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\nprivate static class SingletonHolder&#123;\n  private static final IdGenerator instance &#x3D; new IdGenerator();\n&#125;\npublic static IdGenerator getInstance() &#123;\n  return SingletonHolder.instance;\n&#125;\n\n特殊形式\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;线程唯一单例实现&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\nprivate static final ConcurrentHashMap&lt;Long, IdGenerator&gt; instances &#x3D; new ConcurrentHashMap&lt;&gt;();\npublic static IdGenerator getInstance() &#123;\n    Long currentThreadId &#x3D; Thread.currentThread().getId();\n    instances.putIfAbsent(currentThreadId, new IdGenerator());\n    return instances.get(currentThreadId);\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;集群唯一单例实现&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n&#x2F;&#x2F;不同进程间共享同一个对象需要将单例序列化到外部共享存储区，使用时再反序列化回来，通过给对象加锁保证保证唯一性\nprivate static SharedObjectStorage storage &#x3D; FileSharedObjectStorage(&#x2F;*入参省略，比如文件地址*&#x2F;);\nprivate static DistributedLock lock &#x3D; new DistributedLock();\npublic synchronized static IdGenerator getInstance()&#123;\n    if (instance &#x3D;&#x3D; null) &#123;\n        lock.lock();\n        instance &#x3D; storage.load(IdGenerator.class);\n    &#125;\n\t\treturn instance;\n&#125;\npublic synchroinzed void freeInstance() &#123;\n    storage.save(this, IdGeneator.class);\n    instance &#x3D; null; &#x2F;&#x2F;释放对象\n    lock.unlock();\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;多例模式&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\nprivate static final Map&lt;Long, BackendServer&gt; serverInstances &#x3D; new HashMap&lt;&gt;();\nstatic &#123;\n  serverInstances.put(1L, new BackendServer(1L, &quot;192.134.22.138:8080&quot;));\n  serverInstances.put(2L, new BackendServer(2L, &quot;192.134.22.139:8080&quot;));\n  serverInstances.put(3L, new BackendServer(3L, &quot;192.134.22.140:8080&quot;));\n&#125;\npublic BackendServer getInstance(long serverNo) &#123;\n  return serverInstances.get(serverNo);\n&#125;\n&#x2F;&#x2F;同一类型的只能创建一个对象，不同类型的可以创建多个对象\nprivate static final ConcurrentHashMap&lt;String, Logger&gt; instances &#x3D; new ConcurrentHashMap&lt;&gt;();\npublic static Logger getInstance(String loggerName) &#123;\n  instances.putIfAbsent(loggerName, new Logger());\n  return instances.get(loggerName);\n&#125;\n&#x2F;&#x2F;l1&#x3D;&#x3D;l2, l1!&#x3D;l3\nLogger l1 &#x3D; Logger.getInstance(&quot;User.class&quot;);\nLogger l2 &#x3D; Logger.getInstance(&quot;User.class&quot;);\nLogger l3 &#x3D; Logger.getInstance(&quot;Order.class&quot;);\nSpring中的Bean默认都是singleton的，Spring通过ConcurrentHashMap实现单例注册表的特殊方式实现单例模式\n\n线程安全问题：尽量避免定义可变的成员变量（大部分Bean如Dao、Service都没有实例变量，是线程安全的），如果需要定义则使用ThreadLocal成员变量\n\n&#x2F;&#x2F; 通过 ConcurrentHashMap（线程安全） 实现单例注册表\nprivate final Map&lt;String, Object&gt; singletonObjects &#x3D; new ConcurrentHashMap&lt;String, Object&gt;(64);\n\npublic Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;\n        Assert.notNull(beanName, &quot;&#39;beanName&#39; must not be null&quot;);\n        synchronized (this.singletonObjects) &#123;\n            &#x2F;&#x2F; 检查缓存中是否存在实例\n            Object singletonObject &#x3D; this.singletonObjects.get(beanName);\n            if (singletonObject &#x3D;&#x3D; null) &#123;\n                &#x2F;&#x2F;...省略了很多代码\n                try &#123;\n                    singletonObject &#x3D; singletonFactory.getObject();\n                &#125;\n                &#x2F;&#x2F;...省略了很多代码\n                &#x2F;&#x2F; 如果实例对象在不存在，我们注册到单例注册表中。\n                addSingleton(beanName, singletonObject);\n            &#125;\n            return (singletonObject !&#x3D; NULL_OBJECT ? singletonObject : null);\n        &#125;\n    &#125;\n    &#x2F;&#x2F;将对象添加到单例注册表\n    protected void addSingleton(String beanName, Object singletonObject) &#123;\n            synchronized (this.singletonObjects) &#123;\n                this.singletonObjects.put(beanName, (singletonObject !&#x3D; null ? singletonObject : NULL_OBJECT));\n\n            &#125;\n        &#125;\n&#125;\n\n\n工厂模式\n\n工厂方法：涉及多个if-else和复杂的对象创建语句时，将创建代码抽象出一个新的类作为对象创建的工厂，封装对象的创建过程，将对象的创建和使用相分离，统一调度。还可以利用多态去掉if分支（实现接口，简化插入），利用工厂的工厂来简化使用，符合开闭原则\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;简单实现，构造函数直接抽取出来&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic class RuleConfigParserFactory &#123;\n    public static IRuleConfigParser createParser(String configFormat) &#123;\n        IRuleConfigParser parser &#x3D; null;\n        if (&quot;json&quot;.equalsIgnoreCase(configFormat)) &#123;\n            parser &#x3D; new JsonRuleConfigParser();\n        &#125; else if (&quot;xml&quot;.equalsIgnoreCase(configFormat)) &#123;\n            parser &#x3D; new XmlRuleConfigParser();\n        &#125; else if (&quot;yaml&quot;.equalsIgnoreCase(configFormat)) &#123;\n            parser &#x3D; new YamlRuleConfigParser();\n        &#125; else if (&quot;properties&quot;.equalsIgnoreCase(configFormat)) &#123;\n            parser &#x3D; new PropertiesRuleConfigParser();\n        &#125;\n        return parser;\n    &#125;\n&#125;\n\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;多态，利用接口来满足开闭原则，适合每个对象的创建都很复杂的情况，避免设计一个大而全的工厂方法&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic interface IRuleConfigParserFactory &#123; IRuleConfigParser createParser(); &#125;\npublic class JsonRuleConfigParserFactory implements IRuleConfigParserFactory &#123;\n    @Override\n    public IRuleConfigParser createParser() &#123; return new JsonRuleConfigParser(); &#125;\n&#125;\n&#x2F;&#x2F;省略XmlRuleConfigParserFactory，YamlRuleConfigParserFactory，PropertiesRuleConfigParserFactory\n\npublic class RuleConfigParserFactoryMap &#123; &#x2F;&#x2F;工厂的工厂\n    private static final Map&lt;String, IRuleConfigParserFactory&gt; cachedFactories &#x3D; new HashMap&lt;&gt;();\n  \t&#x2F;&#x2F;缓存，为了节省时间提前创建并缓存对象\n    static &#123;\n        cachedFactories.put(&quot;json&quot;, new JsonRuleConfigParserFactory());\n        cachedFactories.put(&quot;xml&quot;, new XmlRuleConfigParserFactory());\n        cachedFactories.put(&quot;yaml&quot;, new YamlRuleConfigParserFactory());\n        cachedFactories.put(&quot;properties&quot;, new PropertiesRuleConfigParserFactory());\n    &#125;\n\n    public static IRuleConfigParserFactory getParserFactory(String type) &#123;\n        if (type &#x3D;&#x3D; null || type.isEmpty()) &#123;\n            return null;\n        &#125;\n        IRuleConfigParserFactory parserFactory &#x3D; cachedFactories.get(type.toLowerCase());\n        return parserFactory;\n    &#125;\n&#125;\n&#x2F;&#x2F;IRuleConfigParserFactory parserFactory &#x3D; \t\tRuleConfigParserFactoryMap.getParserFactory(ruleConfigFileExtension);&#x2F;&#x2F;利用接口接收对应类型的工厂\n&#x2F;&#x2F;IRuleConfigParser parser &#x3D; parserFactory.createParser();\n抽象工厂：传统工厂方法类只有一种分类方式，对应的构造函数会成倍的增长，抽象工厂可以让一个工厂负责多个不同类型的对象创建，而不是只创建一类对象\npublic interface IConfigParserFactory &#123;\n    IRuleConfigParser createRuleParser();\n    ISystemConfigParser createSystemParser();\n    &#x2F;&#x2F;此处可以扩展新的parser类型，比如IBizConfigParser\n&#125;\n\npublic class JsonConfigParserFactory implements IConfigParserFactory &#123;\n    @Override\n    public IRuleConfigParser createRuleParser() &#123;\n        return new JsonRuleConfigParser();\n    &#125;\n\n    @Override\n    public ISystemConfigParser createSystemParser() &#123;\n        return new JsonSystemConfigParser();\n    &#125;\n&#125;\n&#x2F;&#x2F; 省略XmlConfigParserFactory、YamlConfigParserFactory和PropertiesConfigParserFactory代码\n依赖注入（IOC、DI、Container）\n\nDI容器：设计思路基于工厂模式，底层相当于一个大的工厂类，负责在程序启动的时候根据配置（要创建哪些类的对象、每个对象依赖哪些对象的创建）事先创建好对象，当应用程序需要某个类对象的时候，直接从容器中获取即可。称为容器是因为框架持有一堆对象\n核心功能\n配置解析：从配置文件中读取类对象和创建类对象的相关信息，根据配置文件创建对象，比如Spring的xml文件中的bean\n对象创建：通过一个工厂类，如BeansFactory来以反射的方式，在程序运行过程中动态地加载类、创建对象，不需要一次创建完所有需要的对象\n对象声明周期管理：单例模式（全局只有一个）、原型模式（每次都新创建一个）、懒加载（对象用到的时候再创建）\ninit-method：增加此配置，可以在创建对象之前调用指定方法来初始化对象\ndestroy-method：增加此配置，可以在销毁对象之后调用指定方法来做一些清理工作\n\n\n\n\n示例：通过BeanFactory或ApplicationContext创建Bean对象，其中BeanFactory延迟注入，懒加载，在使用到Bean的时候才会注入；而ApplicationContext在容器启动的时候，一次创建了所有Bean，但是ApplicationContext扩展了BeanFactory的功能，有以下实现类\nClassPathXmlApplicationContext，通过解析配置文件得到配置信息（BeanDefinition），根据配置信息使用BeansFactory通过反射来创建对象并返回\nFileSystemXmlApplication：从文件系统中的 XML 文件载入上下文定义信息\nXmlWebApplicationContext：从 Web 系统中的 XML 文件载入上下文定义信息\n\n\n\n\n\n\n观察者模式：在对象之间定义一个一对多的依赖，当一个对象状态改变的时候，所有依赖的对象都会自动收到通知\n\n模版代码\npublic interface Subject &#123;\n    &#x2F;&#x2F;也可起名为attach\n    void registerObserver(Observer observer);\n    &#x2F;&#x2F;也可起名为detach\n    void removeObserver(Observer observer);\n    &#x2F;&#x2F;一个一个通知\n    void notifyObservers(Message message);\n&#125;\n&#x2F;&#x2F;被依赖的对象叫被观察者（Observable）；依赖的对象叫观察者（Observer）\npublic interface Observer &#123;\n    void update(Message message);\n&#125;\n&#x2F;&#x2F;Concrete：具体的\npublic class ConcreteSubject implements Subject &#123;\n    private List&lt;Observer&gt; observers &#x3D; new ArrayList&lt;Observer&gt;();\n\n    @Override\n    public void registerObserver(Observer observer) &#123;\n        observers.add(observer);\n    &#125;\n\n    @Override\n    public void removeObserver(Observer observer) &#123;\n        observers.remove(observer);\n    &#125;\n\n    @Override\n    public void notifyObservers(Message message) &#123;  &#x2F;&#x2F;通知所有依赖的对象，响应通知调用对应的代码\n      \t&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;同步阻塞和异步非阻塞二选一&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n      \t&#x2F;&#x2F;同步阻塞方式\n        for (Observer observer : observers) &#123;\n            observer.update(message);\n        &#125;\n      \t&#x2F;&#x2F;异步非阻塞方式，新启线程或直接引入线程池\n      \t&#x2F;&#x2F;private Executor executor &#x2F;&#x2F; 线程池\n      \tfor(Observer observer : observers) &#123;\n          executor.execute(new Runnable()&#123;\n            @Override\n            public void run()&#123;\n              observer.update(messgae);\n            &#125;\n          &#125;)\n        &#125;\n    &#125;\n&#125;\n\npublic class ConcreteObserverOne implements Observer &#123;\n    @Override\n    public void update(Message message) &#123;\n        &#x2F;&#x2F;TODO: 获取消息通知，执行自己的逻辑...\n        System.out.println(&quot;ConcreteObserverOne is notified.&quot;);\n    &#125;\n&#125;\n\npublic class ConcreteObserverTwo implements Observer &#123;\n    @Override\n    public void update(Message message) &#123;\n        &#x2F;&#x2F;TODO: 获取消息通知，执行自己的逻辑...\n        System.out.println(&quot;ConcreteObserverTwo is notified.&quot;);\n    &#125;\n&#125;\n\npublic class Demo &#123;\n    public static void main(String[] args) &#123;\n        ConcreteSubject subject &#x3D; new ConcreteSubject();\n        subject.registerObserver(new ConcreteObserverOne());\n        subject.registerObserver(new ConcreteObserverTwo());\n        subject.notifyObservers(new Message());\n    &#125;\n&#125;\nEventBus框架（事件总线）：提供了观察者模式的骨架代码，如Google Guava中的EventBus，同时支持同步阻塞和异步非阻塞\npublic class UserController &#123;\n    private UserService userService; &#x2F;&#x2F; 依赖注入\n\n    private EventBus eventBus;\n    private static final int DEFAULT_EVENTBUS_THREAD_POOL_SIZE &#x3D; 20;\n\n    public UserController() &#123;\n        &#x2F;&#x2F;eventBus &#x3D; new EventBus(); &#x2F;&#x2F; 同步阻塞模式\n        eventBus &#x3D; new AsyncEventBus(Executors.newFixedThreadPool\n                                     (DEFAULT_EVENTBUS_THREAD_POOL_SIZE)); &#x2F;&#x2F; 异步非阻塞\n    &#125;\n\n    public void setRegObservers(List&lt;Object&gt; observers) &#123;\n        for (Object observer : observers) &#123;\n            &#x2F;&#x2F;用来注册任何类型（Object）的观察者，而在经典的观察者模式的实现中，\n            &#x2F;&#x2F;register() 函数必须接受实现了同一 Observer 接口的类对象。\n            eventBus.register(observer);\n        &#125;\n    &#125;\n\n    public Long register(String telephone, String password) &#123;\n        long userId &#x3D; userService.register(telephone, password);\n        \n\t\t\t\t&#x2F;&#x2F;用来给观察者发送信息，当调用post()函数发送信息的时候，并非把消息发送给所有的观察者，而是发送给可匹配的\n      \t&#x2F;&#x2F;观察者，即接受的消息类型是发送消息（post函数定义中的event）类型的父类\n        eventBus.post(userId);\n\n        return userId;\n    &#125;\n&#125;\npublic class RegPromotionObserver &#123;\n    private PromotionService promotionService; &#x2F;&#x2F; 依赖注入\n\n    @Subscribe&#x2F;&#x2F;定义能接收的消息类型\n    public void handleRegSuccess(Long userId) &#123;\n        promotionService.issueNewUserExperienceCash(userId);\n    &#125;\n&#125;\n\npublic class RegNotificationObserver &#123;\n    private NotificationService notificationService;\n\n    @Subscribe\n    public void handleRegSuccess(Long userId) &#123;\n        notificationService.sendInboxMessage(userId, &quot;...&quot;);\n    &#125;\n&#125;\n&#x2F;&#x2F;@Subscribe注解：当通过 register() 函数将 Observer 类对象注册到 EventBus 的时候，EventBus 会根据 @Subscribe \n&#x2F;&#x2F;注解找到 f1() 和 f2()，并且将两个函数能接收的消息类型记录下来（PMsg-&gt;f1，QMsg-&gt;f2）。当我们通过 post() 函数发送\n&#x2F;&#x2F;消息（比如 QMsg 消息）的时候，EventBus 会通过之前的记录（QMsg-&gt;f2），调用相应的函数（f2）\npublic DObserver &#123;\n  &#x2F;&#x2F;...省略其他属性和方法...\n  \n  @Subscribe\n  public void f1(PMsg event) &#123; &#x2F;&#x2F;... &#125;\n  \n  @Subscribe\n  public void f2(QMsg event) &#123; &#x2F;&#x2F;... &#125;\n&#125;\n应用\n\n事件角色：Spring 中默认存在以下事件，他们都是对 ApplicationContextEvent 的实现(继承自ApplicationContextEvent)：\n\nContextStartedEvent：ApplicationContext 启动后触发的事件;\nContextStoppedEvent：ApplicationContext 停止后触发的事件;\nContextRefreshedEvent：ApplicationContext 初始化或刷新完成后触发的事件;\nContextClosedEvent：ApplicationContext 关闭后触发的事件\n\n\n事件监听者和事件发布者\n\nApplicationListener充当了事件监听者角色，它是一个接口，只定义了一个 onApplicationEvent()方法来处理ApplicationEvent\npackage org.springframework.context;\nimport java.util.EventListener;\n@FunctionalInterface\npublic interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener &#123;\n    void onApplicationEvent(E var1);\n&#125;\nApplicationEventPublisher充当了事件的发布者，它也是一个接口，publishEvent（）这个方法在AbstractApplicationContext 类中被实现，底层通过ApplicationEventMulticaster来广播出去的\n@FunctionalInterface\npublic interface ApplicationEventPublisher &#123;\n    default void publishEvent(ApplicationEvent event) &#123;\n        this.publishEvent((Object)event);\n    &#125;\n\n    void publishEvent(Object var1);\n&#125;\n\n\n事件流程\n\n定义一个事件: 实现一个继承自 ApplicationEvent，并且写相应的构造函数；\n\n定义一个事件监听者：实现 ApplicationListener 接口，重写 onApplicationEvent() 方法；\n\n使用事件发布者发布消息: 可以通过 ApplicationEventPublisher 的 publishEvent() 方法发布消息\n\n实现\n&#x2F;&#x2F; 定义一个事件,继承自ApplicationEvent并且写相应的构造函数\npublic class DemoEvent extends ApplicationEvent&#123;\n    private static final long serialVersionUID &#x3D; 1L;\n\n    private String message;\n\n    public DemoEvent(Object source,String message)&#123;\n        super(source);\n        this.message &#x3D; message;\n    &#125;\n\n    public String getMessage() &#123;\n         return message;\n          &#125;\n\n&#x2F;&#x2F; 定义一个事件监听者,实现ApplicationListener接口，重写 onApplicationEvent() 方法；\n@Component\npublic class DemoListener implements ApplicationListener&lt;DemoEvent&gt;&#123;\n\n    &#x2F;&#x2F;使用onApplicationEvent接收消息\n    @Override\n    public void onApplicationEvent(DemoEvent event) &#123;\n        String msg &#x3D; event.getMessage();\n        System.out.println(&quot;接收到的信息是：&quot;+msg);\n    &#125;\n\n&#125;\n&#x2F;&#x2F; 发布事件，可以通过ApplicationEventPublisher  的 publishEvent() 方法发布消息。\n@Component\npublic class DemoPublisher &#123;\n\n    @Autowired\n    ApplicationContext applicationContext;\n\n    public void publish(String message)&#123;\n        &#x2F;&#x2F;发布事件\n        applicationContext.publishEvent(new DemoEvent(this, message));\n    &#125;\n&#125;\n结果：当调用 DemoPublisher 的 publish() 方法的时候，比如 demoPublisher.publish(&quot;你好&quot;) ，控制台就会打印出:接收到的信息是：你好\n\n\n\n\n\n\n\n模版模式：在一个方法中定义一个算法骨架，并将某些步骤推迟到子类中实现。模板方法模式可以让子类在不改变算法整体结构的情况下，重新定义算法中的某些步骤（如Java的IO框架），复用部分已有代码\n\n代码实现：模板方法定义为 final，可以避免被子类重写。需要子类重写的方法定义为 abstract，可以强迫子类去实现。不过，在实际项目开发中，模板模式的实现比较灵活，以上两点都不是必须的\npublic abstract class AbstractClass &#123;\n    &#x2F;&#x2F;定义为final，避免子类重写\n    public final void templateMethod() &#123;\n        &#x2F;&#x2F;...\n        method1();\n        &#x2F;&#x2F;...\n        method2();\n        &#x2F;&#x2F;...\n    &#125;\n\t\t&#x2F;&#x2F;方式一：定义为abstract是为了强迫子类去实现（如InputStream的read方法）\n    protected abstract void method1();\n    protected abstract void method2();\n  \t&#x2F;&#x2F;方式二：虽然没有声明为abstract，但是抛了异常，子类不重写来处理异常就无法使用（如AbstractList的add方法）\n    public void add(int index, E element) &#123;\n      throw new UnsupportedOperationException();\n  \t&#125;\n&#125;\n\npublic class ConcreteClass1 extends AbstractClass &#123;\n    @Override\n    protected void method1() &#123;&#125;\n\n    @Override\n    protected void method2() &#123;&#125;\n&#125;\n\npublic class ConcreteClass2 extends AbstractClass &#123;\n    @Override\n    protected void method1() &#123;&#125;\n\n    @Override\n    protected void method2() &#123;&#125;\n&#125;\nAbstractClass demo &#x3D; ConcreteClass1();\ndemo.templateMethod();\n框架的扩展（Java Servlet）\n\nHttpServlet：处理web应用中的get和post请求，在Tomcat、Jetty这样的Servlet容器启动的时候，会自动加载配置文件中URL和XXXServlet间的映射关系（如/hello对应HelloServlet），容器处理URL请求找到对应的servlet执行service方法（定义在父类HttpServlet中，会调用doGet和doPost方法，然后输出网页）\npublic class HelloServlet extends HttpServlet &#123;\n    @Override\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;\n        this.doPost(req, resp);\n    &#125;\n\n    @Override\n    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;\n        resp.getWriter().write(&quot;Hello World.&quot;);\n    &#125;\n&#125;\nHttpServlet的service方法：是一个模版方法，实现了整个HTTP请求的执行流程，但其中的doGet和doPost方法可以由子类来定制实现，可以不修改Servlet框架源码的情况下将业务代码通过扩展点镶嵌到框架中执行\npublic void service(ServletRequest req, ServletResponse res) throws ServletException, IOException\n&#123;\n    HttpServletRequest  request;\n    HttpServletResponse response;\n    if (!(req instanceof HttpServletRequest &amp;&amp;\n          res instanceof HttpServletResponse)) &#123;\n        throw new ServletException(&quot;non-HTTP request or response&quot;);\n    &#125;\n    request &#x3D; (HttpServletRequest) req;\n    response &#x3D; (HttpServletResponse) res;\n    service(request, response);\n&#125;\n&#x2F;&#x2F;参数类型不同\nprotected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException&#123;\n    String method &#x3D; req.getMethod();\n    if (method.equals(METHOD_GET)) &#123;\n        long lastModified &#x3D; getLastModified(req);\n        if (lastModified &#x3D;&#x3D; -1) &#123;\n            &#x2F;&#x2F; servlet doesn&#39;t support if-modified-since, no reason\n            &#x2F;&#x2F; to go through further expensive logic\n            doGet(req, resp);\n        &#125; else &#123;\n            long ifModifiedSince &#x3D; req.getDateHeader(HEADER_IFMODSINCE);\n            if (ifModifiedSince &lt; lastModified) &#123;\n                &#x2F;&#x2F; If the servlet mod time is later, call doGet()\n                &#x2F;&#x2F; Round down to the nearest second for a proper compare\n                &#x2F;&#x2F; A ifModifiedSince of -1 will always be less\n                maybeSetLastModified(resp, lastModified);\n                doGet(req, resp);\n            &#125; else &#123;\n                resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED);\n            &#125;\n        &#125;\n    &#125; else if (method.equals(METHOD_HEAD)) &#123;\n        long lastModified &#x3D; getLastModified(req);\n        maybeSetLastModified(resp, lastModified);\n        doHead(req, resp);\n    &#125; else if (method.equals(METHOD_POST)) &#123;\n        doPost(req, resp);\n    &#125; else if (method.equals(METHOD_PUT)) &#123;\n        doPut(req, resp);\n    &#125; else if (method.equals(METHOD_DELETE)) &#123;\n        doDelete(req, resp);\n    &#125; else if (method.equals(METHOD_OPTIONS)) &#123;\n        doOptions(req,resp);\n    &#125; else if (method.equals(METHOD_TRACE)) &#123;\n        doTrace(req,resp);\n    &#125; else &#123;\n        String errMsg &#x3D; lStrings.getString(&quot;http.method_not_implemented&quot;);\n        Object[] errArgs &#x3D; new Object[1];\n        errArgs[0] &#x3D; method;\n        errMsg &#x3D; MessageFormat.format(errMsg, errArgs);\n        resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg);\n    &#125;\n&#125;\n\n\n回调（Callback）\n\n实现：相对于普通的函数调用来说，回调是一种双向调用关系。A 类事先注册某个函数 F 到 B 类，A 类在调用 B 类的 P 函数的时候，B 类反过来调用 A 类注册给它的 F 函数。这里的 F 函数就是“回调函数”。A 调用 B，B 反过来又调用 A，这种调用机制就叫作“回调”\npublic interface ICallback &#123;\n    void methodToCallback();\n&#125;\n\npublic class BClass &#123;\n    public void process(ICallback callback) &#123;\n        &#x2F;&#x2F;...\n        callback.methodToCallback();\n        &#x2F;&#x2F;...\n    &#125;\n&#125;\n\npublic class AClass &#123;\n    public static void main(String[] args) &#123;\n        BClass b &#x3D; new BClass();\n        &#x2F;&#x2F;使用包裹了回调函数的类对象，我们简称为回调对象\n        &#x2F;&#x2F;A实现了methodToCallback()，并且调用process()，process()函数又调用了methodToCallback()\n        b.process(new ICallback() &#123; &#x2F;&#x2F;回调对象\n            @Override\n            public void methodToCallback() &#123;\n                System.out.println(&quot;Call back me.&quot;);\n            &#125;\n        &#125;);\n    &#125;\n&#125;\n&#x2F;&#x2F;异步回调：通过三方支付系统来实现支付功能，用户在发起支付请求之后，一般不会一直阻塞到支付结果返回，而是注册回调接口\n&#x2F;&#x2F;（类似回调函数，一般是一个回调用的 URL）给三方支付系统，等三方支付系统执行完成之后，将结果通过回调接口返回给用户\nJdbcTemplate：Spring 提供了很多 Template 类，比如，JdbcTemplate、RedisTemplate、RestTemplate。尽管都叫作 xxxTemplate，但它们并非基于模板模式来实现的，而是基于回调来实现的，确切地说应该是同步回调。JdbcTemplate 通过回调的机制，将不变的执行流程抽离出来，放到模板方法execute()中，将可变的部分设计成回调StatementCallback，由用户来定制。query()函数是对execute()函数的二次封装，让接口用起来更加方便\n@Override\npublic &lt;T&gt; List&lt;T&gt; query(String sql, RowMapper&lt;T&gt; rowMapper) throws DataAccessException &#123;\n    return query(sql, new RowMapperResultSetExtractor&lt;T&gt;(rowMapper));\n&#125;\n\n@Override\npublic &lt;T&gt; T query(final String sql, final ResultSetExtractor&lt;T&gt; rse) throws DataAccessException &#123;\n    Assert.notNull(sql, &quot;SQL must not be null&quot;);\n    Assert.notNull(rse, &quot;ResultSetExtractor must not be null&quot;);\n    if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Executing SQL query [&quot; + sql + &quot;]&quot;); &#125;\n\t\t&#x2F;&#x2F;回调，实现了StatementCallback，由用户来定制，封装了execute模版方法\n    class QueryStatementCallback implements StatementCallback&lt;T&gt;, SqlProvider &#123;\n        @Override\n        public T doInStatement(Statement stmt) throws SQLException &#123;\n            ResultSet rs &#x3D; null;\n            try &#123;\n                rs &#x3D; stmt.executeQuery(sql);\n                ResultSet rsToUse &#x3D; rs;\n                if (nativeJdbcExtractor !&#x3D; null) &#123;\n                    rsToUse &#x3D; nativeJdbcExtractor.getNativeResultSet(rs);\n                &#125;\n                return rse.extractData(rsToUse);\n            &#125;\n            finally &#123;\n                JdbcUtils.closeResultSet(rs);\n            &#125;\n        &#125;\n        @Override\n        public String getSql() &#123;\n            return sql;\n        &#125;\n    &#125;\n\n    return execute(new QueryStatementCallback());\n&#125;\n\n@Override\npublic &lt;T&gt; T execute(StatementCallback&lt;T&gt; action) throws DataAccessException &#123;\n    Assert.notNull(action, &quot;Callback object must not be null&quot;);\n\n    Connection con &#x3D; DataSourceUtils.getConnection(getDataSource());\n    Statement stmt &#x3D; null;\n    try &#123;\n        Connection conToUse &#x3D; con;\n        if (this.nativeJdbcExtractor !&#x3D; null &amp;&amp;\n            this.nativeJdbcExtractor.isNativeConnectionNecessaryForNativeStatements()) &#123;\n            conToUse &#x3D; this.nativeJdbcExtractor.getNativeConnection(con);\n        &#125;\n        stmt &#x3D; conToUse.createStatement();\n        applyStatementSettings(stmt);\n        Statement stmtToUse &#x3D; stmt;\n        if (this.nativeJdbcExtractor !&#x3D; null) &#123;\n            stmtToUse &#x3D; this.nativeJdbcExtractor.getNativeStatement(stmt);\n        &#125;\n        T result &#x3D; action.doInStatement(stmtToUse);\n        handleWarnings(stmt);\n        return result;\n    &#125;\n    catch (SQLException ex) &#123;\n        &#x2F;&#x2F; Release Connection early, to avoid potential connection pool deadlock\n        &#x2F;&#x2F; in the case when the exception translator hasn&#39;t been initialized yet.\n        JdbcUtils.closeStatement(stmt);\n        stmt &#x3D; null;\n        DataSourceUtils.releaseConnection(con, getDataSource());\n        con &#x3D; null;\n        throw getExceptionTranslator().translate(&quot;StatementCallback&quot;, getSql(action), ex);\n    &#125;\n    finally &#123;\n        JdbcUtils.closeStatement(stmt);\n        DataSourceUtils.releaseConnection(con, getDataSource());\n    &#125;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;使用&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic class JdbcTemplateDemo &#123;\n    private JdbcTemplate jdbcTemplate;\n\n    public User queryUser(long id) &#123;\n        String sql &#x3D; &quot;select * from user where id&#x3D;&quot;+id;\n        return jdbcTemplate.query(sql, new UserRowMapper()).get(0);\n    &#125;\n\n    class UserRowMapper implements RowMapper&lt;User&gt; &#123;\n        public User mapRow(ResultSet rs, int rowNum) throws SQLException &#123;\n            User user &#x3D; new User();\n            user.setId(rs.getLong(&quot;id&quot;));\n            user.setName(rs.getString(&quot;name&quot;));\n            user.setTelephone(rs.getString(&quot;telephone&quot;));\n            return user;\n        &#125;\n    &#125;\n&#125;\n回调与模版方法的对比，回调相对于模版模式会更加灵活\n\n像 Java 这种只支持单继承的语言，基于模板模式编写的子类，已经继承了一个父类，不再具有继承的能力。\n回调可以使用匿名类来创建回调对象，可以不用事先定义类；而模板模式针对不同的实现都要定义不同的子类。\n如果某个类中定义了多个模板方法，每个方法都有对应的抽象方法，那即便我们只用到其中的一个模板方法，子类也必须实现所有的抽象方法。而回调就更加灵活，我们只需要往用到的模板方法中注入回调对象即可。\n\n\n\n\n\n\n职责链模式：将请求的发送和接收解耦，让多个接收对象都有机会处理这个请求。将这些接收对象串成一条链，并沿着这条链传递这个请求，直到链上的某个接收对象能够处理它为止\n\n模版代码\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;实现一&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic abstract class Handler &#123;\n    protected Handler successor &#x3D; null;\n\n    public void setSuccessor(Handler successor) &#123;\n        this.successor &#x3D; successor;\n    &#125;\n\n    public final void handle() &#123;\n        &#x2F;&#x2F;如果没有handled判断，则可以全部处理一遍\n        boolean handled &#x3D; doHandle();\n        if (successor !&#x3D; null &amp;&amp; !handled) &#123;\n            successor.handle();\n        &#125;\n    &#125;\n    protected abstract boolean doHandle();\n&#125;\n\npublic class HandlerA extends Handler &#123;\n    @Override\n    protected boolean doHandle() &#123;\n        boolean handled &#x3D; false;\n        &#x2F;&#x2F;...\n        return handled;\n    &#125;\n&#125;\n\npublic class HandlerB extends Handler &#123;\n    @Override\n    protected boolean doHandle() &#123;\n        boolean handled &#x3D; false;\n        &#x2F;&#x2F;...\n        return handled;\n    &#125;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;实现二&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic interface IHandler &#123;\n    boolean handle();\n&#125;\n\npublic class HandlerA implements IHandler &#123;\n    @Override\n    public boolean handle() &#123;\n        boolean handled &#x3D; false;\n        &#x2F;&#x2F;...\n        return handled;\n    &#125;\n&#125;\n\npublic class HandlerB implements IHandler &#123;\n    @Override\n    public boolean handle() &#123;\n        boolean handled &#x3D; false;\n        &#x2F;&#x2F;...\n        return handled;\n    &#125;\n&#125;\npublic class HandlerChain &#123;\n    private List&lt;IHandler&gt; handlers &#x3D; new ArrayList&lt;&gt;();\n\n    public void addHandler(IHandler handler) &#123;\n        this.handlers.add(handler);\n    &#125;\n\n    public void handle() &#123;\n        for (IHandler handler : handlers) &#123;\n            boolean handled &#x3D; handler.handle();\n            if (handled) &#123;\n                break;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n&#x2F;&#x2F; 使用举例\npublic class Application &#123;\n    public static void main(String[] args) &#123;\n        HandlerChain chain &#x3D; new HandlerChain();\n        chain.addHandler(new HandlerA());\n        chain.addHandler(new HandlerB());\n        chain.handle();\n    &#125;\n&#125;\nServelt Filter：可以实现对HTTP请求的过滤功能，比如鉴权、限流、记录日志、验证参数\npublic class LogFilter implements Filter &#123;\n  @Override\n  public void init(FilterConfig filterConfig) throws ServletException &#123;\n    &#x2F;&#x2F; 在创建Filter时自动调用，\n    &#x2F;&#x2F; 其中filterConfig包含这个Filter的配置参数，比如name之类的（从配置文件中读取的）\n  &#125;\n  @Override\n  public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123;\n    System.out.println(&quot;拦截客户端发送来的请求.&quot;);\n    chain.doFilter(request, response);\n    System.out.println(&quot;拦截发送给客户端的响应.&quot;);\n  &#125;\n\n  @Override\n  public void destroy() &#123;\n    &#x2F;&#x2F; 在销毁Filter时自动调用\n  &#125;\n&#125;\n&#x2F;&#x2F; 在web.xml配置文件中添加filter相关的配置（url、相关类）\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;Tomcat&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic final class ApplicationFilterChain implements FilterChain &#123;\n    private int pos &#x3D; 0; &#x2F;&#x2F;当前执行到了哪个filter\n    private int n; &#x2F;&#x2F;filter的个数\n    private ApplicationFilterConfig[] filters;\n    private Servlet servlet;\n\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response) &#123;\n        if (pos &lt; n) &#123;\n            ApplicationFilterConfig filterConfig &#x3D; filters[pos++];\n            Filter filter &#x3D; filterConfig.getFilter();\n            filter.doFilter(request, response, this);&#x2F;&#x2F;传入this，进行递归调用，实现前后双向拦截\n            &#x2F;&#x2F;System.out.println(&quot;拦截客户端发送来的请求.&quot;);\n            &#x2F;&#x2F;chain.doFilter(request, response);\n    \t\t\t\t&#x2F;&#x2F;System.out.println(&quot;拦截发送给客户端的响应.&quot;);            \n        &#125; else &#123;\n            &#x2F;&#x2F; filter都处理完毕后，执行servlet\n            servlet.service(request, response);\n        &#125;\n    &#125;\n\n    public void addFilter(ApplicationFilterConfig filterConfig) &#123;\n\t\t\t\t&#x2F;&#x2F;去重+扩容\n        filters[n++] &#x3D; filterConfig;\n    &#125;\n&#125;\nSpring Interceptor：\n\n&#x2F;&#x2F;使用：实现HandlerInterceptor接口，重写preHandle、postHandle、afterCompletion三个方法\n&#x2F;&#x2F;原理：在 Spring 框架中，DispatcherServlet 的 doDispatch() 方法来分发请求，它在真正的业务逻辑执行前后，执行 \n&#x2F;&#x2F;HandlerExecutionChain 中的 applyPreHandle() 和 applyPostHandle() 函数，用来实现拦截的功能\npublic class HandlerExecutionChain &#123;\n    private final Object handler;\n    private HandlerInterceptor[] interceptors;\n\n    public void addInterceptor(HandlerInterceptor interceptor) &#123;\n        initInterceptorList().add(interceptor);\n    &#125;\n\n    boolean applyPreHandle(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;\n        HandlerInterceptor[] interceptors &#x3D; getInterceptors();\n        if (!ObjectUtils.isEmpty(interceptors)) &#123;\n            for (int i &#x3D; 0; i &lt; interceptors.length; i++) &#123;\n                HandlerInterceptor interceptor &#x3D; interceptors[i];\n                if (!interceptor.preHandle(request, response, this.handler)) &#123;\n                    triggerAfterCompletion(request, response, null);\n                    return false;\n                &#125;\n            &#125;\n        &#125;\n        return true;\n    &#125;\n\n    void applyPostHandle(HttpServletRequest request, HttpServletResponse response, ModelAndView mv) throws Exception &#123;\n        HandlerInterceptor[] interceptors &#x3D; getInterceptors();\n        if (!ObjectUtils.isEmpty(interceptors)) &#123;\n            for (int i &#x3D; interceptors.length - 1; i &gt;&#x3D; 0; i--) &#123;\n                HandlerInterceptor interceptor &#x3D; interceptors[i];\n                interceptor.postHandle(request, response, this.handler, mv);\n            &#125;\n        &#125;\n    &#125;\n\n    void triggerAfterCompletion(HttpServletRequest request, HttpServletResponse response, Exception ex)\n        throws Exception &#123;\n        HandlerInterceptor[] interceptors &#x3D; getInterceptors();\n        if (!ObjectUtils.isEmpty(interceptors)) &#123;\n            for (int i &#x3D; this.interceptorIndex; i &gt;&#x3D; 0; i--) &#123;\n                HandlerInterceptor interceptor &#x3D; interceptors[i];\n                try &#123;\n                    interceptor.afterCompletion(request, response, this.handler, ex);\n                &#125; catch (Throwable ex2) &#123;\n                    logger.error(&quot;HandlerInterceptor.afterCompletion threw exception&quot;, ex2);\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n3.原理及源码分析https://javadoop.com/post/spring-ioc\n2.AOP\n\n\n\n\n\n\n\n\n默认使用基于Java的动态代理机制，即通过java.lang.reflect.Proxy类来生成代理对象\n1.基础知识\n专有名词\n\nAspect：跨多个类的关注点的模块化，例如事务管理\nJoin point：程序执行过程中的一个点，例如方法的执行和异常的处理\nAdvice：Aspect在特定的Join point采取的行动，包括around、before、after（running、throwing、finally）\npointcut：匹配连接点的谓词，Advice和pointcut表达式相关联，并在任何与pointcut匹配的join point运行，例如执行具有特定名称的方法\nIntroduction：代表一个类型声明额外的方法或字段，例如可以使用introduction让bean实现isModified接口，来简化缓存\nTarget object：An object being advised by one or more aspects，即被代理对象\nAOP proxy：由AOP框架创建的对象，用于实现aspect\nWeaving：将apsects和其他应用程序类型或对象链接以创建建议对象\n\n\n使用示例\n\n配置启用@AspectJ支持：增加注解@EnableAspectJAutoProxy\n      @Configuration\n      @EnableAspectJAutoProxy\n      public class AppConfig &#123;\n      \n      &#125;\n声明一个切面（aspect）\n      @Aspect\n      public class NotVeryUsefulAspect &#123;\n      \n      &#125;\n声明一个切点（pointcut），有很多方式，详见文档\n&#x2F;&#x2F;名为anyOldTransfer的切入点，与任何名为transfer的方法执行相匹配\n @Pointcut(&quot;execution(* transfer(..))&quot;) &#x2F;&#x2F; the pointcut expression\n private void anyOldTransfer() &#123;&#125; &#x2F;&#x2F; the pointcut signature\n声明一个advice\n      @Aspect\n      public class BeforeExample &#123;\n          @Before(&quot;com.xyz.myapp.CommonPointcuts.dataAccessOperation()&quot;)\n          public void doAccessCheck() &#123;\n              &#x2F;&#x2F; ...\n          &#125;\n      &#125;\n      @Aspect\n      public class AfterReturningExample &#123;\n          @AfterReturning(&quot;com.xyz.myapp.CommonPointcuts.dataAccessOperation()&quot;)\n          public void doAccessCheck() &#123;\n              &#x2F;&#x2F; ...\n          &#125;\n      &#125;\n      @Aspect\n      public class AroundExample &#123;\n          @Around(&quot;com.xyz.myapp.CommonPointcuts.businessService()&quot;)\n          public Object doBasicProfiling(ProceedingJoinPoint pjp) throws Throwable &#123;\n              &#x2F;&#x2F; start stopwatch\n              Object retVal &#x3D; pjp.proceed();\n              &#x2F;&#x2F; stop stopwatch\n              return retVal;\n          &#125;\n      &#125;\n例子\n      @Aspect\n      public class ConcurrentOperationExecutor implements Ordered &#123;\n      \n          private static final int DEFAULT_MAX_RETRIES &#x3D; 2;\n      \n          private int maxRetries &#x3D; DEFAULT_MAX_RETRIES;\n          private int order &#x3D; 1;\n      \n          public void setMaxRetries(int maxRetries) &#123;\n              this.maxRetries &#x3D; maxRetries;\n          &#125;\n      \n          public int getOrder() &#123;\n              return this.order;\n          &#125;\n      \n          public void setOrder(int order) &#123;\n              this.order &#x3D; order;\n          &#125;\n      \n          @Around(&quot;com.xyz.myapp.CommonPointcuts.businessService()&quot;)\n          public Object doConcurrentOperation(ProceedingJoinPoint pjp) throws Throwable &#123;\n              int numAttempts &#x3D; 0;\n              PessimisticLockingFailureException lockFailureException;\n              do &#123;\n                  numAttempts++;\n                  try &#123;\n                      return pjp.proceed();\n                  &#125;\n                  catch(PessimisticLockingFailureException ex) &#123;\n                      lockFailureException &#x3D; ex;\n                  &#125;\n              &#125; while(numAttempts &lt;&#x3D; this.maxRetries);\n              throw lockFailureException;\n          &#125;\n      &#125;\n\n\n对bean做aop增强问题（？）\n\n子类有则用子类的bean，子类没有则用父类的bean\n在父上下文开启增强，父的bean均被增强，子的bean均未被增强；在子上下文开启增强，子的bean均被增强，父的bean未被增强\n要想都被增强，则需要都开启aop的自动配置并且在父类上定义aop\n\n\n原理\n\n代理模式：Spring AOP基于代理模式实现，主要有两种代理方式，JDK动态代理和CGLIB代理。JDK动态代理要求目标类必须实现接口，而CGLIB代理则可以针对没有实现接口的类进行代理。\n切面（Aspect）：切面是将横切关注点模块化的实现。切面通常包含通知（Advice）和切点（Pointcut）。通知是在特定的切点执行的动作，切点则用于定义通知应该在何处执行。\n连接点（Joinpoint）：连接点代表在应用程序中可以插入切面的点，如方法调用、异常处理等。\n织入（Weaving）：织入是将切面应用到目标对象的过程，从而创建代理对象。在Spring AOP中，织入过程发生在运行时。\n\n\n\n\n2.设计模式\n代理模式：在不改变原始类接口的条件下，为原始类定义一个代理类，主要目的是控制访问（监控、统计、鉴权、限流、事务、幂等、日志），而非加强功能，这是它跟装饰器模式最大的不同（装饰器主要是加强已有功能）\n\n装饰器模式、代理模式、适配器模式\n&#x2F;&#x2F;代理模式中，代理类附加的是跟原始类无关的功能，而在装饰器模式中，装饰器类附加的是跟原始类相关的增强功能\n&#x2F;&#x2F;适配器模式是一种事后补救措施，增加跟原始类不同的接口，让原本因接口不兼容而不能一起工作的类可以一起工作\n&#x2F;&#x2F; 代理模式的代码结构(下面的接口也可以替换成抽象类)\npublic interface IA &#123;\n    void f();\n&#125;\npublic class A impelements IA &#123;\n    public void f() &#123; \n      &#x2F;&#x2F;... \n    &#125;\n&#125;\npublic class AProxy implements IA &#123;\n    private IA a;\n    public AProxy(IA a) &#123;\n        this.a &#x3D; a;\n    &#125;\n\n    public void f() &#123;\n        &#x2F;&#x2F; 新添加的代理逻辑\n        a.f();\n        &#x2F;&#x2F; 新添加的代理逻辑\n    &#125;\n&#125;\nIA a &#x3D; new AProxy(new A());\n&#x2F;&#x2F; 装饰器模式的代码结构(下面的接口也可以替换成抽象类)\npublic interface IA &#123;\n    void f();\n&#125;\npublic class A implements IA &#123;\n    public void f() &#123; \n      &#x2F;&#x2F;... \n    &#125;\n&#125;\npublic class ADecorator implements IA &#123;\n    private IA a;\n    public ADecorator(IA a) &#123;\n        this.a &#x3D; a;\n    &#125;\n\n    public void f() &#123;\n        &#x2F;&#x2F; 功能增强代码\n        a.f();\n        &#x2F;&#x2F; 功能增强代码\n    &#125;\n&#125;\n&#x2F;&#x2F; 类适配器: 基于继承，将不兼容ITarget接口的Adaptee类“转换”为符合ITarget接口定义的类\npublic interface ITarget &#123;\n    void f1();\n    void f2();\n    void fc();\n&#125;\n\npublic class Adaptee &#123;\n    public void fa() &#123; \n        &#x2F;&#x2F;... \n    &#125;\n    public void fb() &#123;\n        &#x2F;&#x2F;... \n    &#125;\n    public void fc() &#123; \n        &#x2F;&#x2F;... \n    &#125;\n&#125;\n\npublic class Adaptor extends Adaptee implements ITarget &#123;\n    public void f1() &#123;\n        super.fa();\n    &#125;\n\n    public void f2() &#123;\n        &#x2F;&#x2F;...重新实现f2()...\n    &#125;\n\n    &#x2F;&#x2F; 这里fc()不需要实现，直接继承自Adaptee，这是跟对象适配器最大的不同点\n&#125;\n静态代理：有接口时实现相同的接口来实现（见前），没有接口时只能通过继承实现（见下）\npublic class A&#123;\n    public void f() &#123; \n      &#x2F;&#x2F;... \n    &#125;\n&#125;\npublic class AProxy extends A &#123;\n    private A a;\n    public AProxy() &#123;\n        this.a &#x3D; new A();\n    &#125;\n\n    public void f() &#123;\n        &#x2F;&#x2F; 新添加的代理逻辑\n        a.f();\n        &#x2F;&#x2F; 新添加的代理逻辑\n    &#125;\n&#125;\nA a &#x3D; new AProxy();\n动态代理：不事先为每个原始类编写代理类，而是在运行的时候，动态地创建原始类对应的代理类，然后在运行的时候，动态地创建原始类对应的代理类，然后在系统中用代理来替换原始类（如Spring AOP）\n\nSpring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用JDK Proxy去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用Cglib生成一个被代理对象的子类来作为代理（也可以使用AspectJ，AOP属于运行时增强而AspectJ属于编译时增强，基于字节码操作）\n\n&#x2F;&#x2F;动态代理类\npublic class MetricsCollectorProxy &#123;\n    private MetricsCollector metricsCollector;\n\n    public MetricsCollectorProxy() &#123;\n        this.metricsCollector &#x3D; new MetricsCollector();\n    &#125;\n\n    &#x2F;&#x2F;封装了代理类的创建\n    public Object createProxy(Object proxiedObject) &#123;\n        &#x2F;&#x2F;返回Class数组，表示Class对象引用的类所实现的所有接口\n        Class&lt;?&gt;[] interfaces &#x3D; proxiedObject.getClass().getInterfaces();\n        DynamicProxyHandler handler &#x3D; new DynamicProxyHandler(proxiedObject);\n        &#x2F;&#x2F;Proxy provides static methods for creating dynamic proxy classes and instances, \n        &#x2F;&#x2F;and it is also the superclass of all dynamic proxy classes created by those \n        &#x2F;&#x2F;methods.\n        return Proxy.newProxyInstance(proxiedObject.getClass().getClassLoader(), interfaces, handler);\n    &#125;\n\n    private class DynamicProxyHandler implements InvocationHandler &#123;\n        private Object proxiedObject;\n\n        public DynamicProxyHandler(Object proxiedObject) &#123;\n            this.proxiedObject &#x3D; proxiedObject;\n        &#125;\n\n        &#x2F;&#x2F;所有方法的调用都会变成调用invoke方法，参数为生成的代理类、要调用的方法、对应的参数\n        @Override\n        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;\n            long startTimestamp &#x3D; System.currentTimeMillis();\n            Object result &#x3D; method.invoke(proxiedObject, args);\n            long endTimeStamp &#x3D; System.currentTimeMillis();\n            long responseTime &#x3D; endTimeStamp - startTimestamp;\n            String apiName &#x3D; proxiedObject.getClass().getName() + &quot;:&quot; + method.getName();\n            RequestInfo requestInfo &#x3D; new RequestInfo(apiName, responseTime, startTimestamp);\n            metricsCollector.recordRequest(requestInfo);\n            return result;\n        &#125;\n    &#125;\n&#125;\n\n&#x2F;&#x2F;MetricsCollectorProxy使用举例\nMetricsCollectorProxy proxy &#x3D; new MetricsCollectorProxy();\nIUserController userController &#x3D; (IUserController) proxy.createProxy(new UserController());\n\n\n装饰者模式：在不改变原始类接口的情况下，对原始类的功能进行增强，并且支持多个装饰器的嵌套使用，如Java的IO类库\n\n用组合代替继承、装饰器类和原始类继承同一父类，从而可以对原始类嵌套多个装饰器类\npublic abstract class InputStream &#123;\n    &#x2F;&#x2F;...\n    public int read(byte b[]) throws IOException &#123; return read(b, 0, b.length); &#125;\n    public int read(byte b[], int off, int len) throws IOException &#123; &#125;\n    &#x2F;&#x2F;...\n&#125;\n\npublic class BufferedInputStream extends InputStream &#123;\n    protected volatile InputStream in;\n    protected BufferedInputStream(InputStream in) &#123;\n        this.in &#x3D; in;\n    &#125;\n\n    &#x2F;&#x2F;...实现基于缓存的读数据接口...  \n&#125;\n\npublic class DataInputStream extends InputStream &#123;\n    protected volatile InputStream in;\n    protected DataInputStream(InputStream in) &#123;\n        this.in &#x3D; in;\n    &#125;\n\n    &#x2F;&#x2F;...实现读取基本类型数据的接口\n&#125;\nInputStream in &#x3D; new FileInputStream(&quot;&#x2F;user&#x2F;wangzheng&#x2F;test.txt&quot;);\nInputStream bin &#x3D; new BufferedInputStream(in);\nDataInputStream din &#x3D; new DataInputStream(bin);\nint data &#x3D; din.readInt();\n为了避免代码重复，Java IO 抽象出了一个装饰器父类 FilterInputStream。InputStream的所有的装饰器类（BufferedInputStream、DataInputStream）都继承自这个装饰器父类。这样，装饰器类只需要实现它需要增强的方法就可以了，其他方法继承装饰器父类的默认实现。例如：BufferedInputStream直接使用了FilterInputStream的close()，而没有重新实现\n\n\n\n适配器模式：是一种事后的补救策略。适配器提供跟原始类不同的接口，而代理模式、装饰器模式提供的都是跟原始类相同的接口，适配器模式主要是将不兼容的接口转换为可兼容的接口，让原本由于接口不兼容而不能一起工作的类可以一起工作\n\n类适配器（继承）\n&#x2F;&#x2F; 类适配器: 基于继承\npublic interface ITarget &#123;\n    void f1();\n    void f2();\n    void fc();\n&#125;\n\npublic class Adaptee &#123;\n    public void fa() &#123;&#125;\n    public void fb() &#123;&#125;\n    public void fc() &#123;&#125;\n&#125;\n\npublic class Adaptor extends Adaptee implements ITarget &#123;\n    public void f1() &#123;\n        super.fa();\n    &#125;\n\n    public void f2() &#123;\n        &#x2F;&#x2F;...重新实现f2()...\n    &#125;\n\n    &#x2F;&#x2F; 这里fc()不需要实现，直接继承自Adaptee，这是跟对象适配器最大的不同点\n&#125;\n对象适配器（组合）\n&#x2F;&#x2F; 对象适配器：基于组合\npublic interface ITarget &#123;\n    void f1();\n    void f2();\n    void fc();\n&#125;\n\npublic class Adaptee &#123;\n    public void fa() &#123;&#125;\n    public void fb() &#123;&#125;\n    public void fc() &#123;&#125;\n&#125;\n\npublic class Adaptor implements ITarget &#123;\n    private Adaptee adaptee;\n    public Adaptor(Adaptee adaptee) &#123; this.adaptee &#x3D; adaptee; &#125;\n    public void f1() &#123; adaptee.fa(); &#125; &#x2F;&#x2F;委托给Adaptee\n    \n    public void f2() &#123;\n        &#x2F;&#x2F;...重新实现f2()...\n    &#125;\n\n    public void fc() &#123;\n        adaptee.fc();\n    &#125;\n&#125;\n应用：封装有缺陷的接口设计、统一不同接口设计、替换依赖的外部系统、兼容老版本接口、适配不同格式的数据\n\n在 Spring MVC 中，DispatcherServlet根据请求信息调用HandlerMapping，解析请求对应的Handler。解析到对应的Handler（也就是我们平常说的Controller控制器）后，开始由HandlerAdapter适配器处理。HandlerAdapter作为期望接口，具体的适配器实现类用于对目标类进行适配，Controller作为需要适配的类（如果不使用，需要自己判断handler（即controller）的类型）\n\n\n\n\n\n3.原理及源码分析https://javadoop.com/post/spring-aop-source\n3.Data Access1.Transaction Management\nSpring的管理事务的方式\n编程式事务：在代码中硬编码(不推荐使用) : 通过 TransactionTemplate或者 TransactionManager 手动管理事务，实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助\n声明式事务：在 XML 配置文件中配置或者直接基于注解（推荐使用） : 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多）\n\n\n声明式事务：使用@EnableTransactionManagement开启事务注解，使用@Transactional声明事务，其有以下属性\ntransactionManager\n事务的传播特性：@Transactional注解的propagation属性，一共有七种，默认为PROPAGATION_REQUIRED\nPROPAGATION_REQUIRED：当前有服务已经开始一个事务，则加入到该事务，与其一同提交/回滚；如果当前没有事务，则新建一个事务\nPROPAGATION_SUPPORTS：支持当前事务，如果当前没有事务，则以非事务方式执行，通常用于处理非原子性的非核心业务逻辑操作\nPROPAGATION_MANDATORY：支持当前事务，如果当前没有事务，则抛出异常，防止上下文忘记添加事务的兜底手段，将事务需求托管给上下文\nPROPAGATION_REQUIRES_NEW：新建事务，如果当前存在事务，把当前事务挂起，与PROPAGATION_REQUIRED的区别在于前一事务回滚时（被挂起）当前事务不再需要回滚\nPROPAGATION_NOT_SUPPORTED： 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起，可以帮助减少前一事务的事务范围，减少回滚的影响\nPROPAGATION_NEVER： 以非事务方式执行，如果当前存在事务，则抛出异常，要求上下文不能存在事务\nPROPAGATION_NESTED： Nested的事务和它的父事务是相依的，它的提交是要等和它的父事务一块提交的，父事务因子事务回滚时仅回滚到savepoint点，然后继续执行另一分支\n\n\n事务的隔离级别：@Transactional注解的isolation属性，一共有五种，默认为ISOLATION_DEFAULT\nISOLATION_DEFAULT：使用数据库默认的事务隔离级别\nISOLATION_READ_UNCOMMITTED：读未提交，一个事务可以看到另一事务未提交的数据，会产生脏读、不可重复读、幻读\nISOLATION_READ_COMMITTED：读已提交，一个事务只能看到另一事务已提交的数据，可以避免脏读，但是会产生不可重复读、幻读\nISOLATION_REPEATABLE_READ：可重复读，可以防止脏读，不可重复读，但是可能出现幻读\n幻读和不可重复读的侧重点是不同的，不可重复读侧重于数据修改，两次读取到的同一行数据不一样；而幻读侧重于添加或删除，两次查询返回的数据行数不同\n\n\nISOLATION_SERIALIZABLE：可序列化，事务顺序执行，可防止脏读，不可重复读外，还避免了幻读\n\n\ntimeout\nreadOnly\n\n\n事务回滚的场景\n抛出unchecked exception（runtime exception）后会触发事务的回滚，对于checked异常使用try捕获就不会回滚，也可以配置spring参数让其回滚\nspring的事务边界是在调用业务方法之前开始的，业务方法执行完毕之后来执行commit or rollback（Spring默认取决于是否抛出runtime异常）\n如果抛出runtime exception并在你的业务方法中没有catch到的话，事务会回滚。一般不需要在业务方法中catch异常\n\n\n事务的问题：脏读、不可重复读、幻读\n脏读：指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据， 那么另外一个事务读到的这个数据是脏数据，依据脏数据所做的操作可能是不正确的\n不可重复读：指在一个事务内，多次读同一数据，在这个事务还没有结束时，另外一个事务也访问该同一数据，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读\n幻读：当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。\n\n\n\n2.JDBC\n包层次结构\n\norg.springframework.jdbc.core：JdbcTemplate、simple子包中simpleJdbcInsert、SimpleJdbcCall类、namedparam子包中NamedParameterJdbcTemplate\norg.springframework.jdbc.datasource：DataSource类、embedded子包中内嵌数据库的支持（HSQL、H2、Derby）\norg.springframework.jdbc.object：关系数据库的查询、更新、存储程序\norg.springframework.jdbc.support：SQLException、一些工具类\n\n\nJDBC Processing\n\nJdbcTemplate：可以处理资源的创建和释放，主要用于运行数据库的查询、更新、存储，对ResultSet实例执行迭代并提取返回的参数值，捕获JDBC异常并翻译成通用的。方法有：query、queryForObject、queryForList、update、execute\nNamedParameterJdbcTemplate：对JdbcTemplate的一层封装，简化有参数的SQL\nSQLExceptionTranslator：翻译SQLException和org.sf.dao.DataAccessException的接口，其中一个默认实现是SQLErrorCodeSQLExceptionTranslator，可以解析错误码。Spring会将数据操作的异常转换为DataAccessException，无论使用何种数据访问方式，都能使用一样的异常\n\n\nDataSource\n\n连接工厂，使得一个容器或者一个框架从应用代码中隐藏连接池和事务管理问题，业务开发人员不再需要知道连接数据库的信息。\n\n如果是JDBC，那么可以通过JNDI（通过配置而不是放在一起的单一url）来获得数据源；也可以配置数据库连接池（HikariCP/druid）\n\nDriverManagerDataSource和SimpleDriverDataSource仅应该用在测试的时候：\nDriverManagerDataSource dataSource &#x3D; new DriverManagerDataSource();\ndataSource.setDriverClassName(&quot;org.hsqldb.jdbcDriver&quot;);\ndataSource.setUrl(&quot;jdbc:hsqldb:hsql:&#x2F;&#x2F;localhost:&quot;);\ndataSource.setUsername(&quot;sa&quot;);\ndataSource.setPassword(&quot;&quot;);\n\n\n\n3.O/R Mapping（MyBatis）\nJPA：Java Persistence API，为对象关系映射提供了一种基于POJO的持久化模型，简化数据持久化代码的开发工作，为Java社区屏蔽不同持久化API的差异\nLombok：能够自动嵌入IDE和构建工具，提升开发效率\nMyBatis：持久层框架，支持定制化SQL、存储过程和高级映射。免除了几乎所有的JDBC代码及相关配置，可以通过注解来配置和映射原始类型、接口和Java POJO为数据库中的记录\nMyBatis：持久层框架，支持定制化SQL、存储过程和高级映射。免除了几乎所有的JDBC代码及相关配置，可以通过注解来配置和映射原始类型、接口和Java POJO为数据库中的记录\nMyBatis Generator：MyBatis代码生成器，根据数据库表生成相关代码：POJO、Mapper接口、SQL Map XML\nMyBatis PageHelper：用来做分页，支持多种数据库和多种分页方式\n\n\n\n4.MVC1.基础知识\n一些专有名词\n\n\nPOJO：plain old java objects简单的Java对象，一般用在数据层映射到数据库表的类，类的属性与表字段一一对应\nPOJO持久化后⇒PO，persistent object，增加了一些getter、setter方法\nPOJO传输过程中⇒DTO，data transfer object，比如一张表有100个字段，对应的PO有100个属性，但view层只需要10个字段，所以依靠只有10个属性的DTO来传输数据给client，可以提高性能\nPOJO用作表示层⇒VO，view object，用于页面展示\n\n\nDAO：data access object数据访问接口，用来封装对数据库的访问（CRUD），可以把POJO持久化为PO，用PO组装出VO、DTO\nBO：Business Object，即业务对象。一般用在业务层，当业务比较复杂，用到比较多的业务对象时，可用BO类组合封装所有的对象一并传递。\ncontroller层：控制请求url用哪个service层逻辑\nservice层：带有业务逻辑的数据访问API\nMVC模式\n模型（Model）表示应用程序的数据和业务逻辑。它负责处理数据的读取、存储、验证以及与数据库的交互等操作。\n视图（View）是用户界面的呈现部分，负责展示模型中的数据给用户。它可以是一个网页、一个图形界面或者其他任何形式。\n控制器（Controller）充当模型和视图之间的中介，负责处理用户的请求、更新模型的状态，以及决定要显示哪个视图。它接收用户的输入，调用相应的模型方法来处理请求，并最终将结果返回给视图进行显示\n\n\n\n\ncontroller：@Controller，是@Component的一个特例，可与@ResponseBody组合成@RestController\n\n使用@RequestMapping(&quot;/brand&quot;)来确定该类的顶级域名\n\npath和value用于指定映射路径，value是path的别名\nmethod用于指定请求方法：Get、Post等，可用@GetMapping、@PostMapping、@PutMapping、@DeleteMapping、@PatchMapping替代\nparams指定有哪些参数，或没有哪些参数（!）\nheaders用来指定请求头中有哪些参数，或没有哪些参数（!）\nconsumes和produces用于限定请求与响应格式，通过MediaType来指定\n\n\n通过依赖注入来使用Service接口\n@Autowired\nprivate PmsBrandService demoService;\n定义子域名和相应的处理逻辑\n\n抽象出通用返回对象CommonResult，主要有code+message+data三个属性\n抽象出常用的操作码属性\n\n@RequestMapping(value &#x3D; &quot;&#x2F;create&quot;, method &#x3D; RequestMethod.POST)\n    @ResponseBody\n    public CommonResult createBrand(@RequestBody PmsBrand pmsBrand) &#123;\n        CommonResult commonResult;\n        int count &#x3D; demoService.createBrand(pmsBrand);\n        if (count &#x3D;&#x3D; 1) &#123;\n            commonResult &#x3D; CommonResult.success(pmsBrand);\n            LOGGER.debug(&quot;createBrand success:&#123;&#125;&quot;, pmsBrand);\n        &#125; else &#123;\n            commonResult &#x3D; CommonResult.failed(&quot;操作失败&quot;);\n            LOGGER.debug(&quot;createBrand failed:&#123;&#125;&quot;, pmsBrand);\n        &#125;\n        return commonResult;\n    &#125;\n\n\nservice\n\nservice接口：写实体类的增删改查等方法\n\nserviceImpl：@Service\n\n实现service接口\n\n通过依赖注入，使用Mapper接口\n@Autowired\nprivate PmsBrandMapper brandMapper;\n使用xxxMapper接口提供的方法实现service接口中的方法\n\n\n\n\n\n定义处理方法\n\n@RequestBody：方法参数是一个请求体，通过HttpMessageConverter读取请求正文并将其反序列化Object\n@GetMapping(&quot;&#x2F;accounts&#x2F;&#123;id&#125;&quot;)\n@ResponseBody\npublic Account handle() &#123;\n    &#x2F;&#x2F; ...\n&#125;\n@ResponseBody：方法返回一个响应体，通过HttpMessageConverter将返回序列化到响应正文\n@PostMapping(&quot;&#x2F;accounts&quot;)\npublic void handle(@RequestBody Account account) &#123;\n    &#x2F;&#x2F; ...\n&#125;\n@ResponseStatus：返回的状态码，通过HttpStatus来指定\n\n@PathVariable：请求URI中的变量\n&#x2F;&#x2F;样例一\n@GetMapping(&quot;&#x2F;owners&#x2F;&#123;ownerId&#125;&#x2F;pets&#x2F;&#123;petId&#125;&quot;)\npublic Pet findPet(@PathVariable Long ownerId, @PathVariable Long petId) &#123;\n    &#x2F;&#x2F; ...\n&#125;\n&#x2F;&#x2F;样例二\n@Controller\n@RequestMapping(&quot;&#x2F;owners&#x2F;&#123;ownerId&#125;&quot;)\npublic class OwnerController &#123;\n    @GetMapping(&quot;&#x2F;pets&#x2F;&#123;petId&#125;&quot;)\n    public Pet findPet(@PathVariable Long ownerId, @PathVariable Long petId) &#123;\n        &#x2F;&#x2F; ...\n    &#125;\n&#125;\n@RequestParam：请求URI中的参数，可以将Servlet请求参数绑定到控制器中的方法参数\n@GetMapping\npublic String setupForm(@RequestParam(&quot;petId&quot;) int petId, Model model) &#123;\n    Pet pet &#x3D; this.clinic.loadPet(petId);\n    model.addAttribute(&quot;pet&quot;, pet);\n    return &quot;petForm&quot;;\n&#125;\n@MatrixVariable：匹配URI中多个参数中的一个，Matrix Variable中，多个变量用;分隔\n&#x2F;&#x2F; GET &#x2F;pets&#x2F;42;q&#x3D;11;r&#x3D;22\n@GetMapping(&quot;&#x2F;pets&#x2F;&#123;petId&#125;&quot;)\npublic void findPet(@PathVariable String petId, @MatrixVariable int q) &#123;\n    &#x2F;&#x2F; petId &#x3D;&#x3D; 42\n    &#x2F;&#x2F; q &#x3D;&#x3D; 11\n&#125;\n\n\nDIspatcherServlet：首先通过一个dispatchservlet去转接请求，到handlermapping去返回一个执行链，就比如拦截器到哪个controller，返回以后就到handler适配器获取这个请求要求的controller，然后去controller这里返回一个数据或者页面modelandview，然后给前端\n\n请求处理（DispatcherServlet里面）\n\n首先，调用doService方法首先绑定一些属性（应用上下文、还有一些Resolver）\n\n然后，调用doDispatch方法为请求确定Handler，执行Controller前后的处理器逻辑\n&#x2F;&#x2F; Determine handler for the current request.\nmappedHandler &#x3D; getHandler(processedRequest);\n&#x2F;&#x2F;前置处理\nif (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return;&#125;\n&#x2F;&#x2F; Actually invoke the handler.\nmv &#x3D; ha.handle(processedRequest, response, mappedHandler.getHandler());\n&#x2F;&#x2F;后置处理\nmappedHandler.applyPostHandle(processedRequest, response, mv);\n最后，doDispatch中处理Handler返回的Model，呈现视图\nprocessDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);\n\n\n视图解析（xxxResolver）\n\nDispatcherServlet中的initStrategies()初始化了对应的ViewResolver\n前面提到的processDispatchResult会做从视图名到视图的解析，通过render呈现视图，在render中解析出view对象\n\n\n异常处理：实现HandlerExceptionResolver接口，例如拦截所有controller\n@RestControllerAdvice\npublic class GlobalControllerAdvice &#123;\n    @ExceptionHandler(ValidationException.class)\n    @ResponseStatus(HttpStatus.BAD_REQUEST)&#x2F;&#x2F;返回400\n    public Map&lt;String, String&gt; validationExceptionHandler(ValidationException exception) &#123;\n        Map&lt;String, String&gt; map &#x3D; new HashMap&lt;&gt;();\n        map.put(&quot;message&quot;, exception.getMessage());\n        return map;\n    &#125;\n&#125;\n\n\n\n\n2.原理及源码分析\nSpringMVC 的组件\nDispatcherServlet：前置控制器，负责接收 HTTP 请求并委托给 HandlerMapping、HandlerAdapter 和 ViewResolver 等组件处理。\nHandler：处理器，完成具体的业务逻辑，相当于 Servlet 或 Action。HandlerMapping：负责将请求映射到对应的 Handler 即控制器(Controller)。\nHandlerInterceptor：处理器拦截器，是一个接口，如果需要完成一些拦截处理，可以实现该接口。HandlerExecutionChain：处理器执行链，包括两部分内容：Handler 和 HandlerInterceptor（系统会有一个默认的 HandlerInterceptor，如果需要额外设置拦截，可以添加拦截器）。\nHandlerAdapter：负责调用处理器方法并封装处理结果，将其传递给 DispatcherServlet。ModelAndView：装载了模型数据和视图信息，作为 Handler 的处理结果，返回给 DispatcherServlet。\nViewResolver：视图解析器，负责根据视图名称解析出对应的 View，最终将渲染结果响应给客户端。\n\n\n拦截器（Interceptors）：拦截器是Spring MVC框架中的一部分，可以对特定的请求进行拦截和处理。它们通常用于处理与Web请求和响应相关的任务，如身份验证、日志记录、性能监控等。可以通过实现HandlerInterceptor接口来编写自定义拦截器\n过滤器（Filters）：过滤器是Java EE标准中的一部分，用于处理Web请求和响应，作用于Servlet容器的请求处理过程，可以在请求到达Servlet之前或响应返回给客户端之前进行操作。它们通常用于执行通用的、与特定请求无关的任务，如请求参数解析、字符编码设置、跨域请求处理等。通过实现javax.servlet.Filter接口来编写自定义过滤器\n\n5.Testing\nSpringBoot提供了@SpringBootTest注解，当需要SpringBoot的特性时，他是Spring-test的@ContextConfiguration注解的替代品，这个注解会通过SpringApplication创建测试中使用的应用上下文来工作，默认是不开启服务器的，但可以通过webEnvironment来重定义：\nMOCK（默认）：加载一个Web ApplicationContext来提供一个模拟Web环境，不启动嵌入式服务器，但如果类路径上没有可用的Web环境，则此模式会回退到非Web ApplicationContext，\nRANDOM_PORT：加载一个WebServerApplicationContext并提供一个真实的Web环境。嵌入式服务器启动并侦听随机端口。\nDEFINED_PORT：加载一个WebServerApplicationContext并提供一个真实的Web环境，嵌入式服务器侦听定义的端口或默认的端口（8080）\nNONE：使用SpringApplication加载ApplicationContext但不提供任何Web环境\n\n\n@Transactional的测试，这个事务会在测试方法结束后默认回滚\n检测测试配置：@Test会自动搜索主要配置，@TestConfiguration类可以覆盖配置并通过@Import导入配置\n使用模拟（mock）环境测试：@AutoConfigureMockMvc\n模拟和窥探Beans：@MockBean用于定义一个应用上下文中的一个bean的Mockito模拟\nAuto-configured Tests：用来自动载入测试需要的程序片段，可以选择一个@…Test注释并手动包含其它片段的@AutoConfigure…注释\n\n6.MyBatis1.使用\n与Spring整合\n\n引入依赖（org.mybatis.generator）\n\n增加配置文件（generatorConfig.xml），可以根据官网的模版更改\n&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;\n&lt;!DOCTYPE generatorConfiguration\n        PUBLIC &quot;-&#x2F;&#x2F;mybatis.org&#x2F;&#x2F;DTD MyBatis Generator Configuration 1.0&#x2F;&#x2F;EN&quot;\n        &quot;http:&#x2F;&#x2F;mybatis.org&#x2F;dtd&#x2F;mybatis-generator-config_1_0.dtd&quot;&gt;\n\n&lt;!-- root element of a MyBatis Generator configuration file--&gt;\n&lt;generatorConfiguration&gt;\n\n    &lt;properties resource&#x3D;&quot;generator.properties&quot;&#x2F;&gt;\n&lt;!--    flat为任何表生成一个domain类，保存表中的所有字段--&gt;\n    &lt;context id&#x3D;&quot;MySQL&quot; targetRuntime&#x3D;&quot;MyBatis3&quot; defaultModelType&#x3D;&quot;flat&quot;&gt;\n        &lt;property name&#x3D;&quot;beginningDelimiter&quot; value&#x3D;&quot;&#96;&quot;&#x2F;&gt;\n        &lt;property name&#x3D;&quot;endingDelimiter&quot; value&#x3D;&quot;&#96;&quot;&#x2F;&gt;\n        &lt;property name&#x3D;&quot;javaFileEncoding&quot; value&#x3D;&quot;UTF-8&quot;&#x2F;&gt;\n\n        &lt;!-- 为模型生成序列化方法--&gt;\n        &lt;plugin type&#x3D;&quot;org.mybatis.generator.plugins.SerializablePlugin&quot;&#x2F;&gt;\n        &lt;!-- 为生成的Java模型创建一个toString方法 --&gt;\n        &lt;plugin type&#x3D;&quot;org.mybatis.generator.plugins.ToStringPlugin&quot;&#x2F;&gt;\n\n        &lt;!--可以自定义生成model的代码注释--&gt;\n        &lt;commentGenerator type&#x3D;&quot;com.rent.mbg.CommentGenerator&quot;&gt;\n            &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt;\n            &lt;property name&#x3D;&quot;suppressAllComments&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;\n            &lt;property name&#x3D;&quot;suppressDate&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;\n            &lt;property name&#x3D;&quot;addRemarkComments&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;\n        &lt;&#x2F;commentGenerator&gt;\n\n\n        \n        &lt;jdbcConnection driverClass&#x3D;&quot;$&#123;jdbc.driverClass&#125;&quot;\n                        connectionURL&#x3D;&quot;$&#123;jdbc.connectionURL&#125;&quot;\n                        userId&#x3D;&quot;$&#123;jdbc.userId&#125;&quot;\n                        password&#x3D;&quot;$&#123;jdbc.password&#125;&quot;&gt;\n            &lt;!--解决mysql驱动升级到8.0后不生成指定数据库代码的问题--&gt;\n            &lt;property name&#x3D;&quot;nullCatalogMeansCurrent&quot; value&#x3D;&quot;true&quot; &#x2F;&gt;\n        &lt;&#x2F;jdbcConnection&gt;\n\n&lt;!--        &lt;javaTypeResolver &gt;--&gt;\n&lt;!--            &lt;property name&#x3D;&quot;forceBigDecimals&quot; value&#x3D;&quot;false&quot; &#x2F;&gt;--&gt;\n&lt;!--        &lt;&#x2F;javaTypeResolver&gt;--&gt;\n\n        &lt;!--指定生成model的路径--&gt;\n        &lt;javaModelGenerator targetPackage&#x3D;&quot;com.rent.mbg.model&quot; targetProject&#x3D;&quot;src&#x2F;main&#x2F;java&quot;&gt;\n&lt;!--            &lt;property name&#x3D;&quot;enableSubPackages&quot; value&#x3D;&quot;true&quot; &#x2F;&gt;--&gt;\n&lt;!--            &lt;property name&#x3D;&quot;trimStrings&quot; value&#x3D;&quot;true&quot; &#x2F;&gt;--&gt;\n        &lt;&#x2F;javaModelGenerator&gt;\n\n        &lt;!--指定生成mapper.xml的路径--&gt;\n        &lt;sqlMapGenerator targetPackage&#x3D;&quot;com.rent.mbg.mapper&quot;  targetProject&#x3D;&quot;src&#x2F;main&#x2F;resources&quot;&gt;\n&lt;!--            &lt;property name&#x3D;&quot;enableSubPackages&quot; value&#x3D;&quot;true&quot; &#x2F;&gt;--&gt;\n        &lt;&#x2F;sqlMapGenerator&gt;\n\n        &lt;!--指定生成mapper接口的的路径--&gt;\n        &lt;javaClientGenerator type&#x3D;&quot;XMLMAPPER&quot; targetPackage&#x3D;&quot;com.rent.mbg.mapper&quot;  targetProject&#x3D;&quot;src&#x2F;main&#x2F;java&quot;&gt;\n&lt;!--            &lt;property name&#x3D;&quot;enableSubPackages&quot; value&#x3D;&quot;true&quot; &#x2F;&gt;--&gt;\n        &lt;&#x2F;javaClientGenerator&gt;\n\n        &lt;table tableName&#x3D;&quot;pms_brand&quot; &gt;\n&lt;!--            &lt;property name&#x3D;&quot;useActualColumnNames&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;--&gt;\n            &lt;generatedKey column&#x3D;&quot;id&quot; sqlStatement&#x3D;&quot;MySql&quot; identity&#x3D;&quot;true&quot; &#x2F;&gt;\n&lt;!--            &lt;columnOverride column&#x3D;&quot;DATE_FIELD&quot; property&#x3D;&quot;startDate&quot; &#x2F;&gt;--&gt;\n&lt;!--            &lt;ignoreColumn column&#x3D;&quot;FRED&quot; &#x2F;&gt;--&gt;\n&lt;!--            &lt;columnOverride column&#x3D;&quot;LONG_VARCHAR_FIELD&quot; jdbcType&#x3D;&quot;VARCHAR&quot; &#x2F;&gt;--&gt;\n        &lt;&#x2F;table&gt;\n\n    &lt;&#x2F;context&gt;\n&lt;&#x2F;generatorConfiguration&gt;\n写Generator：官网有示例\nList&lt;String&gt; warnings &#x3D; new ArrayList&lt;String&gt;();\nboolean overwrite &#x3D; true;\nFile configFile &#x3D; new File(&quot;generatorConfig.xml&quot;);\nConfigurationParser cp &#x3D; new ConfigurationParser(warnings);\nConfiguration config &#x3D; cp.parseConfiguration(configFile);\nDefaultShellCallback callback &#x3D; new DefaultShellCallback(overwrite);\nMyBatisGenerator myBatisGenerator &#x3D; new MyBatisGenerator(config, callback, warnings);\nmyBatisGenerator.generate(null);\nfor (String warning : warnings) &#123;\n\t\tSystem.out.println(warning);\n&#125;\n添加MyBatis的Java配置\n&#x2F;**\n * MyBatis配置类\n * Created by macro on 2019&#x2F;4&#x2F;8.\n *&#x2F;\n@Configuration\n@MapperScan(&quot;com.macro.mall.tiny.mbg.mapper&quot;)\npublic class MyBatisConfig &#123;\n&#125;\nMyBatis使用XML和Annotation来配置、映射原语、映射接口、和Java POJO到数据库记录\n\nPOJO：只有setter、getter、toString的简单类\n\n配置数据源、编写XML文件（包含sql语句）:https://mybatis.org/mybatis-3/sqlmap-xml.html\n\nMapper XML files\nresultMap：how to load your objects from the database result sets.\nsql：A reusable chunk of SQL that can be referenced by other statements.\ninsert：A mapped INSERT statement.\nupdate：A mapped UPDATE statement.\ndelete：A mapped DELETE statement.\nselect：A mapped SELECT statement.\n\n\nDynamic SQL\nif：条件\nchoose (when, otherwise)：switch选择\ntrim (where, set)：\nforeach：循环\n\n\n\n\n依据XML文件来构建*SqlSessionFactory*\nString resource &#x3D; &quot;org&#x2F;mybatis&#x2F;example&#x2F;mybatis-config.xml&quot;;\nInputStream inputStream &#x3D; Resources.getResourceAsStream(resource);\nSqlSessionFactory sqlSessionFactory &#x3D;\n  new SqlSessionFactoryBuilder().build(inputStream);\n&#x2F;&#x2F;从SqlSessionFactory获得一个SqlSession\ntry (SqlSession session &#x3D; sqlSessionFactory.openSession()) &#123;\n  BlogMapper mapper &#x3D; session.getMapper(BlogMapper.class);\n  Blog blog &#x3D; mapper.selectBlog(101);\n&#125;\n\n\n\n\n用于通过数据库的table信息来生成MyBatis代码，可以合并已有XML重写Java文件\n\n实体类（xxx）：table属性、get、set、toString、序列化、注释（commonGenerator）\n\n映射文件（xxxMapper.xml）：具体的sql语句\n\nMapper接口（xxxMapper）：使用了xxxExample中的条件，与xxxMapper.xml中的sql语句一一对应\nlong countByExample(PmsBrandExample example);&#x2F;&#x2F;按条件计数\nint deleteByExample(PmsBrandExample example);&#x2F;&#x2F;按条件删除\n\nint deleteByPrimaryKey(Long id);&#x2F;&#x2F;按主键删除\n\nint insert(PmsBrand record);&#x2F;&#x2F;插入数据，返回值为ID\n\nint insertSelective(PmsBrand record);&#x2F;&#x2F;插入数据，只插入值不为null的字段，内部动态sql判断\n\nList&lt;PmsBrand&gt; selectByExampleWithBLOBs(PmsBrandExample example);\n\nList&lt;PmsBrand&gt; selectByExample(PmsBrandExample example);&#x2F;&#x2F;按条件查询，传入null表示查询所有\n\nPmsBrand selectByPrimaryKey(Long id);&#x2F;&#x2F;按主键查询\n&#x2F;&#x2F;按条件更新值不为null的字段\nint updateByExampleSelective(@Param(&quot;record&quot;) PmsBrand record, @Param(&quot;example&quot;) PmsBrandExample example);\n&#x2F;&#x2F;BLOB：二进制大对象\nint updateByExampleWithBLOBs(@Param(&quot;record&quot;) PmsBrand record, @Param(&quot;example&quot;) PmsBrandExample example);\n&#x2F;&#x2F;按条件更新\nint updateByExample(@Param(&quot;record&quot;) PmsBrand record, @Param(&quot;example&quot;) PmsBrandExample example);\n&#x2F;&#x2F;按主键更新值不为null的字段\nint updateByPrimaryKeySelective(PmsBrand record);\n\nint updateByPrimaryKeyWithBLOBs(PmsBrand record);\n&#x2F;&#x2F;按主键更新\nint updateByPrimaryKey(PmsBrand record);\n条件扩展类（xxxExample）：定义了一系列方法用来做条件，比如排序、去重、大于、小于、等于、模糊查询、数据在某某之间等\n\nGeneratedCriteria：定义了一系列条件方法，最后都会拼接在SQL中（where语句），但是一般不使用它\nCriteria：一般使用这个子类来进行操作，继承了GeneratedCriteria类\nCriterion：将条件需要的属性抽象出来表示组成一个包装类\n\n\n\n\n补充\n\nMyBatis中的ResultMap继承是一种非常有用的特性，它允许您创建一个ResultMap，该ResultMap可以继承另一个已经存在的ResultMap的配置，以便在不重复配置的情况下扩展或修改映射规则。这在处理复杂的查询结果映射时特别有用\n&lt;resultMap id&#x3D;&quot;baseResultMap&quot; type&#x3D;&quot;com.example.User&quot;&gt;\n  &lt;id property&#x3D;&quot;id&quot; column&#x3D;&quot;user_id&quot;&#x2F;&gt;\n  &lt;result property&#x3D;&quot;username&quot; column&#x3D;&quot;user_name&quot;&#x2F;&gt;\n  &lt;result property&#x3D;&quot;email&quot; column&#x3D;&quot;user_email&quot;&#x2F;&gt;\n&lt;&#x2F;resultMap&gt;\n\n&lt;resultMap id&#x3D;&quot;extendedResultMap&quot; type&#x3D;&quot;com.example.ExtendedUser&quot; extends&#x3D;&quot;baseResultMap&quot;&gt;\n  &lt;!-- 添加额外的映射规则 --&gt;\n  &lt;result property&#x3D;&quot;phoneNumber&quot; column&#x3D;&quot;user_phone_number&quot;&#x2F;&gt;\n&lt;&#x2F;resultMap&gt;\n#&#123;&#125; 和 $&#123;&#125;的区别\n\n#&#123;&#125;是MyBatis中的预编译参数占位符。当使用#&#123;&#125;来引用参数时，MyBatis会将参数值以及它的类型安全地设置到SQL语句中，确保SQL语句是预编译的，可以防止SQL注入攻击\n$&#123;&#125;是MyBatis中的字符串替换占位符。当使用$&#123;&#125;时，MyBatis会将参数值直接嵌入到SQL语句中，而不进行预编译。这意味着参数值会被原封不动地插入到SQL语句中，可能会导致SQL注入攻击的风险\n通常情况下，建议使用#&#123;&#125;来绑定参数，以提高安全性和预编译性。只有在必要的情况下，例如需要动态生成表名或列名时，才使用$&#123;&#125;。在使用$&#123;&#125;时，务必确保参数值是可信任的，以防止潜在的安全风险\n\n\n如果在MyBatis中实体类中的属性是String类型，而数据库中的对应列是Integer类型，MyBatis会尝试进行类型转换，但会受到数据库和Java类型之间的限制和差异的影响。以下是可能发生的情况：\n\n类型转换错误： 如果数据库中存储的值无法成功转换为String类型，或者将String类型的值转换为Integer类型时发生错误（例如，如果数据库列包含非数字字符），则会引发类型转换错误\n数据截断： 如果数据库中的Integer值超出了String类型的范围（例如，数据库中的Integer值是很大的整数），则将导致String类型的数据截断，可能导致丢失精度\n查询失败： 在查询时，如果使用了不匹配的类型，例如将String类型的属性与Integer类型的列进行比较，可能会导致查询失败或返回不正确的结果\n\n\n\n\n\n2.设计模式\n工厂模式，工厂模式在 MyBatis 中的典型代表是 SqlSessionFactory\n建造者模式，建造者模式在 MyBatis 中的典型代表是 SqlSessionFactoryBuilder\n单例模式，单例模式在 MyBatis 中的典型代表是 ErrorContext\n适配器模式，适配器模式在 MyBatis 中的典型代表是 Log\n代理模式，代理模式在 MyBatis 中的典型代表是 MapperProxyFactory\n模板方法模式，模板方法在 MyBatis 中的典型代表是 BaseExecutor\n装饰器模式，装饰器模式在 MyBatis 中的典型代表是 Cache\n\n3.原理分析\nMyBatis中创建了一个Mapper接口，在写一个xml文件，java的接口是要实现的，为什么这没有实现呢？\n\nMyBatis中的Mapper接口并不需要实现，它只是定义了一组方法签名。MyBatis会根据Mapper接口中的方法名、参数类型和返回值类型，自动生成实现方法。因此，Mapper接口中的方法不需要实现，也不需要在该接口中编写任何方法体\n相反，你需要编写一个与Mapper接口同名的XML文件，来实现这些方法的具体SQL操作。这样，当你在Java代码中调用Mapper接口中的方法时，MyBatis会自动将该方法映射到对应的XML文件中的SQL语句，并执行该语句\n\n\n与传统的JDBC相比，MyBatis的优点\n\nmybatis的全局配置文件中可以设置数据库连接池，和spring整合可以配置数据库连接\nmybatis把sql和代码分离，提供了Mapper.xml映射文件，在映射文件中通过标签来写sql\nmybatis中自动完成java对象和sql中参数的映射\nmybatis中通过ResultSetHandler自动将结果集映射到对应的java对象中\n\n\nHibernete和MyBatis区别\n\n编程范式\nHibernate采用了全自动的对象关系映射（ORM）方式，它试图完全隐藏SQL操作，开发者只需要处理Java对象。它通过注解或XML文件配置实体类与数据库表的映射关系。\nMyBatis采用了半自动的ORM方式，开发者需要显式编写SQL语句来执行数据库操作。它通过XML或注解配置SQL语句和参数映射，但依然需要手动编写SQL。\n\n\n性能\nHibernate在处理大量数据时可能引发性能问题，因为它需要加载整个对象图，可能会导致懒加载和性能下降\nMyBatis在性能方面更有优势，因为它可以针对每个查询编写优化的SQL语句，避免不必要的数据加载\n\n\n\n\nJDBC连接数据库的操作：注册JDBC驱动、打开链接执行查询（sql字符串）、输出所有结果（循环）\n\n加载数据库驱动程序：使用Class.forName()方法加载对应的数据库驱动程序，例如：Class.forName(“com.mysql.jdbc.Driver”);\n\n建立数据库连接：使用DriverManager.getConnection()方法建立与数据库的连接，需要指定数据库的URL、用户名和密码，例如：Connection conn = DriverManager.getConnection(“jdbc:mysql://localhost/mydatabase”, “username”, “password”);\n\n创建Statement对象：使用Connection对象的createStatement()方法创建一个Statement对象，用于执行SQL语句，例如：Statement stmt = conn.createStatement();\n\n执行SQL语句：使用Statement对象的executeQuery()或executeUpdate()方法执行SQL语句，例如：ResultSet rs = stmt.executeQuery(“SELECT * FROM mytable”);\n\n处理查询结果：如果执行的是查询语句，需要使用ResultSet对象来处理查询结果，例如：while (rs.next()) { String name = rs.getString(“name”); int age = rs.getInt(“age”); }\n\n关闭数据库连接：在程序结束时，需要使用Connection对象的close()方法关闭数据库连接，例如：conn.close();\npackage com.runoob.test;\n \nimport java.sql.*;\n \npublic class MySQLDemo &#123;\n \n    &#x2F;&#x2F; MySQL 8.0 以下版本 - JDBC 驱动名及数据库 URL\n    static final String JDBC_DRIVER &#x3D; &quot;com.mysql.jdbc.Driver&quot;;  \n    static final String DB_URL &#x3D; &quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;RUNOOB&quot;;\n \n    &#x2F;&#x2F; MySQL 8.0 以上版本 - JDBC 驱动名及数据库 URL\n    &#x2F;&#x2F;static final String JDBC_DRIVER &#x3D; &quot;com.mysql.cj.jdbc.Driver&quot;;  \n    &#x2F;&#x2F;static final String DB_URL &#x3D; &quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;RUNOOB?useSSL&#x3D;false&amp;allowPublicKeyRetrieval&#x3D;true&amp;serverTimezone&#x3D;UTC&quot;;\n\n \n    &#x2F;&#x2F; 数据库的用户名与密码，需要根据自己的设置\n    static final String USER &#x3D; &quot;root&quot;;\n    static final String PASS &#x3D; &quot;123456&quot;;\n \n    public static void main(String[] args) &#123;\n        Connection conn &#x3D; null;\n        Statement stmt &#x3D; null;\n        try&#123;\n            &#x2F;&#x2F; 注册 JDBC 驱动\n            Class.forName(JDBC_DRIVER);\n        \n            &#x2F;&#x2F; 打开链接\n            System.out.println(&quot;连接数据库...&quot;);\n            conn &#x3D; DriverManager.getConnection(DB_URL,USER,PASS);\n        \n            &#x2F;&#x2F; 执行查询\n            System.out.println(&quot; 实例化Statement对象...&quot;);\n            stmt &#x3D; conn.createStatement();\n            String sql;\n            sql &#x3D; &quot;SELECT id, name, url FROM websites&quot;;\n            ResultSet rs &#x3D; stmt.executeQuery(sql);\n        \n            &#x2F;&#x2F; 展开结果集数据库\n            while(rs.next())&#123;\n                &#x2F;&#x2F; 通过字段检索\n                int id  &#x3D; rs.getInt(&quot;id&quot;);\n                String name &#x3D; rs.getString(&quot;name&quot;);\n                String url &#x3D; rs.getString(&quot;url&quot;);\n    \n                &#x2F;&#x2F; 输出数据\n                System.out.print(&quot;ID: &quot; + id);\n                System.out.print(&quot;, 站点名称: &quot; + name);\n                System.out.print(&quot;, 站点 URL: &quot; + url);\n                System.out.print(&quot;\\n&quot;);\n            &#125;\n            &#x2F;&#x2F; 完成后关闭\n            rs.close();\n            stmt.close();\n            conn.close();\n        &#125;catch(SQLException se)&#123;\n            &#x2F;&#x2F; 处理 JDBC 错误\n            se.printStackTrace();\n        &#125;catch(Exception e)&#123;\n            &#x2F;&#x2F; 处理 Class.forName 错误\n            e.printStackTrace();\n        &#125;finally&#123;\n            &#x2F;&#x2F; 关闭资源\n            try&#123;\n                if(stmt!&#x3D;null) stmt.close();\n            &#125;catch(SQLException se2)&#123;\n            &#125;&#x2F;&#x2F; 什么都不做\n            try&#123;\n                if(conn!&#x3D;null) conn.close();\n            &#125;catch(SQLException se)&#123;\n                se.printStackTrace();\n            &#125;\n        &#125;\n        System.out.println(&quot;Goodbye!&quot;);\n    &#125;\n&#125;\n\n\nMyBatis是一种持久化框架，它提供了一级缓存和二级缓存来提高数据库访问性能\n\n一级缓存：一级缓存是MyBatis的默认缓存机制，也称为本地缓存。它是一个SqlSession级别的缓存，即在同一个SqlSession内执行的多次查询可以共享一级缓存。当应用程序执行一个查询操作时，查询结果会被缓存在SqlSession的一级缓存中。如果相同的查询再次执行，MyBatis会首先检查一级缓存，如果缓存中存在对应的数据，将直接返回缓存中的结果，而不需要再次查询数据库\n生命周期： 一级缓存的生命周期与SqlSession相同。一旦SqlSession被关闭，一级缓存中的数据也将被清除\n失效情况： 一级缓存会在SqlSession执行增、删、改等修改数据库操作时失效，因为这些操作可能会导致缓存中的数据不再是最新的\n\n\n二级缓存：二级缓存是一个全局性的缓存，它可以被多个SqlSession共享。这意味着多个SqlSession可以从同一个二级缓存中获取数据，而不仅限于同一个SqlSession。 当一个查询被执行时，查询结果会被存储在二级缓存中。如果其他SqlSession执行相同的查询，它们可以从二级缓存中获取数据，而不需要访问数据库。（需要在配置文件中启用二级缓存、选择缓存实现类）\n生命周期： 二级缓存的生命周期与整个应用程序相同，只有当应用程序关闭时才会被清除。\n失效情况： 二级缓存会在执行与缓存数据相关的增删改操作时失效。MyBatis提供了一些机制来配置缓存的失效策略，例如定时清除、手动清除等\n\n\n\n\n\n7.Spring Boot\n\n\n\n\n\n\n\n\n利用注解简化Spring的xml配置文件、提供自动配置功能（根据classpath中的库自动配置数据源、Web服务器、日志记录）、提供了约定大于配置的方式管理依赖（使用“Starter”模块来简化依赖的引入和版本管理）、支持内嵌多种Web容器（Tomcat、Netty、WebFlux（Reactor Netty））\n1.Annotation\n@SpringBootApplication：默认加在主类的main方法上，可以看作是@Configuration、@EnableAutoConfiguration、@ComponentScan注解的集合\n\n@EnableAutoConfiguration：启用 SpringBoot 的自动配置机制\n\n@ComponentScan： 扫描被@Component (@Repository,@Service,@Controller)注解修饰的 bean，注解默认会扫描该类所在的包下所有的类\n\n@Configuration：允许在 Spring 上下文中注册额外的 bean 或导入其他配置类\n\n用@Configuration注释一个类表明一个对象时bean定义的来源，此外，Configuration类允许通过调用同一类中的其它@Bean方法来定义bean间的依赖关系\n@Configuration\npublic class AppConfig &#123;\n    @Bean\n    public MyService myService() &#123;\n        return new MyServiceImpl();\n    &#125;\n&#125;\n&#x2F;&#x2F;与下面xml语句相同：\n&#x2F;&#x2F;&lt;beans&gt;\n&#x2F;&#x2F;    &lt;bean id&#x3D;&quot;myService&quot; class&#x3D;&quot;com.acme.services.MyServiceImpl&quot;&#x2F;&gt;\n&#x2F;&#x2F;&lt;&#x2F;beans&gt;\n当@Configuration类作为输入提供时，@Configuration类本身被注册为bean定义，并且类中所有声明的@Bean方法也被注册为bean定义，使用AnnotationConfigApplicationContext访问\n       public static void main(String[] args) &#123;\n           ApplicationContext ctx &#x3D; new AnnotationConfigApplicationContext(AppConfig.class);\n           MyService myService &#x3D; ctx.getBean(MyService.class);\n           myService.doStuff();\n       &#125;\n\n\n\n\nBean相关的注解：@Autowired、@Component、@Repository、@Service、@Controller、@RestController、@Controller、@ResponseBody、@Scope、@Configuration、@Component\n\n@Bean：用于表示一个方法实例化、配置和初始化一个由IoC容器管理的新对象，与元素的作用相同。可以使用此方法来制定为方法返回值的类型的ApplicationContext中注册bean定义。可以和任何Spring的@Component一起使用，但是通常与@Configurationbean一起使用\n     @Configuration\n     public class AppConfig &#123;\n         @Bean&#x2F;&#x2F;默认情况，bean名称与方法名称相同\n         public TransferServiceImpl transferService() &#123;\n             return new TransferServiceImpl();\n         &#125;\n         &#x2F;&#x2F;可以有任意数量的参数来描述构建该bean所需的依赖项\n         &#x2F;&#x2F;@Bean\n         &#x2F;&#x2F; public TransferService transferService(AccountRepository accountRepository) &#123;\n         &#x2F;&#x2F;     return new TransferServiceImpl(accountRepository);\n         &#x2F;&#x2F;&#125;\n     &#125;\n@Autowired：自动导入对象到类中，被注入进的类同样要被Spring容器管理\n\n示例\n@Service\npublic class UserService &#123;\n  &#x2F;&#x2F;......\n&#125;\n\n@RestController\n@RequestMapping(&quot;&#x2F;users&quot;)\npublic class UserController &#123;\n   @Autowired\n   private UserService userService;\n   &#x2F;&#x2F;......\n&#125;\n其他\n\n用在构造函数上，Spring4.3开始不再需要，但如果有多个构造函数则需要使用\npublic class MovieRecommender &#123;\n    private final CustomerPreferenceDao customerPreferenceDao;\n    @Autowired\n    public MovieRecommender(CustomerPreferenceDao customerPreferenceDao) &#123;\n        this.customerPreferenceDao &#x3D; customerPreferenceDao;\n    &#125;\n    &#x2F;&#x2F; ...\n&#125;\n用于传统的setter方法：\npublic class SimpleMovieLister\n    private MovieFinder movieFinder;\n    @Autowired\n    public void setMovieFinder(MovieFinder movieFinder) &#123;\n        this.movieFinder &#x3D; movieFinder;\n    &#125;\n    &#x2F;&#x2F; ...\n&#125;\n用于字段，甚至可以将其与构造函数混用\npublic class MovieRecommender &#123;\n \n     private final CustomerPreferenceDao customerPreferenceDao;\n     @Autowired\n     private MovieCatalog movieCatalog;\n     @Autowired\n     public MovieRecommender(CustomerPreferenceDao customerPreferenceDao) &#123;\n         this.customerPreferenceDao &#x3D; customerPreferenceDao;\n     &#125;\n     &#x2F;&#x2F; ...\n&#125;\n\n\n\n\n@Component,@Repository,@Service, @Controller：用于将类标识为可自动装配的bean\n\n@Component ：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。\n\n任何满足存储库角色（DAO）的类的标记，用途是异常的自动翻译，类似的其它原型注解有：@Controller（表示层）、@Service（服务层）、@Repository（持久层），尽量不选@Component而选后面那三个\n\nSpring能自动检测原型类，并使用ApplicationContext注册相应的BeanDefinition实例，要自动检测这些类并注册相应的bean，需要将@ComponentScan(basePackages = &quot;org.example&quot;)添加到@Configuration类中\n\n用@Component定义bean元数据：将bean定义元数据贡献给容器\n         @Component\n         public class FactoryMethodComponent &#123;\n             @Bean &#x2F;&#x2F;表示工厂方法和其它bean定义属性\n             @Qualifier(&quot;public&quot;)\n             public TestBean publicInstance() &#123;\n                 return new TestBean(&quot;publicInstance&quot;);\n             &#125;\n         \n             public void doWork() &#123;\n                 &#x2F;&#x2F; Component method implementation omitted\n             &#125;\n         &#125;\n\n\n@Repository: 对应持久层即 Dao 层，主要用于数据库相关操作（dao层的代码注入到ServiceImpl中）\n\n使用Mybatis不需要Repository：关键在于ClassPathMapperScanner对指定包的扫描并且扫描过程，Spring本身只扫描实现类，但是MyBatis的扫描器扫了接口，并且为接口配了个BeanDefinition，其BeanClass是MapperFactoryBean\n@Configuration\n&#x2F;&#x2F;配置了MapperScan，在对应路径下扫描class文件\n@MapperScan(&#123;&quot;com.rent.mbg.mapper&quot;,&quot;com.rent.dao&quot;&#125;)\npublic class MyBatisConfig &#123;\n&#125;\nMapperScannerRegistrar.registerBeanDefinitions()：扫描Mapper并注册是注册BeanDefinitions到Spring中\n\n创建一个扫描器ClassPathMapperScanner，设置好一些属性后，执行doScan()方法区扫描@MapperScan提供的包\n\ndoScan()方法调用父类ClassPathBeanDefinitionScanner的doScan()方法，也就是Spring扫描BeanDefinition的方法，在其中对所有候选者调用isCandidateComponent()方法判断是否为符合要求的BeanDefinition（这里有两组过滤器来过滤扫描到的资源，Spring默认的过滤器是排除掉抽象类/接口，而Mybatis的扫描器重新注册了过滤器，默认对接口放行）\npublic Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123;\n\t&#x2F;&#x2F;调用父类的doscan，即Spring扫描BeanDefinition方法，但是重新注册了过滤器，可以对接口放行\n  Set&lt;BeanDefinitionHolder&gt; beanDefinitions &#x3D; super.doScan(basePackages);\n\n  if (beanDefinitions.isEmpty()) &#123;\n    logger.warn(&quot;No MyBatis mapper was found in &#39;&quot; + Arrays.toString(basePackages) + &quot;&#39; package. Please check your configuration.&quot;);\n  &#125; else &#123;\n\t\t&#x2F;&#x2F;通过接口注册BeanDefinition后，在此实例化Bean对象，因为正常接口无法实例化对象\n    processBeanDefinitions(beanDefinitions);\n  &#125;\n\n  return beanDefinitions;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;processBeanDefinitions里面&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n&#x2F;&#x2F; the mapper interface is the original class of the bean\n&#x2F;&#x2F; but, the actual class of the bean is MapperFactoryBean\n\t\tdefinition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); &#x2F;&#x2F; 使用了Object[] argsToUse将String转换成了Object\n    definition.setBeanClass(this.mapperFactoryBean.getClass());\n以UserDao为例，自动装配时，Spring根据注册时候的BeanDefinition，去工厂mapperFactoryBean里面扔了个UserDao.class参数进去，工厂的getObject方法返回了工厂制造的userDao，其实工厂的getObject使用的是DefaultSqlSession.getMapper(Class type)方法，返回的事MapperProxy代理的类，而这个代理的类的invoke方法并不像平常调用原始目标的 method.invoke，而是去找MapperMethod执行\n\n\n\n加了 @Repository 注解有什么影响：仅仅只能解决 Intellij 静态查找 bean 的问题，没有实际作用。即使加了注解，比如@Controller，@Service 等等，也会被 Spring 的扫描器给忽略掉，因为扫描器会过滤掉接口\n\n\n\n@Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层（service的实现serviceImpl会注入到controller）\n\n@Controller : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面\n\n\n\n@RestController\n\n@RestController注解是@Controller和@ResponseBody的合集，表示这是个控制器bean，并且是将函数的返回值直接填入HTTP响应体中，是REST风格的控制器\n单独使用@Controller不加@ResponseBody的话一般是用在要返回一个视图的情况，这种情况属于比较传统的Spring MVC的应用，对应于前后端不分离的情况，@Controller+@ResponseBody返回 JSON 或 XML 形式数据，写入到HTTP响应中，提供给前端页面进行解析\n\n\n@Scope\n\n声明Spring Bean的作用域，主要有四种常见的作用域：\n\nsingleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。\nprototype : 每次请求都会创建一个新的 bean 实例。\nrequest : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。\nsession : 每一个 HTTP Session 会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效\n\n@Bean\n@Scope(&quot;singleton&quot;)\npublic Person personSingleton() &#123;\n    return new Person();\n&#125;\n\n\n@Configuration：一般用来声明配置类，可以使用 @Component注解替代，不过使用@Configuration注解声明配置类更加语义化\n@Configuration\npublic class AppConfig &#123;\n    @Bean\n    public TransferService transferService() &#123;\n        return new TransferServiceImpl();\n    &#125;\n\n&#125;\n\n\n处理常见的 HTTP 请求类型：@GetMapping、@PostMapping、@PutMapping、@DeleteMapping、@PatchMapping\n\nGET ：请求从服务器获取特定资源。举个例子：GET /users（获取所有学生）\n&#x2F;&#x2F;等价于 @RequestMapping(value&#x3D;&quot;&#x2F;users&quot;,method&#x3D;RequestMethod.GET)\n@GetMapping(&quot;&#x2F;users&quot;)\npublic ResponseEntity&lt;List&lt;User&gt;&gt; getAllUsers() &#123;\n return userRepository.findAll();\n&#125;\nPOST ：在服务器上创建一个新的资源。举个例子：POST /users（创建学生）\n&#x2F;&#x2F;等价于 @RequestMapping(value&#x3D;&quot;&#x2F;users&#x2F;&#123;userId&#125;&quot;,method&#x3D;RequestMethod.PUT)\n@PostMapping(&quot;&#x2F;users&quot;)\npublic ResponseEntity&lt;User&gt; createUser(@Valid @RequestBody UserCreateRequest userCreateRequest) &#123;\n return userRespository.save(userCreateRequest);\n&#125;\nPUT ：更新服务器上的资源（客户端提供更新后的整个资源）。举个例子：PUT /users/12（更新编号为 12 的学生）\n&#x2F;&#x2F;等价于 @RequestMapping(value&#x3D;&quot;&#x2F;users&#x2F;&#123;userId&#125;&quot;,method&#x3D;RequestMethod.PUT)\n@PutMapping(&quot;&#x2F;users&#x2F;&#123;userId&#125;&quot;)\npublic ResponseEntity&lt;User&gt; updateUser(@PathVariable(value &#x3D; &quot;userId&quot;) Long userId,\n  @Valid @RequestBody UserUpdateRequest userUpdateRequest) &#123;\n  ......\n&#125;\nDELETE ：从服务器删除特定的资源。举个例子：DELETE /users/12（删除编号为 12 的学生）\n&#x2F;&#x2F;等价于 @RequestMapping(value&#x3D;&quot;&#x2F;users&#x2F;&#123;userId&#125;&quot;,method&#x3D;RequestMethod.DELETE)\n@DeleteMapping(&quot;&#x2F;users&#x2F;&#123;userId&#125;&quot;)\npublic ResponseEntity deleteUser(@PathVariable(value &#x3D; &quot;userId&quot;) Long userId)&#123;\n  ......\n&#125;\nPATCH ：更新服务器上的资源（客户端提供更改的属性，可以看做作是部分更新），使用的比较少，一般是PUT不够用了之后才用 PATCH 请求去更新数据\n@PatchMapping(&quot;&#x2F;profile&quot;)\npublic ResponseEntity updateStudent(@RequestBody StudentUpdateRequest studentUpdateRequest) &#123;\n      studentRepository.updateDetail(studentUpdateRequest);\n      return ResponseEntity.ok().build();\n  &#125;\n\n\n前后端传值：@PathVariable、@RequestParam、@RequestBody\n\n@PathVariable 和 @RequestParam：@PathVariable用于获取路径参数，@RequestParam用于获取查询参数\n@GetMapping(&quot;&#x2F;klasses&#x2F;&#123;klassId&#125;&#x2F;teachers&quot;)\npublic List&lt;Teacher&gt; getKlassRelatedTeachers(\n   @PathVariable(&quot;klassId&quot;) Long klassId,\n   @RequestParam(value &#x3D; &quot;type&quot;, required &#x3D; false) String type ) &#123;\n\t&#x2F;&#x2F;...\n&#125;\n&#x2F;&#x2F;请求的url是：klasses&#x2F;123456&#x2F;teachers?type&#x3D;web\n&#x2F;&#x2F;获取到的数据就是：klassId&#x3D;123456 type&#x3D;web\n@RequestBody\n\n用于读取Request请求（可能是POST、PUT、DELETE、GET请求）的body部分并且Content-Type为application/json，接收到数据之后会自动将数据绑定到 Java 对象上去。系统会使用HttpMessageConverter或者自定义的HttpMessageConverter将请求的 body 中的 json 字符串转换为 java 对象\n\n一个请求方法只可以有一个@RequestBody，但是可以有多个**@RequestParam和@PathVariable**\n&#x2F;&#x2F;发送POST请求到这个接口，并且body携带JSON数据\n&#x2F;&#x2F;&#123;&quot;userName&quot;:&quot;coder&quot;,&quot;fullName&quot;:&quot;shuangkou&quot;,&quot;password&quot;:&quot;123456&quot;&#125;\n&#x2F;&#x2F;后端就可以直接把 json 格式的数据映射到 UserRegisterRequest\n@PostMapping(&quot;&#x2F;sign-up&quot;)\npublic ResponseEntity signUp(@RequestBody @Valid UserRegisterRequest userRegisterRequest) &#123;\n  userService.save(userRegisterRequest);\n  return ResponseEntity.ok().build();\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;UserRegisterRequest&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class UserRegisterRequest &#123;\n    @NotBlank\n    private String userName;\n    @NotBlank\n    private String password;\n    @NotBlank\n    private String fullName;\n&#125;\n\n\n\n\n\n读取配置信息：@Value、@ConfigurationProperties、@PropertySource\nwuhan2020: 2020年初武汉爆发了新型冠状病毒，疫情严重，但是，我相信一切都会过去！武汉加油！中国加油！\n\nmy-profile:\n  name: Guide哥\n  email: koushuangbwcx@163.com\n\nlibrary:\n  location: 湖北武汉加油中国加油\n  books:\n    - name: 天才基本法\n      description: 二十二岁的林朝夕在父亲确诊阿尔茨海默病这天，得知自己暗恋多年的校园男神裴之即将出国深造的消息——对方考取的学校，恰是父亲当年为她放弃的那所。\n    - name: 时间的秩序\n      description: 为什么我们记得过去，而非未来？时间“流逝”意味着什么？是我们存在于时间之内，还是时间存在于我们之中？卡洛·罗韦利用诗意的文字，邀请我们思考这一亘古难题——时间的本质。\n    - name: 了不起的我\n      description: 如何养成一个新习惯？如何让心智变得更成熟？如何拥有高质量的关系？ 如何走出人生的艰难时刻？\n\n\n@Value(常用)：通常用于注入外部化属性\n&#x2F;&#x2F;applicationConfig会被定义在application.yml中\n@Value(&quot;$&#123;wuhan2020&#125;&quot;)\nString wuhan2020;\n\n&#x2F;&#x2F;示例二\n@Component\n public class MovieRecommender &#123;\n \n     private final String catalog;\n     &#x2F;&#x2F;application.properties中有catalog.name&#x3D;MovieCatalog\n     &#x2F;&#x2F;catalog的值就为MovieCatalog\n     public MovieRecommender(@Value(&quot;$&#123;catalog.name&#125;&quot;) String catalog) &#123;\n         this.catalog &#x3D; catalog;\n     &#125;\n &#125;\n &#x2F;&#x2F;还需以下配置\n @Configuration\n @PropertySource(&quot;classpath:application.properties&quot;)\n public class AppConfig &#123; &#125;\n@ConfigurationProperties(常用)：通过@ConfigurationProperties读取配置信息并与 bean 绑定\n@Component\n@ConfigurationProperties(prefix &#x3D; &quot;library&quot;)\nclass LibraryProperties &#123;\n    @NotEmpty\n    private String location;\n    private List&lt;Book&gt; books;\n\n    @Setter\n    @Getter\n    @ToString\n    static class Book &#123;\n        String name;\n        String description;\n    &#125;\n  省略getter&#x2F;setter\n  ......\n&#125;\n@PropertySource：读取指定 properties 文件\n@Component\n@PropertySource(&quot;classpath:website.properties&quot;)\n\nclass WebSite &#123;\n    @Value(&quot;$&#123;url&#125;&quot;)\n    private String url;\n\n  省略getter&#x2F;setter\n  ......\n&#125;\n\n\n参数校验\n\n数据的校验的重要性就不用说了，即使在前端对数据进行校验的情况下，我们还是要对传入后端的数据再进行一遍校验，避免用户绕过浏览器直接通过一些 HTTP 工具直接向后端请求一些违法数据\n\n验证请求体\n\n字段上加@NotNull(message = &quot;classId 不能为空&quot;)\n参数上加public ResponseEntity&lt;Person&gt; getPerson(@RequestBody @Valid Person person)\n\n\n验证请求参数(Path Variables 和 Request Parameters)\n\n类上加@Validated ****注解，告诉Spring校验方法参数\n@RestController\n@RequestMapping(&quot;&#x2F;api&quot;)\n@Validated\npublic class PersonController &#123;\n\n    @GetMapping(&quot;&#x2F;person&#x2F;&#123;id&#125;&quot;)\n    public ResponseEntity&lt;Integer&gt; getPersonByID(@Valid @PathVariable(&quot;id&quot;) @Max(value &#x3D; 5,message &#x3D; &quot;超过 id 的范围了&quot;) Integer id) &#123;\n        return ResponseEntity.ok().body(id);\n    &#125;\n&#125;\n\n\n\n\nJSR(Java Specification Requests）是一套 JavaBean 参数校验的标准，它定义了很多常用的校验注解，我们可以直接将这些注解加在我们 JavaBean 的属性上面，这样就可以在需要校验的时候进行校验了，非常方便，*一些常用的字段验证的注解如下*\n\n@NotEmpty 被注释的字符串的不能为 null 也不能为空\n@NotBlank 被注释的字符串非 null，并且必须包含一个非空白字符\n@Null 被注释的元素必须为 null\n@NotNull 被注释的元素必须不为 null\n@AssertTrue 被注释的元素必须为 true\n@AssertFalse 被注释的元素必须为 false\n@Pattern(regex=,flag=)被注释的元素必须符合指定的正则表达式\n@Email 被注释的元素必须是 Email 格式。\n@Min(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值\n@Max(value)被注释的元素必须是一个数字，其值必须小于等于指定的最大值\n@DecimalMin(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值\n@DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值\n@Size(max=, min=)被注释的元素的大小必须在指定的范围内\n@Digits(integer, fraction)被注释的元素必须是一个数字，其值必须在可接受的范围内\n@Past被注释的元素必须是一个过去的日期\n@Future 被注释的元素必须是一个将来的日期\n\n\n校验的时候我们实际用的是 Hibernate Validator 框架。Hibernate Validator 是 Hibernate 团队最初的数据校验框架，Hibernate Validator 4.x 是 Bean Validation 1.0（JSR 303）的参考实现，Hibernate Validator 5.x 是 Bean Validation 1.1（JSR 349）的参考实现，目前最新版的 Hibernate Validator 6.x 是 Bean Validation 2.0（JSR 380）的参考实现。SpringBoot 项目的 spring-boot-starter-web 依赖中已经有 hibernate-validator 包，不需要引用相关依赖\n\n需要注意的是： 所有的注解，推荐使用 JSR 注解，即javax.validation.constraints，而不是org.hibernate.validator.constraints\n\n\n\n\n全局处理Controller层异常\n\n@ControllerAdvice ：注解定义全局异常处理类\n@ExceptionHandler ：注解声明异常处理方法\n\n@ControllerAdvice\n@ResponseBody\npublic class GlobalExceptionHandler &#123;\n\n    &#x2F;**\n     * 请求参数异常处理\n\t\t * 处理controller抛出的MethodArgumentNotValidException异常\n     *&#x2F;\n    @ExceptionHandler(MethodArgumentNotValidException.class)\n    public ResponseEntity&lt;?&gt; handleMethodArgumentNotValidException(MethodArgumentNotValidException ex, HttpServletRequest request) &#123;\n       ......\n    &#125;\n&#125;\nJPA相关\n\n@Entity声明一个类对应一个数据库实体\n\n@Table设置表名\n\n@Id声明一个字段为主键\n\n@GeneratedValue指定主键生成策略\n\nTABLE：使用一个特定的数据库表格来保存主键，持久化引擎通过关系数据库的一张特定的表格来生成主键\nSEQUENCE：在某些数据库中,不支持主键自增长,比如Oracle、PostgreSQL其提供了一种叫做”序列(sequence)”的机制生成主键\nIDENTITY：主键自增长\nAUTO：把主键生成策略交给持久化引擎(persistence engine)，根据数据库在以上三种主键生成策略中选择其中一种\n\n\n@Column 声明字段\n\n@Column(name = &quot;user_name&quot;, nullable = false, length=32)\n设置字段类型并且加默认值@Column(columnDefinition = &quot;tinyint(1) default 1&quot;)\n\n\n@Transient声明不需要与数据库映射的字段，在保存的时候不需要保存进数据库\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;************除了 @Transient关键字声明， 还可以采用下面几种方法&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;************\nstatic String secrect; &#x2F;&#x2F; not persistent because of static\nfinal String secrect &#x3D; &quot;Satish&quot;; &#x2F;&#x2F; not persistent because of final\ntransient String secrect; &#x2F;&#x2F; not persistent because of transient\n@Enumerated(EnumType.STRING)声明为枚举类型字段\n\n\n\n事务\n\nException 分为运行时异常 RuntimeException 和非运行时异常，在@Transactionsl注解中如果不配置rollbackFor属性，那么事务只会在遇到RuntimeException的时候才会回滚，加上rollbackFor=Exception.class，可以让事务在遇到非运行时异常时也回滚\n\n\njson数据处理\n\n过滤json数据\n\n@JsonIgnoreProperties 作用在类上用于过滤掉特定字段不返回或者不解析\n@JsonIgnore一般用于类的属性上，作用和上面的@JsonIgnoreProperties 一样\n\n\n@JsonFormat一般用来格式化 json 数据\n@JsonFormat(shape&#x3D;JsonFormat.Shape.STRING, pattern&#x3D;&quot;yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS&#39;Z&#39;&quot;, timezone&#x3D;&quot;GMT&quot;)\nprivate Date date;\n使用@JsonUnwrapped扁平对象，声明在每一个字段上\n&#123;\n    &quot;location&quot;: &#123;\n        &quot;provinceName&quot;:&quot;湖北&quot;,\n        &quot;countyName&quot;:&quot;武汉&quot;\n    &#125;,\n    &quot;personInfo&quot;: &#123;\n        &quot;userName&quot;: &quot;coder1234&quot;,\n        &quot;fullName&quot;: &quot;shaungkou&quot;\n    &#125;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;扁平化后&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n&#123;\n  &quot;provinceName&quot;:&quot;湖北&quot;,\n  &quot;countyName&quot;:&quot;武汉&quot;,\n  &quot;userName&quot;: &quot;coder1234&quot;,\n  &quot;fullName&quot;: &quot;shaungkou&quot;\n&#125;\n\n\n测试相关\n\n@ActiveProfiles一般作用于测试类上， 用于声明生效的 Spring 配置文件\n@SpringBootTest(webEnvironment &#x3D; RANDOM_PORT)\n@ActiveProfiles(&quot;test&quot;)\n@Slf4j\npublic abstract class TestBase &#123;\n  ......\n&#125;\n@Test声明一个方法为测试方法\n\n@Transactional被声明的测试方法的数据会回滚，避免污染测试数据\n\n@WithMockUser Spring Security 提供的，用来模拟一个真实用户，并且可以赋予权限\n@Test\n@Transactional\n@WithMockUser(username &#x3D; &quot;user-id-18163138155&quot;, authorities &#x3D; &quot;ROLE_TEACHER&quot;)\nvoid should_import_student_success() throws Exception &#123;\n    ......\n&#125;\n\n\n其他\n\n@Primary表示当多个bean成为自动装配的候选者时，应该优先考虑特定的bean\n@Configuration\npublic class MovieConfiguration &#123;\n\n    @Bean\n    @Primary\n    public MovieCatalog firstMovieCatalog() &#123; ... &#125;\n\n    @Bean\n    public MovieCatalog secondMovieCatalog() &#123; ... &#125;\n    &#x2F;&#x2F; ...\n&#125;\npublic class MovieRecommender &#123;\n  &#x2F;&#x2F;自动装配firstMovieCatalog\n    @Autowired\n    private MovieCatalog movieCatalog;\n    &#x2F;&#x2F; ...\n&#125;\n@Qualifier：可以将限定符值与特定参数相关联，缩小类型匹配的范围，以便为每个参数选择特定的bean：\npublic class MovieRecommender &#123;\n\n    private MovieCatalog movieCatalog;\n    private CustomerPreferenceDao customerPreferenceDao;\n\n    @Autowired\n    public void prepare(@Qualifier(&quot;main&quot;) MovieCatalog movieCatalog,\n                        CustomerPreferenceDao customerPreferenceDao) &#123;\n        this.movieCatalog &#x3D; movieCatalog;\n        this.customerPreferenceDao &#x3D; customerPreferenceDao;\n    &#125;\n    &#x2F;&#x2F; ...\n&#125;\n@Resource：采用名称属性，默认将该值解释为要注入的bean名称，如果没有明确指定名称，如果是字段，则采用字段名称，如果是setter方法，则采用bean属性名称\n     public class SimpleMovieLister &#123;\n     \n         private MovieFinder movieFinder;\n         @Resource(name&#x3D;&quot;myMovieFinder&quot;)\n         public void setMovieFinder(MovieFinder movieFinder) &#123;\n             this.movieFinder &#x3D; movieFinder;\n         &#125;\n     &#125;\n\n\n\n2.AutoConfiguration\nSPI扩展机制（Service Provider Interface 服务提供者的接口）\n\nAPI\n\n示例：spring项目中，写service层代码前，会约定俗成的添加一个接口层，然后通过spring中的依赖注入（@Autowired）注入这个接口的实现类的实例对象，之后对于service的调用也基于接口操作（虽然有的时候一个接口只有一个实现类，但是面向接口编程可以降低耦合度、方便日后扩展、提高了代码的灵活性和可维护性）\n\n\n\n\nSPI\n\n示例：slf4j框架的LoggerFactory中的findServiceProviders方法返回所有SLF4JServiceProvider（日志服务提供者，一个接口，需要具体的提供者来实现）\n\n服务调用方定义一个接口规范，可以由不同的服务提供者实现，并且，调用方通过某种机制来发现服务提供方，并通过接口调用它的能力\n\nAPI接口是服务提供者向服务调用者提供的一个功能列表（），而SPI机制是服务调用者提供对服务的一种约束（遥控器约束所有空调只有开关等功能），服务提供者根据约束实现的服务，可以被服务调用者发现\n\n\n\n\nSPI工作流程（ServiceLoader）\n\n首先通过ServiceLoader提供的load方法传入接口的class，返回ServiceLoader对象，然后遍历ServiceLoader对象通过接口来引用（接口.getClass）其中的实现类\n\nacc是一个安全管理器，通过System.getSecurityManager()判断并赋值，这里为null\n\nServiceLoader实现了Iterable接口，它的遍历通过Iterator()方法来实现，再Iterator()方法中，首先在一个LinkedHashMap\n实现的名为provider缓存中遍历，没有的时候在LazyIterator类型的懒加载的lookupIterator对象中查找\n\nhasNext方法，逻辑实现为hasNextService方法，取出接口的实现类的全限定名放到nextName中\nnext方法，逻辑实现为nextService方法，通过反射加载（Class.forName）这个实现类，然后实例化对象（newInstance），最后放入之间的provider缓冲中\n\n\n\n\n\n\nspring.factories\n\n@EnableAutoConfiguration\n\n\n3.SpringApplication\n从Java的main方法启动一个Spring应用的过程\n\nSpringApplication的run方法\n\n运行SpringApplication，创建并更新ApplicationContext\nrun方法中的refresh方法\n初始化BeanFactory，加载Bean，注册Bean\n定义的一个个Bean会被转换成BeanDefinition，存在于Spring的BeanFactory中，即Bean可以理解为BeanDefinition的实例，里面保存了Bean的信息（Bean指向哪个类，是否是单例，是否懒加载，依赖了哪些Bean）\nrefreshBeanFactory中的loadBeanDefinitions：根据配置，加载各个Bean，然后放到BeanFactory中\n\n\n\n\n记录应用启动时间\n声明异常链表，报告启动错误\n\n\n两个结构\n\nApplicationContext\n\n\nBeanFactory（Application其实就是一个BeanFactory，里面使用DefaultListableBeanFactory）\n\n\n\n\n启动步骤\n\n根据classpath创建一个ApplicationContext\n\nApplicationContext可以从多个不同数据源读入数据，\n\n\n注册一个CommandLinePropertySource，将命令行参数扩展成Spring属性\n\n刷新应用上下文，载入单例类（PropertyContext）\n\n触发CommandLineRunner的bean\n\n\n\n\n\n\n4.SpringBootStarters5.Actuators8.Spring Security\n\n\n\n\n\n\n\n\nAuthentication（验证）、Authorization（授权）、OAuth2、JWT\n\nSpringSecurity是一个强大的可高度定制的认证和授权框架，对于Spring应用来说它是一套Web安全标准\n\nDelegatingFilterProxy：将Filter委托给实现了Filter接口的Bean来处理\n\nFilterChain：一个客户端向应用发送一个request，会经过一系列的Filter组成的FilterChain，最后交由Servlet来处理\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) &#123;\n\t&#x2F;&#x2F; do something before the rest of the application\n    chain.doFilter(request, response); &#x2F;&#x2F; invoke the rest of the application\n    &#x2F;&#x2F; do something after the rest of the application\n&#125;\nDelegatingFilterProxy：桥接Servlet container的生命周期和Spring的ApplicationContext，DelegatingFilterProxy能被通过标准servlet container机制来注册，但是将所有工作委托给Filter的Spring Bean，FilterChainProxy被包装在DelegatingFilterProxy中，来链接进Servlet container filter chain\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) &#123;\n\t&#x2F;&#x2F; Lazily get Filter that was registered as a Spring Bean\n\t&#x2F;&#x2F; For the example in DelegatingFilterProxy delegate is an instance of Bean Filter0\n\tFilter delegate &#x3D; getFilterBean(someBeanName);\n\t&#x2F;&#x2F; delegate work to the Spring Bean\n\tdelegate.doFilter(request, response);\n&#125;\nFilterChainProxy是Spring Security提供的一个特殊的Filter，将Filter实例委托给SecurityFilterChain，通过内部的一个链表filterChains，来遍历（doFilterInternal中的doFilter方法）确定哪个Spring Security Filter应该被调用（在调试的时候，可以在FilterChainProxy加一个断点，来看所有Spring Security的Servlet）\n\nThe WebSecurity is created by WebSecurityConfiguration to create the FilterChainProxy known as the Spring Security Filter Chain (springSecurityFilterChain).\n\n\n\n常见Filter顺序如下\n\nUsernamePasswordAuthenticationFilter（AbstractAuthenticationProcessingFilter）\nBasicAuthenticationFilter\nExceptionTranslationFIlter（处理异常）\nFilterSecurityInterceptor\n\n\n处理安全异常（未授权通过的抛出异常）\n\nThe ExceptionTranslationFilter allows translation of AccessDeniedException and AuthenticationException into HTTP responses.（检查抛出的异常是否有AccessDeniedException类型的异常）\nprotected void sendStartAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain,\n\t\t\tAuthenticationException reason) throws ServletException, IOException &#123;\n\t\t&#x2F;&#x2F; SEC-112: Clear the SecurityContextHolder&#39;s Authentication, as the\n\t\t&#x2F;&#x2F; existing Authentication is no longer considered valid\n\t\tSecurityContext context &#x3D; SecurityContextHolder.createEmptyContext();\n\t\tSecurityContextHolder.setContext(context);\n\t\t&#x2F;&#x2F;保存HttpServletRequest，用来在授权成功时replay最初的request\n\t\tthis.requestCache.saveRequest(request, response);\n\t\t&#x2F;&#x2F;启动（commence）身份验证方案\n\t\t&#x2F;&#x2F;一般authenticationEntryPoint是LoginUrlAuthenticationEntryPoint的实例\n\t\tthis.authenticationEntryPoint.commence(request, response, reason);\n\t&#125;\n\n\n\n\nUsernamePasswordAuthenticationFilter\n\n\n通过attemptAuthentication方法来返回Authentication对象\n\n从request创造出一个Authentication\n通过username和password来生成一个token传递给request，再使用ProviderManager来看是否授权成功，并返回Authentication对象\n\n\nProviderManager：通过构建一个AuthenticationProvider链表，来看哪个Provider（或ProviderManager的父类）能处理这个authentication\n\nAuthentication对象：保存在SecurityContextHolder的SecurityContext中\n\n\n\n\nAuthorization（授权）\n\n所有Authorization存储在GrantedAuthority对象链表，代表已授权的对象。GrantedAuthority对象由AuthenticationManager插入到Authorization对象中，由AuthorizationManager读取来做出授权决策\nSpring Security包括一个具体的GrantedAuthority实现SimpleGrantedAuthority，允许将任何用户定义的String转换成一个GrantedAuthority\nAccessDecisionManager：Spring Security提供拦截器来控制对安全对象（方法调用或web请求）的访问，AccessDecisionManager在调用发生前决定是否允许调用（取代了AccessDecisionManager 和 AccessDecisionVoter）\nAuthorizationFilter有一个AuthorizationManager链表，每一个AuthorizationManager有两个方法\nverify：做决定，调用check方法检查返回值，来看是否授权\ncheck：传递做授权所需的所有消息\n\n\nAuthorizationManager的实现\nRequestMatcherDelegatingAuthorizationManager：匹配Request到最适合的AuthorizationManager进行处理\nAuthorityAuthorizationManager：配置了一组给定authorities来找到当前的Authentication\nAuthenticatedAuthorizationManager：用来区分anonymous、full-authenticated、remember-me的用户\n\n\n\n\n\n\nJWT是JSON WEB TOKEN的缩写，它是基于 RFC 7519 标准定义的一种可以安全传输的的JSON对象，由于使用了数字签名，所以是可信任和安全的\n\nMD5是不安全的\n\nJWT的格式：header.payload.signature\n\nheader中用于存放签名的生成算法，如：&#123;&quot;alg&quot;: &quot;HS512&quot;&#125;\n\npayload中用于存放用户名、token的生成时间和过期时间，如：&#123;&quot;sub&quot;:&quot;admin&quot;,&quot;created&quot;:1489079981393,&quot;exp&quot;:1489684781&#125;\n\nsignature是以header和payload生成的签名，用来检测header和payload是否被篡改\nString signature &#x3D; HMACSHA512(base64UrlEncode(header) + &quot;.&quot; +base64UrlEncode(payload),secret)\n\n\n实现认证和授权的原理\n\n用户调用登陆接口，登录成功后获取JWT的token（原来是Cookie）\n之后用户每次调用接口都在http的header中添加一个Authorization头，值为JWT的token\n后台程序通过对Authorization头中的信息的解码姐数字签名的校验来获取其中的用户信息，从而实现认证和授权\n\n\n\n\nOAuth2\n- \n\n\n附录\n源码知识点\n\nBean解析流程\nBeanFactory\nFactoryBean\nApplicationContext\nIOC\nBean生命周期\nAOP\n\n\nSpring给我们提供了很多扩展点\n\nBeanFactoryPostProcessor：允许在Spring容器实例化bean之前修改bean的定义。常用于修改bean属性或改变bean的作用域。\nBeanPostProcessor：可以在bean实例化、配置以及初始化之后对其进行额外处理。常用于代理bean、修改bean属性等。\nPropertySource：用于定义不同的属性源，如文件、数据库等，以便在Spring应用中使用。\nImportSelector和ImportBeanDefinitionRegistrar：用于根据条件动态注册bean定义，实现配置类的模块化。\nSpring MVC中的HandlerInterceptor：用于拦截处理请求，可以在请求处理前、处理中和处理后执行特定逻辑。\nSpring MVC中的ControllerAdvice：用于全局处理控制器的异常、数据绑定和数据校验。\nSpring Boot的自动配置：通过创建自定义的自动配置类，可以实现对框架和第三方库的自动配置。\n自定义注解：创建自定义注解，用于实现特定功能或约定，如权限控制、日志记录等。\n\n\n如果让你设计一个SpringIoc，你觉得会从哪些方面考虑这个设计？\n\nBean的生命周期管理：需要设计Bean的创建、初始化、销毁等生命周期管理机制，可以考虑使用工厂模式和单例模式来实现。\n依赖注入：需要实现依赖注入的功能，包括属性注入、构造函数注入、方法注入等，可以考虑使用反射机制和XML配置文件来实现。\nBean的作用域：需要支持多种Bean作用域，比如单例、原型、会话、请求等，可以考虑使用Map来存储不同作用域的Bean实例。\nAOP功能的支持：需要支持AOP功能，可以考虑使用动态代理机制和切面编程来实现。\n异常处理：需要考虑异常处理机制，包括Bean创建异常、依赖注入异常等，可以考虑使用try-catch机制来处理异常。\n配置文件加载：需要支持从不同的配置文件中加载Bean的相关信息，可以考虑使用XML、注解或者Java配置类来实现。\n\n\n源码核心技术点\n\nSpring IOC：Bean生命周期、依赖自动注入\nSpring AOP：AOP源码、事务源码\nSpring后置处理器\nSpring循环依赖\n@Configuration、@Bean注解底层原理\nSpringBoot：底层源码、factories扩展机制、自动配置类、过滤机制、启动过程、第三方starter机制\n\n\n循环依赖\n\n循环依赖\n\n概念\n\nBeanDefinition：Spring核心bean的配置信息，通过扫描注解（@Compoent、@Service、@Configuration）把需要的bean初始化为BeanDefinition的列表\nSpringBean：Spring管理的已经创建好的以后可以使用的实例\nJava Bean：Java通过构造函数创建的对象，Spring推断构造方法后使用反射调用构造函数创建的对象\n\n\n产生原因：在框架启动时会进行bean的加载\n\n\n出现场景\n\n构造器内的循环依赖\nsetter方式单例\nsetter方式原型\nfield属性循环依赖\n\n\n\n\nSpring如何解决\n\n三级缓存解决循环依赖\n\n一级缓存：\nprivate final Map&lt;String, Object&gt; singletonObjects &#x3D; new ConcurrentHashMap&lt;&gt;(256);\n\n\n最基础的单例缓存，限制Bean在beanFactory中只存一份，即实现singleton scope\n\n\n二级缓存：\nprivate final Map&lt;String, Object&gt; earlySingletonObjects &#x3D; new HashMap&lt;&gt;(16);\n\n\n未初始化未填充属性提前暴露的bean\n当调用三级缓存里的对象工厂的getObject方法之后，getEarlyBeanReference 就会把返回值放入二级缓存，删除三级缓存，后续其他依赖该对象的Bean获取的都是同一个earlyBean，保证singleton原则\n\n\n三级缓存：private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);\n\n\n\nAOP循环依赖\n\n\n\n\n\nSpringBootStarter的原理是什么，怎么使用的\n\n\n","slug":"Spring","date":"2023-05-06T05:09:43.000Z","categories_index":"","tags_index":"tools","author_index":"Dajunnnnnn"},{"id":"a978a5e93d8e6628e9f4ee713be55be8","title":"Redis","content":"Redis\n\n\n\n\n\n\n\n\nRedis是一个高性能（内存+Reactor+优化的数据结构）的开源键值数据库，其value支持丰富的数据类型（string、hash、set、list、zset「有序集合」），具有数据可持久化（AOF+RDB）、支持master-slave备份、读写性能高（MySQL的QPS大概1w左右，Redis读11w次/s，写8w次/s）等特点，其单个操作是原子性的，多个连续操作支持事务，常用于缓存，消息队列、分布式锁等场景\n1.高性能1.数据结构\n数据类型及其应用\n\n\n\n类型\n简介\n特性\n场景\n大小\n底层数据结构\n\n\n\nString\n二进制安全\n可以包含任何数据（字符串、整数、浮点数、图片的base64编码、序列化后的对象）\n1.存储数据；2.计数（单位时间请求数，单位时间访问数）\n一个键最大能存储 512MB\nSDS（简单动态字符串）\n\n\nHash\n键值对集合,即编程语言中的Map类型\n适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)\n1.存储、读取、修改用户属性；2.对象数据存储（用户信息、文章信息、购物车信息）\n每个 hash 可以存储 2^32 -1 键值对（4294967295）\nLinkedLIst ZipList\n\n\nList\n链表(双向链表)，按照插入顺序排序\n增删快，提供了操作某一段元素的API（没法用来做排行榜，分页显示时会有串行的问题，使用Sorted Set的score可以解决）\n1、最新消息排行等功能(比如朋友圈的时间线) 2、消息队列\n列表最多可存储 2^32 - 1 元素（4294967295）\nZipList HashTable；3.2后使用QuickList\n\n\nSet\n哈希表实现，元素不重复，可以求交集、并集、差集\n1、添加、删除、查找的复杂度都是O(1) ；2、为集合提供了求交集、并集、差集等操作；3、数据量大时可以选择一个从库\n1、共同好友 2、利用唯一性，统计访问网站的所有独立ip 3、好友推荐时，根据tag求交集，大于某个阈值就可以推荐\n集合中最大的成员数为 2^32 - 1（4294967295）\nZipList Intset\n\n\nZSet（Sorted Set）\n将Set中的元素增加一个权重参数score,元素按score有序排列\n数据插入集合时，已经进行天然排序。类似于Set，但是多了一个权重参数score，使得集合中的元素能够按score进行有序排列，还可以通过score的范围来获取元素的列表\n1、排行榜 2、带权重的消息队列\n—\nZipList SkipList\n\n\nBitmap\n位存储，支持按位与、或、异或\n存储连续的二进制数字，可以看成是存储0/1的数组，数组下标称为offset（活跃用户统计）\n1、用来做二值统计（元素的取值只有0和1），如签到统计\nGETBIT、SETBIT、BITCOUNT\nString（底层为二进制字节数组）\n\n\nHyperLogLogs\n基数统计，元素数量多时仍可保证消耗的空间是固定的\n基数计数概率算法为了节省内存并不会直接存储元数据，而是通过一定的概率统计方法预估基数值（集合中包含元素的个数）\n主要用于数据量巨大的计数场景（热门网站每日访问ip数统计），只存估计值\nHyperLogLogs只需要12KB内存，可以计算接近 2^64 个元素的基数\n基于概率进行统计，给出的结果有偏差\n\n\nGeospatial\n地理位置\n基于Sorted Set实现，将经纬度信息通过GeoHash算法转换成一个整数，将这个整数作为Sorted Set的score使用（实现附近的人功能）\n主要用于存储地理位置信息\nGEOADD、GEORADIUS（根据输入的经纬度，查找以这个经纬度为中心的一定范围内的其他元素）\nSorted Set + GeoHash编码（二分区间、区间编码）\n\n\n\nHash 类型底层结构什么时候使用压缩列表\n\nHash 集合中写入的元素个数超过了hash-max-ziplist-entries，或者写入的单个元素大小超过了hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表\n一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了\n\n\n补充数据结构\n\n\n\n类型\n简介\n特性\nAPI\n底层原理\n\n\n\nRedisTimeSeries\n记录时间序列数据\n支持直接在Redis实例上进行聚合计算（求平均、最值、和），其它方案都需要传输数据到客户端上进行聚合计算\nTS.CREATE；TS.ADD；TS.GET；TS.MGET；TS.RANGE（av g、max/min、sum）\nRedis的扩展模块，使用前需要编译成动态链接库 redistimeseries.so，再使用 loadmodule 命令进行加载\n\n\nStreams\n专门为消息队列设计的数据类型\n消息格式是键值对形式，插入的每一条消息自动生成一个全局唯一ID，读取时可以指定读取起始位置。支持创建消费组\nXADD、XREAD、XREADGROUP、SPENDING、XACK\n自动使用内部队列留存消费者读取的消息直到消费者使用SACK命令，重启时使用命令XPENDING继续处理\n\n\n\n自定义数据类型\n\nRedisObject\ntype：表示值的类型，涵盖了前面学习的五大基本类型\nencoding：是值的编码方式，用来表示 Redis 中实现各个基本类型的底层数据结构，例如 SDS、压缩列表、哈希表、跳表等\nlru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对\nrefcount：记录了对象的引用计数\n*ptr：是指向数据的指针，借助*ptr指针，就可以指向不同的数据类型\n\n\n定义一个新的数据类型的步骤（未完待续）\n\n\n\n\n数据结构对应命令\n\n命令行方式（https://www.runoob.com/redis/redis-tutorial.html、https://redis.io/commands/）\n\n\n\n类型\n命令\n\n\n\nstring\nSET、GET、EXIST、STRLEN、DEL、MSET、MGET、INCR、DECR、EXPIRE、SETNX、TTL\n\n\nlist\nLPUSH、LPOP、RPUSH、RPOP、LRANGE（实现分页）、LLEN\n\n\nhash\nHSET、HSETNX、HMSET、HGET、HMGET、HGETALL（所有）、HEXIXTS、HDEL、HLEN、HINCRBY（增加多少）\n\n\nset\nSADD、SMEMBERS（内容）、SCARD（数量）、SISMEMBER（有无）、求交/并/差集（SINTER、SUNION、SDIFF）、SPOP key count、SRANDMEMBER key count\n\n\nzset\nZADD、ZCARD、ZSCORE、ZINTERSTORE（一共三个）、ZRANGE、ZREVRANGE、ZREVRANK\n\n\nkey\nSET key value、DEL key、EXISTS key（seconds）、TTL key、TYPE key\n\n\npub/sub\nPUBLISH channel message、SUBSCRIBE channel、UNSUBSCRIBE channel\n\n\n事务\nMULTI（开始）、EXEC（执行）、DISCARD（取消）、WATCH、UNWATCH\n\n\n其它\nPING、PONG、QUIT、AUTH password、INFO、FLUSHALL、BGSAVE、BGREWRITEAOF\n\n\n\n使用批量操作减少网络传输\n\nRedis每条命令都会通过网络与服务器交互，可以使用批量操作命令（mget、hmget），但是在Redis Cluster下无法保证所有key都在同一个hash slot上，但仍个减少网络交互耗时\n对于不支持批量操作的命令，可以用pipeline将一批Redis命令封装成一组（非原子操作），但是需要控制批量传输的元素个数，避免网络传输的数据量大，同前一点一样，在Redis Cluster会有问题\n\n\nJedis方式（https://redis.io/commands/）\nimport redis.clients.jedis.Jedis;\n \n import java.util.List;\n import java.util.Set;\n \n public class redisDemo &#123;\n     public static void main(String[] args) &#123;\n         Jedis jedis &#x3D; new Jedis(&quot;localhost&quot;,6379);\n         &#x2F;&#x2F;ping下，看看是否通的\n &#x2F;&#x2F;        System.out.println(&quot;Server is running: &quot; + jedis.ping());\n         &#x2F;&#x2F;String\n         jedis.set(&quot;foo&quot;, &quot;bar&quot;);\n         String value &#x3D; jedis.get(&quot;foo&quot;);\n         &#x2F;&#x2F;List，双端队列可设置为阻塞获取，可返回&#x2F;删除一个范围内的元素，可通过索引设置元素\n         jedis.lpush(&quot;mylist&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         jedis.rpush(&quot;mylist&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         List&lt;String&gt; mylist &#x3D; jedis.lrange(&quot;mylist&quot;, 0, -1);&#x2F;&#x2F;0表示第一个，-1表示最后一个\n         System.out.println(mylist);\n         &#x2F;&#x2F;Set\n         jedis.sadd(&quot;myset&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         jedis.sadd(&quot;myset2&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;);\n         Set&lt;String&gt; setdiff &#x3D; jedis.sdiff(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;差集\n         Set&lt;String&gt; setinter &#x3D; jedis.sinter(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;交集\n         Set&lt;String&gt; sunion &#x3D; jedis.sunion(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;并集\n         &#x2F;&#x2F;Hash\n         jedis.hset(&quot;myhash&quot;, &quot;a&quot;, &quot;b&quot;);\n &#x2F;&#x2F;        jedis.hincrBy(&quot;myhash&quot;, &quot;a&quot;, 1);&#x2F;&#x2F;a的值加1\n         &#x2F;&#x2F;Sorted Set\n         jedis.zadd(&quot;myzset&quot;, 1, &quot;a&quot;);\n         jedis.zadd(&quot;myzset&quot;, 2, &quot;b&quot;);\n         jedis.zadd(&quot;myzset&quot;, 3, &quot;c&quot;);\n         jedis.zlexcount(&quot;myzset&quot;, &quot;-&quot;, &quot;+&quot;);&#x2F;&#x2F;返回有序集合中指定区间内成员的数量\n         jedis.zlexcount(&quot;myzset&quot;, &quot;[b&quot;, &quot;[c&quot;);&#x2F;&#x2F;返回有序集合中指定区间(b到c)内成员的数量\n \n     &#125;\n &#125;\n\n\n底层原理\n\n全局哈希：实现从键到值的访问，具体的数据再根据值的类型不同进行不同的查找（默认使用两个全局哈希表）\n\n哈希冲突解决方法：拉链法，增加next指针，缺点是冲突越多在链上的查找越慢\nrehash：增加hash表长度，减少单个桶中的元素数量，rehash的过程包括以下三步\n给hash表2分配更大的空间\n把hash表1的数据重新映射到hash表2，会产生大量的数据拷贝，导致Redis的线程阻塞，所以使用渐进式rehash\nRedis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries\n处理请求：渐进式rehash过程中，使用两个hash表，t1和t2。针对查找操作，先在t1里面查找，如果没找到就去t2里查找；针对插入操作，一律保存到t2里，保证t1数据只减不增\n\n\n释放hash表1的空间，表1留作下一次rehash使用\n每个 hash table 都有存着一个 used 字段，每次单步 rehash 完成的时候，最后都会检查老表即  ht[0].used 是否变成了 0，变成 0 后，就说明老的哈希表里已经没有数据了，此时就会去 free 掉老表，交换老表新表的指针，rehashidx 置为 -1，然后就完成了整个 rehash\n\n\n\n\n\n\n\n压缩列表：基于压缩列表实现了List、Hash、Set、Sorted Set，节省了dictEntry数量，好多个值共用一个dictEntry\n\n类似于一个数组，不同之处是在表头有三个字段lbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束\n\n查找：查找头尾元素复杂度是O(1)，查找其它元素复杂度是O(N)\n\n\n\n节省内存：使用一系列entry保存数据，每个entry包括以下几部分，通过连续存储不使用指针连接来节省指针占用的空间\n\nprev_len，表示前一个 entry 的长度，prev_len 有两种取值情况1 字节或 5 字节\n\n取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时prev_len 取值为 1 字节，否则，就取值为 5 字节\n\n\nlen：表示自身长度，4 字节\n\nencoding：表示编码方式，1 字节\n\ncontent：保存实际数据\n\n代码（byte==B），一个存储Long类型的entry占用1+4+1+8（向上取整为16）字节\ntypedef struct zlentry &#123;\n    unsigned int prevrawlensize; &#x2F;* Bytes used to encode the previous entry len*&#x2F;\n    unsigned int prevrawlen;     &#x2F;* Previous entry len. *&#x2F;\n    unsigned int lensize;        &#x2F;* Bytes used to encode this entry type&#x2F;len.\n                                    For example strings have a 1, 2 or 5 bytes\n                                    header. Integers always use a single byte.*&#x2F;\n    unsigned int len;            &#x2F;* Bytes used to represent the actual entry.\n                                    For strings this is just the string length\n                                    while for integers it is 1, 2, 3, 4, 8 or\n                                    0 (for 4 bit immediate) depending on the\n                                    number range. *&#x2F;\n    unsigned int headersize;     &#x2F;* prevrawlensize + lensize. *&#x2F;\n    unsigned char encoding;      &#x2F;* Set to ZIP_STR_* or ZIP_INT_* depending on\n                                    the entry encoding. However for 4 bits\n                                    immediate integers this can assume a range\n                                    of values and must be range-checked. *&#x2F;\n    unsigned char *p;            &#x2F;* Pointer to the very start of the entry, that\n                                    is, this points to prev-entry-len field. *&#x2F;\n&#125; zlentry;\n\n\n二级编码技巧\n\n使用集合类型保存单值的键值对，把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value\n以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value\n\n\n\n\n跳表\n\n在链表的基础上，增加了多级索引，通过索引位置的几个跳转就可以实现数据的快速定位，查找的复杂度是O(logN)\n\n如何设计层高的：跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。\n\n示例\n\n\n时间复杂度：二叉查找树的时间复杂度是O(logn)，空间复杂度是O(n)；跳表的时间复杂度是O(log_{k}n)，k为跳表索引步长，空间复杂度是O(n)\n\n实现：\n\n\n\nString的底层实现\n\n相比于c语言的字符串\n\n拼接时会先考虑内存空间，防止内存溢出\n使用len保存了当前字符串的长度，计算长度的时间复杂度是O(1)的\n减少内存分配次数：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）\n二进制安全：C 语言中的字符串以空字符\\\\\\\\0作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题\n\n\nString 还是 Hash 存储对象数据更好\n\nString 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合\nString 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合\n在绝大部分情况，使用 String 来存储对象数据即可\n\n\nString内存占用：以key和value都为10位的整数为例，key16B、value16B、dictEntry32B，合计64B\n\n针对初始化的长度决定用多少字节的struct（支持1、2、4、8），可以减少内存的使用，数据用char buf[]存储\n\nString本身空间占用\n\nint编码：当保存的是 Long 类型整数（8B）时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了\n\nembstr编码：当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片\n\nraw编码模式：当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构\n\n\n\n\n全局哈希的dictEntry结构\n\ndictEntry结构：key指针、value指针、next指针分别为8B\n\n\nRedis的内存分配库jemalloc：分配比所需空间大的最小2次幂走位分配空间，减少分配次数，例如上面的dictEntry结构占用24字节空间\n\n\n\n\n\n\n\nzset\n\n底层实现：\n如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构；\n如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构；\n\n\n范围查询：Redis的ZSet的范围查询命令ZRANGE的时间复杂度是O(log(N)+M)，其中N是有序集合的元素数量，M是返回的元素数量。\n\n\n\n\n\n2.线程模型\n单线程机制：多线程机制会带来不必要的开销，出现并行变串行的情况；通过优化（内存上进行操作、高效的数据结构、多路复用机制）单线程提高性能\n\n阻塞点\n\n客户端：网络 IO（多路复用机制优化），键值对增删改查操作（O(N)操作会阻塞，如全量查询、聚合统计），数据库操作\n\n查询：keys * （获取所有的 key 操作）、Hgetall（返回哈希表中所有的字段和）、smembers（返回集合中所有成员）\n\n优化：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算\n\n\nbigkey删除：短时释放大量内存，删除操作需要释放内存，将空闲内存插入到空闲内存块链表，内存块过多会影响链表操作时间，从而造成Redis主线程的阻塞。bigkey删除即删除包含大量元素的集合，其不同类型常见耗时如下：\n\n优化1：从Redis4.0开始，当集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，建议使用 UNLINK 命令\n优化2：4.0之前，先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞\n\n\n\n清空数据库：如 FLUSHDB 和 FLUSHALL 操作原理同上bigkey删除\n\n优化：从Redis4.0开始，可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库\n\n\n\n\n磁盘：生成 RDB 快照（子进程），记录 AOF 日志，AOF 日志重写（子进程）\n\n记录 AOF 日志：会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是 1～2ms，如果有大量的写操作需要记录在 AOF 日志中，并同步写回的话，就会阻塞主线程\n\n\n主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件\n\n接收RDB文件：主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了 RDB 文件后，需要使用 FLUSHDB 命令清空当前数据库，这会阻塞主线程\n加载RDB文件：从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和 RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢\n优化：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载\n\n\n\n\n切片集群实例：向其他实例传输哈希槽信息，数据迁移\n\nRedsi动态扩缩容时，为保证数据一致性，迁移操作都是同步操作，当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程，一旦有bigkey且内存占用过大时，会触发集群内的故障转移，造成不必要的切换\n\n\n异步子线程机制：除了查询和加载RDB文件这两个读操作，都可以使用异步子线程机制\n\nRedis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行\n惰性删除（Redis4.0）：主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成，数据会在子线程获取任务后才开始删除（使用UNLINK而不是DEL）\nAOF日志的everysec选项：主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了\n\n\n\n\n6.0版本的多线程：为了提高网络IO读写性能，这部分时Redis的一个性能瓶颈，多线程默认是禁用的，不建议开启\n\nredis性能变慢的检测方法\n\n基于当前环境下的Redis基线性能判定Redis是否真的变慢（./redis-cli --intrinsic-latency 120    ）\n\n系统排查及应对方案\n\n自身操作特性：看日志是否有慢查询命令、看是否有key集中过期的情况（EXPIREAT、EXPIRE）、是否存在bigkey、是否在进行自动内存整理\n\n操作系统：Redis是内存数据库，操作系统的内存机制会直接影响Redis的内存效率，如swap机制、内存大页机制\n\n触发swap的原因：物理机器内存不足，Redis实例使用了大量内存、机器上其它进程进行读写操作占用内存，解决方法为，增加机器的内存或使用Redis集群\n$ redis-cli info | grep process_id\nprocess_id: 5332\n$ cd &#x2F;proc&#x2F;5332\n$cat smaps | egrep &#39;^(Swap|Size)&#39;\nSize: 584 kB #一块内存大小\nSwap: 0 kB #有多少内存被swap到磁盘上\nSize: 4 kB\nSwap: 4 kB\nSize: 462044 kB\nSwap: 462008 kB #出现几百MB时，表明Redis实例的内存压力很大，很可能变慢\n大量短连接请求：Redis处理大量短连接请求，TCP三次握手和四次挥手也会增加耗时，可以使用长连接操作Redis\n\n内存大页机制：持久化时通过写时复制机制保证继续响应请求，即使只改小部分数据也需要拷贝整个大页，影响Redis正常的访存操作，所以一般关闭内存大页机制\necho never &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled\n\n\n文件系统：Redis会持久化到磁盘，文件系统写磁盘的机制会影响Redis持久化的效率，如AOF模式不同的写回策略会导致不同的延迟（检查配置）\n\nAOF日志提供了三种日志写回策略no、everysec、always，依赖底层的系统调用write和fsync，后两种写回策略都使用了fsync，但是everysec使用了后台子线程异步完成fsync操作而always没有使用，fsync需要等写回磁盘才返回\nAOF重写会进行大量的IO操作，阻塞fsync操作（等待写完磁盘才返回），主线程虽不等待fsync操作，但是会导致主线程的下一次fsync操作被阻塞（等待上一次的fsync），从而阻塞主线程\n是否运行了 Redis 主从集群，如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞\n\n\n\n\n\n\n\n\n基于多路复用的高性能I/O模型（epoll网络框架）\n\n传统做法：阻塞IO模型\n为了处理一个 Get 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）\n其中的accept、recv操作都是潜在的阻塞点，如果发生阻塞，Redis就不能再响应其它请求\n\n\n基于多路复用的高性能I/O模型（select/epoll）\nRedis向内核注册事件和对应的事件回调函数，由内核来同时保存并监听多个套接字（FD）上的连接请求或数据请求，一旦有请求到达，通过select/epoll提供的基于事件的回调机制（不同事件的不同处理函数）来实现。select/epoll在检测到FD上有请求到达时（事件发生），就将对应事件插入到事件队列中，Redis一直在对事件队列进行处理（如调用epoll_wait函数取事件队列的数据），这样就不会阻塞在某一具体的请求上了\n\n\n\n\n事务：不支持原子性、不支持回滚、每条命令都与服务器交互，所以不推荐使用Redis的事务\n\nRedis 可以通过MULTI（开始事务），EXEC（执行事务），DISCARD（取消事务） 和 WATCH 等命令来实现事务功能\nWATCH 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行\n通过WATCH命令监听指定的 Key，当调用 EXEC命令执行事务时，如果一个被 WATCH命令监视的 Key 被 其他客户端/Session 修改的话，整个事务都不会被执行\n不过，如果 WATCH与 事务在同一个 Session 里，并且被 WATCH监视的 Key 被修改的操作发生在事务内部，这个事务是可以被执行成功\n\n\nRedis事务不支持原子性：Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）\n如果事务中使用的命令语法没问题时，可以保证原子性，所以需要严格按照 Redis 的命令规范进行程序开发，并且通过 code review 确保命令的正确性\n\n\n一致性（支持）：在命令执行错误或 Redis 发生故障的情况下，Redis 事务机制对一致性属性是有保证的\n实例发生故障时，如果有RDB则可以保证一致性；如果有AOF也可以保证一致\n\n\n隔离性（支持）\n并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证\n并发操作在 EXEC 命令后执行，此时，隔离性可以保证\n\n\n持久性：AOF的三种配置会导致数据丢失、RDB快照间隙宕机也会丢失数据\n除了不满足原子性之外，事务中的每条命令都会与 Redis 服务器进行网络交互，这是比较浪费资源的行为。明明一次批量执行多个命令就可以了，这种操作实在是看不懂。因此，Redis 事务是不建议在日常开发中使用的\n\n\n并发安全性：针对读-改-写操作，防止Redis并发写\n\n原子操作\n\n方法一：Redis每个命令是原子性的，可以通过把多个操作在 Redis 中实现成一个操作，实现单命令操作\n如：数据修改涉及读-改-写三个步骤，可以通过INCR/DECR命令可以对数据进行增值 / 减值操作\n\n\n方法二：使用Lua脚本，用于Redis没有提供原子命令的情况\n\n\n加分布式锁\n\n缺点：将低并发安全性，分布式锁的实现困难\n\n单个Redis实现分布式锁\n\n实现：赋予锁变量一个变量名，把这个变量名作为键值对的键，而锁变量的值，则是键值对的值\n\n原子操作\n\n使用SETNX命令实现加锁操作：执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何设置\n释放锁：可以在执行完业务逻辑后，使用 DEL 命令删除锁变量\n\n\n问题\n\n释放失败：给锁加一个过期时间，即使持有锁的客户端发生了异常，无法主动地释放锁，Redis 也会根据锁变量的过期时间，在锁变量过期后，把它删除\n\n加锁后被另一客户端误删再创建新锁：区分来自不同客户端的锁操作，让每个客户端给锁变量设置一个唯一值，这里的唯一值就可以用来标识当前操作的客户端\n\n优化后的实现\n# 加锁, unique_value作为客户端唯一性的标识\n# 使用了 NX 选项，SET 命令只有在键值对不存在时，才会进行设置，否则不做赋值操作\n# PX 10000 则表示 lock_key 会在 10s 后过期，以免客户端在这期间发生异常而无法释放锁\nSET lock_key unique_value NX PX 10000\n\n\n# 释放锁 比较unique_value是否相等，避免误释放，使用的Lua脚本实现的释放锁操作的伪代码\nif redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then\n    return redis.call(&quot;del&quot;,KEYS[1])\nelse\n    return 0\nend\n## 执行上面的脚本\nredis-cli  --eval  unlock.script lock_key , unique_value \n\n\n\n\n多个Redis实现分布式锁（Redlock）\n\n算法思路：让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失\n算法执行步骤\n客户端获取当前时间\n客户端按顺序依次向 N 个 Redis 实例执行加锁操作\n使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识\n客户端获取锁的总耗时没有超过锁的有效时间\n\n\n一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时\n需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况\n\n\n\n\n\n\n\n\n\n\n其它\n\n\n3.内存管理\n内存管理\n\n设置过期时间：内存有限，保存所有数据迟早会OOM\n\nRedis 中除了字符串类型有自己独有设置过期时间的命令 setex 外，其他方法都需要依靠 expire 命令来设置过期时间 。另外， persist 命令可以移除一个键的过期时间\n很多时候业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效，使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多\n\n\n如何判断数据过期（过期字典）\n\n通过过期字典（可看作hash表）来保存数据过期的时间，过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）\n过期数据的删除策略：Redis采用定期删除+惰性删除，对于漏掉的过期key使用内存淘汰机制\n惰性删除 ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。\n定期删除 ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响\n\n\n大量key集中过期的问题\n给 key 设置随机过期时间\n开启 lazy-free（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程（不建议使用）\n\n\n\n\nRedis 内存淘汰机制：干净数据直接删除，脏数据需要写回数据库\n\n不进行数据淘汰\nno-eviction：==禁止驱逐数据==，也就是说当内存不足以容纳新写入数据时，新写入操作会报错，很少用\n\n\n在设置了过期时间（EXPIRE命令）的数据中进行淘汰\nvolatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰，LRU策略的实现如下：\nRedisObject 结构来保存数据的，RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳\n并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如 10 个）的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选\n\n\nvolatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰\nvolatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰\nvolatile-lfu（4.0版 least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰\n缓存污染问题：大量不再访问的数据滞留在缓存中，影响应用的性能；所以需要在写满之前就经常淘汰数据\nLFU策略\n从两个维度筛选并淘汰数据，数据访问的时效性（访问时间离当前时间的远近）和数据的被访问次数\nLFU 缓存策略的优化：在LRU策略基础上，为每个数据增加一个计数器，来统计这个数据的访问次数。筛选时先淘汰访问次数少的，访问次数相同时再淘汰掉距离上一次访问时间更久的数据\nLFU具体实现：把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分，ldt 值（前 16bit，表示数据的访问时间戳）；counter 值（后 8bit，表示数据的访问次数）\nLFU计数规则：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1，可以减慢counter值达到255的速度\nLFU衰减机制：使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以lfu_decay_time值，所得的结果就是数据 counter 要衰减的值\n\n\n\n\n\n\n在所有数据中进行淘汰\nallkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（==这个是最常用的==）\nallkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰，适用于没有明显冷热数据的情况\nallkeys-lfu（4.0版 least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key\n\n\n\n\n内存碎片\n\n产生的原因\n\nOS的内存分配机制：默认使用jemalloc内存分配器，其按照2的幂次大小来分配内存空间，减少分配次数的情况下产生了内部碎片\nRedis的负载特征：频繁修改 Redis 中的数据，当 Redis 中的某个数据删除时，Redis 通常不会轻易释放内存给操作系统\n\n\n查看内存碎片率（&gt;1.5才需要清理）\n\n内存碎片率：mem_fragmentation_ratio = used_memory_rss / used_memory\n\nredis-cli -p 6379 info | grep mem_fragmentation_ratio\n如何清理：Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题（之前版本可以直接重启）\nconfig set activedefrag yes #启用了自动清理功能\n\n###具体清理\n# 内存碎片占用空间达到 500mb 的时候开始清理\nconfig set active-defrag-ignore-bytes 500mb\n# 内存碎片率大于 1.5 的时候开始清理\nconfig set active-defrag-threshold-lower 50\n\n###减少对Redis性能的影响\n# 内存碎片清理所占用 CPU 时间的比例不低于 20%\nconfig set active-defrag-cycle-min 20\n# 内存碎片清理所占用 CPU 时间的比例不高于 50%\nconfig set active-defrag-cycle-max 50\n\n\n缓冲区\n\n用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题，当缓冲区占用的内存超出了设定的上限阈值时，就会出现缓冲区溢出（bigkey/大RDB、处理慢、缓冲区小）\n\n客户端输入和输出缓冲区：输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端\n\n输入缓冲区溢出时\n\n发生场景：写入bigkey、服务端处理请求慢，通过CLIENT LIST命令可以查看客户端的输入缓冲区（qbuf）使用情况\n解决办法：避免客户端写入bigkey、避免Redis主线程阻塞\n\n\n输出缓冲区溢出时\n\n发生场景：返回bigkey、执行了MONITOR命令、缓冲区大小设置不合理\n\nMONITOR 命令是用来监测 Redis 执行的，执行后会持续输出监测到的各个命令操作，持续占用输出缓冲区\n\n缓冲区大小：与输入缓冲区不同输出缓冲区可以设置大小（client-output-buffer-limit）\n# normal 表示当前设置的是普通客户端，第 1 个 0 设置的是缓冲区大小限制\n# 第 2 个 0 和第 3 个 0 分别表示缓冲区持续写入量限制和持续写入时间限制\nclient-output-buffer-limit normal 0 0 0\n\n\n\n\n主从集群中的缓冲区\n\n全量复制：主节点向从节点传输RDB文件时，持续接受客户端发送的写命令请求，并保存在复制缓冲区中，主节点为每一个客户端维护一个复制缓冲区，RDB传输的慢就会导致复制缓冲区溢出，主节点会结束该连接导致全量复制失败\n建议把主节点的数据量控制在 2~4GB，这样可以让全量同步执行得更快些，避免复制缓冲区累积过多命令\n使用 client-output-buffer-limit 配置项，来设置合理的复制缓冲区大小\n控制从节点数量：主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和\n\n\n增量复制：主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区（主从同步中的repl_backlog_buffer）中，读取断连期间主节点接收到的写命令，进而进行增量同步\n环形缓冲区：一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制\n\n\n\n\n\n\n\n\n三种常用的缓存读写策略：旁路缓存、读写穿透、异步缓存\n\nCache Aside Pattern（旁路缓存）：同时维护db和cache，并且以db的结果为准\n\n读取数据流程\n\n\n写数据中的问题\n\n正确方式：先更新db，在直接删除cache\n\n问题一：在写数据的过程中，可以先删除 cache ，后更新 db 么？\n\n回答：会有数据不一致的问题，在删除cache和更新db的过程中，如果有请求从db读取，会读到旧数据\n\n\n问题二：在写数据的过程中，先更新 db，后删除 cache 就没有问题了么？\n\n在请求读取数据后，将新数据写入到缓存这个过程中，如果有请求更新db，那么读取数据的请求插入到cache中的就是旧数据\n\n\n\n\n\n旁路缓存模式的缺陷：\n\n首次请求数据一定不在cache中：提前缓存热点数据\n写操作比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率\n数据库和缓存数据强一致场景 ：更新 db 的时候同样更新 cache，不过需要加一个锁/分布式锁来保证更新 cache 的时候不存在线程安全问题\n可以短暂地允许数据库和缓存数据不一致的场景 ：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小\n\n\n保证缓存和数据库数据的一致性（更新数据库成功，但删除缓存这一步失败的情况）\n增加 cache 更新重试机制： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可\n\n\n\n\n\n\nRead/Write Through Pattern（同步直写）：将cache视为主要数据存储，cache服务负责将数据读取和写入db（很少用），对于首次请求不在cache中的问题，可以提前缓存热点数据\n\n写\n\n\n读\n\n\n\n\nWrite Behind Pattern（异步缓存写入）\n\n与读写穿透类似，都是cache负责db的读写，但是读写穿透是同步更新cache和db，而异步缓存写入更新缓存后，不直接更新db，改为异步批量的方式更新db\n开发中很少见，因为会有数据一致性的问题（没写入db就丢失），应用场景主要是消息队列中消息的异步写入磁盘、MySQL的Innodb Buffer Pool机制\n异步缓存写入下db的写性能非常高，非常适合一些数据经常变化又对数据一致性要求不高的场景，比如浏览量、点赞量\n\n\n\n\n缓存相关问题\n\n缓存雪崩\n\n缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力\n预防机制：构建Redis缓存高可靠集群，如果Redis缓存的主节点故障宕机了，可以进行主从切换\n\n\n原因一：缓存中有大量数据同时过期，导致大量请求无法得到处理\n避免给大量的数据设置相同的过期时间，在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数（例如，随机增加 1~3 分钟）\n通过服务降级，来应对缓存雪崩，即针对不同的数据采取不同的处理方式\n针对非核心数据请求，停止从缓存中查询这些数据，直接返回预定义的信息、空值或错误信息\n针对核心数据请求，仍然允许查询缓存，缓存缺失时继续通过数据库读取\n\n\n\n\n原因二：Redis缓存实例发生故障宕机，无法处理请求\n服务熔断：为了防止连锁的数据库雪崩，暂停应用对缓存系统的接口访问，会影响整个业务应用的运行\n请求限流：只允许通过一小部分请求，避免大量并发请求压力传递到数据库层\n\n\n\n\n缓存击穿\n\n请求的 key 对应的是热点数据，该数据存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期），这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了\n如：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力\n\n\n解决办法\n设置热点数据永不过期或者过期时间比较长\n针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期\n请求数据库写数据到缓存之前，先获==取互斥锁==，保证只有一个请求会落到数据库上，减少数据库的压力\n\n\n\n\n缓存穿透\n\n大量请求的 key 是不合理的，根本不存在于缓存中，也不存在于数据库中。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了\n\n业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据\n恶意攻击：专门访问数据库中没有的数据\n\n\n解决一：做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等\n\n解决二：布隆过滤器，非常方便的判断一个给定的数据是否存在于海量数据中\n\n布隆过滤器原理    \n\n首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值\n然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置\n最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作\n\n\n把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程\n\n误判：布隆过滤器说存在，则可能不存；但是说不存在则一定不存在\n\n计算哈希值，将位数组中对应下标设置为1；判断时检查位数组对应值是否是1（不同字符串可能哈希出来的位置相同）\n\n\n使用**docker redis bloomfilter**\n➜  ~ docker run -p 6379:6379 --name redis-redisbloom redislabs&#x2F;rebloom:latest\n➜  ~ docker exec -it redis-redisbloom bash\nroot@21396d02c252:&#x2F;data# redis-cli\n127.0.0.1:6379&gt;\n\n\n解决三：在请求入口的前端进行请求检测，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库\n\n\n\n\n\n\n2.高可靠1.数据持久化\nAOF\n写后日志：首先执行命令写入内存，然后再将命令记录到日志中。与传统数据库的写前（WAL）日志相比，避免了额外的检查开销，并且不会阻塞当前的命令（但会阻塞后一条命令）。但是在写入日之前宕机会丢失日志\n写回策略：控制一个写命令执行完后AOF日志写回磁盘的时机，即appendfsync配置项的三个可选值\nAlways，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；可以保证不丢失数据，但是回影响主线程性能\nEverysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘\nNo，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘，会有数据丢失的风险\n\n\nAOF重写机制：防止AOF文件过大，故障恢复时恢复过程缓慢\nRedis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入（将多个命令合并成一个命令）\nAOF使用后台子线程bgrewriteaof来完成，避免阻塞主线程：重写时fork出后台bgrewriteaof子线程，通过拷贝父进程的页表的方式共享父进程的内存数据的方式来共享父进程的数据\n写时复制：避免一次性大量拷贝给子进程造成的长时间阻塞问题，在父进程写入操作是一个已经存在的key时，父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间（否则子进程读完，父进程修改，就会丢失这一次修改的数据）\n\n\n两次日志写入：在重写过程中，新请求会先写入到原AOF文件的缓冲区中，然后写入到重写日志的缓冲区，在重写机制结束后再合并到AOF重写日志中（但是需要上面的写时复制来保证数据不会丢失修改）\n\n\n\n\nRDB\nAOF在故障恢复的时候需要逐一执行命令，恢复时间长，所以提出了RDB内存快照的方式来高效的恢复，提供了两个命令\nsave：在主线程中执行，会导致阻塞\nbgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置\n\n\n写时复制：在执行快照的同时，正常处理写操作\n由父进程fork出bgsave子进程，然后开始读取主线程的内存数据，并写入到RDB文件中，在主线程有写入请求时，这块数据会被复制一份，然后主线程在数据副本上进行修改，bgsave子进程继续将原来的数据写入RDB文件\n\n\n优化\n增量快照：一直做全量快照，虽然bgsave执行时不阻塞主线程，但是会对磁盘造成压力，而且fork操作本身也会阻塞主线程。通过记录修改的元数据信息来做增量快照，但是又会产生大量的额外空间开销\nRedis 4.0 中提出了一个混合使用 AOF 日志和内存快照：内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作\n\n\n\n\n如何选择 RDB 和 AOF？\nRDB 比 AOF 优秀的地方\nRDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会必 RDB 文件大很多。当 AOF 变得太大时，Redis 能够在后台自动重写 AOF。新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。不过， Redis 7.0 版本之前，如果在重写期间有写入命令，AOF 可能会使用大量内存，重写期间到达的所有写入命令都会写入磁盘两次。\n使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。\n\n\nAOF 比 RDB 优秀的地方\nRDB 的数据安全性不如 AOF，没有办法实时或者秒级持久化数据。生成 RDB 文件的过程是比较繁重的， 虽然 BGSAVE 子进程写入 RDB 文件的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。AOF 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，操作轻量。\nRDB 文件是以特定的二进制格式保存的，并且在 Redis 版本演进中有多个版本的 RDB，所以存在老版本的 Redis 服务不兼容新版本的 RDB 格式的问题。\nAOF 以一种易于理解和解析的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。比如，如果执行FLUSHALL命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态\n\n\n由于 RDB 和 AOF 各有优势，于是，Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差\n\n\n\n2.主从复制\n使用主从库模式，通过增加副本冗余量，将一份数据同时保存在多个实例上。主从库之间采用读写分离的方式，主库和从库同时支持读操作，写操作通过主库执行然后同步到从库\n不采用主从库读写分离：需要加锁或实例间协商的方式完成修改，带来更大的开销\n\n\n主从库模式的建立\n启动多个Redis实例时，他们相互之间通过replicaof命令形成主库和从库的关系，按照三个阶段完成第一次同步\n第一阶段：从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了\n具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID（实例的随机ID，第一次设置为？）和复制进度offset（-1表示第一次复制）两个参数\n主库收到 psync 命令后，会用 FULLRESYNC 响应命令（全量复制）带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。\n\n\n第二阶段：主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的RDB文件\n主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空\n在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作\n\n\n第三阶段：主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了\n\n\n\n\n优化\n主从级联模式分担全量复制时的主库压力：主库需要进行两个耗时操作，生成RDB文件和传输RDB文件，如果从库数量过多就会忙于fork子进程生成RDB文件，通过主-从-从模式将主库的压力分担下去，让一些从库不再和主库交互，只和级联的从库进行写操作同步，减轻主库上的压力\n基于长连接的命令传播：主从库完成全量复制后，会一直维护一个网络连接，主库通过这个连接将后续命令同步给从库\n增量复制：主从库间网络断了，2.8之前进行全量复制，2.8之后采用部分增量复制仍需全量同步，4.0版本后进行增量同步\nrepl_backlog_buffer缓冲区：repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置\n当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区\n主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距\n\n\n注意事项\n通过reolid和replid2来判断主从切换的时候，新的master和slave是否曾经属于同一个主库，如果属于可进行增量同步的尝试\nmaster同步速度必须比slave快，且不能超过环形缓冲区大小，否则还是要进行全量同步操作\nrepl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致，可以通过调整 repl_backlog_size 这个参数来避免\n一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制\n每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制\n\n\n\n\n\n\n\n3.哨兵机制\n哨兵机制：在Redis主从集群中，实现主从库自动切换的机制，有效地解决了三个问题（主库判活、从库升级为主库、新主库同步消息到从库和客户端），即监控、选主和通知三个任务\n\n监控：哨兵在运行时周期性的给所有的主从库发送PING命令，检测他们是否仍在运行，如果从库规定时间内没响应，则标记为下线状态（主观下线）；如果主库规定时间内也没有响应，则开始自动切换主库的流程（主观下线）\n客观下线：主观下线如果是误判（网络压力大、主库压力大），会产生额外的通信和计算开销，所以选择多哨兵实例的哨兵集群的方式来减少误判率\n客观下线的标准：当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”，但是这个数量标准可以通过设置来指定\n哨兵领导者：哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换\n\n\n选主：在已有从库中，通过一定的规则（筛选+打分）选择一个从库实例，将其升级为主库\n筛选\n判断从库的当前在线状态：从库仍在运行\n判断之前的网络状态：使用配置项down-after-milliseconds * 10，down-after-milliseconds是从库断连的最大连接超时时间，如果down-after-milliseconds内从库都没有连接上则认为主从节点断连，如果从库从运行到现在一共断连次数超过10次，则认为从库网络状况不好（在sentinel.conf中配置）\n\n\n打分：按照三个规则依次打分（从库优先级、从库复制进度以及从库 ID 号），只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。\n第一轮：优先级最高的从库得分高，通过 slave-priority 配置项配置\n第二轮：和旧主库同步程度最接近的从库得分高，repl_backlog_buffer缓冲区的位置，主为master_repl_offset，副为slave_repl_offset，选择复制最快的（选slave_repl_offset最大的）\n第三轮：ID 号小的从库得分高，每个实例都会有一个 ID，类似于从库的编号\n\n\n\n\n通知：在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让他们执行repliicaof命令，和新主库建立连接并进行数据复制。同时，哨兵还会把新主库的连接信息发送给客户端，让它们把请求操作发到新主库上\n通知客户端：哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端\n如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。 所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址\n\n\n\n\n哨兵集群\n\n基于 pub/sub 机制的哨兵集群组成：不同哨兵通过___sentine__:hello频道来相互发现、实现互相通信\n\n主库和哨兵：哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口\n从库和哨兵：哨兵向主库发送 INFO 命令后可以知道从库的IP地址和端口\n\n\n基于 pub/sub 机制的客户端事件通知\n\n从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件\n\n重要频道使用：客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，可以在客户端执行订阅命令（SUBSCRIBE [下面的频道]），来获取不同的事件消息\n\n\n\n\n由哪个哨兵执行主从切换\n\n任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票\n要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds\n\n\n一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的\n需要同时满足：拿到半数以上的赞成票（选举Leader），并且票数需要大于quorum值（判读客观下线）\n\n\n此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader\n如果一轮投票没选出来Leader，哨兵集群就等待一段时间（哨兵故障转移超时时间的2倍），再重新选举\n\n\n\n\n\n\n相关问题：\n\n哨兵机制能防止脑裂吗\nmaster和两个slave节点因网络问题被隔离时，所有写入到master的数据都会丢失（网络恢复后master节点会变为新master的slave）\n解决办法\nmin-replicas-to-write 1：配置写master至少写入的slave数量，0表示关闭此功能，3个节点的情况下，可以配置为1\nmin-replicas-max-lag 10：配制master多长时间无法得到从节点的响应，就认为这个节点失联，失联则停止新的写入命令请求\n\n\n\n\nRaft协议\n\n\n\n3.高可扩展1.数据分片\n\n\n\n\n\n\n\n\n开源实现：Twemproxy、Codis、Redis Cluster（推荐）\n\n单实例：使用RDB进行持久化时，fork子进程的用时与Redis数据量是正相关的，所以采用切片/分片集群，同时启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分为多份，每一份用一份实例来保存\n\nRedis在单机情况下支持多个数据库（同一个访问密码，FLUSHALL可以同时清空所有数据），每个数据库对外都是一个从0开始的递增数字命名，Redis默认支持16个数据库。并且可以随时使用SELECT命令更换数据库\n\n\nRedis Cluster：用于实现切片集群的方案，方案中规定了数据分片和实例的对应关系\n\n哈希槽：一个切片集群共有16384个哈希槽，根据键值对的key，按照CEC16算法计算一个16bit的值，然后与16384取模确定对应的哈希槽。哈希槽默认被均分到Redis实例上，也可以通过命令来配置（cluster meet、cluster addslots）\n\n为什么Redis Cluster的哈希槽是16384个：CRC16算法可以产生16位（65536），但是只用了14位（16384）\n通过bitmap来维护哈希槽信息，如果该位为1，则表示这个哈希槽属于这个节点，哈希槽长度为2048（16384/8）。哈希槽总数越少，bitmap填充率越小，压缩效果越好\n正常的心跳包会携带一个节点的完整配置，也就是说会包含当前节点负责的哈希槽的信息，如果是65536则需要8k的空间，内存占用过高\n\n\n\n\n客户端如何定位数据所在实例\n\nRedis会把自己的哈希槽发给和他相连接的其他实例，来完成哈希槽分配信息的扩散，客户端会把哈希槽信息缓存在本地\n127.0.0.1:6379&gt; cluster slots\n1) 1) (integer) 0\n   2) (integer) 4095\n   3) 1) &quot;192.168.10.3&quot;\n      2) (integer) 6379\n2) 1) (integer) 12288\n   2) (integer) 16383\n   3) 1) &quot;192.168.10.5&quot;\n      2) (integer) 6379\n变化：集群中增减Redis实例、为了负载均衡重新划分，重新划分完后实例间使用上面的方式扩散信息\n\nCLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置 Slot 要迁入的目标实例，Slot 要迁出的源实例，以及 Slot 所属的实例\n\nCLUSTER GETKEYSINSLOT：获取某个 Slot 中一定数量的 key\n\nMIGRATE：把一个 key 从源实例实际迁移到目标实例\n#假设要把 Slot 300 从源实例（ID 为 3）迁移到目标实例（ID 为 5）\n#第 1 步，我们先在目标实例 5 上执行下面的命令，将 Slot 300 的源实例设置为实例 3，表示要从实例 3 上迁入 Slot 300\nCLUSTER SETSLOT 300 IMPORTING 3\n#第 2 步，在源实例 3 上，我们把 Slot 300 的目标实例设置为 5，这表示，Slot 300 要迁出到实例 5 上，如下所示：\nCLUSTER SETSLOT 300 MIGRATING 5\n#第 3 步，从 Slot 300 中获取 100 个 key。因为 Slot 中的 key 数量可能很多，所以我们需要在客户端上多次执行下面的这条命令，分批次获得并迁移 key。\nCLUSTER GETKEYSINSLOT 300 100\n#第 4 步，我们把刚才获取的 100 个 key 中的 key1 迁移到目标实例 5 上（IP 为 192.168.10.5），同时把要迁入的数据库设置为 0 号数据库，把迁移的超时时间设置为 timeout。我们重复执行 MIGRATE 命令，把 100 个 key 都迁移完。\nMIGRATE 192.168.10.5 6379 key1 0 timeout\n#最后，我们重复执行第 3 和第 4 步，直到 Slot 中的所有 key 都迁移完成。\n\n#从 Redis 3.0.6 开始，你也可以使用 KEYS 选项，一次迁移多个 key（key1、2、3），这样可以提升迁移效率。\nMIGRATE 192.168.10.5 6379 &quot;&quot; 0 timeout KEYS key1 key2 key3\n\n\n\n\n重定向\n\n当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回MOVED命令响应结果，这个结果中就包含了新实例的访问地址\n数据迁移过程中的请求：如果不在本地，则返回ASK报错信息返回新地址，客户端给新地址发送ASKING命令在发送数据请求命令（如果不发ASKING直接请求则会报错，因为新实例上还没有管理这个槽位）\n\n\n\n\nGossip协议：Redis Cluster中的节点的通信方式，cluster.h定义了所有消息类型和消息结构\n\nGossip 协议的工作原理可以概括成两点\n\n每个实例之间会按照一定的频率，从集群中随机挑选一些实例，把 PING 消息发送给挑选出来的实例，用来检测这些实例是否在线，并交换彼此的状态信息。PING 消息中封装了发送消息的实例自身的状态信息、部分其它实例的状态信息，以及 Slot 映射表\n一个实例在接收到 PING 消息后，会给发送 PING 消息的实例，发送一个 PONG 消息。PONG 消息包含的内容和 PING 消息一样\n\n\nGossip 消息大小：clusterMsgDataGossip * 集群中实例个数 + 16384bit的Bitmap（slot信息）\ntypedef struct &#123;\n    char nodename[CLUSTER_NAMELEN];  &#x2F;&#x2F;40字节\n    uint32_t ping_sent; &#x2F;&#x2F;4字节\n    uint32_t pong_received; &#x2F;&#x2F;4字节\n    char ip[NET_IP_STR_LEN]; &#x2F;&#x2F;46字节\n    uint16_t port;  &#x2F;&#x2F;2字节\n    uint16_t cport;  &#x2F;&#x2F;2字节\n    uint16_t flags;  &#x2F;&#x2F;2字节\n    uint32_t notused1; &#x2F;&#x2F;4字节\n&#125; clusterMsgDataGossip; &#x2F;&#x2F;104字节 一个实例状态信息大小\n实例间通信频率\n\nRedis Cluster 的实例启动后，默认会每秒从本地的实例列表中随机选出 5 个实例，再从这 5 个实例中找出一个最久没有通信的实例，把 PING 消息发送给该实例。这是实例周期性发送 PING 消息的基本做法\n为了避免有实例一直没有被发送PING信息：Redis Cluster 的实例会按照每 100ms 一次的频率，扫描本地的实例列表，如果发现有实例最近一次接收 PONG 消息的时间，已经大于配置项 cluster-node-timeout 的一半了（cluster-node-timeout/2），就会立刻给该实例发送 PING 消息，更新这个实例上的集群状态信息\n\n\n\n\n\n2.负载均衡\n开源实现\n\n附录\n如何使用慢查询日志和 latency monitor 排查执行慢的操作（也可以使用监控工具latency monitor）\n\n设置参数\n\nslowlog-log-slower-than：慢查询日志对执行时间大于多少微秒的命令进行记录\nslowlog-max-len：慢查询日志最多能记录多少条命令记录（队列）\n\n\n使用SLOWLOG GET命令查看慢查询日志中记录的命令操作\nSLOWLOG GET 1\n1) 1) (integer) 33           &#x2F;&#x2F;每条日志的唯一ID编号\n   2) (integer) 1600990583   &#x2F;&#x2F;命令执行时的时间戳\n   3) (integer) 20906        &#x2F;&#x2F;命令执行的时长，单位是微秒\n   4) 1) &quot;keys&quot;               &#x2F;&#x2F;具体的执行命令和参数\n      2) &quot;abc*&quot;\n   5) &quot;127.0.0.1:54793&quot;      &#x2F;&#x2F;客户端的IP和端口号\n   6) &quot;&quot;                     &#x2F;&#x2F;客户端的名称，此处为空\n\n\nbigkey\n\n如何排查Redis的bigkey：./redis-cli  --bigkeys\n\n在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行\n\n可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能\n\n缺点：只能返回最大的那个bigkey，只统计个数不统计实际占用的内存量\n        $ .&#x2F;redis-cli  --bigkeys\n        \n        -------- summary -------\n        Sampled 32 keys in the keyspace!\n        Total key length in bytes is 184 (avg len 5.75)\n        \n        &#x2F;&#x2F;统计每种数据类型中元素个数最多的bigkey\n        Biggest   list found &#39;product1&#39; has 8 items\n        Biggest   hash found &#39;dtemp&#39; has 5 fields\n        Biggest string found &#39;page2&#39; has 28 bytes\n        Biggest stream found &#39;mqstream&#39; has 4 entries\n        Biggest    set found &#39;userid&#39; has 5 members\n        Biggest   zset found &#39;device:temperature&#39; has 6 members\n        \n        &#x2F;&#x2F;统计每种数据类型的总键值个数，占所有键值个数的比例，以及平均大小\n        4 lists with 15 items (12.50% of keys, avg size 3.75)\n        5 hashs with 14 fields (15.62% of keys, avg size 2.80)\n        10 strings with 68 bytes (31.25% of keys, avg size 6.80)\n        1 streams with 4 entries (03.12% of keys, avg size 4.00)\n        7 sets with 19 members (21.88% of keys, avg size 2.71)\n        5 zsets with 17 members (15.62% of keys, avg size 3.40)\n\n   2. bigkey如何解决\n\n      - **对大Key进行拆分：**例如将含有数万成员的一个HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围\n      - **对大Key进行清理：**将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。注意，要使用异步删除。\n        - 优化1：从Redis4.0开始，当集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，建议使用 UNLINK 命令\n        - 优化2：4.0之前，先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞\n      - **监控Redis的内存水位：**可以通过监控系统设置合理的Redis内存报警阈值进行提醒，例如Redis内存使用率超过70%、Redis的内存在1小时内增长率超过20%等\n      - **对过期数据进行定期清：**堆积大量过期数据会造成大Key的产生，例如在HASH数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。可以通过定时任务的方式对失效数据进行清理\n\n3. hotkey：\n\n   - What：使用多节点集群版的Redis时，对某个key进行读写时，会根据该key的hash计算出对应的slot，根据这个slot就能找到与之对应的分片来存取该K-V，但是在实际业务中，如商品秒杀活动可能会发生大量的请求访问同一个key，此时即使增加新的Redis实例也无法缓解，还是会落到同一台机器上，从而影响整个缓存集群的运作\n\n     - QPS集中在特定的Key：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。\n     - 带宽使用率集中在特定的Key：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的**HGETALL**操作请求。\n     - CPU使用时间占比集中在特定的Key：对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的**ZRANGE**操作请求。\n\n   - Where（热key探测）：\n\n     - 集群中每个slot的qps监控：因为热key出现的情况下，集群整体qps不大，主要因为qps分布不均\n     - proxy的代理机制作为整个流量入口统计：在使用proxy代理转发时，这个热点key的探测统计就可以放在proxy中做，在proxy中基于时间滑动窗口，对每个key进行计数，然后统计超出对应阈值的key\n     - redis基于LFU的热点key发现机制：redis 4.0以上的版本执行redis-cli时加上–hotkeys选项，可以定时在节点中使用该命令来发现对应热点key，这个命令的执行时间较长，可以设置定时执行来统计\n     - 基于Redis客户端做探测：由于redis的命令每次都是从客户端发出，基于此我们可以在redis client的一些代码处进行统计计数，每个client做基于时间滑动窗口的统计，超过一定的阈值之后上报至server，然后统一由server下发至各个client，并且配置对应的过期时间\n\n   - 如何解决\n\n     - 对特定key或slot做限流对于业务来说是有损的，所以建议只用在出现线上问题，需要止损的时候进行特定的限流\n     - 使用二级（本地）缓存：在服务端每次获取到对应热key时，使用本地缓存存储一份，等本地缓存过期后再重新请求，降低redis集群压力，可以使用guavaCache来实现（但是会出现数据不一致的情况）\n\n       &#96;&#96;&#96;java\n       &#x2F;&#x2F;本地缓存初始化以及构造\n       private static LoadingCache&lt;String, List&lt;Object&gt;&gt; configCache\n               &#x3D; CacheBuilder.newBuilder()\n               .concurrencyLevel(8)  &#x2F;&#x2F;并发读写的级别，建议设置cpu核数\n               .expireAfterWrite(10, TimeUnit.SECONDS)  &#x2F;&#x2F;写入数据后多久过期\n               .initialCapacity(10) &#x2F;&#x2F;初始化cache的容器大小\n               .maximumSize(10)&#x2F;&#x2F;cache的容器最大\n               .recordStats()\n               &#x2F;&#x2F; build方法中可以指定CacheLoader，在缓存不存在时通过CacheLoader的实现自动加载缓存\n               .build(new CacheLoader&lt;String, List&lt;Object&gt;&gt;() &#123;\n                   @Override\n                   public List&lt;Object&gt; load(String hotKey) throws Exception &#123;\n                       \n                   &#125;\n               &#125;);\n       \n       &#x2F;&#x2F;本地缓存获取\n       Object result &#x3D; configCache.get(key);\n\n\n\n\n使用配置中心实现本地缓存：长轮询+本地化的配置。首先服务启动时会初始化全部的配置，然后定时启动长轮询去查询当前服务监听的配置有没有变更，如果有变更，长轮询的请求便会立刻返回，更新本地配置；如果没有变更，对于所有的业务代码都是使用本地的内存缓存配置。这样就能保证分布式的缓存配置时效性与一致性\n在Redis集群架构中对热Key进行复制。在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力\n使用读写分离架构。如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。\n\n\n整合Spring\n\n添加依赖、新增Spring下Redis的配置文件\n# Spring节点下\nredis:\n    host: localhost # Redis服务器地址\n    database: 0 # Redis数据库索引（默认为0）\n    port: 6379 # Redis服务器连接端口\n    password: # Redis服务器连接密码（默认为空）\n    jedis: #Redis的Java客户端\n      pool:\n        max-active: 8 # 连接池最大连接数（使用负值表示没有限制）\n        max-wait: -1ms # 连接池最大阻塞等待时间（使用负值表示没有限制）\n        max-idle: 8 # 连接池中的最大空闲连接\n        min-idle: 0 # 连接池中的最小空闲连接\n    timeout: 3000ms # 连接超时时间（毫秒）\n添加RedisService和RedisServiceImpl（注入StringRedisTemplate（继承自RedisTemplate））\npublic interface RedisService &#123;\n    &#x2F;**\n     * 存储数据\n     *&#x2F;\n    void set(String key, String value);\n\n    &#x2F;**\n     * 获取数据\n     *&#x2F;\n    String get(String key);\n\n    &#x2F;**\n     * 设置超期时间\n     *&#x2F;\n    boolean expire(String key, long expire);\n\n    &#x2F;**\n     * 删除数据\n     *&#x2F;\n    void remove(String key);\n\n    &#x2F;**\n     * 自增操作\n     * @param delta 自增步长\n     *&#x2F;\n    Long increment(String key, long delta);\n\n&#125;\n\n@Service\npublic class RedisServiceImpl implements RedisService &#123;\n    @Autowired\n    private StringRedisTemplate stringRedisTemplate;\n\n    @Override\n    public void set(String key, String value) &#123;\n        stringRedisTemplate.opsForValue().set(key, value);\n    &#125;\n\n    @Override\n    public String get(String key) &#123;\n        return stringRedisTemplate.opsForValue().get(key);\n    &#125;\n\n    @Override\n    public boolean expire(String key, long expire) &#123;\n        return stringRedisTemplate.expire(key, expire, TimeUnit.SECONDS);\n    &#125;\n\n    @Override\n    public void remove(String key) &#123;\n        stringRedisTemplate.delete(key);\n    &#125;\n\n    @Override\n    public Long increment(String key, long delta) &#123;\n        return stringRedisTemplate.opsForValue().increment(key,delta);\n    &#125;\n&#125;\n在CRUD代码中，通过注入redisService，来实现缓存功能\n@Service\npublic class UmsMemberServiceImpl implements UmsMemberService &#123;\n    @Autowired\n    private RedisService redisService;\n    @Value(&quot;$&#123;redis.key.prefix.authCode&#125;&quot;)\n    private String REDIS_KEY_PREFIX_AUTH_CODE;\n    @Value(&quot;$&#123;redis.key.expire.authCode&#125;&quot;)\n    private Long AUTH_CODE_EXPIRE_SECONDS;\n\n    @Override\n    public CommonResult generateAuthCode(String telephone) &#123;\n        StringBuilder sb &#x3D; new StringBuilder();\n        Random random &#x3D; new Random();\n        for (int i &#x3D; 0; i &lt; 6; i++) &#123;\n            sb.append(random.nextInt(10));\n        &#125;\n        &#x2F;&#x2F;验证码绑定手机号并存储到redis\n        redisService.set(REDIS_KEY_PREFIX_AUTH_CODE + telephone, sb.toString());\n        redisService.expire(REDIS_KEY_PREFIX_AUTH_CODE + telephone, AUTH_CODE_EXPIRE_SECONDS);\n        return CommonResult.success(sb.toString(), &quot;获取验证码成功&quot;);\n    &#125;\n\n\n    &#x2F;&#x2F;对输入的验证码进行校验\n    @Override\n    public CommonResult verifyAuthCode(String telephone, String authCode) &#123;\n        if (StringUtils.isEmpty(authCode)) &#123;\n            return CommonResult.failed(&quot;请输入验证码&quot;);\n        &#125;\n        String realAuthCode &#x3D; redisService.get(REDIS_KEY_PREFIX_AUTH_CODE + telephone);\n        boolean result &#x3D; authCode.equals(realAuthCode);\n        if (result) &#123;\n            return CommonResult.success(null, &quot;验证码校验成功&quot;);\n        &#125; else &#123;\n            return CommonResult.failed(&quot;验证码不正确&quot;);\n        &#125;\n    &#125;\n\n&#125;\n\n\n分布式锁\n\n特点：只让一个竞争者获取锁并且解锁也只能是该竞争者（同一把锁），宕机也能自动释放（过期时间+集群部署），可重入、自动续期、自动重试\n\n幂等：一般来说，用Redis控制共享资源并且还要求数据安全要求较高的话，最终的保底方案是对业务数据做幂等控制，这样一来，即使出现多个客户端获得锁的情况也不会影响数据的一致性\n本地锁（synchronized）：只能锁定当前服务的线程，但是在锁库存的时候会出现超卖（扣减成功但是库存少减的情况）的情况\n\n\n解决方案对比\n\n\n\n分类\n方案\n实现原理\n优点\n缺点\n\n\n\nMySQL\n基于mysql 表唯一索引\n1.表增加唯一索引2.加锁：执行insert语句，若报错，则表明加锁失败3.解锁：执行delete语句\n完全利用DB现有能力，实现简单\n1.锁无超时自动失效机制，有死锁风险2.不支持锁重入，不支持阻塞等待3.操作数据库开销大，性能不高\n\n\nZookeeper\n基于ZooKeeper分布式协调系统\n1.加锁：在/lock目录下创建临时有序节点，判断创建的节点序号是否最小。若是，则表示获取到锁；否，则则watch /lock目录下序号比自身小的前一个节点2.解锁：删除节点\n1.由zk保障系统高可用2.Curator框架已原生支持系列分布式锁命令，使用简单\n需单独维护一套zk集群，维保成本高\n\n\nRedis+Lua\n基于redis Lua脚本能力\n1. 加锁：SET lock_key unique_value NX PX 10000（NX lock_key不存在时才操作；PX设置过期时间）2. 解锁：del lock_key先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除\n实现简单，相比数据库和分布式系统的实现，该方案最轻，性能最好，实现逻辑上也更严谨，除了单点问题，生产环境采用用这种方案，问题也不大。\n不支持锁重入，不支持阻塞等待\n\n\nRedission\n\n\n\n\n\n\nRedLock\n多master\n\n解决Redis单点问题和时钟漂移问题\n\n\n\n\nJava实现（Redis+Lua）\n&#x2F;&#x2F;SET key value NX EX seconds\n&#x2F;&#x2F;给每个锁设置不同的编号，在设置锁的过期时间时还要设置唯一编号，主动删除锁的时候，需要判断锁的编号是否和设置的一致，如果一致，则认为是自己设置的锁，可以进行主动删除\nBoolean lock &#x3D; redisTemplate.opsForValue().setIfAbsent(&quot;lock&quot;, &quot;123&quot;, 10, TimeUnit.SECONDS);\n&#x2F;&#x2F;其中删除锁的操作可以通过Lua脚本来执行，保证原子性\nString script &#x3D; &quot;if redis.call(&#39;get&#39;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then return redis.call(&#39;del&#39;,KEYS[1]) else return 0 end&quot;;redisTemplate.execute(new DefaultRedisScript&lt;Long&gt;(script, Long.class), Arrays.asList(&quot;lock&quot;), uuid);\n&#x2F;&#x2F;KEYS和ARGV分别是以集合方式传入的参数，对应上文的key和value\nredisTemplate.execute();\n守护线程\n\n用途：防止锁在业务没有执行完成后就释放掉了，开启一个线程来定期对这把锁进行延期操作\n业务线程挂掉了，然后守护线程一直还在更新这把锁的延期时间，会怎么样\n业务线程挂了分情况。一种是整个程序被干掉了，比如掉线了。一个情况是程序出现 bug 了，导致业务线程在执行解锁逻辑之前被干掉了，或者说业务线程死循环了、忘记解锁了这类情况，都归属于 bug\n第一种情况，程序被干掉了，那么守护线程也没了，所以不会续期了，时间到了就释放锁，这个没问题\n第二种情况，根据看门狗机制，它就是会无线续期。相当于变成了一个死锁。这是由它的工作原理决定的，无解。但是可以自己魔改一下看门狗机制，比如设定为续期 1000 次后还要续期，就有可能出问题了，那就释放锁。但是这个方案，聊胜于无。还不如设置一个较长的过期时间。\n\n\n这种情况不应该考虑怎么改进看门狗机制，而是应该考虑怎么监控它是否在正常运行。比如续期了 1000 次还在续期，就发个预警出来，人工看看啥情况，然后具体情况具体分析，是 bug 就修 bug，是正常运行就先不管。人工一介入，就没有啥不能解决的\n\n\n\n\nRedission\n\nRedission提供了使用Redis最简单和最便捷的方法，在Redis基础上实现的Java驻内存数据网格\n\nRedisson采用了基于NIO的Netty框架，不仅能作为Redis底层驱动客户端，具备提供对Redis各种组态形式的连接功能，对Redis命令能以同步发送、异步形式发送、异步流形式发送或普通形式发送的功能，LUA脚本执行处理，以及处理返回结果等\n将原生数据结构封装为Java常用的数据结构，并且提供了分布式的数据结构\nRedisson还实现了Redis文档中提到像分布式锁这样的更高阶应用场景。事实上Redisson并没有不止步于此，在分布式锁的基础上还提供了联锁（MultiLock），读写锁（ReadWriteLock），公平锁（Fair Lock），红锁（RedLock），信号量（Semaphore），可过期性信号量（PermitExpirableSemaphore）和闭锁（CountDownLatch）这些实际当中对多线程高并发应用至关重要的基本部件\n\n\n分布式可重入锁：基于Redis的Redisson分布式可重入锁RLock，实现了java.util.concurrent.locks.Lock接口，同时提供了异步、反射式和RxJava2标准的接口\n\n可重入锁是阻塞的，后面的线程加锁需要等待前面的线程\n\n如果抢占到锁的线程所在的服务宕机了，占用的锁会自动释放（看门狗机制）\n\n看门狗机制：在Redisson实例被关闭前，不断的延长锁的有效期，在宕机后有效期到了的时候，就会自动释放锁（也可以手动设置锁过期时间）\n@Configuration\npublic class MyRedissonConfig &#123;\n    &#x2F;**\n     * 对 Redisson 的使用都是通过 RedissonClient 对象\n     * @return\n     * @throws IOException\n     *&#x2F;\n    @Bean(destroyMethod&#x3D;&quot;shutdown&quot;) &#x2F;&#x2F; 服务停止后调用 shutdown 方法。\n    public RedissonClient redisson() throws IOException &#123;\n        &#x2F;&#x2F; 1.创建配置\n        Config config &#x3D; new Config();\n        &#x2F;&#x2F; 集群模式\n        &#x2F;&#x2F; config.useClusterServers().addNodeAddress(&quot;127.0.0.1:7004&quot;, &quot;127.0.0.1:7001&quot;);\n        &#x2F;&#x2F; 2.根据 Config 创建出 RedissonClient 示例。\n        config.useSingleServer().setAddress(&quot;redis:&#x2F;&#x2F;127.0.0.1:6379&quot;);\n        return Redisson.create(config);\n    &#125;\n&#125;\n\n@Autowired\nRedissonClient redissonClient;\n\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;使用&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n&#x2F;&#x2F; 1.设置分布式锁\nRLock lock &#x3D; redisson.getLock(&quot;lock&quot;);\n&#x2F;&#x2F; 2.占用锁\nlock.lock();\n&#x2F;&#x2F; 3.执行业务\n...\n&#x2F;&#x2F; 4.释放锁\nlock.unlock();\n\n\n分布式读写锁：基于 Redis 的 Redisson 分布式可重入读写锁RReadWriteLock Java对象实现了java.util.concurrent.locks.ReadWriteLock接口。其中读锁和写锁都继承了 RLock接口。其中写锁是一个排他锁（互斥锁），读锁是一个共享锁\nRReadWriteLock rwlock &#x3D; redisson.getReadWriteLock(&quot;anyRWLock&quot;);\n&#x2F;&#x2F; 最常见的使用方法\nrwlock.readLock().lock();\n&#x2F;&#x2F; 或\nrwlock.writeLock().lock();\n\n&#x2F;&#x2F; 10秒钟以后自动解锁\n&#x2F;&#x2F; 无需调用unlock方法手动解锁\nrwlock.readLock().lock(10, TimeUnit.SECONDS);\n&#x2F;&#x2F; 或\nrwlock.writeLock().lock(10, TimeUnit.SECONDS);\n\n&#x2F;&#x2F; 尝试加锁，最多等待100秒，上锁以后10秒自动解锁\nboolean res &#x3D; rwlock.readLock().tryLock(100, 10, TimeUnit.SECONDS);\n&#x2F;&#x2F; 或\nboolean res &#x3D; rwlock.writeLock().tryLock(100, 10, TimeUnit.SECONDS);\n...\nlock.unlock();\n分布式信号量：基于Redis的Redisson的分布式信号量（Semaphore）Java对象RSemaphore采用了与java.util.concurrent.Semaphore相似的接口和用法。同时还提供了异步（Async）、反射式（Reactive）和RxJava2标准的接口\n&#x2F;&#x2F; 在redis中添加park，值等于3\n&#x2F;**\n* 停车，占用停车位\n* 总共 3 个车位\n*&#x2F;\n@ResponseBody\n@RequestMapping(&quot;park&quot;)\npublic String park() throws InterruptedException &#123;\n  &#x2F;&#x2F; 获取信号量（停车场）\n  RSemaphore park &#x3D; redisson.getSemaphore(&quot;park&quot;);\n  &#x2F;&#x2F; 获取一个信号（停车位）\n  park.acquire();\n\n  return &quot;OK&quot;;\n&#125;\n\n&#x2F;**\n * 释放车位\n * 总共 3 个车位\n *&#x2F;\n@ResponseBody\n@RequestMapping(&quot;leave&quot;)\npublic String leave() throws InterruptedException &#123;\n    &#x2F;&#x2F; 获取信号量（停车场）\n    RSemaphore park &#x3D; redisson.getSemaphore(&quot;park&quot;);\n    &#x2F;&#x2F; 释放一个信号（停车位）\n    park.release();\n\n    return &quot;OK&quot;;\n&#125;\n\n\n\n\n\n分布式缓存\n\n本地缓存（HashMap或数组）\n\n优点：减少与数据库的交互，降低因磁盘I/O引起的性能问题；避免数据库的死锁问题；加速响应速度\n缺点：占用本地内存资源；机器宕机重启后缓存丢失；可能会存在数据库数据和缓存数据不一致的问题；同一台机器中的多个微服务缓存的数据不一致；集群环境下存在缓存的数据不一致的问题\n\n\n分布式缓存：使用StringRedisTemplate库（或者RedisTemplate&lt;String, Object&gt;）来操作Redis，数据库中查询的数据需要序列化成JSON字符串（JSON.toJSONString()）后再存入到Redis中，从Redis中查询数据时，也需要反序列化为对象示例（JSON.parseObject()）\npublic List&lt;TypeEntity&gt; getTypeEntityList() &#123;\n  &#x2F;&#x2F; 1.初始化 redis 组件\n  ValueOperations&lt;String, String&gt; ops &#x3D; stringRedisTemplate.opsForValue();\n  &#x2F;&#x2F; 2.从缓存中查询数据\n  String typeEntityListCache &#x3D; ops.get(&quot;typeEntityList&quot;);\n  &#x2F;&#x2F; 3.如果缓存中没有数据\n  if (StringUtils.isEmpty(typeEntityListCache)) &#123;\n    System.out.println(&quot;The cache is empty&quot;);\n    &#x2F;&#x2F; 4.从数据库中查询数据\n    List&lt;TypeEntity&gt; typeEntityListFromDb &#x3D; this.list();\n    &#x2F;&#x2F; 5.将从数据库中查询出的数据序列化 JSON 字符串\n    typeEntityListCache &#x3D; JSON.toJSONString(typeEntityListFromDb);\n    &#x2F;&#x2F; 6.将序列化后的数据存入缓存中\n    ops.set(&quot;typeEntityList&quot;, typeEntityListCache);\n    return typeEntityListFromDb;\n  &#125;\n  &#x2F;&#x2F; 7.如果缓存中有数据，则从缓存中拿出来，并反序列化为实例对象\n  List&lt;TypeEntity&gt; typeEntityList &#x3D; JSON.parseObject(typeEntityListCache, new TypeReference&lt;List&lt;TypeEntity&gt;&gt;()&#123;&#125;);\n  return typeEntityList;\n&#125;\n分布式缓存问题：见内存管理\n\n\n\n如何保证缓存与数据库一致性？代码流程是什么样子的？说一下有缓存情况下查询数据和修改数据的流程。\n\n\n","slug":"Redis","date":"2023-05-04T10:00:34.000Z","categories_index":"","tags_index":"database","author_index":"Dajunnnnnn"},{"id":"838ae74e3a76757d637de803a615bfd9","title":"MySQL","content":"MySQL1.使用1.SQL语法\n数据库概念：数据库（DB）、数据库管理系统（DBMS）、数据库系统（软件+数据库+DBA）、数据库管理员（DBA）、元祖（tuple 一行）、码（列）、候选码（唯一标识元祖）、主码（主键）、外码（另一表的主键）、主属性（候选码中的属性）、非主属性、注释（##，–，/* */）、SQL语句不区分大小写（MySQL 在 Windows 下不区分大小写，但在 Linux 下默认是区分大小写）\n\n表设计\n\nE-R图（Entity Relationship Diagram 实体+属性+联系「1:1, 1:N, M:N」）\n范式\n1NF：强调列的原子性，列不可再分\n2NF：1NF基础上，表必须有一个主键+非主键列不能部分依赖主键\n3NF：2NF基础上，非主键列必须不能传递依赖主键\nBCNF：关系模式中每一个决定因素都包含候选键，只要A能决定B，A内部就必须有主键列\n\n\n\n\n常见数据类型\n\n整数类型：（TINYINT(1)、SMALLINT(2)、MEDIUMINT(3)、INT(4)、BIGINT(8)）\n小数类型：浮点数（FLOAT、DOUBLE）、定点数（DECIMAL、NUMERIC）\n字符串类型：CHAR、VARCHAR、BLOB、TEXT\nVARCHAR：可变长度最大为65535、存储附加元信息、超出长度返回警告（CHAR直接截断）\n大部分情况都使用VARCHAR，但是其修改会导致页分裂、页空隙等问题\nVARCHAR(N)：N表示的是字符数不是字节数，比如VARCHAR(255)，可以最大可存储255个汉字，需要根据实际的宽度来选择N\nVARCHAR(N)，N&gt;5000时，使用BLOB类型\n\n\nInnoDB会将长度超过768字节的定长字段存储为变长字段，可以跨页存储。例如：CHAR(255)在utf8mb4字符集（字符编码可能超过3字节）下可能会被存储成变长字段\nCHAR会截断尾空格，VARCHAR不会，插入没有尾空格的数据时，使用=查找时有没有尾空格都可以查出数据（自动补空格），但是用like查找时查不出没有空格的\n\n\n日期类型：DATE（YYYY-MM-DD）、TIME（hh:mm:ss[.fraction]）、DATETIME（YYYY-MM-DD hh:mm:ss[.fraction]）、TIMESTAMP（从1970年开始的秒数）、YEAR（YYYY）\n不要用字符串存储日期：占用空间大、查询慢（逐个字符进行比对）、无法用日期相关的函数\n数值型时间戳：这种存储方式的具有 Timestamp 类型的所具有一些优点，并且使用它的进行日期排序以及对比等操作的效率会更高，跨系统也很方便；缺点是可读性太差，无法直观的看到具体时间\nDatetime和 Timestamp是 MySQL 提供的两种比较相似的保存时间的数据类型，通常会首选Timestamp\nDateTime 类型没有时区信息，导致服务器更换地址的时候，数据库读出的时间有错误\n\nTimestamp 类型字段的值会随着服务器时区的变化而变化，自动换算成相应的时间，在不同时区，查询同一条记录值会不一样\n# 自动初始化，并且自动更新\ncolumn1 TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATECURRENT_TIMESTAMP\n# 自动初始化\ncolumn1 TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n# 自动更新，初始化的值为0\ncolumn1 TIMESTAMP DEFAULT 0 ON UPDATE CURRENT_TIMESTAMP\n# 初始化的值为0\ncolumn1 TIMESTAMP DEFAULT 0\nTimestamp 只需要使用 4 个字节的存储空间，但是 DateTime 需要耗费 8 个字节的存储空间。但是，这样同样造成了一个问题，Timestamp 表示的时间范围更小（1970年到2037年）\n\n\n\n\n\n\n\n基础SQL语句\n\n数据定义语言（DDL）：CREATE、ALTER、DROP、USE、ADD、TRUNCATE\n操作对象：视图（VIEW）、表（TABLE）、索引（INDEX）\n修饰约束：NOT NULL、UNIQUE、PRIMARY KEY、FOREIGN KEY、CHECK、DEFULT、KEY\n\n\n数据操纵语言（DML）：INSERT、UPDATE、DELETE、SELECT\n约束：DISTINCT返回不同值、LIMIT限制返回行数、ORDER BY排序（ASC升序、DESC降序）\n子查询：子查询可以嵌入 SELECT、INSERT、UPDATE和 DELETE语句中（需要放入()中），也可以和 =、&lt;、&gt;、&lt;&gt;、&gt;=、&lt;=、IN、BETWEEN、EXISTS、LIKE（%或_）、AND、OR、NOT等运算符一起使用\n分组：group by、聚合（count，max，sum，avg忽律null行）、having用于对汇总的 group by结果进行过滤\n连接：join…on…、join…using…（列名相同）、join默认是inner join（还有left join、right join、full join、self join需命名一个表、cross join笛卡尔积）\nstraight_join 让 MySQL 使用固定的连接方式执行查询\n\n\n组合：UNION运算符将两个或更多查询的结果组合起来，并生成一个结果集，其中包含来自UNION中参与查询的提取行\n\n\n事务控制语言：COMMIT、ROLLBACK\n不能回退 SELECT语句，回退 SELECT语句也没意义；也不能回退 CREATE和 DROP语句；默认每一条语句都当成一个事务进行提交\n当出现 START TRANSACTION语句时，会关闭隐式提交；当 COMMIT或 ROLLBACK语句执行后，事务会自动关闭，重新恢复隐式提交\n通过 set autocommit=0可以取消自动提交，直到 set autocommit=1才会提交；autocommit标记是针对每个连接而不是针对服务器\n\n\n补充\n\n\n进阶SQL语句\n\nshow processlist\n\ncommand（查看连接状态）：sleep（空闲连接）、\nstate：\n\nmysql&gt; show processlist;\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------+\n| Id | User            | Host      | db   | Command | Time   | State                  | Info        |\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------+\n|  5 | event_scheduler | localhost | NULL | Daemon  | 610663 | Waiting on empty queue | NULL         |\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------+\ndelimiter\n\nexplain：并不会真的执行语句，而是通过查询优化器对语句进行分析，找出最优的查询方案，并显示对应的信息\nmysql&gt; explain select * from t where a between 10000 and 20000;\n +--+-----------+-----+----------+----+-------------+---+-------+---+----+--------+------------------+\n |id|select_type|table|partitions|type|possible_keys|key|key_len|ref|rows|filtered|Extra    |\n +----+---------+-----+----------+----+-------------+------+---------+------+-------+----------+-----------------------+\n | 1| SIMPLE    | t   | NULL     |range| a          | a | 5     | NULL | 10001 | 100.00 | Using index condition |\n\n\ntype表的访问方法\n\nsystem：这种类型要求数据库表中只有一条数据，是const类型的一个特例，一般情况下是不会出现的\nconst：通过一次索引就能找到数据，一般用于主键或唯一索引作为条件，这类扫描效率极高，速度非常快\neq_ref：常用于主键或唯一索引扫描，一般指使用主键的关联查询\nref : 常用于非主键和唯一索引扫描\nref_or_null：这种连接类型类似于ref，区别在于MySQL会额外搜索包含NULL值的行\nindex_merge：使用了索引合并优化方法，查询使用了两个以上的索引\nunique_subquery：类似于eq_ref，条件用了in子查询\nindex_subquery：区别于unique_subquery，用于非唯一索引，可以返回重复值\nrange：常用于范围查询，比如：between … and 或 In 等操作\nindex：全索引扫描\nALL：全表扫描\n\n\npossible_keys可能用到的索引，一般配合possible_keys列一起看\n\nkey实际用到的索引\n\nrowsMySQL预计要读取的行数，对InnoDB表来说是个估计值\n\nfiltered按表条件过滤后，留存的记录数的百分比，即存储引擎返回的数据在经过过滤后，剩下满足条件的记录数的比例\n\nExtra \n\nUsing filesort：表示按文件排序，一般是在指定的排序和索引排序不一致的情况才会出现。一般见于order by语句\nUsing index ：表示是否用了覆盖索引\nUsing temporary: 表示是否使用了临时表，性能特别差，需要重点优化。一般多见于group by语句，或者union语句\nUsing where : 表示使用了where条件过滤\nUsing index condition：MySQL5.6之后新增的索引下推。在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据\n\n\n\n\n通过查询 sys库的 schema_unused_indexes视图来查询哪些索引从未被使用\n\nkill\n\nkill query + 线程 id：终止这个线程中正在执行的语句\n把session的运行状态改成THD::KILL_QUERY（将变量 killed 赋值为THD::KILL_QUERY），给session的执行线程发信号\nsession语句中执行到预埋点后才可以终止语句逻辑，处于等待状态的必须是可唤醒的等待\n\n\nkill connection + 线程 id：断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的\nkill query + 线程 id失效的情况：show processlist的时候，看到Command列显示为 killed\n线程没有执行到判断线程状态的逻辑\n等行锁时使用pthread_cond_timedwait函数，虽然可被唤醒但是唤醒后的执行逻辑并没有判断线程状态\n由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态\n\n\n终止逻辑耗时较长\n超大事务执行期间被 kill：这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长\n大查询回滚：如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长\nDDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久\n\n\n直接在客户端通过 Ctrl+C 命令也无法终止：由于 MySQL 是停等协议，所以这个线程执行的语句还没有返回的时候，再往这个连接里面继续发命令也是没有用的。实际上，执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 kill query 命令\n\n\n\n\n\n\n\n\n\n2.数据库设计\n命名规范\n采用26个英文字母（区分大小写）和0-9的自然数（基本不需要）加上下划线 _ 组成，使用名词或动宾短语\n表命名：全部用小写，多个单词用下划线 _ 分隔，禁止出现数据库的关键字，一般使用复数\n列命名：在命名表的列时，不要重复表的名称\n字段命名：使用完整名称，禁止缩写，字段一般取单数\n常用缩写：sn（编号）、时间（_at，如created_at）\n\n\n外键：外键约束的作用是维护表与表之间的关系，确保数据的完整性和一致性，举例来说，某一个字段是表b的主键，但是它也是表a中的字段，表a中该字段的使用范围取决于表b\n大表如何添加索引\n不可以随便添加索引的原因：给表添加索引的时候，会对表加锁，会使得对表的增删改查失效\n先创建一张跟原表A数据结构相同的表B，在新表上添加新索引，将原表A数据导入到新表B并将更新表B名字\n\n\n如果 SQL 和索引都没问题，查询还是很慢怎么办？\n大查询改造为分批查询\n数据库分表，降低数据库表的数量\n引入redis缓存 ，减少 mysql 的访问\n\n\n分页\n如果查询出来的结果集，存在连续且递增的字段，可以基于有序字段来进行查询，例如 select xxx from book where 有序字段 &gt;= 1 limit 100\n舍弃limit关键字，如果查询出来的结果集存在连续且递增的字段，使用between and来进行范围结果集查询，例如 select xxx from book where 有序字段 between 10000000 and 1000100\n采用MongoDB、ES搜索引擎优化深分页\n\n\n生成主键的策略\n自增主键\n雪花算法\nUUID 虽然也可以保证唯一性，但是 UUID 的值是随机的，无序的，不太适合作为主键，因为随机插入，可能会引起页分裂的问题，从而影响查询性能。\n\n\n如何排查慢sql\n如果是在项目中，可以通过SpringAOP去查询这个接口运行的时间\n如果是一个sql，可以通过explain的指令去查这个sql的执行计划\n可通过开启mysql的慢日志查询，设置好时间阈值，进行捕获\n\n\n编写查询语句时，考虑性能至关重要，因为良好的查询性能可以显著提高数据库应用程序的响应速度。以下是一些应该考虑的方面，以确保查询的性能最佳化：\n选择合适的列：仅选择你实际需要的列，而不是选择整个表的所有列。这可以减少数据传输和内存占用。\n使用索引：确保查询中的列上有适当的索引（加快查询）、避免在索引列上使用函数（可能导致索引失效）\n避免使用通配符：尽量避免在查询中使用通配符（例如%，_），因为它们可能导致全表扫描，性能下降\n使用JOIN优化：合理使用JOIN语句，确保连接的列有索引，并且选择适当的JOIN类型（INNER JOIN、LEFT JOIN等）以减少数据集的大小\n限制结果集大小：使用LIMIT或TOP来限制结果集的大小，特别是在分页查询中\n使用合适的数据类型：使用最合适的数据类型来存储数据，避免使用过大或不必要的数据类型，以减少存储和检索的开销\n分析执行计划：使用数据库管理工具分析查询的执行计划，确保查询正在以最有效的方式执行\n避免子查询：尽量避免使用嵌套子查询，因为它们可能导致性能下降。在某些情况下，可以用联接来替代子查询\n避免过度规范化：在设计数据库时，避免过度规范化，因为它可能导致复杂的JOIN操作，影响性能\n\n\n\n3.使用规范\n建表规范示例\nCREATE TABLE &#96;student_info&#96; (    \n&#96;id&#96; int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,    \n&#96;stu_name&#96; varchar(10) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;姓名&#39;,    \n&#96;stu_score&#96; smallint(5) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;总分&#39;,    \n&#96;stu_num&#96; int(11) NOT NULL COMMENT &#39;学号&#39;,    \n&#96;gmt_create&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,    \n&#96;gmt_modified&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;更新时间&#39;,    \n&#96;status&#96; tinyint(4) DEFAULT &#39;1&#39; COMMENT &#39;1代表记录有效，0代表记录无效&#39;,      \nPRIMARY KEY (&#96;id&#96;),      \nUNIQUE KEY &#96;uk_student_info_stu_num&#96; (&#96;stu_num&#96;) USING BTREE,    \nKEY &#96;idx_student_info_stu_name&#96; (&#96;stu_name&#96;) USING BTREE\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COMMENT&#x3D;&#39;学生信息表&#39;;\nMySQL单表数据量最大不要超过多少行\n\n主键的大小可以限制表的上限\n\n如果主键声明为int大小（32位），那么能支持2^32-1，也就是21个亿左右\n如果是bigint（64位），那就是2^64-1，太大了，磁盘会先出问题\n如果是tinyint（8位），那最大就是2^8-1，也就是255，插入id=256的数据就会报错\n\n\n索引的结构（B+树）\n\nA表中的数据会存放在A.idb文件（表空间）中，表中的若干行数据在A.idb中会被分成很多小份的数据页，每份大小是16k（页头120B+行数据和页目录+页尾8B），页内通过页目录和二分查找的方式进行\n\nB+树索引：通过记录每个数据页的最小id和数据页页号，组成了B+树的叶子节点和非叶子节点，假设非叶子节点指向内存页的指针数量为x，叶子节点能容纳的记录数量为y，B+树的层数为z，这颗B+树的行数据总量等于(x ^ (z-1)) * y\n\nx的计算：主键bigint（8B）、页号（FIL_PAGE_OFFSET）4B、页头加页尾（128B）加上页目录假设不到1K，其余15K除以12B（8+4）等于1280页\ny的计算：假设真正的行数据是1K，则一页可以存放15行（15KB/1KB）\n行总数的计算：两层时（z=2）有2W行数据，三层时（z=3）有2.5KW行数据，即单表建议最大行数2kw的由来\n\n\n例外：如果单行数据不是1K，则可以存放更多的数据\n\n\n\nB树将行数据都存在非叶子节点上，假设每个数据页还是16kb，掐头去尾每页剩15kb，并且一条数据表行数据还是占1kb，就算不考虑各种页指针的情况下，也只能放个15条数据。数据页扇出明显变少了\n\n\n\n\n\n2.基础知识1.基础架构\n\n\n\n\n\n\n\n\n客户端+server层+存储引擎，其中server层包括五部分，连接器（身份权限验证）、查询缓存（键值对，易失效，8.0移除）、分析器（词法分析+语法分析，返回出错位置）、优化器（选择索引，按照最优方案执行）、执行器（检验表权限，操作引擎，返回结果）\n\n查询语句执行流程；客户端验证登陆并通过TCP三次握手==连接==服务端，提交的执行语句经过分析器进行词法分析和语法分析通过后，提交给优化器来生成最优的执行方案，最后交给引擎来具体执行\n\n查询缓存不命中的情况    \n任何两个查询在任何字符上的不同都会导致缓存不命中\n如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL 库中的系统表，其查询结果也不会被缓存\n表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效\n\n\n客户端长时间（wait_timeout）没有命令时，连接器会自动断开\n数据传输（net_buffer）：服务端不保存一个完整的结果集，而是将取到的每一行写入net_buffer中，写满就发送然后清空；如果发送函数返回EAGAIN或WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送\nMySQL 客户端发送请求后，接收服务端返回结果的方式有两种，默认使用第一种，加上-quick后使用第二种\n一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果用 API 开发，对应的就是 mysql_store_result 方法\n另一种是不缓存，读一个处理一个。如果用 API 开发，对应的就是 mysql_use_result 方法\n\n\n对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，建议使用mysql_store_result这个接口，直接把查询结果保存到本地内存，否则使用mysql_use_result接口\n\n\n\n\n更新语句执行流程：查询缓存，调用引擎API写入数据，InnoDB通过==两阶段提交==记录日志，流程为redo log（prepare）-&gt;binlog-&gt;redo log（commit）\n\n异常时：有prepare，但没有binlog，则回滚事务；由prepare、binlog，但没有commit，则提交事务恢复数据\n非两阶段提交：先写redo log然后宕机，虽然可以通过redo log恢复数据，但是通过binlog备份的时候会丢失数据；先写binlog然后宕机，本地无法通过redo log恢复数据，通过binlog备份时会多出一条事务\nchange buffer：当有更新操作，如果数据页在内存中，则直接更新数据页；如果数据页不在内存中，则会将更新操作先缓存在change buffer中。在后续数据页读入到内存中时执行merger操作，即将change buffer内的更改同步到数据页\n使用场景：适用于普通索引，但唯一索引需要每次都取数据确定唯一性；适用于写多读少的情况（merge操作少）\nchange buffer和redo log：redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗\n\n\n\n\n存储引擎对比\n\nMyISAM 不支持==事务==（MVCC+Next-Key Lock区间锁）和==行级锁==，而且最大的缺陷就是崩溃后无法安全恢复（只有binlog无==redo log==）\n\nMemory引擎：主要用于内存临时表的场景（没有并发问题、不许持久化数据、主备库之间不冲突）\n\n索引组织形式\n\nInnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，称为索引组织表（Index Organizied Table），整体结构为B+树，数据有序存放，数据位置变化时只需要改主键索引，查找需要回表\nMemory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，称为堆组织表（Heap Organizied Table），整体结构为hash表，数据按写入顺序存放，数据位置变化时需要改所有索引\n使用b树索引：alter table t1 add index a_btree_index using btree (id);\n\n\nInnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同\n\n生产环境不使用内存表的原因：内存表不支持行锁，只支持表锁；数据库重启后，所有内存表都会被清空\n\n\n\n存储引擎所支持的索引概述\n\n\n\n\n文件目录结构\n\n每创建一个database，都会在/var/lib/mysql目录下创建一个以数据库名字为名的目录，然后保存表结构和表数据的文件都放在这个目录下，名为my_test的数据库下有一个名为t_order的表\n\n\n数据库名（my_test）目录下的具体文件（以t_order表为例）\n\n\ndb.out：用来存储当前数据库的默认字符集和字符校验规则\nt_order.frm：t_order的表结构会保存在这个文件，MySQL中建立的每一张表都会生成一个.frm文件，用来保存表的元数据信息，如表结构定义\nt_order.ibd：t_order的表数据会保存在这个文件中，表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。由参数 innodb_file_per_table 控制的，5.6.6之后默认是1，即存放在独占表空间文件（文件名：表名字.ibd）中\n\n\n\n\nInnoDB 它如果是存储一张表的话它是怎么去存储的（应为双向链表）\n\n\n\n2.日志\nredo log\n\n定义：InnoDB特有的，组织成大小为4*1GB（文件组）的一个环形缓冲区，使用两个指针记录位置，write pos（下一次写入位置）+ check point（等待擦除的位置），满了之后就阻塞等待，主要用于MySQL崩溃（实例挂了/宕机）后的恢复\nredo log buffer：查询和删除都是直接操作Buffer Pool中的数据页，更新时记录到redo log buffer中，然后刷盘到redo log\n记录条目：“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”\n刷盘时机：innodb_flush_log_at_trx_commit 参数确定何时刷新、一个后台定时线程每秒刷新、redo log buffer占用的空间即将达到 innodb_log_buffer_size一半时刷新\n\n\n写入流程：\n\n\nbinlog\n\n定义：server层的通用模块，与redo log记录物理日志（在哪个数据页上做了什么）不同，binlog记录逻辑日志，即语句的原始逻辑（在哪个表上做了什么），并且不会覆盖已有日志，直接写入新文件。主要用于数据备份和主从数据同步\n格式；statement（SQL语句原文）、row（SQL语句+数据）、mixed（MySQL选择用哪一个）\n\n\nbinlog cache：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。通过binlog_cache_size确定空间大小，一个事务的binlog不能被拆开，空间不够时需要暂存到磁盘上\n数据先write到文件系统的page cache，再fsync到磁盘，由参数sync_binlog控制write和fsync的时机\n\n\n为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中\n\n\nundo log\n\n用途：用于事务执行异常时进行回滚、提供MVCC机制需要的历史版本数据\n回滚日志先于数据持久化到磁盘上，在事务执行中宕机也可以回滚已执行的一半事务\n\n\n确保事务的原子性，用于回滚事务，同时提供mvcc下的非锁定读\n\n\n慢查询日志\n\n记录了执行时间超过long_query_time（默认10s，通常设置为1s）的所有查询语句，在解决SQL慢查询的时候经常用到\n命令：开启（SET GLOBAL slow slow_query_log=ON）、查看状态（show variables like “slow_query_log”; ）\n\n\n中转日志（relay log）：用于主从复制场景下，slave通过io线程拷贝master的bin log后本地生成的日志\n\n提交事务的一整个过程，每个日志都是怎么工作的？具体更新一条记录 UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1; 的流程如下:\n\n执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：\n\n\n如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；\n如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。\n\n\n\n\n执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：\n如果一样的话就不进行后续更新流程；\n如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；\n\n\n开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。\nInnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。\n至此，一条记录更新完了。\n在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。\n事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：\nprepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；\ncommit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；\n\n\n至此，一条更新语句执行完成\n\n\n\n3.锁\n全局锁：Flush tables with read lock;，主要用于做主库逻辑备份，其它全库备份方法如下\nmysqldump+–single-transaction：在一致性读隔离级别开启一个事务，来确保拿到一致性视图，通过MVCC来保证数据可正常更新，需要引擎支持一致性读级别（InnoDB支持MyISAM不支持）\nset global readonly=true：可以让全库进入只读状态，但一方面readonly会有其他用处这样改有副作用，另一方面数据库异常后不自动改此值，导致数据库一直不可写（全局锁自动释放）\n\n\n表级锁（MyISAM、InnoDB）：针对非索引字段加锁，对当前操作的整张表加锁，实现简单，资源消耗少，不会出现死锁，但是高并发下效率低\n表锁：lock tables t1 read, t2 write;\n可以使用unlock tables主动释放锁，也可以在客户端断开的时候自动释放，所以建议把可能影响并发度的锁尽量往后放\nlock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象，比如线程A执行上面的示例语句，线程B写t1、读写t2都会被阻塞；线程A解锁前也只能读t1、读写t2\n意向锁：用表锁的时候快速判断表中的记录是否有行锁，意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁（意向共享锁、意向排他锁）\n\n\n元数据锁（MDL）：MDL 不需要显式使用，在访问一个表的时候会被自动加上，语句执行开始时申请，但是在整个事务提交后才释放（可以通过加超时机制防止阻塞太多后续命令）\n在MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁\n读锁之间不互斥，因此可以有多个线程同时对一张表增删改查；读写锁之间、写锁之间是互斥的，因此两个线程同时给一个表加字段，其中一个要等另一个执行完才能开始执行\n\n\n\n\n行级锁（InnoDB）：针对索引字段进行加锁，只针对当前操作的行记录进行加锁，锁粒度小、并发度高、锁开销大，会出现死锁SELECT * FROM your_table WHERE some_condition FOR UPDATE;\n\n\n两阶段锁：行锁是在需要的时候加上去的，但是要等事务结束时才释放\n行锁是针对索引字段加的锁，如果where语句中字段没有命中唯一索引或者索引失效时，会导致扫描全表，对表中的所有行记录加锁，但有的时候即使用了索引，也会全表扫描（优化器的原因）\nInnoDB有哪几类行锁：REPEATABLE-READ隔离级别下，默认使用Next-Key Lock，操作的索引是唯一索引或主键时，优化降级为Record Lock\n记录锁（Record Lock） ：也被称为记录锁，属于单个行记录上的锁\n间隙锁（Gap Lock） ：锁定一个范围，不包括记录本身。跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作，两个间隙锁之间不存在冲突关系\n两个线程都拿到了同一间隙锁，然后在执行插入时等待对方的间隙锁，这就导致了同样的语句因为间隙锁的存在会锁住更大的范围而产生死锁\n\n\n临键锁（Next-Key Lock） ：Record Lock+Gap Lock，锁定一个范围，包含记录本身，主要目的是为了解决幻读问题。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁\n每个 next-key lock 是前开后闭区间，对于正无穷使用了一个不存在的最大值 supremum 代替（保证闭区间）\n\n\n\n\n\n\n\n4.事务\n基础概念\n\nACID属性：Atomic、Consistency、Isolation、Durability（AID是手段，C是目的）\n原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样\n事务的原子性是通过 undo log 实现的，undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。\n每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。\n\n\n一致性（Consistency）：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如转账的情况\n隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的\n持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失\n通过 redo log 保证持久化。buffer pool 中有 undo 页，对 undo 页的修改也都会记录到 redo log。redo log 会每秒刷盘，提交事务时也会刷盘，数据页和 undo 页都是靠这个机制保证持久化的。\n通过两次写来实现，当缓冲池的脏页刷新时，并不直接写磁盘，而是会通过memcpy函数将脏页先拷贝到内存中的doublewrite buffer，之后通过doublewrite buffer再分两次，每次写入1MB到共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，进行数据持久化。\nWAL （Write-Ahead Logging）技术：InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里\n\n\n\n\n并发带来的问题：脏读（读后被回滚）、丢失修改（写后被覆盖）、不可重复读（两次读结果不同）、幻读（第二次读到的行数多了）\n脏读：如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。\n不可重复读：在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。\n幻读：在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。\n解决幻读的方法：提升事务隔离级别到可序列化、可重复读级别下添加表锁或添加Next-key Lock（记录锁+间隙锁）、隔离级别降到读提交并将binlog改成row格式（记录更改前后数据）\n\n\n\n\n\n\nMVCC\n\n原理：实现依赖==隐藏字段==、==Read View==、==undo log==。在内部实现中，InnoDB 通过数据行的DB_TRX_ID（事务id）和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改\nMySQL 中每条记录在更新的时候都会同时记录一条回滚操作（在回滚日志中，在没有比该条日志更旧的read-view后自动删除），记录上的最新值，通过回滚操作，都可以得到前一个状态的值\nMVCC解决部分幻读：MVCC只能解决读取数据是的幻读（当前事务读取时，不受其他事务修改的影响），但是不能解决写入时的幻读（需要MVCC+锁、或者可串行化事务隔离级别）\n与间隙锁的对比：间隙锁锁定索引范围而非实际数据的锁，MVCC与间隙锁的目的都是保证数据库的并发访问安全性，但是MVCC的优势是没有用到锁，性能比间隙锁更好\n\n\n相关字段\nInnoDB为每一行添加了三个隐藏字段\n\n\nDB_TRX_ID（6字节）：表示最后一次插入或更新该行的事务 id\nDB_ROLL_PTR（7字节）回滚指针，指向该行的 undo log\nDB_ROW_ID（6字节）：如果没有设置主键且该表没有唯一非空索引时，InnoDB 会使用该 id 来生成聚簇索引\n\n\nRead View：用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”\n\n\nm_low_limit_id：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见\nm_up_limit_id：活跃事务列表 m_ids 中最小的事务 ID，如果 m_ids 为空，则 m_up_limit_id 为 m_low_limit_id。小于这个 ID 的数据版本均可见\nm_ids：Read View 创建时其他未提交的活跃事务 ID 列表。创建 Read View时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。m_ids 不包括当前事务自己和已提交的事务（正在内存中）\nm_creator_trx_id：创建该 Read View 的事务 ID\n\n\nundo-log：事务回滚时恢复数据，分为两类\n\ninsert undo log：指在 insert操作中产生的 undo log。因为 insert操作的记录只对事务本身可见，对其他事务不可见，故该 undo log可以在事务提交后直接删除。不需要进行 purge操作\nupdate undo log：update或 delete操作中产生的 undo log。该 undo log可能需要提供 MVCC机制，因此不能在事务提交时就进行删除。提交时放入 undo log链表，等待 purge线程进行最后的删除\n\n\n\n\n底层实现（未完待续）：数据可达性算法\n\n\n事务隔离机制：读未提交、读已提交、可重复读（默认级别）、可序列化\nSET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL [READ UNCOMMITTED|READ COMMITTED|REPEATABLE READ|SERIALIZABLE]\n\n\n避免长事务的方式：通过information_schema.innodb_trx表监控事务的持续时间、增加undo表空间、通过配置参数max_execution_time指定事务执行的最长时间、利用pt工具监控长事务\n\n可重复读\n\n定义：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的\n快照生成\n生成时机：在 MySQL 有两种开启事务的命令，这两种开启事务的命令，创建 read view 的时机是不同的\nbegin/start transaction 命令：执行了 begin/start transaction 命令后，并不会创建 read view，只有在第一次执行 select 语句后， 才会创建 read view\nstart transaction with consistent snapshot 命令：执行了 start transaction with consistent snapshot 命令，就会马上创建 read view\n\n\n执行两个select语句，会生成几个快照：1个\n\n\n同一个事务的所有更新操作，都是可见的。事务隔离性，隔离的是其他事务，不隔离自己人\n\n\n可重复读与幻读\n\n标准的SQL隔离级别定义里，可重复读是不可以防止幻读的，但是InnoDB实现的可重复读隔离级别可以解决幻读问题\n快照读（一致性非锁定读）：由MVCC机制保证不出现幻读\nRR/RC级别select默认是快照读（RC级别读锁定行最新快照数据，RR级别读事务开始的数据）、读取到的行正在执行update或delete则不等待锁释放直接读取快照\n\n\n当前读（锁定读）：由Next-Key Lock加锁来防止幻读\nselect加锁（lock in share mode共享锁、for update排他锁）是当前读、update、insert、delete\nRR级别：扫描到的数据都会加行锁和间隙锁，并在commit时释放\nRC级别：扫描到的数据都会加行锁，但不满足条件的数据，不需等到commit，扫描完就释放\n\n\n\n\n可重复读和读提交有什么区别\n\n读提交，指一个事务提交之后，它做的变更才能被其他事务看到\n可重复读，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别\n对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 MVCC 来实现的，它们的区别在于创建 Read View 的时机不同，「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View\n\n\nMVCC解决幻读问题\n\nMySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种：\n\n针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。\n针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。\n\n\n这两个解决方案是很大程度上解决了幻读现象，但是还是有个别的情况造成的幻读现象是无法解决的。比如这个场景：在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id = 5 的记录并提交。接着，事务 A 对 id = 5 这条记录进行了更新操作，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。\n\n\n\n\n\n\n\n5.索引\n\n\n\n\n\n\n\n\n\n按「数据结构」分类：B+tree索引、Hash索引、Full-text索引\n按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）\n按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引\n按「字段个数」分类：单列索引、联合索引\n\n\nB+树：索引的底层数据结构，InnoDB中每个节点使用一个页（page），页的大小为16KB，元数据占128字节，一条记录大约16字节，对于非叶节点，可以存1000条记录，对于叶节点，假设可以存100条数据，综上，对于一颗3层B+树，可以存储1亿条记录，充分利用局部性原理减少IO次数\n其它索引结构：Hash索引不支持顺序和范围查询、二叉查找树容易不平衡、平衡二叉树由于旋转耗时，删树数据时效率很低、红黑树效率高但是高度太高增加IO次数、B树节点过大增加IO次数、\nB树（B-树）和B+树的区别：B+树非叶子不存数据、叶子节点有一条引用链指向其它相邻叶子节点所以可直接对链表进行遍历、B+树查到叶子才返回数据可在非叶子节点中重复出现\nHash索引和B+树索引的区别：B+树可以进行范围查询、B+树支持联合索引的最左匹配原则、B+树支持order by排序、B+树支持like进行模糊查询；但Hash索引在等值查询上比B+树高效\n范围查询：比如要查主键在[1,17]之间的记录。二次查询，先查找1所在的叶子节点的记录位置，再查找17所在的叶子节点记录的位置（就是16所处的位置），然后顺序地从1遍历链表直到16所在的位置\n前缀匹配模糊查询。假设主键是一个字符串类型，要查询where Key like abc%，其实可以转化成一个范围查询Key in [abc,abcz]。当然，如果是后缀匹配模糊查询，或者诸如where Key like %abc%这样的中间匹配，则没有办法转化成范围查询，只能挨个遍历\nHash索引缺点：容易导致全表扫描，因为可能存在不同的key经过hash运算后值相同；索引列上的值相同的话，易造成hash冲突，效率低下\n\n\nMyISAM和InnoDB引擎对B+树的不同实现\nMyISAM中，叶子节点的data域存放的是数据记录的地址，需要通过改地址读取对应的数据记录\nInnoDB中，索引文件和数据文件是分离的，数据文件是以主键为索引的key形成的树，叶子节点保存了完整的数据，其他的索引的叶子节点存储的是主键的值。所以通过主键查找直接能找到数据，通过其他索引只能找到对应主键，然后再根据主键去数据文件找。所以建议使用单调的字段作为主键，防止造成主索引频繁分裂（B+树的插入机制）\n索引结构和数据一起存放的索引称为聚簇索引，如InnoDB的主键索引；索引结构和数据分开存放的索引称为非聚簇索引，如InnoDB的辅助索引\n\n\n索引维护\n逻辑删除：如果数据出了问题，还是有迹可循（这里是存疑的，因为可以通过Binlog找到操作记录，甚至是数据恢复）\n页分裂\n定义：如果当前数据页写满后，会申请新的数据页用于数据写入，然后挪动部分数据到新的数据页\n页分裂方式：InnoDB会根据数据的插入情况进行分裂，具体在数据页的page header中记录相关信息\n如果监控到每次都是离散的插入，则分裂的时候直接从中间进行分裂\n如果是朝着相同方向连续插入若干数据，可能会从插入点分裂或者是插入点之后的几条记录处分裂\n\n\n\n\n页合并\n当相邻两个页由于删除了数据利用率很低以后（默认50%以下），会将数据页之间进行合并\n数据删除仅作逻辑删除，非物理删除，因此页合并存在数据的重新覆写，效率会慢一些\n\n\n\n\n\n\n主键索引（聚簇索引，clustered index）和非主键索引（二级索引，secondary index）\n主键索引：加速查询 + 列值唯一（不可以有 NULL）+ 表中只有一个，查询速度快但更新代价大，所以一般都是不可修改的，每个表只能有一个主键\n聚簇索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里d\n当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在 null 值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键\n建表语句里一定要有自增主键，只有在类似于哈希表的数据表中才会使用业务字段直接锁主键\n重建主键索引的方法：直接删除重建会使得所有非主键索引都失效，推荐方法为用空的alter操作，比如ALTER TABLE t1 ENGINE = InnoDB;这样子就会原地重建表结构\n为什么自增主键不会覆盖已删除数据的ID\n因为是逻辑删除，虽然数据看似删除，实际只是逻辑删除，所以插入的数据不会覆盖原来删除的主键值，而是不断递增\n另外，自增主键的自增是需要加锁的，只需要对最新的主键加锁就好，如果要维护一个已经删除的ID表，那么就需要维护多个指针的锁，严重影响性能\n\n\n使用：\n优势：插入数据，递增主键，属于追加操作，不涉及挪动其他记录，不触发叶子节点的分裂即调整；主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。非主键索引的叶子节点用自增主键可能空间小；\n主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间就越小\n\n\n\n\n\n非主键索引（二级索引）：叶子节点存储的数据是主键，需要根据主键去主键索引在搜索一次（回表），更新代价小但需要回表\n唯一索引：加速查询 + 列值唯一（可以有 NULL），主要为了保证属性列的数据的唯一性\n普通索引：仅加速查询，允许重复、允许为NULL、允许创建多个\n前缀索引(Prefix)：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符（alter table SUser add index index2(email(6));）\n倒序索引：select field_list from t where id_card = reverse(&#39;input_id_card_string&#39;);\n前缀索引对覆盖索引的影响：使用前缀索引就用不上覆盖索引对查询性能的优化了，因为无法确定前缀索引是否截断了完整信息\n\n\n全文索引：对文本的内容进行分词，进行搜索。目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。一般不会使用，效率较低，通常使用搜索引擎如 ElasticSearch 代替\n\n\n为什么不推荐使用外键和级联（主键改外键需要跟着改）：不适用高并发、分库分表不友好、增加复杂性（外键约束、业务变化）\n外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度\n增加了复杂性：\n每次做 DELETE 或者 UPDATE 都必须考虑外键约束，会导致开发的时候很痛苦, 测试数据极为不方便;\n外键的主从关系是定的，假如那天需求有变化，数据库中的这个字段根本不需要和其他表有关联的话就会增加很多麻烦\n\n\n对分库分表不友好：因为分库分表下外键是无法生效的\n\n\n\n\n联合索引及相关优化：覆盖索引、最左前缀匹配原则、索引下推\n联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并，实现为ALTER TABLE cus_order ADD INDEX id_score_name(score, name);\n覆盖索引：一个索引叶子节点数据包含（或者说覆盖）所有需要查询的字段的值，可以不用二次查询，比如在非主键索引查记录的主键可以不用回表\n最左前缀匹配原则：在使用联合索引时，MySQL会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到范围查询（如**&gt;、&lt;**）才会停止匹配。所以在使用联合索引时，可以将区分度高的字段放在最左边，这样可以过滤掉更多数据\n索引下推：MySQL 5.6 版本中提供的一项索引优化功能，可以在索引遍历过程中，对索引中包含的字段（联合索引）先做判断，过滤掉不符合条件的记录，减少回表次数\n\n\n非主键索引默认与主键建立联合索引，可以减少需要的联合索引个数\n\n\n聚集索引和非聚集索引的区别？非聚集索引一定回表查询吗?\n\n3.进阶知识1.索引选择\n\n\n\n\n\n\n\n\n选择合适的字段创建索引（不为NULL、被频繁查询、被作为条件查询、频繁需要排序的、频繁用于连接的）；频繁用于更新的字段不适合建立索引，维护索引的成本很高；索引数量不能过多，避免冗余索引；不适合建立索引（数据量少、更新频繁、区分度低、已经有联合索引、用不到的字段）\n\n索引选择：\n\n指标\n\n预估扫描行数：show index的cardinality列反应的是索引的基数（索引上不同值个数），通过使用采样统计选择M个数据页，统计每个页面上不同值个数，然后求求平均再乘索引的页面数得到索引的基数（变更的数据行超过1/M时重新统计）\n\nanalyze table tableName;：当索引的统计信息不对时，可以用来重新统计索引信息\n\nMySQL有两种存储索引统计的方式通过设置参数 innodb_stats_persistent 的值来选择：\n\n设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10\n设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16\n\n\n\n\n是否需要回表：选择不需要回表的作为索引\n\n是否需要再次排序：选择已排序列为索引\n\n\n\n引导优化器选择索引的方法\n\n采用 force index 强行选择一个索引：select * from t force index(a) where a between 10000 and 20000;\n修改语句，引导 MySQL 使用我们期望的索引：在保证业务正确的前提下，进行一些优化：如order by b limit 1 改为 order by b,a limit 1，可以使其使用a为索引\n新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引\n\n\n通过查询sys库的schema_unused_indexes视图来查询哪些索引从未被使用\n\n\n示例\n\n问题：index(abc)\nselect * from T where a=x and b=y and c=z\nselect * from T where a=x and b&gt;y and c=z\nselect * from T where c=z and a=x and b=y\nselect (a,b) from T where a=x and b&gt;y\nselect count(*) from T where a=x\nselect count(*) from T where b=y\nselect count(*) form T\n\n\n索引选择：\na、b、c三个字段都可以走联合索引\na和b都会走联合索引，但是由于最左匹配原则， 范围查找后面的字段是无法走联合索引的，但是在 mysql 5.6 版本后，c 字段虽然无法走联合索引，但是因为有索引下推的特性，c 字段在 inndob 层过滤完满足查询条件的记录后，才返回给server 层进行回表，相比没有索引下推，减少了回表的次数。\n查询条件的顺序不影响，优化器会优化，所以a、b、c三个字段都可以走联合索引\na和b都会走联合索引，查询是覆盖索引，不需要回表\na 可以走联合索引\n只有b，无法使用联合索引，由于表存在联合索引，所以 count(*) 选择的扫描方式是扫描联合索引来统计个数，扫描的方式是type=index\n由于表存在联合索引，所以 count(*) 选择的扫描方式是扫描联合索引来统计个数，扫描的方式是type=index\n\n\n\n\n\n\n对索引字段进行函数操作，优化器会放弃走树搜索功能\n\n条件字段函数操作：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定\n\n问题SQL：select count(*) from tradelog where month(t_modified)=7;\n\n原因：对索引字段做函数操作（包括+1操作），可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能，但是不代表放弃这个索引，而是继续根据之前指标来确定索引\n\n改进：把 SQL 语句改成基于字段本身的范围查询，这样优化器就能用上 t_modified 索引的快速定位能力了，否则需要进行全表扫描\nmysql&gt; select count(*) from tradelog where\n    -&gt; (t_modified &gt;&#x3D; &#39;2016-7-1&#39; and t_modified&lt;&#39;2016-8-1&#39;) or\n    -&gt; (t_modified &gt;&#x3D; &#39;2017-7-1&#39; and t_modified&lt;&#39;2017-8-1&#39;) or \n    -&gt; (t_modified &gt;&#x3D; &#39;2018-7-1&#39; and t_modified&lt;&#39;2018-8-1&#39;);\n\n\n隐式类型转换\n\n问题SQL：select * from tradelog where tradeid=110717;\n原因：tradeid字段是varchar(32)，输入的参数确实整型，所以需要做类型转换，这里的类型转换规则是字符串和数组做比较，将字符串转换成数字\n对于优化器来说，上面的语句相当于：select * from tradelog where CAST(tradid AS signed int) = 110717;，即对索引字段使用了函数，优化器放弃走树搜索功能\n\n\n\n\n隐式字符编码转换\n\n问题SQL：select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;，其中tradelog\n字符集为utf8mb4，trade_detail字符集为utf8\n\n底层：select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;\n改进：select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2;\n\n\n原因：两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引，导致tradelog查处一行后去trade_detail查时使用的全表扫描\n\n字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较\n因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，在跟另一表中的字段进行比较\n\n\n不会出现问题的SQL：select operator from tradelog where traideid =$R4.tradeid.value;\n\n底层：select operator from tradelog where traideid =CONVERT($R4.tradeid.value USING utf8mb4);\n这里的 CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引\n\n\n\n\n\n\n常见优化索引的方法：\n\n前缀索引优化：使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小\n覆盖索引优化：覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作\n主键索引最好是自增的：\n如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高\n如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率\n\n\n防止索引失效\n\n\n索引失效的情况\n\n使用 SELECT * 进行查询;\n\n创建了组合索引，但查询条件未遵守最左匹配原则;\n\n在索引列上进行计算（如，+、-、*、/）、函数、类型转换等操作;\n\n以 % 开头的 LIKE 查询比如 like &#39;%abc&#39;;（左模糊）、like %a%;（全模糊）\n\n查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;\n\n如果 or 左右两个字段都是索引，就能走索引\n\n如果 a 和b 是联合索引，会发生索引失效，对于联合索引（比如 bc），如果使用了 b =xxx or c=xxx，会走不了索引\n\n\n\n发生隐式转换\n\n问题：下面四条语句中，第3条比1、2、4慢很多\n1: SELECT * FROM &#96;test1&#96; WHERE num1 &#x3D; 10000;\n2: SELECT * FROM &#96;test1&#96; WHERE num1 &#x3D; &#39;10000&#39;;\n3: SELECT * FROM &#96;test1&#96; WHERE num2 &#x3D; 10000;\n4: SELECT * FROM &#96;test1&#96; WHERE num2 &#x3D; &#39;10000&#39;;\n定义：当操作符与不同类型的操作数一起使用时，会发生类型转换以使操作数兼容。某些转换是隐式发生的。例如，MySQL 会根据需要自动将字符串转换为数字，反之亦然\n\n根据文档：语句2和语句3的两边被转换成了浮点数来比较\n其中语句2都转换成了浮点数进行比较，转换结果是唯一确定的（都是10000），不影响索引使用\n语句3虽然都转换成了10000，但是除了‘10000’可以转换成10000，‘01000’也可以，所以不是唯一的，不可用索引\n转换规则\n不以数字开头的字符串都将转换为0。如&#39;abc&#39;、&#39;a123bc&#39;、&#39;abc123&#39;都会转化为0；\n以数字开头的字符串转换时会进行截取，从第一个字符截取到第一个非数字内容为止。比如&#39;123abc&#39;会转换为123，&#39;012abc&#39;会转换为012也就是12，&#39;5.3a66b78c&#39;会转换为5.3，其他同理\n\n\n\n\n\n\n\n\n两列数据做比较，即使两列都创建了索引，索引也会失效\n\n查询条件是is null时正常走索引，使用is not null时，不走索引\n\n当查询条件为大于等于、in等范围查询时，根据查询结果占全表数据比例的不同，优化器有可能会放弃索引，进行全表扫描\n\nmysql 估计使用全表扫描要比使用索引快，则不使用索引\n\n\n\n补充\n- \n\n\n2.缓存\n刷脏页：InnoDB使用buffer pool管理内存，当内存数据页与磁盘不一样时就称为脏页，需要合适的时机刷新到磁盘上同步数据\n\n刷脏页的时机\n\nInnoDB 的 redo log 写满了。系统会停止所有更新操作，把checkpoint往前推进，将扫到的redo log字段对应的数据页flush到磁盘上，redo log留出空间可以继续写\n系统内存不足需要淘汰掉内存中的页时，如果该页是脏页则需要将数据同步到磁盘上，保证每个数据页不论在内存中还是磁盘上，都是正确的数据（在内存的数据页，其磁盘的就是旧值）\nMySQL 认为系统“空闲”的时候（见缝插针刷新脏页）、MySQL 正常关闭的时候（刷新所有脏页，再次启动时直接读磁盘）\n\n\nInnoDB刷脏页的控制策略\n\n影响性能的情况：一个查询要更新的脏页个数太多；日志写满更新全部堵住，写性能跌为0\n\n刷盘速度：X * max(F1(M), F2(N))\n\ninnodb_io_capacity：告诉 InnoDB 现在的磁盘能力，可以设置成磁盘的IOPS，假设当前为（X）\n\ninnodb_max_dirty_pages_pct：==脏页比例==上限，默认是75%，InnoDB会根据当前脏页比例（假设为M，计算方式 如下），算出一个0到100之间的数字（F1(M)）\nmysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME &#x3D; &#39;Innodb_buffer_pool_pages_dirty&#39;;\nselect VARIABLE_VALUE into @b from global_status where VARIABLE_NAME &#x3D; &#39;Innodb_buffer_pool_pages_total&#39;;\nselect @a&#x2F;@b; #即Innodb_buffer_pool_pages_dirty&#x2F;Innodb_buffer_pool_pages_total\n==redo log写盘速度==：根据写入日志的序号和checkpoint序号之间的差值（假设为N），计算出另一个0到100之间的数字（F2(N)）\n\n\n\n脏页选择算法：改进的LRU算法\n\n按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域，前面是young区域，LRU_old指向old区域第一块\nyoung区域：访问后放到young头部，新数据插入到LRU-old处\nold区域：在LRU中存在超过1s，移到链表头部；否则保持不变（很快失效的不会被保存很久）。所以短时间多次访问一个表不会让其它缓存失效\n\n\n\n\n邻居刷新机制：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷（innodb_flush_neighbors = 1时启用，0时关闭）\n\n\n\n标记删除（为什么mysql删了行记录反而磁盘空间没有减少）：从5.6.6开始每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中，删除的记录不会直接在B+树中删除，而是标记删除并等待被复用，所以经过大量删除的表可能存在空洞，通过重建表来收缩空洞减少内存消耗\n\n原理：新建一个表B，表A的数据按顺序插入到B中，这个过程需要全程拿MDL写锁（需要移动数据，下面的Online DDL不需要移动数据，数据存放在tmp_file临时文件中）\nOnline DDL：MySQL5.6引入，可以在重建表的过程中，保证表A上的更新操作不被阻塞：使用日志文件（row log）记录所有A的操作（alter table t engine=innodb,ALGORITHM=inplace;）\nanalyze table t 不是重建表，只是通过那MDL读锁并重新统计；而 optimize table t 等于 recreate+analyze\n\n\n临时表\n\n特点\n可以使用各种引擎类型，使用InnoDB引擎/MyISAM引擎就写到磁盘上，否则使用Memory引擎写到内存上，支持自动回收\n一个临时表只能被创建它的session访问，对其他线程不可见，不同session的临时表可重名\n创建一个名为\\#sql&#123;进程 id&#125;_&#123;线程 id&#125;_ 序列号.frm的文件，所以可重名\n\n\n可以与普通表同名，同名时除了show tables外，都显示临时表，如show create、增删改查等语句\n内存中每个表都对应一个 table_def_key，普通表的值为库名 + 表名，临时表的值外加了server_id+thread_id\n\n\n\n\n用途：因为不用担心重名冲突，所以常被用在复杂查询的优化过程（sort buffer、join buffer）\n分库分表的跨库查询：把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作\n\n\n日志记录\n临时表 redolog：不记录，因为崩溃之后，临时表全没了，也不需要恢复\nundolog：需要记录，5.6之前是和普通表放一块的；5.7之后放在临时表空间的\nbinlog：row格式不用记，statement/mix需要记录，但不记录\n主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。所以，这时候我们就需要在主库上再写一个 DROP TEMPORARY TABLE 传给备库执行\n线程是session级别的且binlog_fotmat=row时，drop table 临时表不会传过去，因为row模式从库没有临时表\n\n\n\n\n内部临时表\n如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；\njoin_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；\n如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数\n\n\n\n\n\n3.加锁规则\n查询长时间不返回\n阻塞\n可以使用 show processlist命令查看当前执行的语句是否在等待锁\n通过查询 sys.schema_table_lock_waits 这张表（select blocking_pid from sys.schema_table_lock_waits;），就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可\n\n\n等flush\n通过select * from information_schema.processlist where id=1;语句查看是否在等flush\nMySQL 里面对表做 flush 操作的用法，一般有以下两个flush tables t with read lock; 和flush tables with read lock;，但是这两条语句一般都执行很快，waiting for table flush状态可能是有一个flush tables命令被别的语句堵住\n\n\n等行锁\n通过select * from t sys.innodb_lock_waits where locked_table=&#39;test.t&#39;\\\\G来查询谁占着这个写锁\n\n\n不断回滚\n使用带lock in share mode的SQL语句，是当前读，而不带这个的SQL语句会使用undolog，不断回滚找到自己的视图，这样速度会很慢\n\n\n\n\n加锁规则（5.x 系列 &lt;=5.7.24，8.0 系列 &lt;=8.0.13）\n原则 1：加锁的基本单位是 next-key lock（前开后闭区间）\n原则 2：查找过程中访问到的对象才会加锁\n优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁\n优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁\n一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止\n\n\n死锁解除：方法一是设定超时时间（innodb_lock_wait_timeout）、方法二是发起死锁检测（innodb_deadlock_detect=on），主动回滚死锁链条中的某一事务、方法三是控制并发度、方法四是确保业务一定不死锁，产生了就回滚、方法五是将一个总账户分成多个小账户来提高并发度（需要业务控制逻辑正确）\n\n4.日志配置\n双1配置\n定义：sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog\n日志逻辑序列号（log sequence number）：单调递增，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。\n组提交：一个事务提交的时候，使用组里的现有事务作为LSN，并将现有事务一起写入磁盘中。所以在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好\n\n\n如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？\n设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险\n将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志\n将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据\n\n\n主备同步（未完待续）\n\n5.SQL语句\ncount(*)\n\nMyISAM每个表缓存此值，但是InnoDB每次都需要重新计算，因为MVCC机制，每个版本的表不同，一个表记录一个值没有意义\n优化：将此值保存在数据库的一张表里，通过事务机制来保证数据更改的并发问题（使用Redis缓存不是原子操作有并发问题）\n不同的count用法：server层要什么就给什么、InnoDB只给必要的值、优化器之优化了count(*)的语义为“取行数”\n对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加\n对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加\n对于 count(字段) 来说，\n如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，字段肯定不能为 null 可以直接按行累加\n如果这个“字段”定义允许为 null，那么执行的时候，字段有可能是 null，需要把值取出来再判断一下，不是 null 才累加\n\n\n count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加（效率最高）\n\n\n\n\norder by：通过max_length_for_sort_data参数来决定排序方法，需要的一行数据小于此值时使用全字段排序，大于则使用rowid 排序\n\n全字段排序：通过索引取出满足条件的记录的所需字段，放入名为sort_buffer的内存中，然后进行快速排序或外部归并排序（取决于sort_buffer_size的大小，不够则使用磁盘里的临时文件来辅助）\nrowid排序：放入sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id，排序完后按照顺序返回原表中取出所需的其它字段\n优化：建立联合索引（另一字段有序），覆盖索引（不用回表）来使得查询不用每次都排序\n使用SELECT * FROM information_schema.OPTIMIZER_TRACE\\\\G来查看相关数据\nnumber_of_tmp_files：看到使用的临时文件数量\nsort_mode：packed_additional_fields（使用实际大小申请内存）、rowid（使用rowid排序）\n\n\n\n\n\n\n显示随机消息：select word from words order by rand() limit 3;随机拿出的值是需要放到临时表中存储的，大小超过tmp_table_size参数使用order by的InnoDB表的排序方式，小于tmp_table_size参数则使用内存临时表和rowid方法来排序（不用回表）\n\n当limit限制的行数所占用的内存小于sort_buffer_size时，会选择优先级队列排序算法（堆排序），大于sort_buffer_size时，使用外部归并排序算法\n优化方法\n方法一：取得这个表的主键 id 的最大值 M 和最小值 N；用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N；取不小于 X 的第一个 ID 的行（结果不是严格随机的，但是效率高）\n方法二：取得整个表的行数，并记为 C；取得 Y = floor(C * rand())（ floor 函数在这里的作用，就是取整数部分）；再用 limit Y,1 取得一行（结果是严格随机的，但是效果低于方法一）\n\n\n\n\ndrop（删除表）、delete（清除记录）、truncate（清空表中数据）的区别\n\n用法不同\ndrop：丢弃数据，如drop table 表名，直接将表删除掉，不但数据会删除，表的结构也会删除\ntruncate：清空数据，如truncate table 表名，只删除表中的数据，再插入数据的时候自增长 id 又从 1 开始，在清空表中数据的时候使用\ndelete：删除数据，如delete from 表名 where 列名=值，删除某一行的数据，如果不加 where子句和truncate table 表名作用类似\n\n\ndrop和truncate属于DDL（数据定义）语句，操作立即生效，不能回滚，而delete是DML（数据操作语言）语句，如果放到rollback片段中，事务提交之后才会生效\n执行速度不同：一般来说：drop&gt;truncate&gt;delete\ndelete命令执行的时候会产生数据库的binlog日志，而日志记录是需要消耗时间的，但是也有个好处方便数据回滚恢复\ntruncate命令执行的时候不会产生数据库日志，因此比delete要快。除此之外，还会把表的自增值重置和索引恢复到初始大小等\ndrop命令会把表占用的空间全部释放掉\n\n\n\n\njoin\n\nIndex Nested-Loop Join：先从表1取1行数据，然后取出join字段去表2中查找，取出满足条件的行，并且表2该join字段有索引，可以走树搜索过程\n驱动表是走全表扫描，而被驱动表是走树搜索，所以让小表做驱动表更快\n小表确定：在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表\nBatched Key Access算法：set optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;\nMulti-Range Read 优化原理：join得到多个返回值时，先放入read_rnd_buffer进行排序，然后批量返回进行顺序查找\n使用join_buffer来暂存数据用于排序\nBNL算法转成BKA算法：直接在被驱动表上建索引（数据存到临时表再加索引），这时就可以使用NLJ算法，然后使用 BKA 算法了\n\n\n\n\nSimple Nested-Loop Join：先从表1取1行数据，然后取出join字段去表2中查找，取出满足条件的行，但是表2该join字段没有索引，需要走全表扫描，效率低，所以被驱动表没有可用索引时使用下面的join方法\nBlock Nested-Loop Join：把表 t1 的数据读入线程内存 join_buffer 中，扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回\njoin_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，就分段放\n内存判断次数是不受选择哪个表作为驱动表影响的。而考虑到扫描行数还是应该选择小表来作为驱动表\n缺点：多次扫描一个表，虽然有优化后的LRU算法，但是如果是冷表就会有问题\n冷表的数据量小于整个 Buffer Pool 的 3/8：多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部\n冷表很大：由于我们的 join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页，很可能在 1 秒之内就被淘汰了。这样，就会导致这个 MySQL 实例的 Buffer Pool 在这段时间内，young 区域的数据页没有被合理地淘汰，业务正常访问的数据页，没有机会进入 young 区域\n\n\n\n\n\n\ngroup by\n\n如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null\nselect id%10 as m, count(*) as c from t1 group by m order by null;\n尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort\n\n如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过调大 tmp_table_size 参数，避免用到磁盘临时表；\nset tmp_table_size&#x3D;1024;\nselect id%100 as m, count(*) as c from t1 group by m order by null limit 10;\n如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果\nselect SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;\n\n\n\n6.紧急操作\n短期临时提升性能\n\n短连接风暴：正常执行流程是创建短连接，执行少量的SQL，然后断开。但是在连接数暴涨（超过max_connections参数）时，系统就会拒绝接下来的连接请求，返回“Too many connections”\n\n方法一：先处理掉那些占着连接但是不工作的线程，通过kill connection + id;主动断开不需要的连接，类似于实现设置连接的wait_timeout参数，空闲过久则断开连接\n安全删除：通过show processlist;查找sleep的线程，通过查 information_schema 库的 innodb_trx 表看对应事务具体的状态\n断开的连接会返回“ERROR 2013 (HY000): Lost connection to MySQL server during query”，需要业务系统发起新的连接请求，否则业务认为MySQL一直没恢复\n\n\n方法二：减少连接过程的消耗\n跳过权限验证的方法：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内\n\n\n\n\n慢查询性能问题：在上线前使用慢查询日志记录所有语句的执行过程，看看Rows_examined字段是否与预期一致\n\n索引没有设计好：通过紧急创建索引，直接执行alter table语句，可以使用下面的方法，或者使用gh-ost这样的方案\n\n在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引\n执行主备切换；这时候主库是 B，备库是 A\n在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引\n\n\nSQL 语句没写好：5.7开始提供query_rewrite功能，可以把输入的一种语句改写成另一种模式，如下所示\n#改写 select * from t where id + 1 &#x3D; 10000\nmysql&gt; insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (&quot;select * from t where id + 1 &#x3D; ?&quot;, &quot;select * from t where id &#x3D; ? - 1&quot;, &quot;db1&quot;);\nmysql&gt; call query_rewrite.flush_rewrite_rules();\nMySQL 选错了索引：使用查询重写功能，给原来的语句加上 force index\n\n\n\nQPS（每秒查询数）突增：由于业务突然出现高峰，或应用程序bug所导致，解决方案如下\n\n一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉\n如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0\n如果这个新增的功能跟主体功能是部署在一起的，那么只能通过处理语句来限制，可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成”select 1”返回\n\n\n\n\n误删数据\n\n使用 delete 语句误删数据行：用 Flashback 工具通过闪回把数据恢复回来；原理是通过修改binlog的内容，拿回原库重放；前提是确保 binlog_format=row 和 binlog_row_image=FULL\n不建议直接在主库上执行这些操作，恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库\n事前预防：把 sql_safe_updates 参数设置为 on（没有where时会报错）；代码上线前，必须经过 SQL 审计\n使用 truncate /drop table 和 drop database 命令删除的数据，就无法通过 Flashback 来恢复了，因为binlog没有每一条记录\n\n\n使用 drop database 语句误删数据库：使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog\n跳过误操作的语句\n先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position从误操作之后的日志继续执行；\n实例使用了 GTID 模式，通过set gtid_next=gtid1;begin;commit;跳过改语句；\n\n\n一种加速方法：在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，跳过增量日志的读取过程\n在 start slave 之前，先通过执行﻿﻿change replication filter replicate_do_table = (tbl_name)命令，就可以让临时库只同步误操作的表，这样做也可以用上并行复制技术，来加速整个数据恢复过程\n在接入线上备库的从库时, 需要先将误删除的gtid先设置跳过, 然后利用主从同步的并行复制技术，来加速整个数据恢复过程\n\n\n预防方法\n搭建延迟复制的备库，通过CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有 N 秒的延迟\n账号分离：只给业务开发 DML 权限，而不给 truncate/drop 权限\n制定操作规范：在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响后再删除这张表\n\n\n\n\n使用 rm 命令误删整个 MySQL 实例\n对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作\n\n\n\n\n快速复制一张表\n\n使用 mysqldump 命令将数据导出成一组 INSERT 语句\n\n–single-transaction 的作用是，在导出数据的时候不需要对表 db1.t 加表锁，而是使用 START TRANSACTION WITH CONSISTENT SNAPSHOT 的方法；\n–add-locks 设置为 0，表示在输出的文件结果里，不增加” LOCK TABLES t WRITE;” ；\n–no-create-info 的意思是，不需要导出表结构；\n–set-gtid-purged=off 表示的是，不输出跟 GTID 相关的信息；\n–result-file 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的\n\nmysqldump -h$host -P$port -u$user --add-locks&#x3D;0 --no-create-info --single-transaction  --set-gtid-purged&#x3D;OFF db1 t --where&#x3D;&quot;a&gt;900&quot; --result-file&#x3D;&#x2F;client_tmp&#x2F;t.sql\n\n# 将这些 INSERT 语句放到 db2 库里去执行\nmysql -h127.0.0.1 -P13000  -uroot db2 -e &quot;source &#x2F;client_tmp&#x2F;t.sql&quot;\n导出和导入 CSV 文件:\nselect * from db1.t where a&gt;900 into outfile &#39;&#x2F;server_tmp&#x2F;t.csv&#39;;\nload data infile &#39;&#x2F;server_tmp&#x2F;t.csv&#39; into table db2.t;\n物理拷贝方法\n\n\n\n\n","slug":"MySQL","date":"2023-04-27T10:54:53.000Z","categories_index":"","tags_index":"database","author_index":"Dajunnnnnn"},{"id":"75ca176d6b382373bec123f05862c849","title":"Java并发","content":"Java并发1.线程1.JMM\n主内存（Main Memory）： 主内存是所有线程共享的内存区域，它存储了所有的共享变量。在主内存中，变量的读写操作都是原子的。\n工作内存（Working Memory）： 每个线程都有自己的工作内存，它存储了线程私有的局部变量以及共享变量的副本。线程在执行时，将共享变量从主内存复制到工作内存中进行操作，操作完成后再将结果写回主内存。工作内存操作可以是非原子的。\n原子性（Atomicity）： JMM 保证变量的读取和写入操作是原子的，即不会被线程中断，但并不保证复合操作的原子性。复合操作指的是涉及多个变量的操作。\n可见性（Visibility）： JMM 保证一个线程修改了共享变量的值后，其他线程能够立即看到这个变化。这是通过在主内存和工作内存之间的数据同步来实现的。\n有序性（Ordering）： JMM 保证程序的执行顺序不会因为编译器优化或处理器重排序而导致不符合预期的结果。它通过一系列 happens-before 规则来定义操作的执行顺序。\nJMM 使用 happens-before 规则来确保多线程程序的可预测性和稳定性：\n单线程规则:在单线程中，前面的操作先于后面的操作执行。但是编译器可以偷偷的重排序\n锁规则:一个线程释放锁先于另一个线程获取锁。\nvolatile规则:在时间序上，如果对一个volatile变量的写操作，先于后面的对这个变量的读操作执行，那么，volatile读操作必定能读到volatile写操作的结果。也就是说，如果x为volatile变量，在t1时刻执行了x=1，在t2时刻执行了y=x， t1小于t2，那么y肯定等于1。不管编译器或者CPU会如何优化指令的执行顺序，都能保证这个结果。\n线程启动规则:如果线程A在执行过程中，启动了线程B，那么，线程A对共享变量的修改对线程B可见。\n线程终结规则:如果线程A在执行的过程中，通过Thread.join()等待钱程B终止，那么，线程B对共享变量的修改，在线程B终止之后，对线程A可见。\n线程中断规则:线程A对线程B调用interrupt()方法，先行发生于线程B的代码检测到中断事件的发生。\n对象终结规则:一个对象的初始化完成，先行发生于调用它的finalize()方法。\n传递规则:如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。\n\n\n\n2.线程\n线程状态：NEW、RUNNABLE（READY、RUNNING）、WAITING、BLOCKED、TERMINATED、TIME_WAITING\n\n上下文切换：上下文切换（Context Switching）是操作系统在多任务（多线程或多进程）环境中的一种重要机制。它指的是操作系统暂停正在执行的一个线程或进程，并保存其当前状态（包括寄存器的值、程序计数器等信息）到内存中，然后切换到另一个线程或进程继续执行。主要步骤如下：\n\n保存当前上下文： 当操作系统决定要切换到另一个线程或进程时，它首先会保存当前线程或进程的上下文，将其状态保存到内存中。这包括程序计数器、寄存器、内存页表等。\n\n加载新上下文： 接下来，操作系统会从内存中检索要切换到的线程或进程的上下文信息，并加载到CPU寄存器和内存页表等硬件寄存器中，以便新线程或进程继续执行。\n\n切换完成： 一旦新上下文被加载，CPU 将开始执行新线程或进程的指令，这样就完成了上下文切换。\n\n\n\n\n\n\n  \n\n线程模型：内核线程（1:1）、用户线程（1:N）、混合线程（M:N）\n\nJava使用用户线程模型，上层JVM通过协作式调度来管理这些用户线程，可以在一个线程执行过程中暂停切换到另一线程执行，底层JVM将Java线程映射到操作系统的线程，由操作系统调度和管理\n启动main函数时启动了一个JVM进程，而main函数所在的线程就是这个进程中的一个（主）线程。多个线程共享进程的堆（新建的对象）和方法区资源（已加载的类信息、静态变量、常量、JIT代码），但每个线程有自己的程序计数器、虚拟机栈和本地方法栈\n多线程：减少了上下文的开销，提高了系统的并发能力，减弱IO与CPU的速度差；但会造成死锁、内存泄漏、线程不安全等问题\n\n\n子线程\n\n如何获取子线程返回值\n\n使用 Callable 和 Future： 最常见的方式是使用 Callable 接口和 Future 接口。可以将一个 Callable 对象提交给 ExecutorService 来执行，并得到一个 Future 对象。然后使用 Future 对象的 get() 方法来获取子线程的返回值，该方法会等待子线程执行完成并返回结果\nExecutorService executorService &#x3D; Executors.newSingleThreadExecutor();\nFuture&lt;Integer&gt; future &#x3D; executorService.submit(new Callable&lt;Integer&gt;() &#123;\n    @Override\n    public Integer call() throws Exception &#123;\n        &#x2F;&#x2F; 子线程执行的任务，返回一个结果\n        return 42;\n    &#125;\n&#125;);\n\ntry &#123;\n    Integer result &#x3D; future.get(); &#x2F;&#x2F; 获取子线程的返回值\n    System.out.println(&quot;子线程返回值: &quot; + result);\n&#125; catch (InterruptedException | ExecutionException e) &#123;\n    e.printStackTrace();\n&#125;\nexecutorService.shutdown();\n\n使用 CompletableFuture： Java 8 引入了 CompletableFuture，它提供了更强大和灵活的方式来处理异步操作。你可以使用 CompletableFuture 来创建异步任务，并在任务完成后获取返回值\nCompletableFuture&lt;Integer&gt; future &#x3D; CompletableFuture.supplyAsync(() -&gt; &#123;\n    &#x2F;&#x2F; 子线程执行的任务，返回一个结果\n    return 42;\n&#125;);\n\ntry &#123;\n    Integer result &#x3D; future.get(); &#x2F;&#x2F; 获取子线程的返回值\n    System.out.println(&quot;子线程返回值: &quot; + result);\n&#125; catch (InterruptedException | ExecutionException e) &#123;\n    e.printStackTrace();\n&#125;\n\n共享变量： 你还可以使用共享变量来在主线程和子线程之间传递数据。在这种情况下，主线程和子线程都可以访问和修改共享变量。确保在访问共享变量时进行适当的同步，以避免竞态条件\nclass SharedValue &#123;\n    int value;\n&#125;\n\nfinal SharedValue sharedValue &#x3D; new SharedValue();\n\nThread childThread &#x3D; new Thread(() -&gt; &#123;\n    &#x2F;&#x2F; 子线程执行的任务，修改 sharedValue\n    sharedValue.value &#x3D; 42;\n&#125;);\n\nchildThread.start();\nchildThread.join(); &#x2F;&#x2F; 等待子线程执行完成\n\nint result &#x3D; sharedValue.value; &#x2F;&#x2F; 获取子线程的返回值\nSystem.out.println(&quot;子线程返回值: &quot; + result);\n\n\n\n如何获取子线程异常：线程通常不能直接捕获子线程抛出的异常，因为子线程和主线程是独立运行的，异常是在子线程的上下文中抛出的。但你可以使用一些手段来捕获并处理子线程抛出的异常\n\n使用try-catch捕获子线程异常： 你可以在子线程的任务中使用try-catch块来捕获异常，然后将异常信息传递给主线程，主线程可以在获取到子线程的返回值后检查是否包含异常信息\nclass MyRunnable implements Runnable &#123;\n    private volatile Throwable exception &#x3D; null;\n\n    @Override\n    public void run() &#123;\n        try &#123;\n            &#x2F;&#x2F; 子线程的任务\n        &#125; catch (Throwable e) &#123;\n            exception &#x3D; e; &#x2F;&#x2F; 捕获异常并保存\n        &#125;\n    &#125;\n\n    public Throwable getException() &#123;\n        return exception; &#x2F;&#x2F; 获取异常\n    &#125;\n&#125;\n\nMyRunnable myRunnable &#x3D; new MyRunnable();\nThread childThread &#x3D; new Thread(myRunnable);\nchildThread.start();\nchildThread.join();\n\nThrowable childThreadException &#x3D; myRunnable.getException();\nif (childThreadException !&#x3D; null) &#123;\n    &#x2F;&#x2F; 主线程捕获到子线程的异常\n    childThreadException.printStackTrace();\n&#125;\n\n使用ExecutorService和Future： 如果你使用ExecutorService来执行子线程任务，你可以使用Future对象来捕获子线程的异常。在主线程调用get()方法时，如果子线程抛出了异常，get()方法将抛出ExecutionException，并包含子线程抛出的异常信息\nExecutorService executorService &#x3D; Executors.newSingleThreadExecutor();\nFuture&lt;Void&gt; future &#x3D; executorService.submit(() -&gt; &#123;\n    &#x2F;&#x2F; 子线程的任务，可能会抛出异常\n&#125;);\n\ntry &#123;\n    future.get(); &#x2F;&#x2F; 获取子线程的返回值，捕获异常\n&#125; catch (InterruptedException | ExecutionException e) &#123;\n    Throwable childThreadException &#x3D; e.getCause();\n    if (childThreadException !&#x3D; null) &#123;\n        &#x2F;&#x2F; 主线程捕获到子线程的异常\n        childThreadException.printStackTrace();\n    &#125;\n&#125;\nexecutorService.shutdown();\n\n\n\n\n\n线程安全\n\n线程安全：描述的对象可以是函数也可以是类，线程安全意味者不同线程并发执行相同的函数，或者不同线程执行一个类的不同函数，因为线程切换，函数内的指令都可以任意交叉执行，最终任意执行顺序得到的结果都是相同的，符合预期的\n\n临界区：可能会引起线程不安全的局部代码块，有两个特征，一是访问了共享资源、二是包含复合操作（先检查在执行、先读取再修改后写入）\n&#x2F;&#x2F;先检查再执行\npublic class Singleton &#123;\n    private static Singleton instance;\n    private Singleton()&#123;&#125;\n    public static Singleton getInstance()&#123;\n        if (instance &#x3D;&#x3D; null) &#123;\n            instance &#x3D; new Singleton();\n        &#125;\n        return instance;\n    &#125;\n&#125;\n&#x2F;&#x2F;先读取再修改后写入\npublic class Demo &#123;\n    private int count &#x3D; 0;\n    public void increment()&#123;\n        count++;\n    &#125;\n&#125;\n同步互斥：用于保证线程安全的访问临界区资源的方法\n\n\n\n\n3.线程创建\n实现Runnable接口的run()和start()；继承Thread类重写run方法和start方法，==可用Thread类的已有方法==\n&#x2F;&#x2F;class ThreadDemo extends Thread &#123; 内容同下 &#125; \nclass RunnableDemo implements Runnable &#123;\n   private Thread t;\n   private String threadName;\n   \n   RunnableDemo( String name) &#123; threadName &#x3D; name; &#125;\n   \n   public void run() &#123;\n      &#x2F;&#x2F;线程内需要做的操作\n   &#125;\n   \n   public void start () &#123;\n      if (t &#x3D;&#x3D; null) &#123;\n         t &#x3D; new Thread (this, threadName);\n         t.start ();\n      &#125;\n   &#125;\n&#125;\n通过Callable接口和FutureTask类创建线程，==可创建有返回值的线程（在call函数中实现）==\npublic class CallableThreadTest implements Callable&lt;Integer&gt; &#123;\n    public static void main(String[] args)  \n    &#123;  \n        CallableThreadTest ctt &#x3D; new CallableThreadTest();  \n      \t&#x2F;&#x2F;使用FutureTask包装Callable接口的实现类\n        FutureTask&lt;Integer&gt; ft &#x3D; new FutureTask&lt;&gt;(ctt);\n        for(int i &#x3D; 0;i &lt; 100;i++)  \n        &#123;  \n            System.out.println(Thread.currentThread().getName()+&quot; 的循环变量i的值&quot;+i);  \n            if(i&#x3D;&#x3D;20)  \n            &#123;  \n                new Thread(ft,&quot;有返回值的线程&quot;).start();&#x2F;&#x2F;call相当于run，但是有返回值  \n            &#125;  \n        &#125;  \n        try  \n        &#123;  \n            System.out.println(&quot;子线程的返回值：&quot;+ft.get());&#x2F;&#x2F;得到call函数的返回值   \n        &#125; catch (InterruptedException e)  \n        &#123;  \n            e.printStackTrace();  \n        &#125; catch (ExecutionException e)  \n        &#123;  \n            e.printStackTrace();  \n        &#125;  \n  \n    &#125;\n    @Override  \n    public Integer call() throws Exception  \n    &#123;  \n        int i &#x3D; 0;  \n        for(;i&lt;100;i++)  \n        &#123;  \n            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);  \n        &#125;  \n        return i;  \n    &#125;  \n&#125;\n==注意事项==\n\n直接使用Thread类的run方法：new一个Thread类，线程进入NEW状态，调用start方法，启动一个线程并使线程进入READY状态，当分配到时间片后就可以开始运行了，start会执行线程的相应准备工作，然后自动执行run方法的内容，这是真正的多线程工作，但是直接执行run方法，会把run方法当作一个main线程下的普通方法来执行，并不会在某个线程中执行它，所以这并不是多线程工作\nsleep与wait的区别：sleep是Thread类的静态本地方法，wait则是Object类的本地方法\nsleep方法没有释放锁，wait释放了锁\nwait是让获得对象锁的进程实现等待，会自动释放当前线程占有的对象锁，每个对象（Object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入WAITING状态，自然是要操作对应的对象（Object）而非当前的线程（Thread）\n因为Sleep是让当前线程暂停执行，不涉及到对象类，所以不需要对象锁\n\n\nsleep常用于暂停执行，wait方法常用于线程间交互/通信\nwait方法被调用后，线程不会自动苏醒，需要notify方法或notifyAll方法，sleep执行完线程会自动苏醒，或者也可以使用wait(long timeout)超时后自动苏醒\n\n\n\n\n\n4.线程池创建\n线程池出现的原因：因为线程过多会增加创建、调度线程的开销，所以通过线程池提前创建若干线程，一方面避免了处理任务时频繁的，创建销毁线程的开销，另一方面避免了线程数量膨胀导致的过分调度问题，并且可以集中管理线程资源，提高系统稳定性\npublic class ThreadPoolExecutor extends AbstractExecutorService &#123;\n\n    &#x2F;**\n     * 核心线程数\n     * 当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，\n     * 也会通过创建一个新线程来执行该任务，直到已创建的线程数大于或等于corePoolSize\n     *&#x2F;\n    private volatile int corePoolSize;\n\n    &#x2F;**\n     * 最大线程数\n     * 当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。\n     * 另外，对于无界队列，可忽略该参数\n     *&#x2F;\n    private volatile int maximumPoolSize;\n    &#x2F;**\n     * 线程存活保持时间\n     * 当线程池中线程数 超出核心线程数，且线程的空闲时间也超过 keepAliveTime时，\n     * 那么这个线程就会被销毁，直到线程池中的线程数小于等于核心线程数\n     *&#x2F;\n    private volatile long keepAliveTime;\n\n    &#x2F;**\n     * 任务队列\n     * 用于传输和保存等待执行任务的阻塞队列\n     *&#x2F;\n    private final BlockingQueue&lt;Runnable&gt; workQueue;\n\n    &#x2F;**\n     * 线程工厂\n     * 用于创建新线程。threadFactory 创建的线程也是采用 new Thread() 方式，threadFactory\n     * 创建的线程名都具有统一的风格：pool-m-thread-n（m为线程池的编号，n为线程池中线程的编号\n     *&#x2F;\n    private volatile ThreadFactory threadFactory;\n\n    &#x2F;**\n     * 线程饱和策略\n     * 当线程池和队列都满了，再加入的线程会执行此策略\n     *&#x2F;\n    private volatile RejectedExecutionHandler handler;\n\n    &#x2F;**\n     * 构造方法提供了多种重载，但实际上都使用了下面这个构造方法完成了实例化\n     *&#x2F;\n  \t&#x2F;&#x2F;...省略若干构造方法...\t\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue&lt;Runnable&gt; workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) &#123;\n        if (corePoolSize &lt; 0 ||\n            maximumPoolSize &lt;&#x3D; 0 ||\n            maximumPoolSize &lt; corePoolSize ||\n            keepAliveTime &lt; 0)\n            throw new IllegalArgumentException();\n        if (workQueue &#x3D;&#x3D; null || threadFactory &#x3D;&#x3D; null || handler &#x3D;&#x3D; null)\n            throw new NullPointerException();\n        this.corePoolSize &#x3D; corePoolSize;\n        this.maximumPoolSize &#x3D; maximumPoolSize;\n        this.workQueue &#x3D; workQueue;\n        this.keepAliveTime &#x3D; unit.toNanos(keepAliveTime);\n        this.threadFactory &#x3D; threadFactory;\n        this.handler &#x3D; handler;\n    &#125;\n\n    &#x2F;**\n     * 执行一个任务，但没有返回值\n     *&#x2F;\n    public void execute(Runnable command) &#123;\n        if (command &#x3D;&#x3D; null)\n            throw new NullPointerException();\n        int c &#x3D; ctl.get();\n        if (workerCountOf(c) &lt; corePoolSize) &#123;\n            if (addWorker(command, true))\n                return;\n            c &#x3D; ctl.get();\n        &#125;\n        if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;\n            int recheck &#x3D; ctl.get();\n            if (! isRunning(recheck) &amp;&amp; remove(command))\n                reject(command);\n            else if (workerCountOf(recheck) &#x3D;&#x3D; 0)\n                addWorker(null, false);\n        &#125;\n        else if (!addWorker(command, false))\n            reject(command);\n    &#125;\n\n    &#x2F;**\n     * 提交一个线程任务，有返回值。该方法继承自其父类 AbstractExecutorService，有多种重载，\n     * 这是最常用的一个。通过future.get()获取返回值（阻塞直到任务执行完）\n     *&#x2F;\n    public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123;\n        if (task &#x3D;&#x3D; null) throw new NullPointerException();\n        RunnableFuture&lt;T&gt; ftask &#x3D; newTaskFor(task);\n        execute(ftask);\n        return ftask;\n    &#125;\n\n    &#x2F;**\n     * 关闭线程池，不再接收新的任务，但会把已有的任务执行完\n     *&#x2F;\n    public void shutdown() &#123;\n        final ReentrantLock mainLock &#x3D; this.mainLock;\n        mainLock.lock();\n        try &#123;\n            checkShutdownAccess();\n            advanceRunState(SHUTDOWN);\n            interruptIdleWorkers();\n            onShutdown(); &#x2F;&#x2F; hook for ScheduledThreadPoolExecutor\n        &#125; finally &#123;\n            mainLock.unlock();\n        &#125;\n        tryTerminate();\n    &#125;\n\n    &#x2F;**\n     * 立即关闭线程池，已有的任务也会被抛弃\n     *&#x2F;\n    public List&lt;Runnable&gt; shutdownNow() &#123;\n        List&lt;Runnable&gt; tasks;\n        final ReentrantLock mainLock &#x3D; this.mainLock;\n        mainLock.lock();\n        try &#123;\n            checkShutdownAccess();\n            advanceRunState(STOP);\n            interruptWorkers();\n            tasks &#x3D; drainQueue();\n        &#125; finally &#123;\n            mainLock.unlock();\n        &#125;\n        tryTerminate();\n        return tasks;\n    &#125;\n\n    public boolean isShutdown() &#123;\n        return ! isRunning(ctl.get());\n    &#125;\n&#125;\nThreadPoolExecutor\n\n基础\n\n继承链（从下到上）\n\nExecutor接口：声明了execute方法，使得用户不需要关注如何创建线程， 只需要传入实现了Runnable接口的线程任务类\nExecutorService接口：声明了执行一批异步生成Future的方法；声明了管控线程池的方法（关闭等方法）\nAbstractExecutorService：将执行任务的流程串联起来，保证下层的实现只需关注一个执行任务的方法\nThreadPoolExecutor：实现复杂的运行部分（维护自身的生命周期、管理线程和任务）\n\n\n运行状态\n\n\n参数：corePoolSize、maximumPoolSize、keepAliveTime、unit、workQueue、threadFactory、handler\n\n阻塞队列是用于存储待执行任务的队列，有多种不同类型的阻塞队列，常见的包括：\n\nLinkedBlockingQueue： 基于链表的阻塞队列，可以指定容量，当达到容量时阻塞。\n\nArrayBlockingQueue： 基于数组的阻塞队列，必须指定容量，当达到容量时阻塞。\n\nPriorityBlockingQueue： 基于优先级的阻塞队列，不保证先进先出。\n\nSynchronousQueue： 一个没有容量的阻塞队列，用于直接传递任务。\n\n\n\n拒绝策略用于处理无法提交到线程池执行的任务，有以下几种：\n\nAbortPolicy（默认策略）： 如果工作队列已满，且线程池中的线程数达到最大线程数，新任务将会被拒绝，并抛出RejectedExecutionException异常。\nCallerRunsPolicy： 新任务由提交任务的线程执行。\nDiscardOldestPolicy： 丢弃工作队列中最老的任务，然后尝试将新任务添加到工作队列。\nDiscardPolicy： 直接丢弃新任务，不做任何处理。\n\n\n新线程添加的流程\n\n当有一个新任务提交到线程池时，线程池会检查当前活动线程数是否小于核心线程数（corePoolSize）\n\n如果小于核心线程数，线程池会创建一个新的线程来执行任务。\n\n如果当前活动线程数达到或超过核心线程数，线程池会将任务添加到工作队列（workQueue）中等待执行。\n\n如果工作队列已满，线程池会检查当前线程数是否小于最大线程数（maximumPoolSize）。\n\n如果小于最大线程数，线程池会创建一个新的线程来执行任务。\n\n如果当前线程数已达到最大线程数且工作队列也已满，根据所配置的拒绝策略来处理新任务。\n\n\n\n\n\n池内线程创建过程：首先使用工厂函数针对新任务创建线程直到数量达到核心线程池数量，然后将新任务存储在工作队列中，待工作队列满了之后创建一个新线程来处理任务（没任务一段时间后会被销毁），直到总线程数量达到最大线程池数量后，后续的新任务根据拒绝策略来确定对应操作\n\nworker进程==实现了Runnable接口继承自AQS==，持有一个线程thread（通过TheradFactory来创建），一个初始化任务firstTask\n确定线程状态：线程池通过一张==hash表==来保存线程的引用，通过增删引用来控制线程的生命周期。因为使用了==AQS锁==来实现独占锁，根据独占锁的状态反应线程现在的执行状态\nworker线程增加（addWorker方法）：增加一个线程，有两个参数==firstTask和core==，根据core的值判断现有线程数在哪个区间\nworker线程的回收：线程池中的回收==依赖JVM自动的回收==，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可\nworker线程执行任务：worker类中的run方法调用了runWorker方法来执行任务，==轮询获取任务==，再获取锁，直到没有任务\n\n\n任务与线程的匹配：通过生产者消费者模型，缓存任务，供线程池针对任务进行线程的分配\n\n线程池使用==AtomicInteger==变量维护：运行状态（runState）和线程数量（workerCount）\n&#x2F;&#x2F;高三位保存runState，低29位保存workerCount\nprivate final AtomicInteger ctl &#x3D; new AtomicInteger(ctlOf(RUNNING, 0));\n\n\n\n\n示例\n\nExecutors 类通过 ThreadPoolExecutor 封装了 4 种常用的线程池：==CachedThreadPool==，==FixedThreadPool==，==ScheduledThreadPool== 和 ==SingleThreadExecutor==。其功能如下：\n\nScheduledThreadPool：适用于执行 延时 或者 周期性 任务。\n\nFixedThreadPool：它的核心线程数和最大线程数是一样的，所以可以把它看作是固定线程数的线程池，它的特点是线程池中的线程数除了初始阶段需要从 0 开始增加外，之后的线程数量就是固定的，就算任务数超过线程数，线程池也不会再创建更多的线程来处理任务，而是会把超出线程处理能力的任务放到任务队列中进行等待。而且就算任务队列满了，到了本该继续增加线程数的时候，由于它的最大线程数和核心线程数是一样的，所以也无法再增加新的线程了。\n\nCachedThreadPool：可以称作可缓存线程池，它的特点在于线程数是几乎可以无限增加的（实际最大可以达到 Integer.MAX_VALUE，为 2^31-1，这个数非常大，所以基本不可能达到），而当线程闲置时还可以对线程进行回收。也就是说该线程池的线程数量不是固定不变的，当然它也有一个用于存储提交任务的队列，但这个队列是 SynchronousQueue，队列的容量为0，实际不存储任何任务，它只负责对任务进行中转和传递，所以效率比较高。==适用于执行大量短生命周期的异步任务==。\n\nSingleThreadExecutor：它会使用唯一的线程去执行任务，原理和 FixedThreadPool 是一样的，只不过这里线程只有一个（单线程），==如果线程在执行任务的过程中发生异常，线程池也会重新创建一个线程来执行后续的任务==。这种线程池由于只有一个线程，所以非常适合用于所有任务都需要按被提交的顺序依次执行的场景，而前几种线程池不一定能够保障任务的执行顺序等于被提交的顺序，因为它们是多线程并行执行的。\n\nSingleThreadScheduledExecutor：它实际和 ScheduledThreadPool 线程池非常相似，它只是 ScheduledThreadPool 的一个特例，内部只有一个线程。\n\n\n\nThreadPoolExecutor\npublic class ThreadPoolExecutorDemo &#123;\n\n    public static void main(String[] args) &#123;\n        &#x2F;&#x2F; 创建一个线程池，包含5个线程\n        ThreadPoolExecutor executor &#x3D; (ThreadPoolExecutor) Executors.newFixedThreadPool(5);\n        &#x2F;&#x2F; 提交10个任务给线程池执行\n        for (int i &#x3D; 0; i &lt; 10; i++) &#123;\n            Runnable worker &#x3D; new WorkerThread(&quot;Task &quot; + i);\n            executor.execute(worker);\n        &#125;\n        &#x2F;&#x2F; 关闭线程池\n        executor.shutdown();\n        while (!executor.isTerminated()) &#123;\n            &#x2F;&#x2F; 等待线程池中的任务执行完毕\n        &#125;\n        System.out.println(&quot;All tasks have been completed.&quot;);\n    &#125;\n&#125;\n\nclass WorkerThread implements Runnable &#123;\n    private String taskName;\n\n    public WorkerThread(String taskName) &#123;\n        this.taskName &#x3D; taskName;\n    &#125;\n\n    @Override\n    public void run() &#123;\n        System.out.println(Thread.currentThread().getName() + &quot; executing &quot; + taskName);\n        try &#123;\n            &#x2F;&#x2F; 模拟执行任务需要的时间\n            Thread.sleep(1000);\n        &#125; catch (InterruptedException e) &#123;\n            e.printStackTrace();\n        &#125;\n    &#125;\n&#125;\n\nExecutor框架的Executors，不推荐使用，原因如下：\n\n固定线程数的线程池： Executors.newFixedThreadPool 和类似的方法创建的线程池具有固定的线程数，如果任务队列中的任务数量超过了线程数，会导致任务等待。这可能会导致资源浪费和性能问题，因为线程数不会根据工作负载的变化而自动调整\n无界队列： Executors.newCachedThreadPool 创建的线程池使用一个无界队列来存储等待执行的任务。这意味着如果任务的生产速度远远大于消费速度，可能会导致内存耗尽，因为队列会持续增长\n缺乏对线程池参数的控制： Executors 提供的方法通常使用默认的线程池参数，这可能不适用于你的特定用例。例如，线程池的大小、任务队列的大小、拒绝策略等参数可能需要根据应用程序的性质进行调整\n缺乏对线程池行为的控制： Executors 创建的线程池通常使用默认的拒绝策略，如果队列已满并且无法接受新任务时，可能会丢弃任务或抛出异常。这可能不符合你的需求，你可能需要自定义拒绝策略\n\n&#x2F;&#x2F;1.创建\nExecutorService service &#x3D; Executors.newFixedThreadPool(10);\n&#x2F;&#x2F;2.执行\nservice.execute(new MyThread());\nservice.execute(new MyThread());\nservice.execute(new MyThread());\nservice.execute(new MyThread());\n&#x2F;&#x2F;3.关闭连接\nservice.shutdown();\n\n\n\n5.补充\n实现Runnable接口和Callable接口的区别\n\n返回值：Runnable接口的run方法没有返回值，Callable接口的call方法可以返回一个结果\n\n异常抛出：run() 方法不能抛出受检查异常，只能抛出未受检查异常；call() 方法可以抛出受检查异常（Checked Exception），因此需要在方法签名中声明可能抛出的异常\n\n执行方式：\n\nRunnable 任务由 Thread 或者线程池中的工作线程执行。\nCallable 任务通常由 ExecutorService 的 submit 方法执行，并且返回一个 Future 对象，可以用来获取任务的执行结果\n\n\nRunnable示例\npublic class MyRunnable implements Runnable &#123;\n    @Override\n    public void run() &#123;\n        &#x2F;&#x2F; 执行任务，无返回值\n        System.out.println(&quot;Runnable executed.&quot;);\n    &#125;\n&#125;\n\nThread thread &#x3D; new Thread(new MyRunnable());\nthread.start();\n\nCallable示例\nimport java.util.concurrent.Callable;\n\npublic class MyCallable implements Callable&lt;String&gt; &#123;\n    @Override\n    public String call() throws Exception &#123;\n        &#x2F;&#x2F; 执行任务，返回结果\n        return &quot;Callable executed.&quot;;\n    &#125;\n&#125;\n\nExecutorService executorService &#x3D; Executors.newSingleThreadExecutor();\nFuture&lt;String&gt; future &#x3D; executorService.submit(new MyCallable());\nString result &#x3D; future.get(); &#x2F;&#x2F; 获取任务执行结果\n\n\n\nsleep()、 wait()、notify/notifyAll() 的区别\n\nsleep()是Thread的方法，sleep() 允许指定以毫秒为单位的一段时间作为参数，它使得线程在指定的时间内进入阻塞状态，不能得到CPU 时间，指定的时间一过，线程重新进入可执行状态。Thread.sleep(2000);\nwait()和notify/notifyAll() 是Object类的方法\n所有的类中都有这一对方法，调用任意对象的 wait() 方法导致线程阻塞，并且该对象上的锁被释放\nnotify()是释放因调用该对象的 wait() 方法而阻塞的线程（但是也要当得到锁后才可以运行）但是这个释放是随机的，也就是不一定要释放那个线程\n调用 notifyAll() 方法将把因调用该对象的 wait() 方法而阻塞的所有线程一次性全部解除阻塞。当然，只有获得锁的那一个线程才能进入可执行状态\n\n\n\n\n\n\n2.互斥2.1synchronized\n粒度：对象锁（this、newObject）、局部代码锁、类锁（Demo.class）\n\n静态synchronized方法和非静态synchronized方法之间的调用不互斥（一个是类的锁一个是实例对象的锁）\n\n尽量不要使用synchronized(String a)，因为JVM中，字符串常量池具有缓存功能\n\n构造方法不能使用 synchronized 关键字修饰，因为构造方法本身就属于线程安全的，不存在同步的构造方法\npublic synchronized void add(int value) &#123;&#125; &#x2F;&#x2F;方法\nsynchronized (this)&#123;&#125; &#x2F;&#x2F;局部代码块\nsynchronized (obj1) &#123;&#125; &#x2F;&#x2F;内部的一个对象 Object obj1 &#x3D; new Object()\nsynchronized (Wallet.class) &#x2F;&#x2F;类锁\n\n\n锁类别：偏向锁（一个）、轻量级锁（不竞争）、重量级锁（竞争）\n\n通过MarkWork字段辨别锁的类别，新创建的对象处于无锁状态，随后自动变为偏向锁状态，线程可以通过CAS操作竞争偏向锁（单进程使用），竞争成功则执行完任务，执行完后锁会继续保持偏向锁状态，竞争失败则请求线程将锁升级为轻量级锁\n\n\n升级过程先暂停（JVM的STW）持有锁进程，如其在运行synchronized代码，则升级为轻量级锁（线程交叉使用不存在竞争），否则将MarkWork设置为无锁状态（偏向锁升级代价大，不如直接升级为轻量级锁）\n\n\n在轻量级锁状态，如果通过（自适应）自旋方式循环执行CAS操作请求锁达到一定数量仍未获得时，就申请升级为重量级锁，唤醒等待重量级锁的进程\n\n锁升级：通过CAS操作，持有锁的线程继续执行，请求锁的线程负责升级任务，包括创建Monitor锁，将自己放到Monitor锁的_cxq中，调用OS系统调用来阻塞自己\n\n解锁：先检查锁标志位，如果没有升级，只需要使用CAS操作解锁即可；如果已升级为重量级锁，那么持有轻量级锁的线程去唤醒等待重量级锁的进程\n\nMonitor锁（hotspot）：\nclass ObjectlMonitor &#123;\n    void * volatile _object;&#x2F;&#x2F;该Monitor锁所属的对象\n    void * volatile _owner;&#x2F;&#x2F;获取到该Monitor锁的线程\n    ObjectWaiter * volatile _cxq;&#x2F;&#x2F;没有获取到锁的线程暂时加入_cxq\n    ObjectWaiter * volatile _EntryList;&#x2F;&#x2F;存储等待被唤醒的线程\n    &#x2F;&#x2F;存储调用了wait()的线程，用来实现wait()、notify()线程同步功能\n\t\t&#x2F;&#x2F;wait、notify等方法也依赖于monitor对象\n    ObjectWaiter * volatile _waitSet;\n    &#x2F;&#x2F;...\n&#125;\n\n\n多个对象通过CAS操作（底层为cmpxchg指令）竞争_owner字段，没有获取到锁的线程加入_cxq队列中等待，待锁释放先通知_EntryList队列中的线程通过CAS操作竞争_owner字段，如果_EntryList队列为空，则将_cxq队列中移到_EntryList队列（一个负责存，一个负责取，减少并发冲突）\n内核线程执行上述步骤没得到锁时，会调用Linux的park函数自行阻塞；阻塞线程获取到锁之后，调用unpark函数来取消对应内核线程的阻塞状态\n\n\n\n\n\n\n锁优化\n\n锁消除：虚拟机在执行JIT编译时，有时会根据对代码的分析(逃逸分析)，去掉某些没有必要的锁（局部变量的锁）\n锁粗化：虚拟机在执行JIT编译时，有时会扩大加锁范围，将对多个小范围代码的加锁，合并一个对大范围代码的加锁（如for循环内的锁）\n\n\n\n2.2锁\n锁类别\n\n\n可重入锁：可以被同一个线程多次加锁的锁，即在锁没有解锁前，再次加锁，通过变量记录重入次数，JUC提供的锁都是可重入锁\n公平锁：线程会按照请求的先后顺序获得锁。synchronized是非公平锁（新请求可插队），ReentrantLock既支持公平锁也支持非公平锁，默认为非公平锁，通过在构造函数中添加true可声明为公平锁。非公平锁的性能比公平锁更好。ReentrantLock通过AQS（抽象队列同步器）来排队等待锁的线程\n可中断锁：对于synchronized来说，一个线程在阻塞等待锁时，是无法响应中断的，即不可被打断。JUC Lock接口提供了lockInterruptibly()函数，支持可响应中断的方式来请求锁（用于线程池，关闭正在执行的线程）\n非阻塞锁：JUC提供了tryLock()函数，支持非阻塞的方式获取锁，如果锁已经被其他线程获取，则不阻塞直接返回\n可超时锁：JUC提供了带参数的tryLock()函数，支持非阻塞获取锁的同时设置超时时间，tryLock()也可被中断，主要用于对响应时间敏感的系统，如Tomcat\n读写锁：为了提到并发度，可多次获得读锁，JUC提供了ReadWrite接口和其实现类ReetrantReadWriteLock。读锁是一种共享锁，可以被多个线程同时获取，写锁是排他锁，同时只能被一个线程获取，读写锁之间也是排他的（写优先）\n乐观读锁：StampedLock是对ReadWriteLock的进一步优化，提供了读锁、写锁和乐观读锁，其中的读锁和写锁与ReadWriteLock中的类似，乐观读锁是对读锁的进一步优化，在读多写少的时候，大部分读操作都不会被写操作干扰，因此连读锁都不需要加，只有验证真正有被写操作干扰的情况下，再加读锁即可\n\n\nAQS\n\n抽象队列同步器，与synchronized底层的ObjectMonitor类相似，都实现了排队线程、阻塞线程和唤醒线程等功能，但只有一个队列，且基于Java语言实现，是锁实现的原理，在ReentrantLock类有体现（Sync、NofairSync、FairSync都继承自AbstractQueuedSynchronizer）\n\nCLH(Craig,Landin,and Hagersten) 队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。在 CLH 同步队列中，一个节点表示一个线程，它保存着线程的引用（thread）、 当前节点在队列中的状态（waitStatus）、前驱节点（prev）、后继节点（next）\n\n方法\n\nAQS定义了8个模板方法，可以分为两组：独占模式（Lock）和共享模式（Semaphore）\n&#x2F;&#x2F;独占模式\npublic final void acquire(int arg) &#123; ...&#125;\npublic final void acquirelnterruptibly(int arg)throws InterruptedException &#123; ...&#125;\npublic final boolean tryAcquireNanos(int arg, long nanosTimeout)throws InterruptedException &#123; ...&#125;\npublic final boolean release(int arg) &#123; ...&#125;\n&#x2F;&#x2F;共享模式\npublic final void acquireShared(int arg) &#123; ...&#125;\npublic final void acquireSharedInterruptibly(int arg)throws InterruptedException &#123; ...&#125;\npublic final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)throws InterruptedException &#123; ...&#125;\npublic final boolean releaseShared(int arg) &#123; ...&#125;\nAQS提供了4个抽象方法：没有声明为abstract是为了减少代码量，更灵活编写代码\n&#x2F;&#x2F;独占模式\nprotected boolean tryAcquire(int arg)&#123;throw new UnsupportedOperationException();&#125;\nprotected boolean tryRelease(int arg)&#123;throw new UnsupportedOperationException();&#125;\n&#x2F;&#x2F;共享模式\nprotected int tryAcquireShared(int arg) &#123;throw new UnsupportedOperationException();&#125;\nprotected boolean tryReleaseShared(int arg) &#123;throw new UnsupportedOperationException();&#125;\n\n\n\n\nReetrantLock：定义了两个继承自AQS的子类：NofairSync和FairSync，分别用来实现非公平锁和公平锁，并且因为底层释放锁的逻辑相同，故又抽象出公共父类Sync\n\nSync，NofairSync和FairSync（根据构造函数的不同使用不同的Sync实现）\npublic class ReentrantLock implements Lock, java.io.Serializable &#123;\n\t  private final sync sync;\n\t  \n\t  abstract static class Sync extends AbstractQueuedSynchronizer &#123; ...&#125;\n\t  static final class NonfairSync extends Sync &#123; ...&#125;\n\t\tstatic final class FairSync extends Sync &#123; ...&#125;\n\t    \n\t\tpublic ReentrantLock()&#123;\n\t\t\t\tsync &#x3D; new NonfairSync();\n\t   &#125;\n\t\tpublic ReentrantLock(boolean fair) &#123;\n\t\t\t\tsync &#x3D; fair ? new FairSync() : new NonfairSync();\n\t   &#125;\n\t        \n\t\tpublic void lock()&#123;sync.acquire(1);&#125;\n\t\tpublic void unlock() &#123;sync.release(1);&#125;\n\t\t&#x2F;&#x2F;...省略其他方法...\n\t    &#125;\n&#125;\nacquire：改state值，是否查看等待队列（公平/不公平），addWaiter（自旋+CAS）、acquireQueued（唤醒后竞争锁）\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;Sync&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic final void acquire(int arg) &#123;\n    &#x2F;&#x2F;1.调用tryAcquire去竞争获取锁，如果成功，则直接返回\n    &#x2F;&#x2F;2.调用addWaiter，将线程包裹为Node节点放入等待队列的尾部\n    &#x2F;&#x2F;3.调用acquireQueued阻塞当前线程，\n    if ( !tryAcquire(arg) &amp;&amp; acquireQueued( addWaiter(Node.EXCLUSIVE), arg ) )\n        &#x2F;&#x2F;用来处理中断，如果在等待锁的过程中，被其它线程中断，\n        &#x2F;&#x2F;则在获取锁之后，将现成的中断标记设置为true\n        selfInterrupt();\n&#125;\n\nstatic final class NonfairSync extends Sync &#123;\n    &#x2F;&#x2F;尝试获取锁，成功返回true，失败返回false。AQS用于实现锁时，acquires&#x3D;1\n    protected final boolean tryAcquire(int acquires)&#123;\n        final Thread current &#x3D; Thread.currentThread();\n        int c &#x3D; getState(); &#x2F;&#x2F;获取state值\n        if (c &#x3D;&#x3D; 0)&#123;&#x2F;&#x2F;锁没有被其他线程占用\n            if (compareAndSetstate(0,acquires)) &#123; &#x2F;&#x2F; CAS设置state值为1\n                setExclusiveOwnerThread(current);&#x2F;&#x2F; 设置exclusiveownerThread\n                return true;&#x2F;&#x2F;获取锁成功\n            &#125;\n        &#125;else if (current &#x3D;&#x3D; getExclusiveOwnerThread())&#123;&#x2F;&#x2F; 锁已被自己占用，可重入\n            int nextc &#x3D; c + acquires; &#x2F;&#x2F; state+1\n            if (nextc &lt; 0)&#x2F;&#x2F;重入次数太多，超过了int最大值，溢出为负数，此情况罕见\n                throw new Error(&quot;Maximum lock count exceeded&quot;);\n            setState(nextc); &#x2F;&#x2F; state&#x3D;state+1,state记录重入的次数，解锁的时候用\n            return true;&#x2F;&#x2F;获取锁成功\n        &#125;\n        return false;&#x2F;&#x2F;获取锁失败\n    &#125;\n&#125;\nstatic final class FairSync extends Sync &#123;\n    protected final boolean tryAcquire(int acquires) &#123;\n        final Thread current &#x3D; Thread.currentThread();\n\t\t\t\tint c &#x3D; getState();\n        if (c &#x3D;&#x3D; 0)&#123;\n            if (!hasQueuedPredecessors() &amp;&amp;&#x2F;&#x2F;等待队列中没有线程时才获取锁\n                compareAndSetstate(0, acquires))&#123;\n                setExclusiveownerThread(current);\n                return true;\n            &#125;\n        &#125;else if (current &#x3D;&#x3D; getExclusiveOwnerThread())&#123;\n            int nextc &#x3D; C + acquires;\n            if (nextc &lt; 0)\n                throw new Error(&quot;Maximum lock count exceeded&quot;);setState(nextc);\n            return true;\n        &#125;\n        return false;\n    &#125;\n&#125;\n\n&#x2F;&#x2F;通过自旋和CAS操作解决往链表尾部添加节点和特殊处理链表为空所存在的线程安全问题\nprivate Node addWaiter(Node mode)&#123;\n    Node node &#x3D; new Node(Thread.currentThread(), mode);\n    &#x2F;&#x2F;自旋执行CAS操作，直到成功为止\n    for (;;) &#123;\n        Node t &#x3D; tail;\n        if (t &#x3D;&#x3D; null) &#123;&#x2F;&#x2F;链表为空，添加虚拟头节点\n            &#x2F;&#x2F;CAS操作解决添加虚拟头节点的线程安全问题\n            if (compareAndSetHead(null, new Node()))\n                tail &#x3D; head;\n        &#125;else &#123;&#x2F;&#x2F;链表不为空\n            node.prev &#x3D; t;\n            &#x2F;&#x2F;CAS操作解决了同时往链表尾部添加节点时的线程安全问题\n            if (compareAndSetTail(t, node)) &#123;\n                t.next &#x3D; node;\n                return t;\n            &#125;\n        &#125;\n    &#125;\n    return node;\n&#125;\n\n&#x2F;&#x2F;主要有两部分逻辑，使用tryAcquire函数来竞争锁和使用park()函数来阻塞线程\n&#x2F;&#x2F;采用for循环来交替执行这两个逻辑，为了在线程被唤醒后，并不是直接获取锁，\n&#x2F;&#x2F;而是重新竞争锁，如果竞争失败，则需要再次被阻塞\nfinal boolean acquireQueued(final Node node, int arg) &#123;\n    boolean failed &#x3D; true;\n    try &#123;\n        boolean interrupted &#x3D; false;\n        for (;;)&#123;\n            &#x2F;&#x2F;使用tryAcquire()函数来竞争锁\n            final Node p &#x3D; node.predecessor();\n            if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123;\n                setHead(node);\n                p.next &#x3D; null; &#x2F;&#x2F; help GC\n                failed &#x3D; false;\n                return interrupted;\n            &#125;\n            &#x2F;&#x2F;调用park()函数来阻塞线程，等待其他线程调用unpark()函数唤醒\n            if (parkAndCheckInterrupt()) interrupted &#x3D; true;\n        &#125;\n    &#125;finally &#123;\n        if (failed) cancelAcquire(node);\n    &#125;\n&#125;\nprivate final boolean parkAndChecklnterrupt() &#123;\n    LockSupport.park(this);&#x2F;&#x2F;底层也是调用JVM提供的native park()函数来实现\n    return Thread.interrupted();\n&#125;\nrelease：sync和nofairsync的实现相同，state-1→setExclusiveownerThread(state==0)-&gt;setState(state != 0有重入)\npublic final boolean release(int arg) &#123;\n    &#x2F;&#x2F;tryRelease释放锁\n    if (tryRelease(arg)) &#123;\n        Node h &#x3D; head;\n        if (h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0)\n            unparkSuccessor(h);&#x2F;&#x2F;内部调用unpark()函数，唤醒链表首节点对应的线程\n        return true;\n    &#125;\n    return false;\n&#125;\n&#x2F;&#x2F;公平锁和非公平锁的实现相同\nstatic final class Sync extends AbstractQueuedSynchronizer &#123;\n    &#x2F;&#x2F;释放锁，成功返回true，失败返回false。AQS用于实现锁时，releases&#x3D;1\n    protected final boolean tryRelease(int releases)&#123;\n        int c &#x3D; getState() - releases; &#x2F;&#x2F;state-1\n        &#x2F;&#x2F;不持有锁的线程去释放锁，抛出异常\n        if (Thread.currentThread() !&#x3D; getExclusiveownerThread())\n            throw new lllegalMonitorStateException();\n        boolean free &#x3D; false;\n        if (c &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;stat-1之后为0，解锁\n            free &#x3D; true;\n            setExclusiveownerThread(null);\n        &#125;\n        setState(c); &#x2F;&#x2F;state-1之后不为0，说明锁被重入多次，还不能解锁。\n        return free;\n    &#125;\n&#125;\n中断机制：lockInterruptibly→acquirelnterruptibly→doAcquireInterruptibly（类似于acquireQueued，但对中断的响应处理不同）\npublic void lockInterruptibly() throws InterruptedException &#123;\n    sync.acquirelnterruptibly(1);\n&#125;\n&#x2F;&#x2F;如果线程中断则抛出异常，否则。调用tryAcquire()竞争获取锁，\n&#x2F;&#x2F;获得失败后调用doAcquireInterruptibly\npublic final void acquirelnterruptibly(int arg) throws InterruptedException &#123;\n    if (Thread.interrupted()) throw new InterruptedException();\n    if (!tryAcquire(arg)) doAcquireInterruptibly(arg);\n&#125;\n&#x2F;&#x2F;与acquireQueued()函数的代码非常相似，唯一区别是对中断的响应处理不同\nprivate void doAcquireInterruptibly(int arg) throws InterruptedException &#123;\n    final Node node &#x3D; addWaiter(Node.EXCLUSIVE);\n    boolean failed &#x3D; true;\n    try &#123;\n        for(;;)&#123;\n            final Node p &#x3D; node.predecessor();\n            if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123;\n                setHead(node);\n                p.next &#x3D; null; &#x2F;&#x2F; help GC\n                failed &#x3D; false;\n                return;\n            &#125;\n            if (parkAndChecklnterrupt())\n                throw new lnterruptedException(); &#x2F;&#x2F;区别:抛出异常! 阻止等待锁\n        &#125;\n    &#125;finally &#123;\n        if (failed) \n            cancelAcquire(node);&#125;\n&#125;\n超时机制：tryLock→tryAcquireNanos→doAcquireNanos（在acquireInterruptibly的基础上增加了超时机制）\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;ReentrantLock&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic boolean tryLock(long timeout,TimeUnit unit)\n    throws InterruptedException &#123;\n    return sync.tryAcquireNanos(1 , unit.toNanos(timeout));\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;AbstractQueueSynchronizer&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123;\n    &#x2F;&#x2F;如果线程被中断则抛出异常\n    if (Thread.interrupted()) throw new InterruptedException();\n    &#x2F;&#x2F;调用tryAcquire竞争获取锁，成功则返回，失败则调用doAcquireNanos\n    return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);\n&#125;\n&#x2F;&#x2F;在acquireInterruptibly函数基础上，添加了对超时的处理机制\nprivate boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123;\n    if (nanosTimeout &lt;&#x3D; 0L) return false;\n    final long deadline &#x3D; System.nanoTime() + nanosTimeout;\n    final Node node &#x3D; addWaiter(Node.EXCLUSIVE);\n    boolean failed &#x3D; true;\n    try &#123;\n        for (;;)&#123;\n            final Node p &#x3D; node.predecessor();\n            if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg))&#123;\n                setHead(node);\n                p.next &#x3D; null; &#x2F;&#x2F; help GC\n                failed &#x3D; false;\n                return true;\n            &#125;\n            nanosTimeout &#x3D; deadline - System.nanoTime();\n            if (nanosTimeout &lt;&#x3D; 0L) return false;\n            if(nanosTimeout &gt; spinForTimeoutThreshold)&#x2F;&#x2F;不着急阻塞，先自旋—下\n                LockSupport.parkNanos(this, nanosTimeout);&#x2F;&#x2F;超时阻塞\n            if (Thread.interrupted()) throw new InterruptedException();\n        &#125;\n    &#125;finally &#123;\n        if (failed) cancelAcquire(node);\n    &#125;\n&#125;\n&#x2F;&#x2F;为了支持超时阻塞，在阻塞线程时，doAcquireNanos调用parkNanos函数\n&#x2F;&#x2F;synchronized中park函数实现如下，parkNanos只将其中的pthread_cond_wait换成了\n&#x2F;&#x2F;pthread_cond_timewait，便可实现超时等待。\npthread_mutex_t mutex &#x3D; PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond &#x3D; PTHREAD_COND_INITIALIZER;\nvoid park() &#123;\n    pthread_mutex_lock(&amp;mutex);\n    pthread_cond_wait(&amp;cond,&amp;mutex);&#x2F;&#x2F;阻塞等待其他线程发送信号\n    pthread_mutex_unlock(&amp;mutex);\n&#125;\n\n\nReadWriteLock：读锁不可以转成写锁，但在写锁释放前加读锁，在写锁释放后线程持有的锁自动从写锁降级为读锁\n\nstate：低16位写锁、高16位读锁\n\n低16位表示，0表示没有加写锁，1表示已经加写锁，大于1表示写锁的可重入次数\n高16位表示，0表示没有加读锁，1表示已经加读锁，大于1表示读锁总共被获取了多少次（每个线程对读锁重入的次数相加），使用ThreadLocal变量存储重入次数\n\n\n写锁\nprotected final boolean tryAcquire(int acquires) &#123;\n    Thread current &#x3D; Thread.currentThread();\n    int c &#x3D; getState();\n    int w &#x3D; exclusiveCount(c);&#x2F;&#x2F;高16位的值，也就是写锁的加锁情况\n    &#x2F;&#x2F;1.已经加读锁或写锁（state!&#x3D;0）\n    if (c !&#x3D; 0) &#123;\n        &#x2F;&#x2F; 已加读锁(w&#x3D;&#x3D;0)或者当前加写锁的线程不是自己\n        if (w &#x3D;&#x3D; 0 || current !&#x3D; getExclusiveOwnerThread())\n            return false;&#x2F;&#x2F;去排队\n        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)\n            throw new Error(&quot;Maximum lock count exceeded&quot;);\n        &#x2F;&#x2F; 获取到了写锁\n        setState(c + acquires);&#x2F;&#x2F;更新写锁的重入次数\n        return true;\n    &#125;\n    &#x2F;&#x2F;2.没有加锁（state&#x3D;0）\n    if (writerShouldBlock() || !compareAndSetState(c, c + acquires))\n        return false;&#x2F;&#x2F;去排队\n    setExclusiveOwnerThread(current);\n    return true;&#x2F;&#x2F;获取了锁\n&#125;\n&#x2F;&#x2F;writerShouldBlock函数控制锁是否为公平锁，在state&#x3D;0，也就是没有加读锁和\n&#x2F;&#x2F;写锁的情况下，如果writerShouldBlock返回值为true，那么线程不尝试竞争锁，而是直接去排队，\n&#x2F;&#x2F;如果writerShouldBlock返回值是false，那么线程尝试竞争锁，失败再去排队。\n&#x2F;&#x2F;对于非公平锁，总是返回false，对于公平锁如果等待队列中有线程，则返回true\n读锁\npublic final void acquireShared(int arg) &#123;\n    if (tryAcquireShared(arg) &lt; 0)&#x2F;&#x2F;竞争读锁\n        doAcquireShared(arg);&#x2F;&#x2F;竞争失败去排队\n&#125;\n&#x2F;&#x2F;返回-1表示竞争锁失败，返回1表示竞争锁成功\nprotected final int tryAcquireShared(int unused) &#123;\n    Thread current &#x3D; Thread.currentThread();\n    int c &#x3D; getState();\n    &#x2F;&#x2F;一些优化代码\n    return fullTryAcquireShared(current);\n&#125;\nfinal int fullTryAcquireShared(Thread current) &#123;\n    HoldCounter rh &#x3D; null;\n    &#x2F;&#x2F;如果state没加锁或者是加了读锁，那么线程会通过CAS操作改变state值来竞争锁;\n    &#x2F;&#x2F;如果其他线程也在竟争读锁，并且竞争成功，那么此线程就会竟争失败;\n    &#x2F;&#x2F;于是，此线程就要自旋(for循环)再次尝试去竞争读锁。\n    for (;;) &#123;\n        int c &#x3D; getState();\n        if (exclusiveCount(c) !&#x3D; 0) &#123;&#x2F;&#x2F;已加写锁\n            &#x2F;&#x2F;如果加写锁的线程不是此线程，那么读锁也加不成，直接返回-1\n            &#x2F;&#x2F;否则，读写锁支持锁降级，加了写锁的线程可以再加读锁\n            if (getExclusiveOwnerThread() !&#x3D; current)\n                return -1;\n        &#125; \n        &#x2F;&#x2F;理论上讲，如果没有加写锁，不管有没有加读锁，都可以去竞争读锁了，\n        &#x2F;&#x2F;毕竟读锁是共享锁。但是，存在两个特殊情况:\n        &#x2F;&#x2F;1.对于公平锁来说，如果等待队列不为空，并且当前线程没有持有读锁(重入加\n        &#x2F;&#x2F;锁)，那么，线程就要去排队。\n        &#x2F;&#x2F;2.对于非公平锁来说，如果等待队列中队首线程(接下来要被唤醒的）是写线\n        &#x2F;&#x2F;程，那么，线程就要去排队。这样做是为了避免请求写锁的线程迟迟获取不\n        &#x2F;&#x2F;到写锁。\n        else if (readerShouldBlock()) &#123;&#x2F;&#x2F;上述1和2情况在此时返回true      \n            if (readHolds.get().count &#x3D;&#x3D; 0)&#x2F;&#x2F;此线程没有持有读锁，不能重入\n                return -1;\n            &#x2F;&#x2F;以下是对上述代码中readHolds的解释:readHolds是ThreadLocal变量，保存\n            &#x2F;&#x2F;跟这个线程的读锁重入次数。如果重入次数为0，表示没有加读锁，返回-1去\n            &#x2F;&#x2F;排队。如果重入次数大于等于0，表示已加读锁，可以继续重入，不用排队。\n        &#125;\n        if (sharedCount(c) &#x3D;&#x3D; MAX_COUNT)\n            throw new Error(&quot;Maximum lock count exceeded&quot;);\n        &#x2F;&#x2F;CAS竞争读锁，此时有可能还有其他线程在竞争读锁或写锁\n        if (compareAndSetState(c, c + SHARED_UNIT)) &#123;&#x2F;&#x2F;SHARED_UNIT&#x3D;1&lt;&lt;16\n            &#x2F;&#x2F;竞争读锁成功\n            readHolds.get().count++;&#x2F;&#x2F;更新线程重入次数\n            return 1;&#x2F;&#x2F;成功获取读锁\n        &#125;\n    &#125;\n&#125;\n&#x2F;&#x2F;负责排队和等待唤醒，与之前的acquireQueued有两个不同\nprivate void doAcquireShared(int arg) &#123;\n    final Node node &#x3D; addWaiter(Node.SHARED);&#x2F;&#x2F;一：标记此线程等待的是共享锁\n    boolean failed &#x3D; true;\n    try &#123;\n        boolean interrupted &#x3D; false;\n        for (;;) &#123;\n            final Node p &#x3D; node.predecessor();\n            if (p &#x3D;&#x3D; head) &#123;\n                int r &#x3D; tryAcquireShared(arg);\n                if (r &gt;&#x3D; 0) &#123;\n                    &#x2F;&#x2F;区别二：如果下一个节点对应的线程也在等待读锁，那么顺道唤醒它\n                    &#x2F;&#x2F;线程获取到读锁之后，如果下一个节点对应的线程也在等待读锁，\n                    &#x2F;&#x2F;那么也会被唤醒。下一个节点对应的线程获取到读锁之后，又会去唤醒\n                    &#x2F;&#x2F;下下个节点对应的线程(如果下下个节点对应的线程也在等待读锁的\n                    &#x2F;&#x2F;话)。唤醒操作一直传播下去，直到遇到等待写锁的线程为止。\n                    setHeadAndPropagate(node, r);\n                    p.next &#x3D; null; &#x2F;&#x2F; help GC\n                    if (interrupted)\n                        selfInterrupt();\n                    failed &#x3D; false;\n                    return;\n                &#125;\n            &#125;\n            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;\n                parkAndCheckInterrupt())\n                interrupted &#x3D; true;\n        &#125;\n    &#125; finally &#123;\n        if (failed)\n            cancelAcquire(node);\n    &#125;\n&#125;\n\n\nReentrantReadWriteLock：readerLock、writerLock、Sync、FairSync、NonfairSync\npublic class ReentrantReadWriteLock\n    implements ReadWriteLock, java.io.Serializable &#123;\n    &#x2F;&#x2F;内部类提供实现，使用NonfairSync和FairSync来编程实现读锁（ReadLock）和\n    &#x2F;&#x2F;写锁（WriteLock），均实现了Lock接口、相同的AQS、Lock接口中的所有加解锁函数\n    private final ReentrantReadWriteLock.ReadLock readerLock;\n    private final ReentrantReadWriteLock.WriteLock writerLock;\n    final Sync sync;&#x2F;&#x2F;执行所有同步机制\n    public ReentrantReadWriteLock() &#123;\n        this(false);\n    &#125;\n    public ReentrantReadWriteLock(boolean fair) &#123;\n        sync &#x3D; fair ? new FairSync() : new NonfairSync();\n        readerLock &#x3D; new ReadLock(this);\n        writerLock &#x3D; new WriteLock(this);\n    &#125;\n    public ReentrantReadWriteLock.WriteLock writeLock() &#123; return writerLock; &#125;\n    public ReentrantReadWriteLock.ReadLock  readLock()  &#123; return readerLock; &#125;\n    &#x2F;&#x2F;AQS的子类NonfairSync和FairSync的公共父类\n    abstract static class Sync extends AbstractQueuedSynchronizer &#123;\n        abstract boolean readerShouldBlock();&#x2F;&#x2F;区分公平锁和非公平锁\n        abstract boolean writerShouldBlock();&#x2F;&#x2F;区分公平锁和非公平锁\n        &#x2F;&#x2F;以下为AQS模板方法的抽象方法的实现\n        protected final boolean tryRelease(int releases) &#123;&#125;\n        protected final boolean tryAcquire(int acquires) &#123;&#125;\n        protected final boolean tryReleaseShared(int unused) &#123;&#125;\n        protected final int tryAcquireShared(int unused) &#123;&#125;\n\n        final boolean tryWriteLock() &#123;&#125;\n        final boolean tryReadLock() &#123;&#125;      \n    &#125;\n    static final class NonfairSync extends Sync &#123;\n        final boolean writerShouldBlock() &#123;return false; &#125;\n        final boolean readerShouldBlock() &#123;return apparentlyFirstQueuedIsExclusive();&#125;\n    &#125;\n    static final class FairSync extends Sync &#123;\n        final boolean writerShouldBlock() &#123;return hasQueuedPredecessors();&#125;\n        final boolean readerShouldBlock() &#123;return hasQueuedPredecessors();&#125;\n    &#125;\n&#125;\nStampedLock：在读写锁的基础上提供了乐观读锁。在读多写少的情况下，大部分操作都不会被写操作干扰，只有在真正被干扰的情况下再加读锁重复执行读操作\n\n不可重入且不支持条件变量Condition，没有实现Lock和ReadWriteLock接口，而是实现CLH锁（AQS也是基于此）\nCLH锁是对自旋锁的一种改良，是一种隐式的链表队列，StampedLock通过CLH进行线程的管理，通过同步状态值state来表示锁的状态和类型\n\n\n不可重入的原因：StampedLock在获取锁的时候会返回一个 long 型的数据戳，该数据戳用于稍后的锁释放参数，当前线程持有了锁再次获取锁还是会返回一个新的数据戳\n性能更好：StampedLock的乐观读锁允许一个写线程获取写锁，所以不会导致所有写线程阻塞，也就是当读多写少的时候，写线程有机会获取写锁，减少了线程饥饿的问题，吞吐量大大提高\n\n\n\n2.3补充\n关键字：volatile、synchronized、final\n\nvolatile：每次都去主内存读取，修改立即写入内存（c语言中的volatile的意思是禁用cpu缓存）\n解决可见性问题：用volatile修饰的变量，在编译成机器指令时，会加入特殊指令，使得CPU对此变量的修改立即写入内存，并通过其它CPU更新缓存数据\n解决有序性问题：volatile通过禁止指令重排序来解决有序性问题，并且是部分指令重排\n内存屏障：JMM定义了4个细粒度的内存屏障，其底层依赖CPU提供的内存屏障指令（StoreStore、StoreLoad、LoadLoad、LoadStore）分别禁止屏障前后的写写、写读、读读、读写操作重排\nJMM内存模型定义部分禁止重排序的方法：volatile写操作后或者volatile读操作前会添加[StoreLoad]来防止volatile写和读的重排序，一般选择添加在写后面，因为读多写少。\n\n\n解决原子性问题\n在32位计算机上，读写64位的long或double类型数据，会执行两次内存读写操作，如果用volatile修饰，那么编译器会在两次读或写之间锁定总线指令，保证变量读写的原子性，但在64位机上就不需要了\n自增语句（count++）因为是对寄存器的值进行操作，但是volatile对变量只能保证立刻写入内存让所有CPU的缓存失败，所以不能影响寄存器内的值，需要synchronized关键字\n\n\n\n\nsynchronized：通过让原本并发执行的代码串行执行，并且每次加锁和释放锁，都会同步CPU缓存和内存中的数据，可以解决可见性、有序性、原子性的问题\nfinal：JMM对final的语义做了增强，禁止编译器将构造函数中对final变量的写操作，重排序到对象引用之后，也就是禁止初始化对象（构造函数中的语句）和将内存空间赋值给引用的重排序，否则在多线程环境下，一个线程可能看到final变量的两个不同的值\n\n\nsynchronized和volatile有什么区别（互补）\n\nvolatile关键字是线程同步的轻量级实现，所以性能比synchronized好，但是volatile只能用于变量而synchronized可以修饰方法以及代码块\nvolatile关键字能保证数据的可见性，但不能保证数据的原子性，synchronized关键字两者都能保证\nvolatile关键字主要用于解决变量在多个线程之间的可见性，而synchronized关键字解决的是多个线程之间访问资源的同步性\n\n\nsynchronized和ReentrantLock有什么区别\n\n相同点：两者都是可重入锁，即线程可以再次获取自己的内部锁，不可重入的此时会产生死锁\nReentrantLock属于可中断锁，获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理；synchronized锁属于不可中断锁，一旦线程申请了锁，就只能等到拿到锁之后才能进行其他的逻辑处理\nsynchronized依赖于JVM（用户不能直接看到代码）而ReentrantLock依赖于API（lock、unlock等方法）\nReentrantLock 比 synchronized 增加了一些高级功能，如可中断锁、公平锁、可超时锁、非阻塞锁、选择性通知（锁可以绑定多个条件）\nsynchronized需要和wait、notify结合才能实现等待/通知机制，ReentrantLock类通过Condition接口和newCondition方法实现\nCondition接口可以实现多路通知功能，也就是在一个Lock对象中可以创建多个Condition实例（对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活\n在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”\nsynchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll方法的话就会通知所有处于等待状态的线程，这样会造成很大的效率问题\n而Condition实例的signalAll()方法，只会唤醒注册在该Condition实例中的所有等待线程\n\n\n\n\nsynchronized 的 lock 的区别\n\n关键字 vs. 接口：synchronized是Java内置的关键字，而Lock是java.util.concurrent.locks 包中定义的一个接口，并且Lock 可以比 synchronized 更好地支持高并发\n锁的获取方式：synchronized 是隐式锁，当线程进入synchronized块时，自动加解锁；Lock 是显式锁，需要调用lock加锁，调用unlock解锁\n锁的可中断性：synchronized 不支持锁的中断，Lock 支持可中断的锁，可以使用 tryLock(long timeout, TimeUnit unit) 方法来尝试获取锁，超时仍未获取则放弃等待\n\n\n非阻塞同步\n\n悲观锁（阻塞同步）：\n\n乐观锁（非阻塞同步）：先进行操作，操作完成之后再判断操作是否成功，是否有并发问题，如果有则进行失败补偿，如果没有就算操作成功\n\n在 Java 中应用最广泛的非阻塞同步就是 CAS。从 JDK1.5 以后，可以使用 CAS 操作，该操作由 sun.misc.Unsafe 类里的 compareAndSwapInt() 和 compareAndSwapLong() 等方法实现。通常情况下 sun.misc.Unsafe 类 对于开发者是不可见的，因此，JDK 提供了很多 CAS 包装类 简化开发者的使用，如 AtomicInteger。使用 Java 自带的 Atomic 原子类，可以避免同步锁带来的并发访问性能降低的问题，减少犯错的机会\n\n\n\n\n3.同步2.1条件变量\nObject类：执行wait()或notify()前先加锁、使用while循环避免假唤醒，底层依赖ObjectMonitor\npublic class QueueCond&#123;\n  private List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;();\n  private int count &#x3D; 0;\n  \n  public void put(String elem)&#123;\n    synchronized(this)&#123;&#x2F;&#x2F;加锁\n      list.add(count,elem);\n      count++;&#x2F;&#x2F;更新状态变量\n      this.notify();&#x2F;&#x2F;通知\n    &#125;\n  &#125;\n  \n  public String get()&#123;\n    synchronized(this)&#123;&#x2F;&#x2F;加锁\n      while(count &lt;&#x3D; 0)&#123;&#x2F;&#x2F;检查状态变量是否满足条件\n        try&#123;\n          this.wait();&#x2F;&#x2F;等待并释放锁，被唤醒之后重新竞争获取锁\n        &#125;catch(InterruptedException e)&#123;\n          return null;\n        &#125;\n      &#125;&#x2F;&#x2F;以下为业务逻辑\n      count--;\n      return list.get(count);\n    &#125;\n  &#125;\n&#125;\nCondition接口：使用前后需要lock和unlock，使用中要while，底层依赖ConditionObject（AQS的内部类）\npublic class QueueCondJUC&#123;\n  private List&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;();\n  private int count &#x3D; 0;\n  private Lock lock &#x3D; new ReentrantLock();\n  private Condition condition &#x3D; lock.newCondition();\n  \n  private void put(String elem)&#123;\n    lock.lock();&#x2F;&#x2F;加锁\n    try&#123;\n      list.add(count,elem);\n      count++;&#x2F;&#x2F;更新状态变量\n      condition.signal();&#x2F;&#x2F;通知\n    &#125;finally&#123;\n      lock.unlock();&#x2F;&#x2F;解锁\n    &#125;\n  &#125;\n  public String get()&#123;\n    lock.lock();&#x2F;&#x2F;加锁\n    try&#123;\n      while(count &lt;&#x3D; 0)&#123;&#x2F;&#x2F;检查状态变量是否满足条件\n        try&#123;\n          condition.await();&#x2F;&#x2F;等待并释放锁，被唤醒之后重新竞争获取锁\n        &#125;catch(InterruptedException e)&#123;\n          return null;\n        &#125;\n      &#125;&#x2F;&#x2F;以下为业务逻辑\n      count--;\n      return list.get(count);\n    &#125;finally&#123;\n      lock.unlock();&#x2F;&#x2F;解锁\n    &#125;\n  &#125;\n&#125;\n\n2.2信号量（Semaphore）\nSemaphore类\n\n信号量与锁的区别是：释放锁的线程必须持有锁，而信号量则不用。即没有调用acquire()函数的线程也可以直接调用release()函数，用来增加可用许可个数。此时，信号量不再是用来限制对临界区的并发访问，而是用来对共享资源的并发访问\n如果信号量中的许可个数为1，那么信号量就退化成了互斥锁；如果互斥量的许可个数大于1，信号量就可以看作是一种共享锁\n\npublic class Semaphore implements java.io.Serializable &#123;\n  &#x2F;&#x2F;第一组，默认一次获取或释放的许可（permit）个数为1\n  public void acquire() throws InterruptedException &#123;&#125;&#x2F;&#x2F;可中断获取\n  public void acquireUninterruptibly() &#123;&#125;&#x2F;&#x2F;不可中断获取\n  public boolean tryAcquire()&#123;&#125;;&#x2F;&#x2F;非阻塞获取\n  public boolean tryAcquire(long timeout, TimeUnit unit)&#x2F;&#x2F;可超时获取\n        throws InterruptedException &#123;&#125;\n  public void release()&#123;&#125;\n\n  &#x2F;&#x2F;第二组，默认制定一次获取或释放的许可个数\n  public void acquire(int permits) throws InterruptedException &#123;&#125;&#x2F;&#x2F;可中断获取\n  public void acquireUninterruptibly(int permits) &#123;&#125;&#x2F;&#x2F;不可中断获取\n  public boolean tryAcquire(int permits)&#123;&#125;;&#x2F;&#x2F;非阻塞获取\n  public boolean tryAcquire(int permits, long timeout, TimeUnit unit)&#x2F;&#x2F;可超时获取\n        throws InterruptedException &#123;&#125;\n  public void release(int permits)&#123;&#125;\n&#125;\n应用：共享资源并发访问控制\npublic class QueueSemaphore&#123;\n  private static final int Q_SIZE &#x3D; 20;\n  &#x2F;&#x2F;表示队列中的空闲位置\n  private Semaphore semaphore &#x3D; new Semaphore(Q_SIZE);\n  private list&lt;String&gt; list &#x3D; new ArrayList&lt;&gt;(Q_SIZE);\n  private int count &#x3D; 0;\n  \n  public void put(String elem)&#123;\n    &#x2F;&#x2F;当可用许可个数为0时，线程执行put函数时会阻塞在acquireUniterruptibly()函数中\n    semaphore.acquireUniterruptibly();\n    synchronized(this)&#123;\n      list.add(count, elem);\n      count++;\n    &#125;\n  &#125;\n  public String get()&#123;\n    if(count &#x3D;&#x3D; 0) return null;\n    synchronized(this)&#123;\n      if(count &#x3D;&#x3D; 0) return null;&#x2F;&#x2F;双重检测\n      String ret &#x3D; list.get(--count);\n      semaphore.release();\n      return ret;\n    &#125;\n  &#125;\n&#125;\n原理\n\n调用semaphore.acquire()，线程尝试获取许可证，如果 state &gt;= 0的话，则表示可以获取成功。如果获取成功的话，使用 CAS 操作去修改 state的值 state=state-1。如果 state&lt;0的话，则表示许可证数量不足。此时会创建一个 Node 节点加入阻塞队列，挂起当前线程\n调用semaphore.release();，线程尝试释放许可证，并使用 CAS 操作去修改 state的值 state=state+1。释放许可证成功之后，同时会唤醒同步队列中的一个线程。被唤醒的线程会重新尝试去修改 state的值 state=state-1，如果 state&gt;=0则获取令牌成功，否则重新进入阻塞队列，挂起线程。\n\npublic class Semaphore implements java.io.Serializable &#123;\n  &#x2F;&#x2F;实现AQS，模版模式\n  private final Sync sync;\n  abstract static class Sync extends AbstractQueuedSynchronizer &#123;\n    Sync(int permits) &#123;setState(permits);&#125;\n    protected final boolean tryReleaseShared(int releases) &#123;&#125;\n  &#125;\n\n  static final class NonfairSync extends Sync &#123;\n    NonfairSync(int permits) &#123;super(permits);&#125;\n    protected int tryAcquireShared(int acquires) &#123;\n      return nonfairTryAcquireShared(acquires);\n    &#125;\n  &#125;\n  \n  &#x2F;*\n  final int nonfairTryAcquireShared(int acquires) &#123;\n    for (;;) &#123;\n      int available &#x3D; getState();&#x2F;&#x2F;许可个数存放在state变量中\n      int remaining &#x3D; available - acquires;\n      if (remaining &lt; 0 ||\n          compareAndSetState(available, remaining))\n        return remaining;\n    &#125;\n  &#125;\n  *&#x2F;\n\n  static final class fairSync extends Sync &#123;\n    fairSync(int permits) &#123;super(permits);&#125;\n    protected int tryAcquireShared(int acquires) &#123;\n      for (;;) &#123;\n        if (hasQueuedPredecessors()) return -1;&#x2F;&#x2F;比NonfairSync多了这一行\n        int available &#x3D; getState();\n        int remaining &#x3D; available - acquires;\n        if (remaining &lt; 0 ||\n            compareAndSetState(available, remaining))\n          return remaining;\n      &#125;\n    &#125;\n  &#125;\n\n  public Semaphore(int permits) &#123;&#x2F;&#x2F;默认非公平模式\n    sync &#x3D; new NonfairSync(permits);\n  &#125;\n\n  public Semaphore(int permits, boolean fair) &#123;&#x2F;&#x2F;指定工作模式（公平&#x2F;非公平）\n    sync &#x3D; fair ? new FairSync(permits) : new NonfairSync(permits);\n  &#125;\n  &#x2F;&#x2F;暂时省略核心方法的实现\n&#125;\n\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;acquireUninterruptibly()函数&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n&#x2F;&#x2F;位于Semaphore.java中\npublic void acquireUninterruptibly() &#123;\n  sync.acquireShared(1);\n&#125;\n&#x2F;&#x2F;位于AbstractQueuedSynchronizer.java中\npublic final void acquireShared(int arg) &#123;\n  if (tryAcquireShared(arg) &lt; 0)&#x2F;&#x2F;竞争获取许可，返回值&lt;0表示失败，需要排队等待许可\n    doAcquireShared(arg);&#x2F;&#x2F;排队等待许可\n&#125;\n&#x2F;&#x2F;其中tryAcquireShared()函数的代码实现位于NonfairSync和FairSync中，实现见上\n&#x2F;&#x2F;两种实现均通过自旋+CAS的方式获取许可，唯一区别是从等待队列中取还是可以插队\n\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;release()函数&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n\n2.3Latch&amp;Barrier\nCountDownLatch：等其他线程结束，允许count个线程阻塞在一个地方，直至所有线程的任务都执行完毕（是一次性的，不能重复使用）\npublic class DemoJoin&#123;\n  public static void main(String[] args) throws InterruptedException&#123;\n    Thread t1 &#x3D; new Thread(new RunnableForJoin());\n    THread t2 &#x3D; new THread(new RunnableForJoin());\n    t1.start();\n    t2.start();\n    t1.join();&#x2F;&#x2F;join只用来等待线程执行结束，并且必须知道被等待线程是谁\n    t2.join();\n  &#125;\n  public static class RunnableForJoin implements Runnable&#123;\n    @Override\n    public void run()&#123;\n      &#x2F;&#x2F;业务逻辑\n    &#125;\n  &#125;\n&#125;\npublic class DemoLatch&#123;\n  private static final CountDownLatch latch &#x3D; new CountDownLatch(2);\n  public static void main(String[] args) throws InterruptedException&#123;\n    new Thread(new RunnableForLatch()).start();\n    new Thread(new RunnbaleForLatch()).start();\n    latch.await();&#x2F;&#x2F;等待something执行完成而非等待线程结束，并且不需要知道在等谁\n    &#x2F;&#x2F;执行后续逻辑\n  &#125;\n  public static class RunnableForLatch implements Runnable&#123;\n    @Override\n    public void run()&#123;\n      &#x2F;&#x2F;do something\n      latch.countDown();\n      &#x2F;&#x2F;do otheer thing\n    &#125;\n  &#125;\n&#125;\nCyclicBarrier：CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活\npublic class Demo&#123;\n  &#x2F;&#x2F;创建parties为10的CyclicBarrier对象，用于10个线程之间相互等待，尽管10个线程的启动（执行\n  &#x2F;&#x2F;start函数）的时间不同，但每个线程结束都会调用await函数，将paeties减一，然后检查parties\n  &#x2F;&#x2F;如果不为0，则当前线程阻塞等待，如果parties为0，则当前线程唤醒所有调用了await函数的线程。\n  private static final CyclicBarrier barrier &#x3D; new CyclicBarrier(10);\n  public static void main(String[] args)&#123;\n    for(int i&#x3D;0; i&lt;10; ++i)&#123;\n      new Thread(new Runnbale()&#123;\n        @Override\n        public void run()&#123;\n          try&#123;\n            barrier.await();\n          &#125;catch(InterruptedException e)&#123;&#x2F;&#x2F;当前线程被中断\n            e.printStackTrace();\n          &#125;catch(BrokenBarrierException e)&#123;&#x2F;&#x2F;其他线程调用await()期间被中断\n            e.printStachTrace();\n          &#125;\n          &#x2F;&#x2F;执行业务逻辑\n        &#125;\n      &#125;).start();\n    &#125;\n    &#x2F;&#x2F;主线程需要等待以上10个线程执行结束，方法有以下3种：\n    &#x2F;&#x2F;1.sleep() 2.join() 3.CountDownLatch()\n  &#125;\n&#125;\n\n4.JUC\n1.并发阻塞（xxxBlockingQueue）\n\n\n\n\n\n\n\n\n线程安全和支持读写阻塞，阻塞并发队列一般用于实现生产者-消费者模型\n\nxxxBlockingQueue：ArrayBlockingQueue、LinkedBlockingQueue、LinkedBlockingDeque、PriorityBlockingQueue的实现原理类似，都是基于ReentrantLock锁来实现线程安全，基于Condition条件变量来实现阻塞等待\nArrayBlockingQueue：有界队列实现类，底层采用数组来实现，一旦创建容量不能改变\n使用方法和普通队列类似，只不过增加了读写可阻塞，支持公平和非公平两种工作模式，默认为非公平\n支持读写阻塞的put和take函数（ReentrantLock+Condition）\n非阻塞的offer和poll函数，只通过ReentrantLock锁来保证线程安全，没有通过条件变量来实现阻塞读写\n\n\nLinkedBlockingQueue：基于链表实现的有界阻塞并发队列，默认大小为Integer.MAX_VALUE，可以指定队列大小\nLinkedBlockingDeque：与LinkedBlockingQueue的区别在于，它是一个双端队列，支持两端读写操作\nPriorityBlockingQueue：是一个无界阻塞并发优先级队列，底层基于支持扩容的堆来实现，写操作永远不需要阻塞，只有读操作会阻塞，不可插入null值且插入对象必须可比较大小（comparable）\n\n\nDelayQueue\n延迟阻塞并发队列，底层基于PriorityQueue来实现，因为PriorityQueue支持动态扩容，所以DelayQueue为无界队列，写永远都不会阻塞，只有读会阻塞\nDelayQueue中存储的每个元素都必须实现Delayed接口，提供延迟被读取时间delayTime，PriorityQueue按照delayTime的大小将元素组织成最小顶堆，也就是说，堆顶的元素是delayTime最小的元素，应该最先被读取到\ntake函数，包含两个逻辑，针对leader线程的逻辑和针对非leader线程的逻辑。当多个线程先后调用take函数，第一个线程就是leader线程，剩下的就是非leader线程。第一个线程执行读取操作完成之后，第二个线程便称为leader线程。\n非leader线程直接调用await函数阻塞，等待leader线程执行完成之后调用signal来唤醒\nleader线程读取的是队首的元素，如果队首的元素delayTime大于0，那么leader线程会调用awaitNanos阻塞delayTime时间，当delayTime时间过去之后，leader线程自动唤醒，为了避免假唤醒（插队情况见下），leader线程会检查队首元素的delayTime是否真正变为小于等于0，如果是，则队首元素出队，调用signal唤醒第二个线程，第二个线程就成了leader线程\n插队情况：如果一个线程执行take函数时，如果检查发现队列不为空，并且队首元素的delayTime小于等于0，于是，不管是不是有其他线程在调用await或awaitNanos阻塞等待，这个线程都会直接读取队首元素并返回\n\n\n\n\n较少使用\nSynchronousQueue：用于两个线程之间传递数据，每个put操作必须阻塞等待take操作，队列中不存储任何元素\nLinkedTransferQueue：基于链表实现的无界阻塞并发队列，是LinkedBlockingQueue和SynchronousQueue的综合体，提供了transfer函数，跟SynchronousQueue的put函数的功能相同，调用transfer的线程会一直阻塞，直到数据被其他线程消费才会返回\n\n\n\n2.分段加锁（ConcurrentHashMap）\nHashMap不是线程安全的原因：HashMap 使用了数组和链表（或红黑树）来存储键值对，这些数据结构在多线程环境下可能导致并发问题，包括但不限于以下几点：\n不同线程的并发修改： 当多个线程同时尝试插入、删除或修改键值对时，会导致数据不一致性和不可预测的行为\n遍历问题： 在遍历 HashMap 时，如果一个线程在遍历的过程中另一个线程修改了 HashMap 的结构，可能会导致 ConcurrentModificationException 异常或者遗漏元素\nHash 冲突和重建： HashMap 在内部使用哈希函数来确定元素在数组中的位置。当多个线程同时尝试插入具有相同哈希码但不同键的元素时，可能会导致链表或红黑树的结构被破坏，使得查询和修改操作变得不可预测\n\n\n原理\n底层数据结构：ConcurrentHashMap底层采用数组+链表/红黑树（1.7使用分段数组+链表）\n实现线程安全的方式\nJDK1.7的ConcurrentHashMap：对整个桶数组进行分割分段，每一把锁只锁其中的一部分数据，多线程访问不同段的数据就不会产生锁竞争\nJDK1.8的ConcurrentHashMap：直接用Node数组+链表/红黑树来实现，并发控制使用synchronized和CAS来操作\nTreeNode是存储红黑树节点，被TreeBin包装，TreeBin通过root属性维护红黑树的根节点，因为红黑树在旋转的时候，根节点可能会被它原来的子节点替换掉，在这个时间点如果有其他线程要写这颗红黑树就会产生线程不安全问题，所以在ConcurrentHashMap中TreeBin通过waiter属性维护当前使用这颗红黑树的线程，来防止其他线程的进入\n\n\nConcurrentHashMap比HashTable效率高的原因：ConcurrentHashMap中，table数组被分段加锁，如果table数组的大小为n，那么就对应存在n把锁，每一个链表独享一把锁，不同链表之间的操作可以多线程并行执行，互不影响，以此来提高并发性能。而HashTable使用synchronized（同一把锁）来保证线程安全，效率低，当一个线程使用put时，另一个线程既不能使用put，也不能使用get\n\n\nConcurrentHashMap类\nHashMap、HashTable、ConcurrentHashMap\nHashMap不是线程安全的：在扩容之后的resize时，如果有两个线程同时在resize，一个线程resize结束了，另一个线程才开始resize，这个时候，后开始的线程因为不知道链表结构已经被改变了，所以会继续之前的逻辑，造成链表节点环形引用\nHashTable和ConcurrentHashMap的区别：线程安全的实现方式不同\n底层数据结构：HashTable使用数组加链表；ConcurrentHashMap底层采用数组+链表/红黑树（1.7使用分段数组+链表）\n实现线程安全的方式\nJDK1.7的ConcurrentHashMap：对整个桶数组进行分割分段，每一把锁只锁其中的一部分数据，多线程访问不同段的数据就不会产生锁竞争\nJDK1.8的ConcurrentHashMap：直接用Node数组+链表/红黑树来实现，并发控制使用synchronized和CAS来操作\nHashTable（同一把锁）：使用synchronized来保证线程安全，效率低，当一个线程使用put时，另一个线程既不能使用put，也不能使用get\n\n\nTreeNode是存储红黑树节点，被TreeBin包装，TreeBin通过root属性维护红黑树的根节点，因为红黑树在旋转的时候，根节点可能会被它原来的子节点替换掉，在这个时间点如果有其他线程要写这颗红黑树就会产生线程不安全问题，所以在ConcurrentHashMap中TreeBin通过waiter属性维护当前使用这颗红黑树的线程，来防止其他线程的进入\n\n\n\n\nConcurrentHashMap\nHashTable和SynchronizedMap都通过简单的对所有方法加锁，来解决线程安全问题，SynchronziedMap的引入是为了让JCF框架的类结构更加清晰，线程安全容器和非线程安全容器相分离，线程安全容器通过统一的方式（Collections的synchronizedXXX方法）来创建\nJDK8版本的ConcurrentHashMap比JDK7版本的分段加锁力度更小，并发度更高，扩容方式有所不同，size实现更高效等优势\nConcurrentHashMap中，table数组被分段加锁，如果table数组的大小为n，那么就对应存在n把锁，每一个链表独享一把锁，不同链表之间的操作可以多线程并行执行，互不影响，以此来提高并发性能\n\n\nget函数的实现原理\nget函数就是读操作，没有加锁的处理逻辑，get函数可以跟任何操作（读操作、写操作、树化、扩容）并行执行，并发性能极高\nget与其他操作没有线程安全问题，但get和扩容操作之间因为有线程安全问题，所以需要特殊处理\n\n\nput函数的实现原理\n写操作：两种加锁方式，链表为空的时候，通过CAS操作将table[index]指向写入数据对应的节点；链表不为空，先对头节点使用synchronized加锁，再执行写操作\n树化：写入操作完成后，如果链表中的节点个数大于等于树化阈值（默认为8），put会执行树化操作，尽管是写时复制操作，但是在树化的同时执行写入操作或扩容，会导致数据丢失，因此树化操作也需要使用synchronzied加锁\n扩容：扩容需要对整个table的所有链表加锁，也是通过分段加锁分段执行，对HashMap增加了两点改进\n写时复制：\n在创建好新的table数组之后，采用写时复制的方法，一点点复制，在全部复制完之后，才会将table引用指向新创建的table数组\ntable会出现三种不同类型的链表，已复制未加锁链表、在复制已加锁链表、未复制未加锁链表，根据类型不同决定在那个table处理读、写、树化操作\n类型的标记由新节点类型ForwardingNode标记，此节点类型的hash值为-1。在扩容的时候，将复制完解锁前的链表头节点换成ForwardingNode节点，并将ForwardingNode节点中的nextTable属性指向新创建的table数组，读、写、树化table数组的某个链表时，如果头节点的hash值为-1.就在这个节点的nextTable属性所指向的table数组中重新查找对应的链表，在执行相应操作\n\n\n复制替代搬移：扩容基于复制而非搬移实现，将老的table数组中的节点中的key、value等数据，复制一份存储在一个新创建的节点中，再将新创建的节点插入到新的table数组中\n多个线程共同协作完成扩容：\n每个线程根据transferIndex来决定具体负责哪几个链表的复制，transferIndex初始化为table.length，多个线程通过CAS修改transferIndex共享变量，谁成功更新，谁就获得[transferIndex-stride, transferIndex)之间的stride个链表的复制权，争夺失败的线程自旋重新执行CAS\n执行table引用更新的线程：ConcurrentHashMap定义了一个int类型的sizeCtl变量，用来标记当前正在参与扩容的线程个数，进入和退出的线程通过CAS操作增减sizeCtl，如果变为0，那么这个线程就是最后一个线程，负责引用更新\n\n\n\n\n\n\nsize函数的实现原理\n扫描统计：每次调用size函数时，都把table数组中的所有链表都遍历一遍，统计得到总的元素个数。每次扫描都需要加锁，导致并发性能降低，执行效率也非常低\n实时统计：ConcurrentHashMap中维护一个size成员变量，每当执行增、删元素操作时，同步更新size，无论将size设置为AtomicInteger还是通过CAS更新size，在高并发场景下，都会存在性能问题，进而影戏那个增、删操作的性能\n非一致性统计：借鉴LongAdder的实现思路，每个链表维护一个实时统计的cellSize，表示这个链表的节点个数，当调用size函数时，每个链表的cellSize相加即可得到元素总个数，但会导致统计结果不一致\n\n\n\n\n\n3.写时复制（CopyOnWriteArrayList、CopyOnWriteArraySet）\n主要应用于并发容器中，为了避免读操作和写操作（增、删、改）同时发生而产生的线程安全问题，写时复制将原始容器中的数据复制一份放入新创建的容器，然后对新创建的容器进行写操作，而对读操作继续在原始容器上进行，这样读写之间不会存在数据访问冲突，当写操作执行完成后，新创建的容器替代原始容器\n这样读操作完全不需要加锁，写入也不会阻塞读取操作，只有写入和写入之间需要进行同步等待\n\n\n弱一致性：CopyOnWriteArrayList源码显示，写操作的结果并非对读操作立即可见，这就导致了短暂的数据不一致，称为弱一致性，在某些业务场景下，会引发bug\n解决办法：CopyOnWriteArrayList提供了用于遍历容器的迭代器\n\n\n连续存储：JUC提供了CopyOnWriteArrayList、CopyOnWriteArraySet，却没有提供CopyOnWriteLinkedList、CopyOnWriteHashMap等其他类型的写时复制容器的原因：因为执行写操作需要复制整个数据，对于链表和哈希表来说，因为数据在内存中不是连续存储的，所以耗时非常大，写操作的性能无法满足工业级通用类对性能的要求。CopyOnWriteArrayList、CopyOnWriteArraySet底层都是基于数组来实现的，而且使用了JVM底层提供的native方法，通过C++代码中的指针实现了内存块的快速拷贝\n\n5.无锁编程\nCAS：CAS指的是先检查后更新这类复合操作，全称为Compare And Set或Compare And Swap。在CAS操作失败后，可以选择自旋直到CAS成功 或 执行失败处理相关的业务逻辑\n\n原子类：原子类的每个操作都可以看成是原子操作，在多线程环境下，执行原子类的操作不会出现线程安全问题\n\n\nLongAdder\n\n基本用法\npublic class CounterLongAdder&#123;\n  private LongAdder ladder &#x3D; new LongAdder();\n  \n  public void add(long value)&#123;\n    ladder.add(value);\n  &#125;\n  public long get()&#123;\n    &#x2F;&#x2F;sum用来返回累加之后的总和，高并发情况下，不能返回精确的累加值，为了高性能付出的代价\n    return ladder.sum();\n  &#125;\n&#125;\n数据分片\n\n\n去伪共享：主要用于提高多线程并发执行效率，在DIsruptor高性能消息队列中也有用到\n\n伪共享：CPU操作缓存的最小单元是缓存行，不同CPU上的缓存行大小不同，可以为32字节、64字节或128字节。计算Cell对象大小，Cell对象头占12字节，value成员变量为long类型，占8个字节，对象头与value成员变量之间有4字节对齐填充，所以一个Cell对象占24字节，如果一个缓存行大小为64字节，那么两个Cell对象就可能存储在同一个缓存行中。当t1更改cellA的时候，会把缓存行设为无效，导致t2对cellB的缓存也会失效，t1和t2互相影响，导致缓存频繁失效\n为了解决伪共享的问题，可以使用@Contended注解。标记在类上会强制这个类的对象独占一个缓存行，不够的做对齐填充，标记在变量上的作用相同，强制这个变量独占一个缓存行\n\n\n非准确求和：LongAdder中的sum()函数会累加base和cells中的Cell对象的value值，和便是最终的累加值。但这个值是不准确的。因为LongAdder在执行sum()函数时，并没有加锁，也就是说，在执行sum()的同时，有可能其他线程正在执行add()函数。所以会使得累加值不准确\n\n\n\nThreadLocal（又称线程本地存储区「Thread Local Storage，简称为 TLS」）：使用ThreadLocal线程局部变量替代共享变量，以实现在不需要加锁的情况下达到线程安全。其作用域范围介于类的成员变量和函数内局部变量之间，既是线程私有的，又可以在函数之间共享，不但避免了线程安全问题，还能避免参数传递带来的代码耦合问题\n\n每个线程都有自己的私有的本地存储区域，不同线程之间彼此不能访问对方的 TLS 区域。使用 ThreadLocal 变量 的 set(T value)方法可以将数据存入该线程本地存储区，使用 get() 方法可以获取到之前存入的值\n\n实现原理\npublic class ThreadLocal&lt;T&gt; &#123;\n\n    &#x2F;**\n     * 下面的 getMap()方法 传入当前线程，获得一个ThreadLocalMap对象，说明每一个线程维护了\n     * 自己的一个 map，保证读取出来的value是自己线程的。\n     *\n     * ThreadLocalMap 是ThreadLocal静态内部类，存储value的键值就是ThreadLocal本身。\n     *\n     * 因此可以断定，每个线程维护一个ThreadLocalMap的键值对映射Map。不同线程的Map的 key值 是一样的，\n     * 都是ThreadLocal，但 value 是不同的。\n     *&#x2F;\n    public T get() &#123;\n        Thread t &#x3D; Thread.currentThread();\n        ThreadLocalMap map &#x3D; getMap(t);\n        if (map !&#x3D; null) &#123;\n            ThreadLocalMap.Entry e &#x3D; map.getEntry(this);\n            if (e !&#x3D; null) &#123;\n                @SuppressWarnings(&quot;unchecked&quot;)\n                T result &#x3D; (T)e.value;\n                return result;\n            &#125;\n        &#125;\n        return setInitialValue();\n    &#125;\n\n    public void set(T value) &#123;\n        Thread t &#x3D; Thread.currentThread();\n        ThreadLocalMap map &#x3D; getMap(t);\n        if (map !&#x3D; null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n    &#125;\n&#125;\n\n\nUnsafe类\n\nUnsafe对象的获取\npublic final class Unsafe &#123;\n  &#x2F;&#x2F; 单例对象\n  private static final Unsafe theUnsafe;\n  ......\n  private Unsafe() &#123;\n  &#125;\n  @CallerSensitive\n  public static Unsafe getUnsafe() &#123;\n    Class var0 &#x3D; Reflection.getCallerClass();\n    &#x2F;&#x2F; 仅在引导类加载器&#96;BootstrapClassLoader&#96;加载时才合法，在我们去调用他的时候，因为类加载器不对，会抛出异常\n    if(!VM.isSystemDomainLoader(var0.getClassLoader())) &#123;\n      throw new SecurityException(&quot;Unsafe&quot;);\n    &#125; else &#123;\n      return theUnsafe;\n    &#125;\n  &#125;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;正确的获取方式&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\nField field &#x3D; Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);\nfield.setAccessible(true);\nreturn (Unsafe)field.get(null);\nUnsafe功能\n\n内存操作：内存分配、调整大小、设置为指定值、内存拷贝、内存释放\n\n使用的是堆外内存，好处如下：\n对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是 JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在 GC 时减少回收停顿对于应用的影响。\n提升程序 I/O 操作的性能。通常在 I/O 通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。\n\n\n\nprivate void memoryTest() &#123;\n    int size &#x3D; 4;\n    long addr &#x3D; unsafe.allocateMemory(size);&#x2F;&#x2F;4字节长度\n    long addr3 &#x3D; unsafe.reallocateMemory(addr, size * 2);&#x2F;&#x2F;重新分配一块8字节长度\n    System.out.println(&quot;addr: &quot;+addr);\n    System.out.println(&quot;addr3: &quot;+addr3);\n    try &#123;\n        unsafe.setMemory(null,addr ,size,(byte)1);\n        for (int i &#x3D; 0; i &lt; 2; i++) &#123;\n            unsafe.copyMemory(null,addr,null,addr3+size*i,4);\n        &#125;\n        System.out.println(unsafe.getInt(addr));\n        System.out.println(unsafe.getLong(addr3));\n    &#125;finally &#123;\n        unsafe.freeMemory(addr);\n        unsafe.freeMemory(addr3);\n    &#125;\n&#125;\n内存屏障（例子：StampedLock）\n\n通过阻止编译器和CPU对代码进行重排序，内存屏障就是阻止屏障两边的指令重排序来避免编译器和硬件的不正确优化\n内存屏障可以看做对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作\n主要解决：运行中的线程不是直接读取主内存中的变量的，只能操作自己工作内存中的变量，然后同步到主内存中，并且线程的工作内存是不能共享的。但是子线程借助于主内存，通过屏障，将修改后的结果同步给了主线程，进而修改主线程中的工作空间\n\n&#x2F;&#x2F;内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前\npublic native void loadFence();\n&#x2F;&#x2F;内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前\npublic native void storeFence();\n&#x2F;&#x2F;内存屏障，禁止load、store操作重排序\npublic native void fullFence();\n对象操作\n\n可以通过内存偏移量获取字段值\n\n\n数据操作\n\nCAS 操作\n\n线程调度\n\nClass 操作\n\n类加载：\n静态变量的操作方法：\n\n\n系统信息：返回系统相关信息，如系统指针的大小（addressSize）、内存页的大小（pageSize）\n\n\n\n\n\nFuture类\n\n\n\n\n\n\n\n\n\nFuture模式：异步思想的典型应用，主要用在一些执行耗时任务的场景，避免程序一直原地等待耗时任务执行完成，将耗时任务交给一个子线程来异步执行，等事情干完后，再通过Future类获取到耗时任务的执行结果\n\nJava中Future是JUC包下的一个泛型接口，定义了5个方法，主要包括下面4个功能\n\n取消任务\n判断任务是否取消\n判断任务是否已经执行完成\n获取任务执行结果\n\n&#x2F;&#x2F; V 代表了Future执行的任务返回值的类型\npublic interface Future&lt;V&gt; &#123;\n    &#x2F;&#x2F; 取消任务执行\n    &#x2F;&#x2F; 成功取消返回 true，否则返回 false\n    boolean cancel(boolean mayInterruptIfRunning);\n    &#x2F;&#x2F; 判断任务是否被取消\n    boolean isCancelled();\n    &#x2F;&#x2F; 判断任务是否已经执行完成\n    boolean isDone();\n    &#x2F;&#x2F; 获取任务执行结果\n    V get() throws InterruptedException, ExecutionException;\n    &#x2F;&#x2F; 指定时间内没有返回计算结果就抛出 TimeOutException 异常\n    V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutExceptio\n\n&#125;\nCallable和Future有什么关系\n\nFutureTask提供了Future接口的基本实现，常用来封装Callable和Runnable，具有取消任务、查看任务是否执行完成以及获取任务执行结果的方法，可以作为任务直接被线程执行\n&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);\nFuture&lt;?&gt; submit(Runnable task);\nFutureTask相当于对Callable 进行了封装，管理着任务执行的情况，存储了 Callable 的 call 方法的任务执行结果\n\n\n\nFuture实现阻塞等待获取结果的原理\n\n任务提交： 当一个任务被提交给 ExecutorService（通常是线程池）时，它会返回一个 Future 对象，该对象代表了任务的执行状态和结果。\n\n状态管理： Future 内部维护了任务的执行状态和结果，通常可以有以下几种状态：\n\n等待状态： 任务还没有执行完成，get() 方法调用时会阻塞等待。\n完成状态： 任务已经执行完成，结果可用。\n异常状态： 任务执行过程中抛出了异常。\n\n\n等待结果： 当调用 Future 对象的 get() 方法时，如果任务已经完成，它会立即返回结果。如果任务还未完成，get() 方法会阻塞当前线程，直到任务完成。\n\n线程同步： 在 get() 方法内部，会使用线程同步机制（通常是 wait() 和 notify() 或 Lock）来等待任务完成状态的通知。当任务完成时，它会唤醒等待的线程。\n\n异常处理： 如果任务执行过程中抛出了异常，get() 方法会将异常包装成 ExecutionException 并抛出。你可以通过捕获 ExecutionException 来获取底层任务抛出的异常。\n\n取消任务： Future 通常还提供了取消任务的方法，允许在任务尚未执行或正在执行时取消它。取消任务会将 Future 置于已完成状态，但可以通过 isCancelled() 方法来检查是否取消成功。\n\n\n\nCompletableFuture类\n\n\nFuture在实际使用过程中存在一些局限性比如不支持异步任务的编排组合、获取计算结果的 get()方法为阻塞调用，Java8引入CompletableFuture类来解决这些缺陷\nCompletableFuture同时实现了 Future和 CompletionStage接口\nCompletionStage接口描述了一个异步计算的阶段，很多计算可以分成多个阶段或步骤，此时可以通过它将所有步骤组合起来，行成异步计算的流水线\n\n\n\n\n\n6.补充\n乐观锁和悲观锁\n\n悲观锁总是假设最坏的情况，认为共享资源每次访问的时候都会出现问题，所以每次在获取资源的时候都会上锁，如synchronized、ReentrantLock等独占锁，常用于多写场景\n\n乐观锁总是假设最好的情况，认为共享资源每次访问的时候都不会出现问题，无需加锁也无需等待，所以只是在提交修改的时候去验证对应的资源是否被其他线程修改了，如JUC的atomic包下面的原子变量类使用了乐观锁的一种实现方式CAS实现的，常用于多读场景\n\n乐观锁存在哪些问题（ABA问题、循环时间长、只能保证一个共享变量的原子操作）\n\nABA问题：如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回 A，那 CAS 操作就会误认为它从来没有被修改过。这个问题被称为 CAS 操作的 \n“ABA”问题。\n\nABA 问题的解决思路是在变量前面追加上版本号或者时间戳\n\n\n循环时间长：CAS经常会用到自旋操作来进行重试，如果长时间不成功，会给 CPU 带来非常大的执行开销\n\n如果 JVM 能支持处理器提供的 pause指令那么效率会有一定的提升，pause 指令有两个作用：\n可以延迟流水线执行指令，使 CPU 不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零\n可以避免在退出循环的时候因内存顺序冲而引起 CPU 流水线被清空，从而提高 CPU 的执行效率\n\n\n\n\nCAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5 开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作\n\n\n\n乐观锁实现方式一：版本号机制\n\n一般是在数据表中加上一个数据版本号 version字段，表示数据被修改的次数。当数据被修改时，version值会加一。当线程 A 要更新数据值时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值为当前数据库中的version 值相等时才更新，否则重试更新操作，直到更新成功\n\n\n乐观锁实现方式一：CAS算法\n\nCAS 的全称是 Compare And Swap（比较与交换），用于实现乐观锁，被广泛应用于各大框架中。CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新\nCAS 是一个原子操作，底层依赖于一条 CPU 的原子指令。CAS涉及到三个操作数，当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。\nV ：要更新的变量值(Var)\nE ：预期值(Expected)\nN ：拟写入的新值(New)\n\n\n当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作\n\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;Unsafe类提供了方法来实现CAS操作，内部使用C++内联汇编来实现\n&#x2F;**\n\t*  CAS\n  * @param o         包含要修改field的对象\n  * @param offset    对象中某field的偏移量\n  * @param expected  期望值\n  * @param update    更新值\n  * @return          true | false\n  *&#x2F;\npublic final native boolean compareAndSwapObject(Object o, long offset,  Object expected, Object update);\n\npublic final native boolean compareAndSwapInt(Object o, long offset, int expected,int update);\n\npublic final native boolean compareAndSwapLong(Object o, long offset, long expected, long update);\n\n\n使用场景\n\n乐观锁： 通常适用于多读少写的情况，即并发冲突较少发生。当多个线程可以并发读取数据，但只有少数线程会尝试写入数据时，乐观锁是一个不错的选择。它避免了不必要的阻塞，提高了并发性能。\n消息中间件： 在消息队列中，多个消费者可以并行处理消息，但每个消息有一个版本号，消费者在处理消息前会检查版本号，确保不会重复处理。\n缓存： 在缓存中，使用版本号或时间戳来控制数据的更新，避免同时更新相同的缓存项。\nJava： 使用 Atomic 类，如 AtomicInteger 或 AtomicLong，来实现乐观锁，可以在多线程环境中进行原子操作。\n数据库： 乐观锁通常通过在数据表中添加一个版本号字段（例如，version）来实现。更新数据时，检查版本号是否仍然匹配，如果匹配，则允许更新。\n\n\n悲观锁： 适用于多写少读或并发冲突频繁发生的情况。当多个线程需要同时修改数据，或者存在潜在的数据冲突风险时，悲观锁可以确保数据的一致性。悲观锁可能导致较多的线程阻塞等待锁，因此在高并发情况下，需要慎重使用，以避免性能问题。\n消息中间件： 在消息队列中，可以使用锁来确保只有一个消费者处理特定消息，防止重复处理。\n缓存： 在缓存中，可以使用锁来保护共享资源，确保只有一个线程可以修改。\nJava： 使用 synchronized 关键字或 ReentrantLock 来创建临界区，确保只有一个线程可以访问关键部分的代码。\n数据库： 数据库中的行级锁和表级锁就是悲观锁的一种实现方式，例如，使用 SELECT ... FOR UPDATE 语句。\n\n\n\n\n\n\n线程暂停的四种方法\n\njoin：线程A在运行期间，可以调用线程B的join()方法，让线程B和线程A联合。这样，线程A就必须等待线程B执行完毕后，才能继续执行\nsleep：使用当前正在执行的线程休眠millis秒，线程处于阻塞状态\nyield：当前正在执行的线程暂停一次，允许其他线程执行，不阻塞，线程进入就绪状态，如果没有其他等待执行的线程，这个时候当前线程就会马上恢复执行\nstop：强迫线程停止执行，已过时，不推荐使用\n\n\n把ArrayList变成线程安全有哪些方法\n\n使用Collections.synchronizedList()方法将ArrayList转换为线程安全的list，会通过在访问方法上添加synchronized方法来保证线程安全\nList&lt;Type&gt; synchronizedList &#x3D; Collections.synchronizedList(new ArrayList&lt;&gt;());\n使用CopyOnWriteArrayList类来替代ArrayList，通过写时复制机制来保证写操作的线程安全性，在读操作时不需要添加锁，提高读取效率\nList&lt;Type&gt; threadSafeList &#x3D; new CopyOnWriteArrayList&lt;&gt;();\n显式使用同步控制： 使用 synchronized 来锁定对 ArrayList 的访问，确保一次只有一个线程可以修改列表\nList&lt;Type&gt; arrayList &#x3D; new ArrayList&lt;&gt;();\nsynchronized (arrayList) &#123;\n    &#x2F;&#x2F; 在这里执行对 arrayList 的操作\n&#125;\n使用Lock接口来实现同步，可以用ReentrantLock类来实现对ArrayList的同步操作，该类提供了与synchronized类似的功能，但是提供了更灵活的操作，如trylock()\n\n使用读写锁，用ReentrantReadWriteLock类来实现对ArrayList的读写操作的同步，该类提供了读锁和写锁两种锁，多个线程可以同时获取读锁，但是只有一个线程可以获取写锁，写操作前先获取写锁\n\n\n\n两个线程按顺序交替输出1-100\n\n解法一：原子类\npublic class PrintNumber extends Thread &#123;\n    private static AtomicInteger cnt &#x3D; new AtomicInteger();\n    private int id;\n    public PrintNumber(int id) &#123;\n        this.id &#x3D; id;\n    &#125;\n    @Override\n    public void run() &#123;\n        while (cnt.get() &lt;&#x3D; 100) &#123;\n            while (cnt.get() % 2 &#x3D;&#x3D; id) &#123;\n              \t&#x2F;&#x2F;这两句不可调换位置，保证incr后下一个线程才能get并进入循环\n              \tSystem.out.println(&quot;Thread &quot; + id + &quot; : &quot; + cnt);\n                cnt.incrementAndGet();\n            &#125;\n        &#125;\n    &#125;\n    public static void main(String[] args) &#123;\n        Thread thread0 &#x3D; new PrintNumber(0);\n        Thread thread1 &#x3D; new PrintNumber(1);\n        thread0.start();\n        thread1.start();\n    &#125;\n&#125;\n解法二：synchronized关键字\npublic class PrintNumber extends Thread &#123;\n    private static int cnt &#x3D; 0;\n    private int id;  &#x2F;&#x2F; 线程编号\n    public PrintNumber(int id) &#123;\n        this.id &#x3D; id;\n    &#125;\n    @Override\n    public void run() &#123;\n        while (cnt &lt;&#x3D; 100) &#123;\n            while (cnt%2 &#x3D;&#x3D; id) &#123;\n                synchronized (PrintNumber.class) &#123;\n                    cnt++;\n              \t\t\tSystem.out.println(&quot;Thread &quot; + id + &quot; : &quot; + cnt);\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    public static void main(String[] args) &#123;\n        Thread thread0 &#x3D; new PrintNumber(0);\n        Thread thread1 &#x3D; new PrintNumber(1);\n        thread0.start();\n        thread1.start();\n    &#125;\n&#125;\n解法三：wait和notify机制\n@Override\npublic void run() &#123;\n    while (cnt &lt;&#x3D; 100) &#123;\n        synchronized (PrintNumber.class) &#123;\n            cnt++;\n            System.out.println(&quot;Thread &quot; + id + &quot; : &quot; + cnt);\n            PrintNumber.class.notify();\n            try &#123;\n                PrintNumber.class.wait();\n            &#125; catch (InterruptedException e) &#123;\n                e.printStackTrace();\n            &#125;\n        &#125;\n    &#125;\n&#125;\n解法四：ReentrantLock：Lock、Condition的signal和await\npublic class PrintNumber extends Thread &#123;\n    private static Lock lock &#x3D; new ReentrantLock();\n    private static Condition condition &#x3D; lock.newCondition();\n    private int id;\n    private static int cnt &#x3D; 0;\n    public PrintNumber(int id) &#123;\n        this.id &#x3D; id;\n    &#125;\n    private static void print(int id) &#123;\n    &#125;\n    @Override\n    public void run() &#123;\n        while (cnt &lt;&#x3D; 100) &#123;\n            lock.lock();\n            System.out.println(&quot;Thread &quot; + id + &quot; : &quot; + cnt);\n            cnt++;\n            condition.signal();\n            try &#123;\n                condition.await();\n            &#125; catch (InterruptedException e) &#123;\n                e.printStackTrace();\n            &#125;\n            lock.unlock();\n        &#125;\n    &#125;\n    public static void main(String[] args) &#123;\n        Thread thread0 &#x3D; new PrintNumber(0);\n        Thread thread1 &#x3D; new PrintNumber(1);\n        thread0.start();\n        thread1.start();\n    &#125;\n&#125;\n其它问题\n\n如果是三个线程交替输出：三个线程的解法可以使用while (cnt%3 == id)的方式实现忙等，但简单的唤醒+等待的方式必然不适用了， 没有判断的synchronized必然实现不了，java Object的notify和wait方法只能唤醒全部线程，然后另外两个线程输出前都需要额外判断下是否轮到自己输出了。这时候lock中condition的优势就体现出来了，它可以通过设置不同的condition来实现不同线程的精确唤醒。\n使用while做条件判断（虚假唤醒）：由于把所有线程都唤醒了，但是只有其中一部分是有用的唤醒操作，其余的唤醒都是无用功，对于不应该被唤醒的线程而言，便是虚假唤醒。如果使用if则会使得假唤醒的线程继续执行已经不满足条件的后续操作，但是使用while的时候会保证在继续执行时再次判断是否满足条件，解决假唤醒问题\n\n\n\n\n\n\n","slug":"Java Concurrent","date":"2023-04-13T23:56:43.000Z","categories_index":"","tags_index":"language","author_index":"Dajunnnnnn"},{"id":"b4296f0600f693552b5b6c6b665f6025","title":"Java特性","content":"Java1.基础知识1.关键字\ntrue, false, 和 null 虽然不是关键字，但它们是不能用作标识符的文字和保留字\nstrictfp（精确浮点数，跨平台产生相同结果）、native（原生方法）\ntransient关键字：用于修饰类的成员变量（字段）。当一个字段被声明为 transient 时，它告诉 Java 虚拟机不要将该字段持久化（序列化）到对象的持久化存储（如磁盘或网络传输）中。换句话说，transient 用于暂时排除特定字段不参与对象的序列化和反序列化过程（反序列化时会被赋值为默认值），使用场景如下：\n敏感信息： 如果一个对象包含密码、密钥或其他敏感信息的字段，你可能不希望这些信息在序列化时暴露，可以将这些字段标记为 transient\n临时状态： 有些字段表示对象的临时状态，而不需要在序列化过程中保存。例如，计数器字段或缓存字段\n不可序列化的对象引用： 如果一个对象引用了其他不可序列化的对象，将这个字段标记为 transient 可以防止序列化失败\n\n\n\n\n\n\nclass\nreturn\nbyte\ntry\nif\n\n\n\nimport\npublic\nboolean\ncache\nelse\n\n\nextends\nprotected\nshort\nfinally\nfor\n\n\nimplements\nprivate\nint\nthrow\nwhile\n\n\nenum\n==final==\nchar\nthrows\ndo\n\n\ninterface\n==static==\nlong\nresource\nswitch\n\n\npackage\nabstract\nfloat\n==volatile==\ncase\n\n\nnew\nnative\ndouble\n==synchronized==\ndefault\n\n\nsuper\nconst\nvoid\n==transient==\nbreak\n\n\nthis\ngoto\ninstanceof\nstrictfp\ncontinue\n\n\n2.概念辨析\n值传递与引用传递\n\n引用类型（数组、接口、类）的数据存储在堆上，栈上存储的是堆的地址，直接更改对象对所有引用都可见，但不能像C++那样让引用指向新的对象\n引用数据判等：==判断两个引用是否指向同一对象，equals方法+重写的hashcode方法判断属性是否相等\n\n\n深拷贝、浅拷贝、引用拷贝\n\n深拷贝与浅拷贝：深拷贝会复制整个对象，包括对象包含的内部对象；浅拷贝会在堆上创建一个新对象，但是对象内部引用类型变量只会复制引用地址，不会直接复制内部数据\n\n引用拷贝：两个不同引用指向同一对象\n\n示例\npublic class Address implements Cloneable&#123;\n    private String name;\n    &#x2F;&#x2F; 省略构造函数、Getter&amp;Setter方法\n    @Override\n    public Address clone() &#123;\n        try &#123;\n            return (Address) super.clone();\n        &#125; catch (CloneNotSupportedException e) &#123;\n            throw new AssertionError();\n        &#125;\n    &#125;\n&#125;\n\npublic class Person implements Cloneable &#123;\n    private Address address;\n    &#x2F;&#x2F; 省略构造函数、Getter&amp;Setter方法\n    @Override\n    public Person clone() &#123;\n        try &#123;\n\t\t\t\t\t\t&#x2F;&#x2F;浅拷贝\n            Person person &#x3D; (Person) super.clone();\n            return person;\n        &#125; catch (CloneNotSupportedException e) &#123;\n            throw new AssertionError();\n        &#125;\n    &#125;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;浅拷贝&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\nPerson person1 &#x3D; new Person(new Address(&quot;武汉&quot;));\nPerson person1Copy &#x3D; person1.clone();\n&#x2F;&#x2F; true\nSystem.out.println(person1.getAddress() &#x3D;&#x3D; person1Copy.getAddress());\n\n\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;深拷贝&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n@Override\npublic Person clone() &#123;\n    try &#123;\n        Person person &#x3D; (Person) super.clone();\n\t\t\t\t&#x2F;&#x2F;深拷贝\n        person.setAddress(person.getAddress().clone());\n        return person;\n    &#125; catch (CloneNotSupportedException e) &#123;\n        throw new AssertionError();\n    &#125;\n&#125;\nPerson person1 &#x3D; new Person(new Address(&quot;武汉&quot;));\nPerson person1Copy &#x3D; person1.clone();\n&#x2F;&#x2F; false\nSystem.out.println(person1.getAddress() &#x3D;&#x3D; person1Copy.getAddress());\n\n\n重载和重写的区别\n\n重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理（如构造函数）；重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，就要覆盖父类方法（如Override）\n如果方法的返回类型是 void 和基本数据类型，则返回值重写时不可修改。但是如果方法的返回值是引用类型，重写时是可以返回该引用类型的子类的\n\n\n接口和抽象类\n\n共同点：都不能被实例化、都可以包含抽象方法，都可以有默认实现方法（default声明，子类可不实d现）\n不同点：\n接口主要是对API声明（参数类型、返回值类型、函数名），抽象类主要是为了代码复用\n一个类可以实现多个接口，但只能继承自一个抽象类\n接口中的成员变量只能是public static final类型的，不能被修改且必须有初始值，而抽象类的成员变量默认default，可在子类中被重新定义，也可被重新赋值\n\n\n\n\nfinal和static\n\n只有成员变量能被static、public、protected、private修饰，局部变量不行，但是两者都能被final修饰\nlamdba表达式和匿名类为什么要将变量final：\nfinal是不可变的，线程安全，确保了在匿名类或Lambda表达式内部使用的变量的值不会在外部范围中被改变，从而避免了在多线程环境下可能出现的问题（避免共享变量被其他线程修改）\n\n\n\n\n\n引用类型转换：仅限于有继承关系的类之间，分为向上转换和向下转换两种\n\n向上转换，自动类型转换，总是可以的\n向下转换需要保证转换的对象本身就是子类类型的，只不过暂时转换为了父类型，现在只是再转回去而已\n\n\n基本数据类型和包装类\n\n整数类型（Integer Types）：\nbyte：包装类型为 Byte，占用 1 个字节（8 位）。\nshort：包装类型为 Short，占用 2 个字节（16 位）。\nint：包装类型为 Integer，占用 4 个字节（32 位）。\nlong：包装类型为 Long，占用 8 个字节（64 位）。\n\n\n浮点数类型（Floating-Point Types）：\nfloat：包装类型为 Float，占用 4 个字节（32 位）。\ndouble：包装类型为 Double，占用 8 个字节（64 位）。\n\n\n字符类型（Character Type）：\nchar：包装类型为 Character，占用 2 个字节（16 位）。\n\n\n布尔类型（Boolean Type）：\nboolean：包装类型为 Boolean，理论上占用 1 位，但在内存中通常占用 1 个字节。\n\n\n\n\n面向对象与面向过程\n\n面向过程就是把问题分解成一个一个函数，然后调用函数去解决问题。而面向对象就是把这个世界抽象成一个一个对象，然后赋予这些对象一个属性，成员变量和方法，然后去调用对象的方法去解决问题，耦合性比较低\n面向对象可以提高代码的复用性和扩展性、出现问题可以对每个模块单独调试\n\n\n序列化和反序列化\n\n序列化就是将数据结构或对象转换成二进制字节流的过程，反序列化就是将序列化生成的二进制字节流转换成数据结构或对象的过程\n实现Serializable接口，即可使用JDK自带的序列化\nserialVersionUID：属于版本控制的作用，反序列化时，会检查其是否和当前类的serialVersionUID一致，反序列化之后，static变量并没有被序列化，因为他是静态变量，位于方法区，反序列化时就像是默认赋予给了对象一样\n\n\n常见应用场景：网络传输、数据库存储、对象存储到内存中\n不想进行序列化的变量：使用transient关键字修饰，transient可以阻止实例中那些用此关键字修饰的变量序列化，当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复\ntransient只能修饰变量，不能修饰类和方法\ntransient修饰的变量，在反序列化后变量会被置成类型的默认值（如int会被置为0）\nstatic变量因为不属于任何对象，所以无论有没有transient修饰，均不会被序列化\n\n\n\n\ncomparable 和 Comparator 的区别\n\nComparable接口出自java.lang包，它有一个compareTo(Object obj)方法用来排序\n\n一般用在自己的类声明中，在声明的过程中实现Comparable接口\n&#x2F;&#x2F;通过this和参数来比较\n@Override\npublic int compareTo(Person o) &#123;\n    if (this.age &gt; o.getAge()) &#123;\n        return 1;\n    &#125;\n    if (this.age &lt; o.getAge()) &#123;\n        return -1;\n    &#125;\n    return 0;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;使用&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic static void main(String[] args) &#123;\n\t\t&#x2F;&#x2F;要么传入的key实现comparable接口，要么构造时传入的comparator接口的匿名对象\n    TreeMap&lt;Person, String&gt; pdata &#x3D; new TreeMap&lt;Person, String&gt;();\n    pdata.put(new Person(&quot;张三&quot;, 30), &quot;zhangsan&quot;);\n    pdata.put(new Person(&quot;李四&quot;, 20), &quot;lisi&quot;);\n    pdata.put(new Person(&quot;王五&quot;, 10), &quot;wangwu&quot;);\n    pdata.put(new Person(&quot;小红&quot;, 5), &quot;xiaohong&quot;);\n    &#x2F;&#x2F; 得到key的值的同时得到key所对应的值\n    Set&lt;Person&gt; keys &#x3D; pdata.keySet();\n    for (Person key : keys) &#123;\n        System.out.println(key.getAge() + &quot;-&quot; + key.getName());\n\n    &#125;\n&#125;\n\n\nComparator接口实际上是出自java.util包，它有一个compare(Object obj1, Object obj2)方法用来排序\n\n通过实现Comparator接口的对象，作为参数传递新的比较方法到工具类（sort方法）中\n&#x2F;&#x2F;通过传入的两个参数，确定比较规则，返回比较结果\nCollections.sort(arrayList, new Comparator&lt;Integer&gt;() &#123;\n    @Override\n    public int compare(Integer o1, Integer o2) &#123;\n        return o2.compareTo(o1);\n    &#125;\n&#125;);\n\n\n\n\n\n3.语法糖\nswitch支持String与枚举：int比数、char比ascii码、字符串用hashCode()和equals()，其它如short、byte、int都需要转换为整数\n\n泛型和类型擦除：编译时会使用泛型做类型检查，但是当代码编译为字节码之后，泛型中的类型参数和通配符都替换为上界限（==类型擦除==）\n\n常用通配符\n\n?通配符（Wildcard）：表示不确定的类型。它通常与泛型方法一起使用，用于接受不特定类型的参数\n\n? extends T通配符：表示某种类型的子类型，其中T是某个类或接口。用于限制方法的参数类型为T或T的子类型\n\n? super T通配符：表示某种类型的父类型，其中T是某个类或接口。用于限制方法的参数类型为T或T的父类型\n\n\n\n泛型遇到重载：因为都会转成父类型，所以List&lt;String&gt;和List&lt;Integer&gt;这种重载会编译失败\n\n当泛型遇到catch：泛型的类型参数不能用在catch语句中，因为异常处理是由JVM在运行时刻来进行的，类型信息被擦除了，所以JVM是无法区分两个异常类型MyException&lt;String&gt;和MyException&lt;Integer&gt;的\n\n创建对象时：不能使用new T()来创建类型参数对象，在代码编译成字节之后类型信息已经擦除，所以，在运行时，JVM无法确定具体类型，也就无法知道T是否存在无参构造函数\n\n当泛型内包含静态变量：由于经过类型擦除，所有的泛型类实例都关联到同一份字节码上，泛型类的所有静态变量是共享的\npublic class StaticTest&#123;\n    public static void main(String[] args)&#123;\n        GT&lt;Integer&gt; gti &#x3D; new GT&lt;Integer&gt;();\n        gti.var&#x3D;1;\n        GT&lt;String&gt; gts &#x3D; new GT&lt;String&gt;();\n        gts.var&#x3D;2;\n        System.out.println(gti.var); &#x2F;&#x2F;输出为2\n    &#125;\n&#125;\nclass GT&lt;T&gt;&#123;\n    public static int var&#x3D;0;\n    public void nothing(T x)&#123;&#125;\n&#125;\n因为需要继承自Object，所以基本类型不可以传入类型参数，只有引用类型可以。但是有语法糖可以让List&lt;int&gt;中的int替换为Integer，但是开发上依旧需要为每个基本类型分别定义多个不同的函数接口\n\n\n\n自动装箱与拆箱：\n\n原理\n\n自动装箱是将基本数据类型转换为对应的包装类型的过程：编译器会自动调用包装类型的构造函数将基本数据类型的值封装成包装类型对象\n\n自动拆箱是将包装类型转换为基本数据类型的过程：编译器会自动调用包装类型的 xxxValue() 方法（例如 intValue()、doubleValue()）将包装类型对象的值提取出来\n\n\n\n基本类型和包装类型的区别：包装类型不赋值时是null，可用于范型，占用空间大\n\n基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 static 修饰 ）存放在 Java 虚拟机的堆中。包装类型属于对象类型，几乎所有对象实例都存在于堆中（JIT优化，逃逸分析，分配到栈上）\n基本数据类型存放在栈中是一个常见的误区！基本数据类型的成员变量如果没有被 static修饰的话（不建议这么使用，应该要使用基本数据类型对应的包装类型），就存放在堆中\n类静态成员变量存放在方法区中！（方法区又叫静态区，跟堆一样，被所有线程共享，方法区包含所有的class和static变量）\n\n\n常量池（包装类型的缓存机制）\n\nInteger等包装类使用了常量池技术，IntegerCache类（享元模式）中会缓存值为-128到127之间的Integer对象，当通过自动装箱，也就是调用valueOf()来创建Integer对象时，如果要创建的Integer对象的值在-128到127之间，会从IntegerCache中直接返回，否则才会真正调用new方法创建，详见Integer类的valueOf()（JVM也提供了方法，可以自定义缓存的最大值）\n\nByte、Short、Integer、Long这四种包装类默认创建了数值[-128,128]的相应类型的缓存数据（存放在一个Cache数组中，由static代码块直接初始化），Character创建了数值在[0，127]范围的缓存数据，Boolean直接返回True或False（return (b ? TRUE : FALSE);）\n\n所有整型包装类对象之间值的比较，全部使用 equals 方法比较\nInteger i1 &#x3D; 40; &#x2F;&#x2F;触发自动装箱，使用缓存中的对象\nInteger i2 &#x3D; new Integer(40); &#x2F;&#x2F;新创建的对象\nSystem.out.println(i1&#x3D;&#x3D;i2); &#x2F;&#x2F;返回false\n\n\n示例代码：项目首选基本类型，业务相关可选包装类用null表示空而不是0\n&#x2F;&#x2F;自动装箱，语法糖，底层实现为：Integer iobj &#x3D; Integer。valueOf(12);\nInteger iobj &#x3D; 12;\n&#x2F;&#x2F;自动拆箱，语法糖，底层实现为：int i &#x3D; iobj.intValue();\nint i &#x3D; iobj;\n\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;触发自动装箱和拆箱的几种情况&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\n&#x2F;&#x2F;将基本类型数据赋值给包装类变量（包括参数传递）时，触发自动装箱\nint i1 &#x3D; 5\nInteger iobj1 &#x3D; 5;&#x2F;&#x2F;1\niobj &#x3D; i1;&#x2F;&#x2F;1\nList&lt;Integer&gt; list &#x3D; new ArrayList&lt;&gt;();\nlist.add(i1);&#x2F;&#x2F;1\n&#x2F;&#x2F;将包装类对象赋值给基本类型变量（包括参数传递）时，触发自动拆箱\nInteger iobj2&#x3D; new Integer(6);\nint i2 &#x3D; iobj2;&#x2F;&#x2F;2\n&#x2F;&#x2F;当包装类对象参与算术运算、关系运算（&lt;,&gt;）时，触发自动拆箱操作\nInteger iobj3 &#x3D; iobj1 + iobj2;\nboolean bl &#x3D; (iobj1 &lt; iobj2);\nbl &#x3D; (iobj1 &lt; 2);\n&#x2F;&#x2F;当包装类对象参与关系运算（&#x3D;&#x3D;），且另一方是基本类型数据时，触发自动拆箱操作。\nInteger iobj4 &#x3D; new Integer(123);\nbl &#x3D; (iob4 &#x3D;&#x3D; 123);\n\n\n方法变长参数：String… args用一个数组实现，用foreach遍历，编译后会被转变成数组\n\n枚举：当我们使用enum来定义一个枚举类型的时候，编译器会自动创建一个final类型的类继承Enum类，所以枚举类型不能被继承（public enum t&#123;&#125; =&gt; public final class T extends Enum&#123;&#125;）\n\n内部类：\n\n会独立于外部类，生成一个新的class文件，名字为外部类名$内部类名.class或外部类名$[序号].class，静态匿名内部类可访问静态成员变量+静态函数；普通匿名内部类不可访问外部函数中非final修饰的局部变量\n外部函数通过类似参数传递的方式，将局部变量通过值传递的方式传入到匿名内部类，这是外部函数局部变量的副本，所以如果能访问非final修饰的局部变量的话，内部类对其的更改不起作用，违反直觉，类似于形参的改变不影响实参\n\npublic interface I&#123;&#125;\npublic class A&#123;\n    private class B&#123;&#125; &#x2F;&#x2F;类似于ArrayList的内部类Itr\n    private class C implements I&#123;&#125;&#x2F;&#x2F;实现外部接口的内部类\n    public class D&#123;&#125;&#x2F;&#x2F;public修饰的内部类\n\t\tpublic static class E&#123;&#125;&#x2F;&#x2F;静态内部类\n    \n    public B getB()&#123; return new B(); &#125;\n    public I getC()&#123; return new C(); &#125;\n    public D getD()&#123; return new D(); &#125;\n&#125;\npublic class Demo&#123;\n    public static void main(String[] args)&#123;\n        A a &#x3D; new A();\n        A.B b &#x3D; a.getB();&#x2F;&#x2F;编译报错，满足封装原则\n        I c &#x3D; a.getC();&#x2F;&#x2F;可访问\n        A.D d1 &#x3D; a.getD();\n        A.D d2 &#x3D; a.new D();\n\t\t\t\tA.E e &#x3D; new A.E();&#x2F;&#x2F;静态内部类的对象可以独立于外部类单独创建\n    &#125;\n&#125;\n条件编译：if的条件是final且为false时，对应代码块不被编译，主要出于对代码优化的考虑\n\n断言：其实断言的底层实现就是if语言，如果断言结果为true，则什么都不做，程序继续执行，如果断言结果为false，则程序抛出AssertError来打断程序的执行\n\n数值字面量：不管是整数还是浮点数，都允许在数字之间插入任意多个下划线，为了方便阅读\n\n增强for循环：for-each用了普通的for循环和Iterator迭代器的hasNext()方法，在遍历过程中不能增删内部元素，会抛出异常（可以使用Iterator.remove()方法在删除当前迭代对象的同时维护索引的一致性）\n\ntry-with-resource：在try()中写资源申请，就不用在finally中判断是否为null在关闭了，编译期帮助我们关闭了（资源类需要实现Java.lang.AutoClosale接口）\n\nlambda表达式：只有一个函数的接口叫做函数式接口，可以用Lambda表达式简化\n\nLambda表达式\n(类型 a,类型 b)-&gt;&#123;语句1;语句2; ... ;return 输出;&#125;&#x2F;&#x2F;a，b为输入参数\n(a,b)-&gt;&#123;语句1;语句2; ... ;return 输出;&#125;&#x2F;&#x2F;a，b为输入参数\na-&gt;&#123;语句1;语句2; ... ;return 输出;&#125;&#x2F;&#x2F;a为输入参数\n&#123;语句1;语句2; ... ;return 输出;&#125;&#x2F;&#x2F;没有入参\n方法引用：当Lambda中的逻辑已经有现成的方法实现时，可以直接使用方法引用。方法引用要求所引用的方法的参数列表的返回值，跟函数接口中未实现方法的参数列表和返回值完全一致，格式如下\n&#x2F;&#x2F;对象::实例方法\n&#x2F;&#x2F;类::静态方法\n&#x2F;&#x2F;类::实例方法\npublic class FPDemo &#123;\n    public static void main(String] args) &#123;\n        List&lt;String&gt; strList &#x3D; Arrays.asList(&quot;wz-a.java&quot;, &quot;wz-b.txt&quot;, &quot;c.java&quot;);\n        strList.stream()\n\t\t\t\t\t\t&#x2F;&#x2F;直接引用String的方法\n            .filter(((Predicate&lt;String&gt;) String::isEmpty).negate())\n            &#x2F;&#x2F; .filter(s-&gt;s.isEmpty())\n            .filter(s-&gt;s.startsWith(&quot;wz-&quot;))\n            .map(String::length)\n            &#x2F;&#x2F;.map(s-&gt;s.length())\n            .forEach(l-&gt;System.out.printIn(I));&#x2F;&#x2F;输出9、8\n    &#125;\n&#125;\n\n\n\n2.进阶知识1.特殊语法\n反射：在运行的过程中动态告知JVM去创建对象、创建方法、获取类信息（构造函数、方法、成员变量、注解），重要应用见Spring框架的依赖注入\n\n核心概念\n\nClass类：是一个存储类的信息的特殊的类，提供了大量的方法，可以获取类的信息，比如获取类中的方法，获取构造函数，获取成员变量等\n\nConstructor类：用来存储构造函数的信息，如通过newInstance()方法来进行有参/无参构造\nMethod类：存储方法的信息，如通过invoke()方法可以执行类中的对应方法\nField类：用来存储成员变量的信息\n\n\njava.lang.reflect 包：这个包提供了一组类，如Method、Field、Constructor等，用于描述和操作类的成员。\n\n获取反射的三种方法\n\n通过对象获取反射\nObject obj &#x3D; new Object(); &#x2F;&#x2F; 创建一个对象\nClass&lt;?&gt; clazz &#x3D; obj.getClass(); &#x2F;&#x2F; 获取 Class 对象\n通过类名获取反射\nClass&lt;?&gt; clazz &#x3D; Class.forName(&quot;com.example.MyClass&quot;); &#x2F;&#x2F; 获取 Class 对象\n通过类字面常量获取反射\nClass&lt;?&gt; clazz &#x3D; MyClass.class; &#x2F;&#x2F; 获取 Class 对象\n\n\n\n\n用途：根据类的全限定名在运行时加载类、通过反射示例化编译时无法确定的类、可以读取和修改类的字段（包括私有字段）、在运行时处理和解析注解、动态调用类的方法（传递参数并获取返回值）\n\n缺点\n\n性能开销：反射通常比直接调用代码要慢，因为它涉及到动态查找和方法调用。这可能会在需要高性能的应用程序中成为性能瓶颈\n编译时类型检查问题：由于反射允许在运行时操作类，因此编译器无法进行类型检查，可能导致在运行时出现类类型转换异常（ClassCastException）或其他错误，而不是在编译时捕获错误\n反射攻击：在Constructor、Method、Field类，包含一个公共的方法，能够改变构造函数、方法、成员变量的访问权限public void setAccessible(boolean flag)，利用这个方法，可以将私有的构造函数、方法、成员变量设置为可以访问的，这样就可以超越权限限制，在代码中访问私有的构造函数、方法和成员变量（打破单例类只能实例化一个对象的限制的情况）\n\n\n\n\n注解：注解相当于给元素打了一个tag，任何编译器或者应用程序通过反射可以访问的代码元素，都可以用注解去标识\n\n功能：添加代码的元数据（作者、版本、用途）在编译时生成文档或代码分析；编译期检查（使用 @Override 来确保方法重写正确）；代码生成和处理（根据配置文件生成代码、Spring依赖注入、JUnit单元测试）；减少配置文件、提升代码可读性\n\n自定义注解：通过反射来读取注解，重要应用为Spring用注解代替XML配置文件\n&#x2F;&#x2F;Java内建注解\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.SOURCE)\npublic @interface Override &#123;\n&#125;\n\n&#x2F;&#x2F;自定义注解\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\npublic @interface RateLimit &#123;\n\tpublic enum TimeUnit &#123; SECOND,MINUTE, HOUR, DAY,MONTH&#125;\n    string apiName();\n\tint limitCount();\n\tTimeUnit timeUnit() default TimeUnit.SECOND;\n&#125;\n元注解\n\n@Target：用来描述注解的使用范围（如类、接口、方法、成员变量等）\n@Retention：用来描述注解的可见范围、或叫生命周期（如源码可见、字节码可见、运行时可见）\n@Documented：表示注解信息会输出到Javadoc文档中\n@interface：class、interface、enum、@interface这四者是平级关系，@interface用来定义注解，在注解中，还可以定义一些变量，特殊的是注解使用方法来定义变量，对于只有一个变量的注解，可以将其定义为value，这样，在使用时，可以不指定变量的名称\n\n\n实践应用\n\n替代注释：Guava提供@VisibleForTesting注解在方法上进行标记，这个注解只起到注释的作用，并没有实际的作用\n作为标记：Java中有一种特殊的接口，叫做标记接口（Marker Interface）。标记接口中不包含任何方法，跟注解类似，起到标记作用，比如RandomAccess、Cloneable、Serializable，可以根据标记接口判断对象是否可以执行某些操作\n替代XML文件\n@Configuration注解修饰的类中的@Bean创建首字母小写的对象\n@Component注解创建同名对象，使用@Autowired注入对象\n\n\n\n\n\n\n动态代理\n\n静态代理：通过实现接口或继承的方式，通过注入原始类并添加新功能的方式实现。实现简单，但会导致项目中的类成倍增加，所有相关的类都需要增加代理类，重复代码多\n动态代理\n一般静态指的编译阶段，动态指的运行阶段。在代理模式上，静态代理指的是在编译阶段时生成代理类的字节码，动态代理指的是运行时生成代理类的字节码，且字节码只存在与内存中，并不会生成对应的class文件\n之所以可以实现动态代理，是因为JVM设计得非常灵活，只要是符合类的格式的字节码，都可以在运行时被JVM解析并加载，不管这个字节码是来自预先编译好的(class文件)，还是在内存中临时生成的(典型应用:动态代理)，又或者从网络加载而来的(典型应用: Applet)。这部分内容涉及到JVM的类加载机制，见JVM\n实现方法一：利用JDK提供的类来实现（InvocationHandler接口+Proxy类）\n&#x2F;&#x2F;为UserController类实现动态代理，当为其它Controller类中的方法也添加时间统计代码时，\n&#x2F;&#x2F;可以复用CtrlProxyHandler类，并通过Proxy类的newProxyInstance()静态方法生成对应的代理类对象\npublic class CtrlProxyHandler implements InvocationHandler &#123;\n    private Object origBean;\n\n    public CtrlProxyHandler(Object origBean) &#123;\n        this.origBean &#x3D; origBean;\n    &#125;\n    @override\n    public Object invoke(Object proxy， Method method, Object[] args) throws Throwable &#123;\n        long startTime &#x3D; system.currentTimeMillis();\n        \n\t\t\t\t&#x2F;&#x2F;所有方法的调用都会变成调用invoke方法，参数为生成的代理类、要调用的方法、对应的参数\n\t\t\t\t&#x2F;&#x2F;通过Proxy类的newProxyInstance()创建的代理对象在调用方法的时候，实际会调用到实现InvocationHandler接口的类的\n\t\t\t\t&#x2F;&#x2F;invoke()方法，可以在invoke()方法中自定义处理逻辑，比如在方法执行前后做什么事情\n        Object res &#x3D; method.invoke(origBean, args);\n        \n        long costTime &#x3D; System.currentTimeMillis() - startTime;\n        System.out.printIn(origBean.getClass().getSimpleName()+&quot;#&quot;+ method.getName() + &quot; cost time: &quot; + costTime);\n        return res;\n    &#125;\n&#125;\n\npublic class JDKProxyDemo &#123;\n    public static void main(String] args) &#123;\n        UserController userController &#x3D; new UserController();\n        CtrlProxyHandler handler &#x3D; new CtrlProxyHandler(userController);\n        &#x2F;&#x2F;用Proxy的静态方法生成代理类\n        IUserController userControllerProxy &#x3D; (IUserController)Proxy.newProxyInstance\n            (handler.getClass().getClassLoader(), UserController.class.getInterfaces(), handler);\n        userControllerProxy.login(&quot;139********&quot;，&quot;*********&quot;);\n    &#125;\n&#125;\n\n\nnewProxyInstance函数：\npublic static Object newProxyInstance(\n    ClassLoader loader, Class&lt;?&gt;[]interfaces,InvocationHandler h)&#123;\n\t\t&#x2F;&#x2F;参数为：被代理的类的类加载器（上面的代码都是同一个类加载器AppClassLoader，但是如果定义了别的类加载器就需要注意）、\n\t\t&#x2F;&#x2F;被代理的类实现的所有接口、动态代理处理器（实现InvocationHandler接口，重写invoke方法）\n    \n    &#x2F;&#x2F;1)生成动态代理类\n    &#x2F;&#x2F;2)加载动态代理类\n\t\t&#x2F;&#x2F;动态代理类具有哪些方法：只跟接口有关，跟原始类没有任何关系，这也是基于JDK实现的动态代理要求原始类必须有接口定义才行\n    Class&lt;?&gt; cl&#x3D; getProxyClass0(loader, intfs);\n\n    &#x2F;&#x2F;3)实例化动态代理类对象\n    final Class&lt;?&gt;[] constructorParams &#x3D; &#123; InvocationHandler.class &#125;;\n    final Constructor&lt;?&gt; cons &#x3D; cl.getConstructor(constructorParams);\n    return cons.newlnstance(new Object]&#123;h);\n&#125;d f\n\n\nClassLoader loaderloader表示类加载器，用于加载动态代理类到JVM\nClass&lt;?&gt;[] interfaces用于生成动态代理类，接口中的方法就是动态代理类包含的方法\nInvocationHandler h用于创建（实例化）动态代理类对象\n\n\nProxyGenerator类：newProxyInstance()函数调用ProxyGenerator类(JDK提供的生成字节码的类)，按照类的字节码格式，生成动态代理类的字节码，并存储到内存（proxyClassFile）中\n&#x2F;&#x2F;生成动态代理类的名称\nfinal String proxyClassNamePrefix &#x3D; &quot;$Proxy&quot;;\nlong num &#x3D; nextUniqueNumber.getAndIncrement();\nString proxyName &#x3D; proxyPkg + proxyClassNamePrefix + num;\n\n&#x2F;&#x2F;ProxyGenerator类似字节码类库，可以生成动态代理类的字节码\nbyte[] proxyClassFile &#x3D; ProxyGenerator.generateProxyClass(\n    proxyName, interfaces, accessFlags);\ntry &#123;\n    &#x2F;&#x2F;通过JVM的类加载器来加载动态代理类\n    return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length);\n&#125; \ncatch(ClassFormatError e) &#123; &#x2F;&#x2F;如果生成的动态代理类的字节码格式有误，则报错\n    throw new lllegalArgumentException(e.toString());\n&#125;\n\n\n实现方法二：使用第三方的字节码类库来实现，比如CGLIB、BECL、ASM、Javassit等直接编辑字节码\n\n\n\n\n\n\n\n\n2.工具类\nString\nString不可变的原因\nfinal修饰的数组，数组内容是可变的private final char value[];\n但是String没有暴露更改该数组的公共方法\n因为String类是final修饰的，所以子类无法继承，避免了子类破坏String的不可变性\n\n\n常量池技术\nString类型跟Integer等包装类类似，使用常量池技术，并且==只有使用字符串常量赋值时，才触发==，如果字符串常量在常量池中已经创建过，则直接使用已经创建的对象。用new创建的对象不在常量池中\n除了使用字符串常量赋值外，还可以使用intern()方法，将分配在堆上的String对象，原模原样在常量池中复制一份。当无法用字符串常量赋值，但又有大量重复字符串时，就可以使用intern()方法复制到常量池中，代码中使用常量池中的String对象，原String对象就被JVM回收掉\n示例\nString a = &quot;123&quot;; 这行代码创建了一个字符串变量 a 并将其初始化为字符串文字 “123”。在JVM中，这将在字符串常量池中创建一个字符串对象，如果常量池中已经存在相同内容的字符串，则会重用现有的对象。\nString b = new String(&quot;456&quot;); 这行代码创建了一个字符串变量 b 并将其初始化为通过new关键字创建的字符串对象，内容为 “456”。不同于上一行，这里会在堆内存中创建一个新的字符串对象，即使内容与常量池中的相同。这是因为使用new关键字强制创建了一个新对象。\nString c = a + b; 这行代码创建了一个字符串变量 c，并将其初始化为将字符串 a 和字符串 b 连接起来的结果。这种字符串连接操作会在堆内存中创建一个新的字符串对象，其中包含了 “123456”。原始的 a 和 b 字符串对象不受影响，因为字符串在Java中是不可变的，所以每次修改字符串都会创建一个新的字符串对象。\n\n\n\n\n其它\nsubstring()\nsubstring(int beginIndex, int endIndex)方法截取并返回下标在[beginIndex, endIndex)范围内的子串\n在JDK7及其以上版本中，substring()方法会生成新的String对象来存储子串，但如果传入参数正好等于字符串的长度，那么会返回字符串本身，不会创建新对象\n在JDK6及以前的版本，通过substring()方法获取到的子串会共享char数组，并有count和offset属性标志子串的长度和起点\n\n\n运算符重载：C++能直接重载运算符，但Java并不支持（重载运算符是函数式编程、并且语法太复杂），但是String类却实现了加法操作String sc = sa + sb;，主要是因为String比较常用，所以延续了基本类型及其包装类的设计，这样使用起来就方便和统一\nStringBuilder与StringBuffer\n因为String不可变，用+拼接效率低，每次都需要创建新的String对象，所以Java设计了StringBuilder，StringBuilder支持修改和动态扩容，可以用append()函数拼接，可以把StringBuilder看作是char类型的ArrayList（ArrayList），在平时开发中，经常用+号连接多个字符串，实际上底层就采用StringBuilder来实现。\nStringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder并没有对方法进行加同步锁，所以是非线程安全的。相同情况下使用 StringBuilder相比使用 StringBuffer仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。\n\n\n\n\n\n\nCollections\nsort()：用来对List进行排序，默认为从小到大，支持传入Comparator接口的匿名类改为降序，底层依赖Arrays\n基本类型数组排序算法：JDK8及以后使用DualPivotQuickSort()，JDK7及其以前使用快排，使用不稳定排序\nDualPivotQuickSort根据长度和元素类型，使用双轴快速排序算法、插入排序、计数排序、归并排序等算法来组合进行排序操作\n\n\n对象数组排序算法：JDK8及其以后使用TimSort()，JDK7及其以前使用归并排序，使用的是稳定的排序方式\nTimSort用非递归版本归并排序，归并到阈值后开始进行二分插入排序算法，即在插入时选择用二分查找来确定插入位置\n\n\n\n\nbinarySearch()：用来对已排序的List容器进行二分查找，因为涉及元素比较，所以需要传入实现Comparable接口的对象或者主动传入Comparator接口的匿名类对象\nindexedBinarySearch：查找mid使用的是链表的get函数，需要从头遍历链表来得到对应值\niteratorBinarySearch：查找mid使用的是新定义的get函数，从上一次迭代器的位置（mid）开始向前或向后查找，需要遍历的范围变小了，执行效率就变高了\n\n\nsynchronizedXXX()：JCF中的容器都是非线程安全的，当要使用线程安全的容器时，首选使用JUC并发容器，但当没有合适的JUC并发容器可以使用时，可以使用Collectinos类中的synchronizedXXX()函数来创建线程安全的容器\n\n\nArrays\n\n3.JCF框架\n\nArrayList动态扩容：在增加元素的时候要检测是否需要扩容，首先确定最小扩容量（最小是10），然后判断是否需要扩容（最小扩容量大于当前数组长度），执行grow函数进行扩容，扩容为原来的1.5倍，如果不够的话就直接使用最小扩容量来作为长度，避免多次扩容，若是1.5倍长度大于数组最大长度，则需要看最小扩容量是否大于最大容量，如果是则为MAX_VALUE否则为MAX_VALUE-8\npublic boolean add(E e) &#123;\n    ensureCapacityInternal(size + 1);  &#x2F;&#x2F; Increments modCount!!\n    elementData[size++] &#x3D; e;\n    return true;\n&#125;\n\nprivate void ensureCapacityInternal(int minCapacity) &#123;\n    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));\n&#125;\n\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;确定是否需要扩容，主要用在添加大量元素之前，减少增量分配的次数，通过提前扩容，可以提升性能&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\npublic void ensureCapacity(int minCapacity) &#123;\n    int minExpand &#x3D; (elementData !&#x3D; DEFAULTCAPACITY_EMPTY_ELEMENTDATA)\n        &#x2F;&#x2F; any size if not default element table\n        ? 0\n        &#x2F;&#x2F; larger than default for default empty table. It&#39;s already\n        &#x2F;&#x2F; supposed to be at default size.\n        : DEFAULT_CAPACITY;\n\t\t&#x2F;&#x2F;如果期待最小容量大于已有的最大容量\n    if (minCapacity &gt; minExpand) &#123;\n        ensureExplicitCapacity(minCapacity);\n    &#125;\n&#125;\n&#x2F;&#x2F;得到最小扩容量\nprivate static int calculateCapacity(Object[] elementData, int minCapacity) &#123;\n    if (elementData &#x3D;&#x3D; DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;\n        return Math.max(DEFAULT_CAPACITY, minCapacity);\n    &#125;\n    return minCapacity;\n&#125;\n&#x2F;&#x2F;得到最小扩容量，通过最小扩容量扩容\nprivate void ensureCapacityInternal(int minCapacity) &#123;\n    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));\n&#125;\n&#x2F;&#x2F;判断是否需要扩容\nprivate void ensureExplicitCapacity(int minCapacity) &#123;\n    modCount++;\n\n    &#x2F;&#x2F; overflow-conscious code\n    if (minCapacity - elementData.length &gt; 0)\n\t\t\t\t&#x2F;&#x2F;调用grow方法进行扩容，调用此方法代表已经开始扩容了\n        grow(minCapacity);\n&#125;\nprivate void grow(int minCapacity) &#123;\n    &#x2F;&#x2F;oldCapacity为旧容量，newCapacity为新容量\n    int oldCapacity &#x3D; elementData.length;\n    &#x2F;&#x2F;将oldCapacity 右移一位，其效果相当于oldCapacity &#x2F;2，\n    &#x2F;&#x2F;我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，\n    int newCapacity &#x3D; oldCapacity + (oldCapacity &gt;&gt; 1);\n    &#x2F;&#x2F;然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，\n    if (newCapacity - minCapacity &lt; 0)\n        newCapacity &#x3D; minCapacity;\n    &#x2F;&#x2F;再检查新容量是否超出了ArrayList所定义的最大容量，\n    &#x2F;&#x2F;若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE，\n    &#x2F;&#x2F;如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为MAX_ARRAY_SIZE。\n    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)\n        newCapacity &#x3D; hugeCapacity(minCapacity);\n    &#x2F;&#x2F; minCapacity is usually close to size, so this is a win:\n    elementData &#x3D; Arrays.copyOf(elementData, newCapacity);\n&#125;\n&#x2F;&#x2F;比较minCapacity和MAX_ARRAY_SIZE\nprivate static int hugeCapacity(int minCapacity) &#123;\n    if (minCapacity &lt; 0) &#x2F;&#x2F; overflow\n        throw new OutOfMemoryError();\n    return (minCapacity &gt; MAX_ARRAY_SIZE) ?\n        Integer.MAX_VALUE :\n        MAX_ARRAY_SIZE;\n&#125;\nHashMap\n\n\nSet容器包括HashSet、LinkedHashSet、TreeSet，从代码实现上来说，这三个类底层分别是依赖HashMap、LinkedHashMap、TreeMap。例如：往HashSet中存储对象obj，底层将obj作为key，一个空的Object对象作为value，一并存储到HashMap中\n\n底层为哈希表，对key求哈希作为hash值，包裹hash值、key和value为Node对象，作为哈希表（数组+链表）的组成节点。key不能重复，存储重复的key，新value会覆盖旧value（可以存一个key为null的键值对，但是不同key的value都可以是null）\n&#x2F;&#x2F; 包含另一个“Map”的构造函数\n public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;\n     this.loadFactor &#x3D; DEFAULT_LOAD_FACTOR;\n     putMapEntries(m, false);&#x2F;&#x2F;下面会分析到这个方法\n &#125;\nfinal void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123;\n    int s &#x3D; m.size();\n    if (s &gt; 0) &#123;\n        &#x2F;&#x2F; 判断table是否已经初始化\n        if (table &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; pre-size\n            &#x2F;&#x2F; 未初始化，s为m的实际元素个数\n            float ft &#x3D; ((float)s &#x2F; loadFactor) + 1.0F;\n            int t &#x3D; ((ft &lt; (float)MAXIMUM_CAPACITY) ?\n                    (int)ft : MAXIMUM_CAPACITY);\n            &#x2F;&#x2F; 计算得到的t大于阈值，则初始化阈值\n            if (t &gt; threshold)\n                threshold &#x3D; tableSizeFor(t);\n        &#125;\n        &#x2F;&#x2F; 已初始化，并且m元素个数大于阈值，进行扩容处理\n        else if (s &gt; threshold)\n            resize();\n        &#x2F;&#x2F; 将m中的所有元素添加至HashMap中\n        for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123;\n            K key &#x3D; e.getKey();\n            V value &#x3D; e.getValue();\n            putVal(hash(key), key, value, false, evict);\n        &#125;\n    &#125;\n&#125;\n哈希函数\nstatic final int hash(Object key) &#123;\n    int h;\n\t\t&#x2F;&#x2F;key为null的值存储在下标为0的位置，但一个HashMap只能存储一个值为null的key\n\t\t&#x2F;&#x2F;hashCode底层为JNI，定义在Object类中，根据对象在内存中的地址来计算哈希值，子类中可以重写\n\t\t&#x2F;&#x2F;h^(h&gt;&gt;&gt;16)：数组长度一般不超过2^16，所以通过将h的高16位和低16位异或，来增加参与运算的信息\n    return (key &#x3D;&#x3D; null) ? 0 : (h &#x3D; key.hashCode()) ^ (h &gt;&gt;&gt; 16);\n&#125;\n&#x2F;&#x2F;确定插入数组时的位置，使用位操作与数组长度n进行取模计算（前提是n为2的幂次方），防止索引越界\nint index &#x3D; hash(key)&amp;(n-1); &#x2F;&#x2F; n-1为 11111，与其进行&amp;运算，相当于对n取余数\n\npublic V get(Object key) &#123;\n    Node&lt;K,V&gt; e;\n    return (e &#x3D; getNode(hash(key), key)) &#x3D;&#x3D; null ? null : e.value;\n&#125;\nfinal Node&lt;K,V&gt; getNode(int hash, Object key) &#123;\n    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;\n    if ((tab &#x3D; table) !&#x3D; null &amp;&amp; (n &#x3D; tab.length) &gt; 0 &amp;&amp;\n        (first &#x3D; tab[(n - 1) &amp; hash]) !&#x3D; null) &#123;&#x2F;&#x2F; hash表不为空，待查找链表有值\n        if (first.hash &#x3D;&#x3D; hash &amp;&amp; &#x2F;&#x2F; always check first node，先查hash(key)，再查key.equals()\n            ((k &#x3D; first.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k))))&#x2F;&#x2F;检测是否哈希冲突\n            return first;\n        if ((e &#x3D; first.next) !&#x3D; null) &#123;\n            if (first instanceof TreeNode) &#x2F;&#x2F;已经树化，进行树上的查找\n                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);\n            do &#123;\n                if (e.hash &#x3D;&#x3D; hash &amp;&amp;\n                    ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k))))\n                    return e;\n            &#125; while ((e &#x3D; e.next) !&#x3D; null);&#x2F;&#x2F;未树化，进行链表上的遍历查找\n        &#125;\n    &#125;\n    return null;\n&#125;\n装载因子：table大小（n）和装载因子（loadFactor）可以用默认的也可以通过构造函数传入，一般为0.75：\n\n权衡时间效率和空间效率之后的结果\n大概是[0.5,1]之间，因为小于0.5会有一半空间从来未用，当大于1时，哈希冲突的概率会大大增加，即使有链表和树化，也会影响性能\n因为table数组的大小n都是2的倍数，而且触发扩容的阈值threshold = n * loadfactor，所以，在[0.5,1]之间，只有0.75能使得得到的阈值一直是整数\n\npublic HashMap(int initialCapacity, float loadFactor) &#123;\n\t\t&#x2F;&#x2F;...initialCapacity和loadFactor的可行性检验代码...\n    this.loadFactor &#x3D; loadFactor;\n\t\t&#x2F;&#x2F;直接赋值的原因：此时table数组只声明未创建，其值为null，在第一次调用put()函数后，\n\t\t&#x2F;&#x2F;HashMap会先用threshold作为数组大小创建table数组，再将其重新赋值为真正的扩容阈值\n\t\t&#x2F;&#x2F;this.table &#x3D; new T[this.threshold];\n\t\t&#x2F;&#x2F;this.threshold *&#x3D; this.factor;\n    this.threshold &#x3D; tableSizeFor(initialCapacity);\n&#125;\n&#x2F;&#x2F;initialCapacity需要是2的幂次方，如果不是，需要寻找比initialCapacity大的第一个2的幂次方数\nstatic final int tableSizeFor(int cap) &#123; &#x2F;&#x2F; 1100  12 应该返回 10000\n    int n &#x3D; cap - 1; &#x2F;&#x2F; 1011\n    n |&#x3D; n &gt;&gt;&gt; 1; &#x2F;&#x2F; 0101 - 1111\n    n |&#x3D; n &gt;&gt;&gt; 2; &#x2F;&#x2F; 0011 - 1111\n    n |&#x3D; n &gt;&gt;&gt; 4; &#x2F;&#x2F; 0000 - 1111\n    n |&#x3D; n &gt;&gt;&gt; 8; &#x2F;&#x2F; 0000 - 1111\n    n |&#x3D; n &gt;&gt;&gt; 16; &#x2F;&#x2F; 0000 - 1111\n    return (n &lt; 0) ? 1 : (n &gt;&#x3D; MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#x2F;&#x2F; 10000 16\n&#125;\n动态扩容：put后，若元素个数超过threshold=n*loadFactor时触发（n为table大小，loadFactor为装载因子）\n\nHashMap的默认初始化大小为16，之后每次扩充容量为原来的2倍，如果指定了大小，也会选择2的幂次来作为初始值\n因为Hashmap的容量大小是2的幂次方，所以可以通过&amp;运算来优化%运算。例如：（16 % 5 ）等价于 （16 &amp; （5 - 1））\n为了能把数据分配均匀，Hash值的范围是-2147483648 到 2147483647，很难碰撞，但是需要对数组取模，操作如上\n\n\n因为容量变大，位置会发生变化，将每个节点的hash值与新的容量取模，取模操作仍可以用位运算来替代，但JDK8中优化为：如果node.hash&amp;oldCap == 0，则节点在新table数组中的下标不变；如果node.hash &amp; oldCap != 0，则节点在新table数组中的下标变为i+oldCap（i为在原数组的下标）\n扫描table数组中的每一条链表，根据节点的下标是否更改，将链表中的节点分配到lo链表和hi链表，lo链表中存储的是下标值未变的节点，hi链表存储的是下标值有所改变的节点。处理完一条链表后，将lo链表和hi链表分别存储到新的table数组中的对应位置\n\npublic V put(K key, V value) &#123;\n    return putVal(hash(key), key, value, false, true);\n&#125;\n\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n               boolean evict) &#123;\n    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;\n    if ((tab &#x3D; table) &#x3D;&#x3D; null || (n &#x3D; tab.length) &#x3D;&#x3D; 0)\n        n &#x3D; (tab &#x3D; resize()).length; &#x2F;&#x2F;使用resize创建新table\n    if ((p &#x3D; tab[i &#x3D; (n - 1) &amp; hash]) &#x3D;&#x3D; null)&#x2F;&#x2F;数组中链表头不存在，初始化\n        tab[i] &#x3D; newNode(hash, key, value, null);\n    else &#123;&#x2F;&#x2F;数组中插入位置有链表头，遍历\n        Node&lt;K,V&gt; e; K k;\n        if (p.hash &#x3D;&#x3D; hash &amp;&amp;\n            ((k &#x3D; p.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k))))&#x2F;&#x2F;先检查第一个节点\n            e &#x3D; p;&#x2F;&#x2F;找到\n        else if (p instanceof TreeNode)\n            e &#x3D; ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);\n        else &#123;\n\t\t\t\t\t\t&#x2F;&#x2F;遍历链表\n            for (int binCount &#x3D; 0; ; ++binCount) &#123;\n                if ((e &#x3D; p.next) &#x3D;&#x3D; null) &#123;&#x2F;&#x2F;没找到，新建节点\n                    p.next &#x3D; newNode(hash, key, value, null);\n\t\t\t\t\t\t\t\t\t\t&#x2F;&#x2F; 如果链表元素个数大于等于TREEIFY_THRESHOLD（8）\n                    if (binCount &gt;&#x3D; TREEIFY_THRESHOLD - 1) &#x2F;&#x2F; -1 for 1st\n                        treeifyBin(tab, hash); &#x2F;&#x2F;树化？红黑树转换，并不会直接转换成红黑树\n                    break;\n                &#125;\n                if (e.hash &#x3D;&#x3D; hash &amp;&amp;\n                    ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) &#x2F;&#x2F;找到\n                    break;\n                p &#x3D; e;&#x2F;&#x2F;继续遍历\n            &#125;\n        &#125;\n        if (e !&#x3D; null) &#123; &#x2F;&#x2F; existing mapping for key\n            V oldValue &#x3D; e.value;\n            if (!onlyIfAbsent || oldValue &#x3D;&#x3D; null)\n                e.value &#x3D; value;&#x2F;&#x2F;更新值\n            afterNodeAccess(e);&#x2F;&#x2F;见LinkedHashMap\n            return oldValue;\n        &#125;\n    &#125;\n    ++modCount;\n    if (++size &gt; threshold)\n        resize();\n    afterNodeInsertion(evict);&#x2F;&#x2F;见LinkedHashMap\n    return null;\n&#125;\n\nfinal Node&lt;K,V&gt;[] resize() &#123;\n    Node&lt;K,V&gt;[] oldTab &#x3D; table;\n    int oldCap &#x3D; (oldTab &#x3D;&#x3D; null) ? 0 : oldTab.length;\n    int oldThr &#x3D; threshold;\n    int newCap, newThr &#x3D; 0;\n    if (oldCap &gt; 0) &#123;\n        &#x2F;&#x2F; 超过最大值就不再扩充了，就只好随你碰撞去吧\n        if (oldCap &gt;&#x3D; MAXIMUM_CAPACITY) &#123;\n            threshold &#x3D; Integer.MAX_VALUE;\n            return oldTab;\n        &#125;\n        &#x2F;&#x2F; 没超过最大值，就扩充为原来的2倍\n        else if ((newCap &#x3D; oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;&#x3D; DEFAULT_INITIAL_CAPACITY)\n            newThr &#x3D; oldThr &lt;&lt; 1; &#x2F;&#x2F; double threshold\n    &#125;\n    else if (oldThr &gt; 0) &#x2F;&#x2F; initial capacity was placed in threshold\n        newCap &#x3D; oldThr;\n    else &#123;\n        &#x2F;&#x2F; signifies using defaults\n        newCap &#x3D; DEFAULT_INITIAL_CAPACITY;\n        newThr &#x3D; (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n    &#125;\n    &#x2F;&#x2F; 计算新的resize上限\n    if (newThr &#x3D;&#x3D; 0) &#123;\n        float ft &#x3D; (float)newCap * loadFactor;\n        newThr &#x3D; (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);\n    &#125;\n    threshold &#x3D; newThr;\n    @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;)\n        Node&lt;K,V&gt;[] newTab &#x3D; (Node&lt;K,V&gt;[])new Node[newCap];\n    table &#x3D; newTab;\n    if (oldTab !&#x3D; null) &#123;\n        &#x2F;&#x2F; 把每个bucket都移动到新的buckets中\n        for (int j &#x3D; 0; j &lt; oldCap; ++j) &#123;\n            Node&lt;K,V&gt; e;\n            if ((e &#x3D; oldTab[j]) !&#x3D; null) &#123;\n                oldTab[j] &#x3D; null;\n                if (e.next &#x3D;&#x3D; null)\n                    newTab[e.hash &amp; (newCap - 1)] &#x3D; e;\n                else if (e instanceof TreeNode)\n                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);\n                else &#123;\n                    Node&lt;K,V&gt; loHead &#x3D; null, loTail &#x3D; null;\n                    Node&lt;K,V&gt; hiHead &#x3D; null, hiTail &#x3D; null;\n                    Node&lt;K,V&gt; next;\n                    do &#123;\n                        next &#x3D; e.next;\n                        &#x2F;&#x2F; 原索引\n                        if ((e.hash &amp; oldCap) &#x3D;&#x3D; 0) &#123;\n                            if (loTail &#x3D;&#x3D; null)\n                                loHead &#x3D; e;\n                            else\n                                loTail.next &#x3D; e;\n                            loTail &#x3D; e;\n                        &#125;\n                        &#x2F;&#x2F; 原索引+oldCap\n                        else &#123;\n                            if (hiTail &#x3D;&#x3D; null)\n                                hiHead &#x3D; e;\n                            else\n                                hiTail.next &#x3D; e;\n                            hiTail &#x3D; e;\n                        &#125;\n                    &#125; while ((e &#x3D; next) !&#x3D; null);\n                    &#x2F;&#x2F; 原索引放到bucket里\n                    if (loTail !&#x3D; null) &#123;\n                        loTail.next &#x3D; null;\n                        newTab[j] &#x3D; loHead;\n                    &#125;\n                    &#x2F;&#x2F; 原索引+oldCap放到bucket里\n                    if (hiTail !&#x3D; null) &#123;\n                        hiTail.next &#x3D; null;\n                        newTab[j + oldCap] &#x3D; hiHead;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    return newTab;\n&#125;\n链表树化：降低单个链表长度（jdk1.8新增的特性，1.7仅有链表）\n\n当某个链表中的节点个数大于等于8（TREEIFY_THRESHOLD静态常量），并且table数组的大小大于等于64时，将会把链表转化为红黑树，这个过程就叫treeify（树化）\n\n如果table数组长度小于64，即便链表中的节点个数大于等于8，也不会触发treeify，而是触发扩容操作，将长链表拆分为短链表\n\n当红黑树中节点个数比较少时，HashMap会再将其转换回链表，因为维护红黑树的成本比较高，对于少许节点，使用链表存储更高效，红黑树转换为链表的过程，叫做untreeify，促发untreeify的场景有以下两个：\n\n删除键值对：如果红黑树满足以下结构，则会触发untreeify，这个结构的红黑树的节点个数应该处于[2,6]之间，尽管treeify的阈值是8，但untreeify的阈值是[2,6]之间的某个数，之所以不相等是为了避免频繁的插入删除操作，导致节点个数在7，8之间频繁波动\n&#x2F;&#x2F;removeTreeNode函数中\nif (root &#x3D;&#x3D; null || root.right &#x3D;&#x3D; null ||\n    (rl &#x3D; root.left) &#x3D;&#x3D; null || rl.left &#x3D;&#x3D; null) &#123;\n    tab[index] &#x3D; first.untreeify(map);  &#x2F;&#x2F; too small\n    return;\n&#125;\n扩容：每一条链表都会分割为lo和hi两条，同理红黑树也会分割为lt和ht两个红黑树，lt中存储的是下标位置不变的节点，ht中存储的是下标位置变化的节点。不过，在构建lt和ht之前，会先统计属于lt和ht的节点个数lc和hc，如果lc小于等于6（UNTREEIFY_THRESHOLD静态常量），在新的table数组中，HashMap会使用链表来存储下标不变的节点，同理，如果hc小于等于6，在新的table数组中，HashMap会使用链表来存储下标改变的节点。\n\n\n\n\n\n红黑树是一种自平衡的二叉查找树，可以保证在最坏情况下基本动态操作的时间复杂度为O(log n)。红黑树中的每个节点都有一个颜色属性，可以是红色或黑色。红黑树满足以下5个性质。通过这些性质，红黑树可以保证在插入和删除节点时，自动调整树的结构，以保持树的平衡和性质的满足。相比于普通的二叉查找树，红黑树的平衡性更好，查找、插入和删除都具有更稳定的时间复杂度，因此在很多场景下被广泛应用。\n\n每个节点要么是红色，要么是黑色。\n根节点是黑色的。\n每个叶子节点（NIL节点，空节点）是黑色的。\n如果一个节点是红色的，则它的两个子节点都是黑色的。\n对于每个节点，从该节点到其所有后代叶子节点的简单路径上，均包含相同数目的黑色节点。\n\n\n\n\nPriorityQueue\n\n优先级队列底层实现：\nPriorityQueue 是一个基于二叉堆（binary heap）实现的优先级队列。二叉堆是一个完全二叉树，具有特殊的性质：父节点的值小于或等于子节点的值。这使得在二叉堆中最小（或最大）元素总是位于堆顶。\nJava中的 PriorityQueue 通过数组来表示二叉堆，实际上并不使用 TreeMap 或 Queue，而是使用堆数据结构进行管理。\n\n\n为什么优先级队列底层不用Queue加上权重：\n优先级队列通常用于按照一定优先级顺序处理元素，而不仅仅是按照队列的先进先出顺序\n使用 Queue 来表示优先级队列并添加权重可能会使实现复杂化。而二叉堆在维护元素的相对优先级时，通常更加高效\nPriorityQueue 通过使用堆来实现优先级队列，可以保持插入和删除元素的时间复杂度为 O(log N)，其中 N 是队列中的元素数量。这在处理大量元素时非常高效。\n\n\n\n\n\n\n4.IO类库\n\nIO类库（装饰器模式、适配器模式、工厂模式、观察者模式）\n\n明确要操作的数据是数据源还是数据目的（要读还是要写）+要操作的数据是字节还是字符（字符流比字节流多了一个字符编码转换的环节）\n\n输入（读）：InputStream （字节）、Reader（字符）\n\n\n输出（写）：OutputStream（字节）、Writer（字符）\n\n\n装饰器模式：实现相同接口，使用组合调用被装饰方法，并在前后增加上新的装饰方法\n&#x2F;&#x2F; 装饰器模式的代码结构(下面的接口也可以替换成抽象类)\npublic interface IA &#123;\n  void f();\n&#125;\npublic class A implements IA &#123;\n  public void f() &#123; &#x2F;&#x2F;... &#125;\n&#125;\npublic class ADecorator implements IA &#123;\n  private IA a;\n  public ADecorator(IA a) &#123;\n    this.a &#x3D; a;\n  &#125;\n  \n  public void f() &#123;\n    &#x2F;&#x2F; 功能增强代码\n    a.f();\n    &#x2F;&#x2F; 功能增强代码\n  &#125;\n&#125;\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;装饰器类是对原始类的增强，不能独立使用，使用方式如下&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\nInputStream in &#x3D; new FileInputStream(&quot;...&quot;);\nInoutStream bin &#x3D; new BufferedInputStream(in);\nbyte[] data &#x3D; new byte[1024];\nwhile(bin.read(data) !&#x3D; -1)&#123;\n    &#x2F;&#x2F;处理data数组\n&#125;\n\n\n明确数据存在的具体设备\n\n硬盘（文件）：Filexxx（4）\nInputStream fis &#x3D; new FileInputStream(&quot;input.txt&quot;)\nwhile ((content &#x3D; fis.read()) !&#x3D; -1) &#123;\n    System.out.print((char) content);\n&#125;\n\nFileOutputStream output &#x3D; new FileOutputStream(&quot;output.txt&quot;)\nbyte[] array &#x3D; &quot;JavaGuide&quot;.getBytes();\noutput.write(array);\n管道：Pipedxxx（4）\n&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;Java中的管道是同一个进程内的两个线程之间通信的工具&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;\nPipedOutputStream out &#x3D; new PipedOutputStream();\ntry &#123;\n    PipedInputStream in &#x3D; new PipedInputStream(out);\n    new Thread(new Runnable() &#123;\n        @Override\n        public void run() &#123;\n            try &#123;\n                out.write(&quot;Hi Dajunnnnnn&quot;.getBytes());\n            &#125; catch (IOException e) &#123;\n                e.printStackTrace();\n            &#125;\n        &#125;\n    &#125;).start();\n    new Thread(new Runnable() &#123;\n        @Override\n        public void run() &#123;\n            byte[] buffer &#x3D; new byte[512];\n            try &#123;\n                in.read(buffer);\n                System.out.println(new String(buffer));\n            &#125; catch (IOException e) &#123;\n                e.printStackTrace();\n            &#125;\n        &#125;\n    &#125;).start();\n&#125; catch (IOException e) &#123;\n    e.printStackTrace();\n&#125;\n内存：CharArrayxxx（字符）、Stringxxx（字符）、ByteArrayxxx（字节）\n\n在大部分情况下，直接对byte数组，char数组进行读写即可，不需要这种内存读写类\n\n情境一：实现兼容，调用第三方类库中的某个函数来处理byte数组中的数据时，但这个函数的入参是InputStream类型的，那么就需要将待处理byte数组封装成ByteArrayInputStream对象，在传递给这个函数\nbyte[] source &#x3D; &quot;测试数据&quot;.getBytes();\nInputStream in &#x3D; new ByteArrayInputStream(source);\n&#x2F;&#x2F;用in代替source继续处理\n情景二：编写单元测试时，这些内存读写类可以替代文件或网路，将测试数据内置于内存，准备起来更加容易\n&#x2F;&#x2F;待测试函数\npublic int readFromFIle(InputStream inputStream)&#123;...&#125;\n\n&#x2F;&#x2F;测试代码\npublic void test_readFromFile()&#123;\n    byte[] testData &#x3D; new byte[512];\n    &#x2F;&#x2F;构建测试数据，填入testData数组\n    InputStream in &#x3D; new ByteInputStream(testData);\n    int res &#x3D; readFromFile(in);\n    &#x2F;&#x2F;assert 判断返回值是否符合预期\n&#125;\n\n\n键盘/屏幕：System.in、System.out、System.err（使用内部的PrintStream和InputStream）\n\n定义在System类中的静态InputStream对象\n定义在System类中的静态PrintStream，需要嵌套OutputStream来使用\n\n\n网络：Socket\n&#x2F;&#x2F;java.io类库并没有提供专门的类用于网络I&#x2F;O的读写，而是直接复用InputStream&#x2F;OutputStream类进行网络I&#x2F;O的读写\nSocket socket &#x3D; new Socket(&quot;127.29.2.4&quot;,8090);\nOutputStream out &#x3D; socket.getOutputStream();\nout.write(&quot;hi&quot;.getBytes());\n\nInputStream in &#x3D; socket.getInputStream();\nbyte[] data &#x3D; new byte[1024];\nwhile(in.read(data) !&#x3D; -1)&#123;\n    &#x2F;&#x2F;do something\n&#125;\n\n\n明确是否需要额外的功能\n\n需要高效（缓冲流，用来包装别的类）：Bufferedxxx（4），在内存中维护一个8192字节的缓存区\n\nBufferedInputStream会在内存中维护一个8192字节大小的缓存，如果缓存中没有足够的数据，那么read()函数会从I/O设备中读取8192个字节存储到缓存中，然后read()函数再从缓存中返回需要的数据量。如果缓存中有足够多的数据，read()函数直接从缓存中读取数据，而不会触发真正I/O操作，可以减少I/O操作的次数，但是如果每次请求的数据量大于等于8192字节，那么BufferedInputStream就不起作用了\n同理OutputStream用于缓存写入I/O设备中的数据，当积攒到一定量（默认为8192字节），再一次性将其写入I/O设备，减少I/O操作的次数，提高程序的性能\n\n&#x2F;&#x2F; 新建一个 BufferedInputStream 对象，需要传入一个原始类对象，通过装饰器设计模式来增加功能\nBufferedInputStream bufferedInputStream &#x3D; new BufferedInputStream(new FileInputStream(&quot;input.txt&quot;));\n&#x2F;&#x2F; 读取文件的内容并复制到 String 对象中\nString result &#x3D; new String(bufferedInputStream.readAllBytes());\nSystem.out.println(result);\n支持基本类型数据读写：DataInputStream、DataOutStream\n\nDataInputStream支持将输入流中读取的数据解析为基本类型（byte、char、short、int、float、double等），DataOutputStream类支持将基本类型数据转化为字节数组写入输出流\n\nDataOutputStream out &#x3D; new DataOutputStream(new FileOutputStream(&quot;...&quot;));\nout.writeInt(12);\nout.writeChar(&quot;a&quot;);\nout.writeFloat(12,12f);\nout.close();\n\nDataIntputStream in &#x3D; new DataInputStream(new FileInputStream(&quot;...&quot;));\nSystem.out.println(in.readInt());\n&#x2F;&#x2F;readChar()、writeChar()也可以按字符为单位读取、写入数据，但是，DataInputStream一次只能处理一个字符，\n&#x2F;&#x2F;而字符流可以处理char数组，并且字符流提供的函数更多，功能更丰富\nSystem.out.println(in.readChar());\nSystem.out.println(in.readFloat());\nin.close();\n支持对象读写：ObjectInputStream、ObjectOutputStream\n&#x2F;&#x2F;ObjectOutputStream支持将对象序列化之后写入到输出流\nObjectOutputStream out &#x3D; new ObjectOutputStream(new FileOutputStream(&quot;.&quot;));\nout.writeObject(new Person(12,&quot;Dajunnnnnn&quot;));\n&#x2F;&#x2F;ObjectInputStream支持将从输入流中读取到的数据反序列化为对象\nObjectInputStream in &#x3D; new ObjectInputStream(new FileInputStream(&quot;.&quot;));\nPerson p &#x3D; (Person) in.readObject();\n保证数据的输出形式（打印流）：PrintStream、PrintWriter\n&#x2F;&#x2F;PrintStream和PrintWrite可以将数据按照一定的格式，转化为字符串，写入到输出流\nPrintStream printStream &#x3D; new PrintStream(new FileOutputStream(&quot;..&quot;));\nprintStream.print(124);&#x2F;&#x2F;int-&gt;Integer-&gt;toString(),写入字符串“124”\nprintStream.print(&quot;hello %d&quot;,43);&#x2F;&#x2F;写入字符串“hello 43”\n需要转换（字符流通向字符的桥梁）：InputStreamReader、OutputStreamWriter\n\nInputStreamReader可以充当InputStream的装饰器类，OutputStreamWriter可以充当OutputStream的装饰器类，它们可以将字节流转化为字符流\n\nOutputStream outStream &#x3D; new FileOutputStream(&quot;&#x2F;Users&#x2F;wangzheng&#x2F;a.txt&quot;);\nOutputStreamWriter writer &#x3D; new OutputStreamWriter(outStream, &quot;gbk&quot;);\nwriter.write(&quot;王a争&quot;); &#x2F;&#x2F;按照gbk编码将字符串写入文件\n回退（允许读取字节，然后再将它们回推到流中）：PushbackInputStream、PushbackReader\nString s &#x3D; &quot;abcdefg&quot;;\ntry (ByteArrayInputStream in &#x3D; new ByteArrayInputStream(s.getBytes());\n\t\t\t\tPushbackInputStream pbin &#x3D; new PushbackInputStream(in)) &#123;\n    int n;\n    while ((n &#x3D; pbin.read()) !&#x3D; -1) &#123;\n        System.out.print((char) n);\n        if(&#39;b&#39; &#x3D;&#x3D; n) pbin.unread(&#39;U&#39;);\n    &#125;&#x2F;&#x2F;输出 abUcdefg\n&#125;\n多个源（序列流）：SequenceInputStream\n\n\n\n\n\nNIO类库（JDK1.4引入，也称：New I/O、Non-blocking I/O、Network I/O，主要用于网络编程）\n\n核心概念：java.nio中引入Channel代替Stream，并且引入新的概念：Buffer，用来存储待写入或读取的数据\n\nBuffer：在IO库中，通常使用byte数组来接收数据，分为字节流解析和字符流解析。在nio中， 将将这些部分抽离出来，封装到Buffer中，通过不同的Channel和不同的Buffer组合在一起，实现不同的IO读写需求（常见的Buffer有：ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer、MappedByteBuffer）\nFileChannel channel &#x3D; FileChannel.open(Paths.get(&quot;...&quot;));\nByteBuffer buffer &#x3D; ByteBuffer.allocate(512);\nwhile(channel.read(buffer) !&#x3D; -1)&#123;\n    &#x2F;&#x2F;处理buffer中的数据data\n&#125;\nChannel：同步（FileChannel、DatagramChannel、SocketChannel、ServerSocketChannel），异步（AdynchronousFileChannel、AsynchronousSocketChannel、AsynchronousServerSocketChannel）\n\n同步\n常用的同步的Channel有：FileChannel（文件）、DatagramChannel（UDP）、SocketChannel（TCP）、ServerSocketChannel（TCP，服务器，即可以使用accept()函数监听客户端SocketChannel的连接请求）\nChannel既可以读也可以写，每个Channel类通过实现不同的接口组合，来支持不同的功能组合\nChannel有两种运行方式：阻塞（等待数据读写）和非阻塞（不等待数据读写）方式，其中除FileChannel只支持阻塞模式外，其余三个都同时支持两种方式，默认为阻塞方式，可以调用configureBlocking(false)函数将其设置为非阻塞模式，非阻塞Channel一般会配合Selector，用于实现多路复用I/O模型\n\n\n异步\njdk7在已有Selector的情况下，进行了升级，引入了支持异步模式的Channel，主要包括：AdynchronousFileChannel、AsynchronousSocketChannel、AsynchronousServerSocketChannel\n在异步模式下，Channel不再注册到Selector，而是注册到操作系统内核中，由内核来通知某个Channel可读、可写或可连接，java.nio收到通知之后，为了不阻塞主线程，会使用线程池去执行事先注册的回调函数\n\n\n\n\nSelector：注册Channel到Selector，Selector隔一段时间轮询是否有Channel可读、可写、可连接\n\n多路复用I/O：用来解决while轮询的问题。为了实现多路复用，Unix提供了epoll库、Windows提供了iocp库、BSD提供了kequeue库，Java作为一种跨平台语言，对不同操作系统的实现进行了封装，提供了统一的Selector，可以将需要监听的Channel，调用registor()函数，注册到Selector中，Selector底层会通过轮询的方式，查看哪些Channel可读、可写、可连接等，并将其返回处理（避免手写轮询代码）\n\nSeverSocketChannel serverChannel &#x3D; ServerSocketChannel.open();\nserverChannel.bind(new InetSocketAddress(&quot;127.0.0.1&quot;,1192));\nserverChannel.configureBlocking(false);\nByteBuffer buffer &#x3D; ByteBuffer.allocate(1024);\n\nSocketChannel clinetChannel &#x3D; null;\n&#x2F;&#x2F;在网络编程中，使用非阻塞模式，线程需要通过while循环，不停轮询调用read()、write()、accept()函数，\n&#x2F;&#x2F;查看是否有数据可读，是否可写，是否有客户端连接到来\nwhile(clinetChannel &#x3D;&#x3D; null)&#123;\n    clientChannel &#x3D; serverChannel.accept();\n&#125;\n\nwhile(clientChannel.read(buffer) &#x3D;&#x3D; -1);\n\nbuffer.flip();&#x2F;&#x2F;将buffer从用于读变成用于写\nwhile(buffer.hasRemaining())&#123;\n    clientChannel.write(buffer);&#x2F;&#x2F;echo,读了啥就写啥\n&#125;\n\n\nJava IO模型：堆Unix5种I/O模型：阻塞I/O模型、非阻塞I/O模型、多路复用I/O模型、信号驱动I/O模型、异步I/O模型的封装\n\n阻塞I/O模型（BIO）：阻塞IO+线程，多线程+read阻塞等待\n\n利用阻塞模式搭配多线程来实现服务器，因为read()是阻塞函数，所以需要提前创建线程池和大量线程，来等待客户端发来的连接。如果有n个客户端连接服务器，那么服务器需要创建n+1个线程，其中n个线程用于调用read()函数，1个线程用来调用accept()函数接收连接。当线程比较多时，内存资源的消耗就会比较大。\n同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间；在客户端连接数量不高时没问题，当面对十万甚至百万连接时会无能为力\n\npublic class BioEchoServer &#123;\n    public static void main(String[] args) throws IOException &#123;\n        ServerSocket serverSocket &#x3D; new ServerSocket();\n        serverSocket.bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 1192));\n        while (true) &#123;\n            &#x2F;&#x2F; accept()为阻塞函数，直到有连接到来才返回\n            Socket clientSocket &#x3D; serverSocket.accept();\n            &#x2F;&#x2F; 为每个客户端单独创建一个线程处理\n            new Thread(new ClientHandler(clientSocket)).start();\n        &#125;\n    &#125;\n\n    private static class ClientHandler implements Runnable &#123;\n        private Socket socket;\n        public ClientHandler(Socket socket) &#123;\n            this.socket &#x3D; socket;\n        &#125;\n\n        @Override\n        public void run() &#123;\n            byte[] data &#x3D; new byte[1024];\n            while (true) &#123; &#x2F;&#x2F;持续接收客户端发来的数据\n                try &#123;\n                    &#x2F;&#x2F; read()为阻塞函数，直到读取到数据再返回\n                    socket.getInputStream().read(data);\n                    &#x2F;&#x2F; write()为阻塞函数，全部写完成才会返回\n                    socket.getOutputStream().write(data); &#x2F;&#x2F;echo\n                &#125; catch (IOException e) &#123;\n                    &#x2F;&#x2F; log and exit\n                    break;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n非阻塞I/O模型（NIO）：Selector+非阻塞IO，注册channel（不会一直占用线程） + Selector多路复用（隔一段时间轮询，找能执行的channel）\n\n非阻塞模型利用非阻塞模式和Selector多路复用器来开发服务器，也叫做多路复用I/O模型。只有实现了SelectableChannel接口的Channel才可以注册到Selector中被监听，比如DatagramChannel、SocketChannel、ServerSocketChannel，FileChannel无法被Selector监听\n\n在NioEchoServer类中，如果有n可客户端连接服务器，那么就会创建n+1个Channel，其中一个serverChannel用于接受客户端的连接，另外n个clientChannel用于与客户端进行通信。这n+1个Channel均注册到Selector中。Selector会间隔一定时间轮训这n+1个Channel，查找可连接、可读、可写的Channel，然后再进行连接、读取、写入操作\n\n在NIO中，主线程通常只有一个，但是可以使用Selector来管理多个Channel，实现多个连接的非阻塞读写操作。当有多个Channel需要进行IO操作时，Selector会轮询这些Channel，检查它们的状态是否可读或可写，如果有可读或可写的Channel，就将其加入到一个已选择键集合中，等待程序处理。这样，一个线程就可以同时处理多个Channel，提高了系统的并发处理能力\nNIO底层是用Selector、Channel和ByteBuffer来实现的。主线程在循环使用select方法进行阻塞等待，当有acceptable、readable或者writable事件发生的时候，循环就会往下走，将对应的事件交给对应的事件处理器进行处理\nSelector是一个可以监控多个通道（Channel）是否有数据可读或可写的对象，当一个或多个Channel准备好读或写时，Selector会通知程序进行读写操作，而不是像BIO一样阻塞等待IO操作完成\n\n\n多路复用I/O模型：只需要一个线程即可，解决了阻塞I/O模型线程开销大的问题。但是如果某些clientChannel耗时比较久，那么其它clientChannel便需要阻塞，使得服务器响应的延迟变高，但可以用过线程池中取线程来处理，而不是所有的clientChannel都在一个线程中处理。跟非阻塞I/O的区别在于不管有没有数据可读，阻塞I/O模型中的每个clientSocket都会一直占用线程。而这里的多线程只会处理经过Selector筛选之后有可读数据的clientChannel，并且处理完之后就释放回线程池，线程的利用率更高\n\n\npublic class NioEchoServer &#123;\n    public static void main(String[] args) throws IOException &#123;\n        &#x2F;&#x2F; Selector\n        Selector selector &#x3D; Selector.open();\n\n        &#x2F;&#x2F; create serverChannel and register to selector\n        ServerSocketChannel serverChannel &#x3D; ServerSocketChannel.open();\n        serverChannel.bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 1192));\n        serverChannel.configureBlocking(false);&#x2F;&#x2F;非阻塞\n      \t&#x2F;&#x2F;注册\n        serverChannel.register(selector, SelectionKey.OP_ACCEPT);\n\n        ByteBuffer buffer &#x3D; ByteBuffer.allocate(1024);\n        while (true) &#123;\n            int channelCount &#x3D; selector.select(); &#x2F;&#x2F;取来准备好的selector\n            if (channelCount &gt; 0) &#123;\n                Set&lt;SelectionKey&gt; keys &#x3D; selector.selectedKeys();\n                Iterator&lt;SelectionKey&gt; iterator &#x3D; keys.iterator();\n                while (iterator.hasNext()) &#123;\n                    SelectionKey key &#x3D; iterator.next();&#x2F;&#x2F;链表\n                    if (key.isAcceptable()) &#123;\n                        &#x2F;&#x2F; create clientChannel and register to selector\n                        SocketChannel clientChannel &#x3D; serverChannel.accept();\n                        clientChannel.configureBlocking(false);&#x2F;&#x2F;非阻塞\n                        clientChannel.register(selector, SelectionKey.OP_READ);\n                    &#125; else if (key.isReadable()) &#123;\n                        SocketChannel clientChannel &#x3D; (SocketChannel) key.channel();\n                        clientChannel.read(buffer);\n                        buffer.flip(); &#x2F;&#x2F;从&quot;用于读&quot;变为&quot;用于写&quot;\n                        if (buffer.hasRemaining())&#123;&#x2F;&#x2F;也可以注册到selector中\n                            clientChannel.write(buffer); &#x2F;&#x2F;echo\n                        &#125;\n                        buffer.clear(); &#x2F;&#x2F;重复利用\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n异步I/O模型（AIO）：异步IO，通过异步Channel，数据读取完成后会执行回调函数\n\n与NIO不同的是，AIO不需要用户线程等待IO操作完成，而是由操作系统来完成IO操作，操作系统完成IO操作后会通知用户线程处理。AIO适用于连接数较多且连接时间较长的场景，如高性能网络服务器等\n通过异步Channel调用accept()、read()、write()函数。当有连接建立、数据读取完成、数据写入完成时，底层会通过线程池执行对应的回调函数。这种服务器的实现方式叫做异步I/O模型\n\npublic class AioEchoServer &#123;\n    public static void main(String[] args) throws IOException, InterruptedException &#123;\n        AsynchronousServerSocketChannel serverChannel &#x3D; AsynchronousServerSocketChannel.open();\n        serverChannel.bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 1192));\n        &#x2F;&#x2F; 异步accept()\n        serverChannel.accept(null, new AcceptCompletionHandler(serverChannel));\n        Thread.sleep(Integer.MAX_VALUE);\n    &#125;\n\n    private static class AcceptCompletionHandler implements CompletionHandler&lt;AsynchronousSocketChannel, Object&gt; &#123;\n        private AsynchronousServerSocketChannel serverChannel;\n        public AcceptCompletionHandler(AsynchronousServerSocketChannel serverChannel) &#123;\n            this.serverChannel &#x3D; serverChannel; \n        &#125;\n\n        @Override\n        public void completed(AsynchronousSocketChannel clientChannel, Object attachment) &#123;\n            &#x2F;&#x2F; in order to accept other client&#39;s connections\n            serverChannel.accept(attachment, this);\n            ByteBuffer buffer &#x3D; ByteBuffer.allocate(1024);\n            &#x2F;&#x2F; 异步read()\n            clientChannel.read(buffer, buffer, new ReadCompletionHandler(clientChannel)); \n        &#125;\n\n        @Override\n        public void failed(Throwable exc, Object attachment) &#123;\n            &#x2F;&#x2F; log exc exception\n        &#125;\n    &#125;\n\n    private static class ReadCompletionHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; &#123;\n        private AsynchronousSocketChannel clientChannel;\n        public ReadCompletionHandler(AsynchronousSocketChannel clientChannel) &#123;\n            this.clientChannel &#x3D; clientChannel;\n        &#125;\n\n        @Override\n        public void completed(Integer result, ByteBuffer buffer) &#123;\n            buffer.flip();\n            &#x2F;&#x2F; 异步write()。回调函数为null，写入完成就不用回调了\n            clientChannel.write(buffer, null, null); &#x2F;&#x2F; echo\n        &#125;\n\n        @Override\n        public void failed(Throwable exc, ByteBuffer attachment) &#123;\n            &#x2F;&#x2F; log exc exception\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n文件（高速IO）：上下文切换耗时（环境重置、缓存失效）、系统调用（read、write、open、close）、新技术（DMA、mmap、零拷贝）\n\n用户态和内核态\n\n系统调用：操作系统内核包含各种操作硬件资源的系统调用，应用程序必须通过操作系统提供的系统调用才能访问硬件资源。\n库函数：系统调用比较底层，所以Linux又提供了库函数，比如Glibc库、Posix库，对系统调用进行封装，提供更加简单易用的函数，供应用程序开发使用，比如：Glibc中的malloc()函数封装了sbrk()系统调用，fread()、fwrite()封装了read()、write()系统调用，在开发应用程序的时候，既可以使用库函数，也可以直接使用系统调用\nShell：Linux还提供了Shell这一程序，即命令行，Shell能在不进行编程的情况下，通过命令行中运行Shell命令或脚本，达到访问硬件的目的，比如cp拷贝文件、rm删除文件\n用户态&amp;内核态：为避免应用程序在运行时，访问到内核所用的内存空间，操作系统将虚拟内存分为内核空间和用户空间两部分，CPU因此有内核态和用户态两种，在内核态CPU拥有最高权限，可以执行所有的机器指令并且可以访问硬件，而且内核态能访问所有虚拟内存空间，在用户态则不能\n上下文切换：当应用调用操作系统的系统调用时，会涉及内核态与用户态的上下文切换，主要耗时的操作有：\n寄存器保存与恢复耗时：因为内核空间不使用应用程序的函数调用栈，会分配新的函数调用栈，所以在上下文切换时需要更新更多栈相关的寄存器，比如SS栈基址寄存器。除此之外，应用程序和内核程序的代码存储位置也不同，CS代码段基址寄存器也需要更新。并且更新前会保存下来原始值，以便切换回用户态之后恢复执行\n缓存失效带来的性能损耗：CPU有L1、L2、L3三级Cache，用于缓存将要执行的代码以及所需的内存数据，上下文切换会导致CPU缓存失效\n\n\n\n\nIO读写底层原理\n\nLinux操作系统下，Java的I/O类库调用open()、read()、write()系统调用来实现，通过open()返回Linux下I/O设备的文件描述符，来和I/O设备建立连接。\n操作系统为每个文件描述符都分配一个内核读缓存区和一个内核写缓存区（数据会先被放到内核读写缓存区，读缓冲区不够时才会从磁盘读取文件，写缓冲区满时才会写入到磁盘中），内核读写缓存区只有在第一次调用read()或write()系统调用时，才会真正被分配内存空间。默认读缓冲区的大小为8192字节，写缓冲区的大小为16384字节。当然，也可以根据业务需求，通过系统调用，来重新设置，这样做的目的主要是为了减少与I/O设备的交互次数\n在读写完成后需要调用close()系统调用\n\n\n新技术：DMA（替代CPU读写数据）、mmap（将大文件映射到虚拟内存地址上）、零拷贝（直接从内核读缓冲区拷贝到内核写缓冲区）\n\nDMA（Direct Memory Access）：通过在主板上安装一个叫做DMAC (DMA Controller，DMA控制器)的协处理器(或叫芯片)，协助CPU来完成I/O设备的数据读写工作（现在很多IO设备都自带DMAC）。DMAC替代CPU从设备中读取数据或向设备写入数据，通过中断通知CPU，CPU利用率提高了\n\n\nmmap（memory-mapped file，内存映射文件）：提高文件读写性能的有效技术，一般用于文件读写，不适用于网络这种数据未知的I/O设备\n&#x2F;&#x2F;java.nio.FileChannel类中\npublic MappedByteBuffer map(MapMode mode , long position, long size);\n\n\n通过将文件或文件中的某段映射到用户空间中的某段虚拟内存地址上，如果没加载到物理内存，则触发缺页中断；如果有脏页，操作系统自动写回磁盘或者调用msync()立即写回\nmmap相当于直接将数据在磁盘和用户空间之间互相拷贝，相对于使用read()、write()系统调用读写文件，数据拷贝次数由2次减少为1次，并且减少了内核态和用户态上下文切换的耗时，之后读写文件就像读写内存一样\n对于少量文件读写，使用read()、write()更合适，对于大文件的读写，一般使用mmap，并且需要一些测试来验证性能。进程间通信当两个应用程序都采用MAP_SHARED模式创建匿名的内存映射文件时，这两个应用程序会共享物理内存，一个应用程序可以读取另一个程序写入物理内存的数据，以此来实现互相通信\n\nint main(void)&#123;\n    char file &#x3D; &quot;&#x2F;users&#x2F;root&#x2F;in.txt&quot;;\n    int fd &#x3D; open(file, O_RDWR,0666);\n    if(fd &lt;0)&#123;\n        printf(&quot;open file failedl\\\\n&quot;);\n        return -1;\n    &#125;\n    &#x2F;&#x2F;映射文件开头(offset&#x3D;0)的512字节(length&#x3D;512)到ptr\n    size_t length &#x3D; 512;\n    int offset &#x3D; 0;\n\t\t&#x2F;&#x2F;mmap，后面就和使用fd一样了\n    char *ptr &#x3D; mmap(null, length, PROT_READ|PROT_WRITE, MAP_SHARED, fd , offset);\n    if (ptr &#x3D;&#x3D; MAP_FAILED)&#123;\n        printf(&quot;mmap failed.&quot;);\n        return -1;\n    &#125;\n    &#x2F;&#x2F;创建好内存映射文件之后，fd就没用了，可以释放了\n    close(fd);\n    \n    &#x2F;&#x2F;操作ptr就等同于读写文件\n    for (int i &#x3D; 0; i &lt; length; i++)&#123;\n        ptr[i] &#x3D; &#39;a&#39; + (length%26);\n    &#125;\n\n    for (int i &#x3D; 0; i &lt;N, i++)&#123;\n        printf(&quot;%c&quot;,ptr[i]);\n    &#125;\n    &#x2F;&#x2F;删除内存映射文件，释放占用的虚拟内存空间\n    munmap(ptr, length);\n    return 0;\n&#125;\n零拷贝（Zero-copy）：sendfile 系统调用实现了零拷贝技术，零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运，使用零拷贝的项目有nginx、kafka\n\n\n主要用于两个I/O设备之间互相传输数据，特别是将文件中的数据发送到网络或者将从网络接受的数据存储到文件这一场景中\n&#x2F;&#x2F;java.nio.FileChannel\npublic abstract long transferTo(long position,long count WritableByteChannel target);\npublic abstract long transferFrom(ReadableByteChannel src, long position,long count);\n零拷贝不需要将数据拷贝到应用程序缓冲区，而是直接从内核读缓冲区拷贝到内核写缓冲区，应用程序只需要进行一次系统调用（执行sendfile()），就可以将文件发送到网络\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;sys&#x2F;sendfile.h&gt;\n#include &lt;sys&#x2F;stat.h&gt;\n#include sys&#x2F;types.h&gt;\nint main (int argc, char*argv[)&#123;\n    int read_fd;\n    int write_fd;\n    struct stat stat_buf;\n    off_t offset &#x3D; o;\n    read_fd &#x3D; open (argv[1],O_RDONLY);\n    fstat (read_fd, &amp;stat_buf) ;\n    write_fd &#x3D; open (argv[2],O_WRONLY \\\\ O_CREAT, stat_buf.st_mode);\n    sendfile (write_fd, read_fd, &amp;offset, stat_buf.st_size);\n    close(read_fd);\n    close (write_fd);\n    return 0;\n&#125;\n\n\n\n\n\n\n\n5.Exception体系\n\n\n\n\n\n\n\n\n相比较C语言返回错误码的方式，可以携带更多的错误信息（message、stack trace等），并且可以将业务代码和异常处理代码分离，这样代码的可读性会更好\n\n异常体系\n\n\n继承自Error的异常：表示程序无法处理的严重错误，这些错误有可能导致线程或JVM终止\n继承自Exception的异常：也叫做受检异常（Checked Exception）或编译时异常（Compile Exception），在编写代码的时候，需要主动取捕获或者在函数定义中声明此类异常，否则编译就会报错\n继承自RuntimeException的异常：也叫做非受检异常（Unchecked Exception）或者运行时异常（Runtime Exception），在编写代码的时候，可以不主动取捕获和在函数定义中声明此类异常，不处理也可以通过编译\n\n\n自定义异常：要么继承自Exception，要么继承自RuntimeException，但是现在一般都依赖框架来编程，受检和非受检异常大部分情况下都会被框架兜底捕获并处理，并不会直接导致程序的终止，所以从这个角度来看，继承自哪个异常均可\n&#x2F;&#x2F;受检异常的使用违反开闭原则，整条调用链都需要修改代码；非受检异常需要主动处理，但容易被遗忘\npublic class UserNotExistingException extends Exception&#123;\n    public UserNotExistingException()&#123;\n        super();\n    &#125;\n    public UserNotExistingException(String msg,Throwable cause)&#123;\n        super(msg,cause)；\n    &#125;\n    public UserNotExistingException(String msg)&#123;\n        super(msg);\n    &#125;\n    public UserNotExistingException(Throwable cause)&#123;\n        super(cause);\n    &#125;\n&#125;\n异常处理\n\n打印调用链：在函数内部，如果某代码的异常行为，并不会导致调用此函数的上层代码出现异常行为，也就是说，上层代码并不关心被调用函数内部的这个异常，我们就可以在函数内部将这个异常捕获并打印日志记录\npublic void f() throws LowLevelException&#123;...&#125;\n&#x2F;&#x2F;捕获后记录日志\npublic void g()&#123;\n    try&#123;\n        f();\n    &#125;catch(LowLevelException e)&#123;\n        log.warn(&quot;...&quot;,e);&#x2F;&#x2F;使用日志框架记录日志\n    &#125;\n&#125;\n使用throws抛出异常：如果函数内部的异常行为会导致调用此函数的上层代码出现异常行为，那么，就必须让上层代码感知此异常的存在\n&#x2F;&#x2F;原封不动再抛出\n&#x2F;&#x2F;如果LowLevelException是非受检异常，则不需要再函数g()定义中声明\npublic void g() throws LowLevelException&#123;\n    f();\n&#125;\n使用new创建新的异常：如果此异常跟函数的业务相关，上层代码在调用此函数时，知道如何处理异常，那么直接将其抛出即可；如果此异常跟业务无关，上层代码无法理解这个异常的含义，那么就需要包装成新的跟函数业务相关的异常重新抛出\n&#x2F;&#x2F;包装成新异常抛出\npublic void g()&#123;\n    try&#123;\n        f();\n    &#125;catch(LowLevelExceptioin e)&#123;\n\t\t\t\t&#x2F;&#x2F;异常调用链可以完整的描述异常发生的整个过程，但需要特别注意的是，捕获异常并包裹成新的异常抛出时，\n\t\t\t\t&#x2F;&#x2F;一定要将先前的异常通过cause参数（下面代码中的e）传递进新的异常，否则，异常调用链会断开\n        throw new HighLevelException(&quot;...&quot;,e);\n    &#125;\n&#125;\n\n\n异常实现原理：异常代码块执行顺序：不管try监听的代码块有没有异常抛出，finally代码块总是被执行，并且在finally代码执行完成之后，try代码块和catch代码块中的return语句才会被执行\n\n\n异常表：对应于上图最后一部分的Exception table，其中from、to、target都表示字节码的行号，当行号在[from，to）之间的代码抛出type类型的异常时，JVM会跳转至target行字节码继续执行\n异常兜底：第50行代码开始，主要是捕获try代码块和catch代码块中未被捕获的异常，然后再执行完finally代码块之后，在原封不动的将异常抛出\nfinally内联：JVM在生成字节码时，会将finally代码块内联（插入）到try代码块和catch代码块中的return语句之前，这样就可以实现不管程序是否抛出异常，finally代码块总是会被执行，并且再函数返回之前执行。如果finally有return语句，会提前返回\n\n\n异常性能分析\n\n使用new创建异常：在堆上创建异常对象，初始化成员变量，调用异常父类Throwable中的fillInStackTrace()函数生成栈追踪信息，通过getStackTrace()函数打印stackTrace栈追踪信息（当调用层次过深时，会导致fillInStackTrace耗时高，所以在递归中不要轻易抛出异常）\n&#x2F;&#x2F;当创建异常时函数调用栈中的所有函数的信息，栈追踪信息记录了异常产生的整个函数调用链路，方便定位此异常是如何产生的\nprivate StackTraceElement[] stackTrace;\npublic final class StackTraceElement implements java.io.Serializable &#123;\n    &#x2F;&#x2F; Normally initialized by VM (public constructor added in 1.5)\n    private String declaringClass;&#x2F;&#x2F;函数所属类名\n    private String methodName;&#x2F;&#x2F;函数名\n    private String fileName;&#x2F;&#x2F;函数所属类文件名\n    private int    lineNumber;&#x2F;&#x2F;异常抛出时，函数执行到了哪一行\n    &#x2F;&#x2F;...\n&#125;\n&#x2F;&#x2F;通过getStackTrace()函数，将异常的stackTrace栈追踪信息打印出来\nRuntimeException e &#x3D; new RuntimeException(&quot;oops&quot;);\nStackTraceElement[] stackTrace &#x3D; e.getStackTrace();\nfor(StackTraceElement element : stackTrace)&#123;\n    System.out.println(element);\n&#125;\n使用throw抛出异常：当有函数抛出异常时，JVM会在底层执行栈展开（stack unwinding），依次将函数调用栈中的函数栈帧弹出，直到找到哪个函数可以捕获这个异常为止，然后JVM从这个函数继续再执行（不同于return导致的栈展开，异常导致的栈展开会有一个在函数的异常表中查找是否有可匹配的处理规则的过程，这样的查找在调用层次过深时和耗时）\n&#x2F;&#x2F;throw new RuntimeException(&quot;oops&quot;)这样一个异常抛出代码包括两个操作：创建异常和抛出异常等价于下面的两行代码\nRuntimeException e &#x3D; new RuntimeException(&quot;oops!&quot;);\nthrow e;\n打印异常调用链\n\n\n\n\n\n\n\n\n\n每个异常的stackTrace栈追踪消息都是一直到main函数的，不可以只记录生命周期内的函数，因为stackTrace栈追踪信息是在异常创建时生成的，在打印异常时，异常的声明周期未必就一定结束，所以无法只填充生命周期内所经历的函数\n\n原封不动抛出：相当于没捕获\n\n封装成新的异常抛出\ntry&#123;\n    &#x2F;&#x2F;...\n&#125;catch(IOException e)&#123;\n\t\t&#x2F;&#x2F;将捕获的异常通过cause参数传递给新的异常，调用链就不会断，主要调用了下面的Throwable的构造函数\n    throw new RuntimeException(&quot;oops&quot;,e);\n&#125;\n\npublic class Throwable&#123;\n    private String detailMessage;\n    private Throwable cause &#x3D; this;&#x2F;&#x2F;异常调用\n    private StackTraceElement[] stackTrace &#x3D; UNASSIGNED_STACK;\n    \n    public Throwable(String message, Throwable cause) &#123;\n        fillInStackTrace();&#x2F;&#x2F;生成stackTrace\n        detailMessage &#x3D; message;\n        this.cause &#x3D; cause;\n    &#125;\n    &#x2F;&#x2F;...\n&#125;\n记录日志：一般在开发中使用日志框架来记录异常，异常调用链信息会输出到日志文件中，方便开发者事后查看，一般不推荐使用e.pringStackTrace()来打印异常日志，因为会打印到标准出错输出System.err中，即命令行中，这不方便保存以便反复查看\ntry&#123;\n    &#x2F;&#x2F;...\n&#125;catch(IOException e)&#123;\n    log.error(&quot;...&quot;,e);\n    &#x2F;&#x2F;e.printStackTrace() 不推荐\n&#125;\n\n\n\n\n异常最佳实践：对于业务异常只需要将一些有用的信息，记录在异常的detailMessage成员变量中即可，通过向构造函数的参数writableStackTrace传入false，即可禁止在创建异常的同时调用fillStackTrace()函数\nprotected Throwable(String message, Throwable cause,\n                    boolean enableSuppression,\n                    boolean writableStackTrace) &#123;\n    if (writableStackTrace) &#123;\n        fillInStackTrace();\n    &#125; else &#123;\n        stackTrace &#x3D; null;\n    &#125;\n    detailMessage &#x3D; message;\n    this.cause &#x3D; cause;\n    if (!enableSuppression)\n        suppressedExceptions &#x3D; null;\n&#125;\n&#x2F;&#x2F;使用，可以解决高并发下程序中大量业务异常导致的程序变慢的问题\npublic class UserNotExistingException extends Throwable&#123;\n    public UserNotExistingException() &#123;\n        super(null,null,true,false);\n    &#125;\n\n    public UserNotExistingException(String message) &#123;\n        super(message,null,true,false);    &#125;\n\n    public UserNotExistingException(String message, Throwable cause) &#123;\n        super(message,cause,true,false);\n    &#125;\n\n    public UserNotExistingException(Throwable cause) &#123;\n        super(null,cause,true,false);\n    &#125;\n&#125;\n\n3.附录1.代码设计原则\nSOLID\n\nSRP单一职责原则：==A class or module should hava a single responsibility==\n\n不要设计大而全的类，要设计粒度小、功能单一的类。也就是说，如果一个类包含了两个或以上业务不相干的功能，那么他的职责就不够单一，应该被拆分成多个功能单一、粒度更细的类。\n要判断职责是否单一，不能脱离具体的应用场景，所以可以先写一个粗粒度的类，满足业务需求，随着业务的发展，如果粗粒度的类越来越庞大，代码越来越多，这个时候，就可以将这个独粒度的类拆分成几个更细粒度的类，这就是所谓的==持续重构==。\n==技巧==：\n类中的代码行数（200行内）、函数或属性过多（少于10个），会影响代码的可读性和可维护性，我们就需要对类进行拆分\n类依赖的其他类过多，或者依赖类的其他类过多，不符合高内聚、低耦合的设计思想，我们就需要对类进行拆分\n私有方法过多，我们就要考虑能否将私有方法独立到新的类中，设置为public方法，供更多的类使用，从而提高代码的复用性\n比较难给类起一个合适的名字，很难用一个业务名词概括或者只能用一些笼统的Manager、Context之类的词语来命名，这就说明类的职责定义的可能不够清晰\n类中大量的方法都是集中操作类中的某几个属性。\n\n\n\n\nOCP开闭原则：==Software entities(modules,classes,functions) should be open for extension,but closed for modification==\n\n添加一个新功能应该是，在已有的代码基础上扩展代码（新增模块、类、方法等），而非修改已有的代码（修改模块、类、方法等）\n\n指导思想：为了尽量写出扩展性好的代码，我们要时刻具备扩展意识、抽象意识、封装意识，这些潜意识可能比任何开发技巧都重要。\n\n==方法==：多态、依赖注入、基于接口而非实现编程、大部分设计模式（装饰、策略、模板、职责链、状态）\n\n\n\nLSP里式替换原则：==子类对象（object of subtype/derived class）能够替换程序（program）中父类对象（object of base/parent class）出现的任何地方，并且保证原来程序的逻辑行为不变及正确性不被破坏==\n\n虽然从定义描述和代码实现上来看，多态和里氏替换有点类似，但他们的关注角度是不一样的。多态是面向对象编程的一大特性，也是面向对象编程语言的一种语法，它是一种代码实现的思路。而里氏替换原则是一种设计原则，是用来直到继承关系中子类该如何设计的，子类的设计要保证在替换父类的时候，不改变原有程序的逻辑以及不破坏原有程序的正确性。\n==按照协议来设计==：子类在设计的时候，要遵守父类的行为约定（或协议），父类定义了函数的行为约定，子类可以改变函数内部实现逻辑，但不能改变函数原有的行为约定（函数声明是实现的功能、对输入、输出、异常的约定、注释中所罗列的任何特殊说明）。\n==技巧==：用父类的单元测试来验证子类的代码，如果某些单元测试运行失败，就有可能违背里氏替换原则\n\n\nISP接口隔离原则：==Clients should not be forced to depend upon interfaces that they do not use==\n\n一组API接口集合：在设计微服务或者类库接口的时候，如果部分接口只被部分调用者使用，那么我们就需要将这部分接口隔离出来，单独给对应的调用者使用，而不是强迫其他调用者也依赖这部分不会被用到的接口。\n单个API接口或函数：函数的设计要功能单一，不要将多个功能逻辑在一个函数中实现。接口隔离原则跟单一职责原则有点类似，但是单一职责原则针对的是模块、类、接口的设计；而接口隔离原则相对于单一职责原则，一方面他更侧重于接口的设计，另一方面它提供了一种判断接口是否职责单一的标准（如果调用者只使用部分接口或接口的部分功能，那接口的设计就不够指责单一）。\nOOP中的接口概念：拆分成小接口，而不是一个大而全的config接口\n\n\nDIP依赖倒置原则：==High-level modules shouldn’t depend on low-level modules. Both modules should depend on abstractions. In addition, abstractions shouldn’t depend on details. Details depend on abstractions.（高层模块和低层模块的划分就是，在调用链上，调用者属于高层，被调用者属于低层）==\n\n\n\nKISS原则：==尽量保持简单==\n\n不要使用同事可能不懂的技术来实现代码，例如正则表达式或编程语言中的高级语法\n不要重复造轮子，要善于使用已经有的工具类库\n不要过度优化，不要过度使用一些奇技淫巧（位运算、复杂条件语句、过于底层函数）来优化代码，牺牲代码的可读性\n\n\nYAGNI原则：==You ain’t gonna need it 你不会需要它==，不要去设计当前用不到的功能，不要去编写当前用不到的代码，即不要过度设计，只需要预留好扩展点。\n\nDRY原则：==Don’t repeat yourself==，不要写重复的代码。\n\n实现逻辑重复：尽管代码的实现逻辑是重复的，但是语义上不是重复的，可以判定它并不违反DRY原则\n功能语义重复：实现逻辑不重复，但语义重复，那么也就是功能重复，我们认为它违反了DRY原则\n代码执行重复：例如对输入校验了两次\n\n\nLOD原则（Law of Demeter）：==Each unit should have only limited knowledge about other units: only units “closely” related to the current unit. Or: Each unit should only talk to its friends; Don’t talk to strangers.==\n\n高内聚，松耦合：\n\n高内聚：用来指导类本身的设计，相近的功能应该放到同一个类中，不想近的功能不要放到同一个类中，相近的功能往往会被同时更改，放到一个类中，代码容易维护\n低耦合：用来指导类与类之间依赖关系的设计，在代码中，类与类之间的依赖关系应该简单清晰，一个类的代码改动不会或者很少导致依赖类的代码改动\n\n\n迪米特法则\n\n\n\n\n2.JDBC连接数据库\n加载数据库驱动程序：使用Class.forName()方法加载对应的数据库驱动程序，例如：Class.forName(“com.mysql.jdbc.Driver”);\n建立数据库连接：使用DriverManager.getConnection()方法建立与数据库的连接，需要指定数据库的URL、用户名和密码，例如：Connection conn = DriverManager.getConnection(“jdbc:mysql://localhost/mydatabase”, “username”, “password”);\n创建Statement对象：使用Connection对象的createStatement()方法创建一个Statement对象，用于执行SQL语句，例如：Statement stmt = conn.createStatement();\n执行SQL语句：使用Statement对象的executeQuery()或executeUpdate()方法执行SQL语句，例如：ResultSet rs = stmt.executeQuery(“SELECT * FROM mytable”);\n处理查询结果：如果执行的是查询语句，需要使用ResultSet对象来处理查询结果，例如：while (rs.next()) { String name = rs.getString(“name”); int age = rs.getInt(“age”); }\n关闭数据库连接：在程序结束时，需要使用Connection对象的close()方法关闭数据库连接，例如：conn.close();\n\n3.Socket编程示例4.Collections工具类\n排序\nvoid reverse(List list)&#x2F;&#x2F;反转\nvoid shuffle(List list)&#x2F;&#x2F;随机排序\nvoid sort(List list)&#x2F;&#x2F;按自然排序的升序排序\nvoid sort(List list, Comparator c)&#x2F;&#x2F;定制排序，由Comparator控制排序逻辑\nvoid swap(List list, int i , int j)&#x2F;&#x2F;交换两个索引位置的元素\nvoid rotate(List list, int distance)&#x2F;&#x2F;旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面\n查找、替换操作\nint binarySearch(List list, Object key)&#x2F;&#x2F;对List进行二分查找，返回索引，注意List必须是有序的\nint max(Collection coll)&#x2F;&#x2F;根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll)\nint max(Collection coll, Comparator c)&#x2F;&#x2F;根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)\nvoid fill(List list, Object obj)&#x2F;&#x2F;用指定的元素代替指定list中的所有元素\nint frequency(Collection c, Object o)&#x2F;&#x2F;统计元素出现次数\nint indexOfSubList(List list, List target)&#x2F;&#x2F;统计target在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target)\nboolean replaceAll(List list, Object oldVal, Object newVal)&#x2F;&#x2F;用新元素替换旧元素\n同步控制（不推荐，多线程下应该直接使用JUC下的并发集合）：Collections提供了多个synchronizedXXX方法，该方法可以指定集合包装成线程同步的集合，从而解决多线程并发访问集合时的线程安全问题\nsynchronizedCollection(Collection&lt;T&gt;  c) &#x2F;&#x2F;返回指定 collection 支持的同步（线程安全的）collection。\nsynchronizedList(List&lt;T&gt; list)&#x2F;&#x2F;返回指定列表支持的同步（线程安全的）List。\nsynchronizedMap(Map&lt;K,V&gt; m) &#x2F;&#x2F;返回由指定映射支持的同步（线程安全的）Map。\nsynchronizedSet(Set&lt;T&gt; s) &#x2F;&#x2F;返回指定 set 支持的同步（线程安全的）set。\n\n5.其它\nSPI：服务提供者的接口，如SLF4J是Java的一个日志接口，具体实现由Logback、Log4j、Log4j2 等等\n\nJava集合使用注意事项（阿里巴巴Java开发手册）\n\n判断所有集合内部的元素是否为空，使用 isEmpty() 方法，而不是 size()==0 的方式：isEmpty()方法的可读性更好，并且时间复杂度为 O(1)\n\n在使用 java.util.stream.Collectors 类的 toMap() 方法转为 Map 集合时，一定要注意当 value 为 null 时会抛 NPE 异常\n\ntoMap方法调用了Map接口的merge方法，merge方法就先调用Objects.requireNonNull方法来判断value是否为空\n\n\n不要在 foreach 循环里进行元素的 remove/add 操作（抛出ConcurrentModificationException异常，即fail-fast机制）。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁\n\n可以使用java.util.concurrent包下面的类\n\n可以使用Collection的removeIf方法\nList&lt;Integer&gt; list &#x3D; new ArrayList&lt;&gt;();\nfor (int i &#x3D; 1; i &lt;&#x3D; 10; ++i) &#123;\n    list.add(i);\n&#125;\nlist.removeIf(filter -&gt; filter % 2 &#x3D;&#x3D; 0); &#x2F;* 删除list中的所有偶数 *&#x2F;\nSystem.out.println(list); &#x2F;* [1, 3, 5, 7, 9] *&#x2F;\n\n\n集合去重：可以利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 List 的 contains() 进行遍历去重或者判断包含操作\n\nHashSet的contains方法依赖底部的HashMap，时间复杂度时时O（1）的\nArrayList的contains方法是通过遍历所有元素来实现的，时间复杂度是O（n）\n\n&#x2F;&#x2F; Set 去重代码示例\npublic static &lt;T&gt; Set&lt;T&gt; removeDuplicateBySet(List&lt;T&gt; data) &#123;\n\n    if (CollectionUtils.isEmpty(data)) &#123;\n        return new HashSet&lt;&gt;();\n    &#125;\n    return new HashSet&lt;&gt;(data);\n&#125;\n\n&#x2F;&#x2F; List 去重代码示例\npublic static &lt;T&gt; List&lt;T&gt; removeDuplicateByList(List&lt;T&gt; data) &#123;\n\n    if (CollectionUtils.isEmpty(data)) &#123;\n        return new ArrayList&lt;&gt;();\n\n    &#125;\n    List&lt;T&gt; result &#x3D; new ArrayList&lt;&gt;(data.size());\n    for (T current : data) &#123;\n        if (!result.contains(current)) &#123;\n            result.add(current);\n        &#125;\n    &#125;\n    return result;\n&#125;\n使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一致、长度为 0 的空数组\nString [] s&#x3D; new String[]&#123;\n    &quot;dog&quot;, &quot;lazy&quot;, &quot;a&quot;, &quot;over&quot;, &quot;jumps&quot;, &quot;fox&quot;, &quot;brown&quot;, &quot;quick&quot;, &quot;A&quot;\n&#125;;\nList&lt;String&gt; list &#x3D; Arrays.asList(s);\nCollections.reverse(list);\n&#x2F;&#x2F;没有指定类型的话会报错，new String[0]起到一个模版的作用，指定了返回参数的类型，0是为了节省空间，因为只是为了说明返回的类型\ns&#x3D;list.toArray(new String[0]);\n使用工具类Arrays.asList把数组转换成集合时，返回的不是平常使用的ArrayList，而是Arrays的一个内部类，\n\n不能使用其修改集合相关的方法，它的add、remove、clear方法会抛出**UnsupportedOperationException**异常，该Arrays内部类里面并没有上述方法\nasList收到的是传入集合的地址值，而不是数据，所以get方法在参数为0的时候返回地址值，在参数为1的时候返回数组越界异常\n所以最好手动实现工具类，通过for循环来一个一个add进list里\n\n&#x2F;&#x2F;方法一\nList list &#x3D; new ArrayList&lt;&gt;(Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;))\n&#x2F;&#x2F;方法二\nfor循环一个一个加进去\n&#x2F;&#x2F;方法三 Stream\n\t\tInteger [] myArray &#x3D; &#123; 1, 2, 3 &#125;;\n\t\tList myList &#x3D; Arrays.stream(myArray).collect(Collectors.toList());\n\t\t&#x2F;&#x2F;基本类型也可以实现转换（依赖boxed的装箱操作）\n\t\tint [] myArray2 &#x3D; &#123; 1, 2, 3 &#125;;\n\t\tList myList &#x3D; Arrays.stream(myArray2).boxed().collect(Collectors.toList());\n&#x2F;&#x2F;方法四：使用Guava\n&#x2F;&#x2F;不可变集合\n\tList&lt;String&gt; il &#x3D; ImmutableList.of(&quot;string&quot;, &quot;elements&quot;);  &#x2F;&#x2F; from varargs\n\tList&lt;String&gt; il &#x3D; ImmutableList.copyOf(aStringArray);      &#x2F;&#x2F; from array\n&#x2F;&#x2F;可变集合\n\tList&lt;String&gt; l1 &#x3D; Lists.newArrayList(anotherListOrCollection);    &#x2F;&#x2F; from collection\n\tList&lt;String&gt; l2 &#x3D; Lists.newArrayList(aStringArray);               &#x2F;&#x2F; from array\n\tList&lt;String&gt; l3 &#x3D; Lists.newArrayList(&quot;or&quot;, &quot;string&quot;, &quot;elements&quot;); &#x2F;&#x2F; from varargs\n&#x2F;&#x2F;方法五：使用Java9的List.of方法\n\tInteger[] array &#x3D; &#123;1, 2, 3&#125;;\n\tList&lt;Integer&gt; list &#x3D; List.of(array);\n\t\n\n\nCloneable接口实现原理\n\nJDK8新特性\n\nLambda 表达式：Lambda 表达式是 Java 8 中的一个重大改进，它允许开发人员以更简洁的方式编写匿名函数。这大大提高了代码的可读性和可维护性，尤其在函数式编程方面有很大的影响。\n流 API：流（Stream）是一种新的抽象，它允许以声明性方式操作集合数据。流可以轻松进行过滤、映射、聚合等操作，提供了更优雅的集合处理方式。\n默认方法（Default Methods）：接口可以包含默认方法的实现，这样在接口的实现类中不需要重新实现这些方法。这使得在不破坏现有接口的情况下，向接口添加新方法成为可能。\n方法引用：方法引用是一种简化 Lambda 表达式的语法，它允许开发人员重复使用现有方法作为 Lambda 表达式的实现。\n函数式接口：引入了 @FunctionalInterface 注解来标记函数式接口，这有助于编译器检查接口是否满足函数式接口的要求。\n新的时间日期 API：java.time 包提供了更现代、更全面的时间日期处理工具，解决了旧的 java.util.Date 和 java.util.Calendar 存在的问题。\n新的重复注解（Repeatable Annotations）：Java 8 允许相同类型的注解在同一个程序元素上重复使用，而不需要使用容器注解。\nNashorn JavaScript 引擎：Java 8 引入了 Nashorn JavaScript 引擎，用于在 Java 程序中执行 JavaScript 代码。\n并行流：流 API 支持并行处理，可以更轻松地利用多核处理器进行并行计算。\n其他改进：还包括其他一些小的改进，如新的集合方法、新的编译器工具、改进的注解处理等。\n\n\n大文件处理：\n\n使用文件流处理：对于大文件的读取和写入，通常建议使用文件流（FileInputStream 和 FileOutputStream 或 FileReader 和 FileWriter）而不是一次性将整个文件加载到内存中，以避免内存溢出问题。\n分块处理：可以将大文件分成多个块（chunk），每个块分别处理。这样可以减小内存消耗，并且允许逐块处理文件，而不是一次性处理整个文件。\n断点续传：如果涉及到文件上传或下载，考虑实现断点续传功能，以允许在中断后继续上传或下载文件。这需要在上传或下载过程中记录已经传输的字节位置，以便下次可以从这个位置继续。\n合理的缓冲区大小：在读取或写入大文件时，使用适当大小的缓冲区进行数据传输，以减少磁盘 I/O 操作的次数，提高性能。通常，缓冲区大小应根据具体情况进行调整，一般情况下，4KB 到 8KB 的缓冲区大小是一个合理的起点。\n并行处理：如果处理大文件需要一定时间，可以考虑使用多线程或异步方式来处理，以提高处理速度。但要注意多线程可能带来的线程同步问题。\n处理异常：在处理大文件时，要格外小心处理异常，包括文件不存在、磁盘空间不足、权限问题等。合适的错误处理和日志记录非常重要。\n性能监控和优化：对于大文件处理任务，定期进行性能监控，查找瓶颈并进行优化是很重要的。使用性能分析工具可以帮助你找到潜在的性能问题。\n\n\n\n","slug":"Java Base","date":"2023-04-13T11:25:47.000Z","categories_index":"","tags_index":"language","author_index":"Dajunnnnnn"},{"id":"d8c28dc067d04110f6447cc712799b2d","title":"DataStructure","content":"数据结构1.数据结构1.1常用方法\n\n\n接口\nAPI\n\n\n\nCollection\nsize、isEmpty、contains、toArray、add、remove、clear\n\n\nList\nget(index)、set(index)、add(index,element)、remove(index)、indexOf()、lastIndexOf()、subList(from, to)、sort\n\n\nQueue\noffer(element)、poll()、peek()\n\n\nDuque\nofferFirst(E e)、offerLast(E e)、pollFirst()、pollLast()、peekFirst()、peekLast()、push(E e)、pop()\n\n\nSet\nsize、isEmpty、contains、toArray、add、remove\n\n\nSortedSet\nSortedSet subSet(E fromElement, E toElement)、headSet(E toElement)、tailSet(E fromElement)、first、last\n\n\nMap\nsize、isEmpty、containsKey、containsValue、get、put、remove、keySet、values、entrySet\n\n\nMap补\ngetOrDefault(Object key, V defaultValue)、putIfAbsent(K key, V value)、replace(K key, V oldValue, V newValue)\n\n\n1.2工具类\n\n\n类名\nAPI\n\n\n\nString\ncharAt、toCharArray、split、substring（新String）、indexOf、lastIndexOf、replace、length\n\n\nString补\ntrim、toLowerCase、toUpperCase、split(String regex)、format（”%.nf”, d）\n\n\nStringBuilder\nappend、toString、charAt、length、deleteCharAt、replace、insert、reverse、indexOf、lastIndexOf\n\n\nCollections\nsort（list）、binarySearch、reverse、swap、fill、copy、replaceAll、emptyXXX\n\n\nArrays\nsort、binarySearch、equals、fill、asList、copyOf、copyOfRange\n\n\nMath\nmin、max、abs、sqrt(double)、pow(double, double)、ceil（上整）、floor（下整）、round（四舍五入）\n\n\nMath补\nInteger.MAX_VALUE、Integer.MIN_VALUE、\n\n\nScanner\nnext（下一String）、nextInt、nextLong、nextLine（nextInt不会洗掉换行符，需要nextLine吸掉）\n\n\nSystem.out\nprintln、print、format(“x = %d, y = %f\\n”, x, y)\n\n\n\n简化代码：输入一串数字组成的字符\n&#x2F;&#x2F; 1 2 3 4 5...\nint[] nums&#x3D;Arrays.stream(scanner.nextLine().split(&quot; &quot;)).mapToInt(Integer::parseInt).toArray();\n\n1.3补充知识\nArrayList\n\n实现特殊接口\n\nRandomAccess：Arrays的静态方法binarySearch会根据接口调用不同的实现方法\nCloneable：使用clone方法，返回一个浅拷贝\n\n\n底层为可动态扩容的数组（支持存储null数据）\n\n首先==确定最小扩容量==，默认最小为10，如果传入的所需容量比10大，则按传入的所需容量来扩容\n\n然后==判断是否需要扩容==，如果前一阶段判定的需要容量比内部数组的长度大，则进行扩容\n\n使用位移操作，将容量扩展为内部数组长度的1.5倍，如果比需要容量小，则直接使用需要容量，防止多次扩容，然后使用System.arraycopy来复制数据\npublic static native void arraycopy(Object src,  int  srcPos,Object dest, int destPos,int length);\n\n\n使用modCount：来记录容量更改的次数，每次调用ensureCapacityInternal就将modCount加1，容量不够使才改容量。用来确定迭代的过程中，是否有其他线程更改过数据，如果有人修改过，则抛出ConcurrentModificationException异常\n\n一种转换方式\nList&lt;int[]&gt; merged &#x3D; new ArrayList&lt;int[]&gt;();\nint[][] result &#x3D; merged.toArray(new int[merged.size()][]);\n\n\nLinkedList\n\n可以根据引用的接口不同，使用不同方法，支持List、Queue、Deque，根据结构的不同可以调用不同的方法\n底层为双向链表，并且有头尾指针，支持存储null数据\n\n\nArrayDeque\n\n基于数组实现，性能比LinkedList好，也可用来实现栈\n\n使用\nList&lt;int[]&gt; merged &#x3D; new ArrayList&lt;int[]&gt;();\nreturn merged.toArray(new int[merged.size()][]);\n\n\nPriorityQueue\n\n底层依赖堆来实现（使用可变长数组），默认情况下为小顶堆，最先出队列的为当前队列中的最小值，支持Comparator接口\nQueue&lt;Integer&gt; minH &#x3D; new PriorityQueue&lt;&gt;(); &#x2F;&#x2F;小顶堆，默认大小为11\nQueue&lt;Integer&gt; maxH &#x3D; new PriorityQueue&lt;&gt;((i1, i2) -&gt; i2 - i1); &#x2F;&#x2F;大顶堆，默认大小为11\n&#x2F;&#x2F; 支持数组\nPriorityQueue&lt;int[]&gt; pq &#x3D; new PriorityQueue&lt;int[]&gt;(new Comparator&lt;int[]&gt;() &#123;\n    public int compare(int[] pair1, int[] pair2) &#123;\n        return pair1[0] !&#x3D; pair2[0] ? pair2[0] - pair1[0] : pair2[1] - pair1[1];\n    &#125;\n&#125;);\n不支持存储NULL和non-comparable对象，通过堆元素的上浮和下沉，实现了在O(logn)的时间复杂度内插入和删除堆顶元素\n\n堆的构建过程，需要比较节点中数据的大小，所以，添加到优先级队列中的元素，需要能够比较大小，方法有两种：基于Comparable接口和基于Comparator接口，都有时则优先使用comparator，详见siftUp\nprivate void siftUp(int k, E x) &#123;\n    if (comparator !&#x3D; null)\n        siftUpUsingComparator(k, x);\n    else\n        siftUpComparable(k, x);\n&#125;\n\n\nSet（HashSet、LinkedHashSet、TreeSet）\n\n底层实现分别为：HashMap、LinkedHashMap、TreeMap，存储对象的时候，使用对象作为key，一个空的Object对象作为value，插入到底层的Map中，不管\n如何检查重复：无论Set中是否已经存在了某元素，都会直接在底层进行插入，通过add方法的返回值来确定插入前是否有相同的元素\n应用场景：HashSet用于==不需要保证元素插入和取出顺序==的场景；LinkedHashSet用于==保证元素的插入和取出顺序满足FIFO==的场景（LinedHashMap底层使用双向有序链表+哈希表）；TreeSet用于支持对元素==自定义排序规则==的场景\n\n\nHashMap（==数组+链表/红黑树==）\n\n底层为哈希表，对key求哈希作为hash值，包裹hash值、key和value为Node对象，作为哈希表（数组+链表）的组成节点。key不能重复，存储重复的key，新value会覆盖旧value（可以存一个key为null的键值对，但是不同key的value都可以是null）\n\n底层数组长度为2的倍数：hash函数可以使用与n-1取交替代与n取余、装载因子使用0.75使得阈值（n*0.75）一直为整数、初始化的时候选择比传入参数大的最小2的幂次方数\n\n动态扩容：默认初始化大小为16，每次超过阈值的时候就扩容为原来的2倍；扫描数组的每一条链表，根据节点下标决定是否要更改，插入到lo链表（不需改）和hi链表（需要改），处理完一条链表，将新链表插入到对应位置\n\n新位置确定方式：如果node.hash&amp;oldCap == 0，则节点在新table数组中的下标不变；如果node.hash &amp; oldCap != 0，则节点在新table数组中的下标变为i+oldCap（i为在原数组的下标）\n链表树化：当某个链表中的节点个数大于等于8（TREEIFY_THRESHOLD静态常量），并且table数组的长度大于等于64时，将会把链表转化为红黑树；如果table长度不满足则触发扩容操作；如果红黑树节点数在[2，6]之间，则退化为链表\n\n\n遍历\nfor(Map.Entry&lt;Integer, Integer&gt; entry : a.entrySet())&#123;...&#125;\n\n\nArrays的sort\n\nCollections的sort函数底层依赖的Arrays类的sort函数，如List接口中的sort的默认实现\n&#x2F;&#x2F;支持数组的排序\nArrays.sort(intervals, new Comparator&lt;int[]&gt;() &#123;\n    public int compare(int[] interval1, int[] interval2) &#123;\n        return interval1[0] - interval2[0];\n    &#125;\n&#125;);\n基本类型：使用==DualPivotQuickSort==，jdk7之前使用快排\n\n对快排进行改进，选取两个pivot，通过数组的长度决定什么时候选用双轴快排、插入排序、归并排序、记数排序\n\n\n对象数组：使用==TimSort==，jdk7之前使用归并\n\n使用非递归版本归并排序算法，在归并排序的过程中，大的排序区间不断分解为小的待排序区间，如果带排序区间的长度小于MIN_MERGE（32），就不再继续分解，转而执行二分插入排序算法\n二分插入排序：将数组分为已排序区间和未排序区间，通过二分查找，查找插入位置，当找到后，通过调用System.arraycopy()函数，将插入点之后的数据整体快速后移一位，腾出位置给要插入的数据\n\n\nArrays的fill：Arrays.fill(dis, Integer.MAX_VALUE);\n\n\n\nString（final数组）\n\nString不可变的原因：内部是final修饰的数组（引用不可改但是数据可改）、没有提供更改数组的方法、String类也是final的子类无法继承，避免了子类破坏String的不变性\n常量池技术：使用字符串常量赋值时触发，直接复用常量池已存在的对象，也可以使用intern方法复制堆上对象到常量池并回收堆上的对象（判等的时候使用equals()）\n运算符重载：因为String比较常用，所以延续了基本类型和包装类的设计，实现了加法操作String sc = sa + sb;，底层使用了StringBuilder来实现（StringBuffer加了锁，是线程安全的）\n\n\n比较\nclass Status implements Comparable&lt;Status&gt; &#123;\n    int val;\n    ListNode ptr;\n\n    Status(int val, ListNode ptr) &#123;\n        this.val &#x3D; val;\n        this.ptr &#x3D; ptr;\n    &#125;\n\n    public int compareTo(Status status2) &#123;\n        return this.val - status2.val;\n    &#125;\n&#125;\n补充\n\n使用数组实现一个栈\n   public class ArrayStack&lt;T&gt; &#123;\n    private Object[] array;\n    private int maxSize;\n    private int top;\n\n    public ArrayStack(int size) &#123;\n        this.maxSize &#x3D; size;\n        this.array &#x3D; new Object[size];\n        this.top &#x3D; -1; &#x2F;&#x2F; 初始化栈顶指针为-1\n    &#125;\n\n    public boolean isEmpty() &#123; return top &#x3D;&#x3D; -1; &#125;\n    public boolean isFull() &#123; return top &#x3D;&#x3D; maxSize - 1; &#125;\n   \tpublic int size() &#123; return top + 1; &#125;\n\n    public void push(T item) &#123;\n        if (isFull()) &#123;\n            System.out.println(&quot;栈已满，无法入栈&quot;);\n            return;\n        &#125;\n        array[++top] &#x3D; item;\n    &#125;\n\n    public T pop() &#123;\n        if (isEmpty()) &#123;\n            System.out.println(&quot;栈已空，无法出栈&quot;);\n            return null;\n        &#125;\n        T item &#x3D; (T) array[top];\n        array[top--] &#x3D; null; &#x2F;&#x2F; 清空出栈元素的引用\n        return item;\n    &#125;\n\n    public T peek() &#123;\n        if (isEmpty()) &#123;\n            System.out.println(&quot;栈已空，无法查看栈顶元素&quot;);\n            return null;\n        &#125;\n        return (T) array[top];\n    &#125;\n  \n    public static void main(String[] args) &#123;\n        ArrayStack&lt;Integer&gt; stack &#x3D; new ArrayStack&lt;&gt;(5);\n        stack.push(1);\n        stack.push(2);\n        stack.push(3);\n        stack.push(4);\n        stack.push(5);\n\n        System.out.println(&quot;栈顶元素：&quot; + stack.peek()); &#x2F;&#x2F; 输出 5\n        System.out.println(&quot;栈大小：&quot; + stack.size()); &#x2F;&#x2F; 输出 5\n\n        while (!stack.isEmpty()) &#123;\n            System.out.print(stack.pop() + &quot; &quot;); &#x2F;&#x2F; 输出 5 4 3 2 1\n        &#125;\n    &#125;\n&#125;\n\n\n使用数组实现一个队列\n   public class ArrayQueue&lt;T&gt; &#123;\n    private Object[] array;\n    private int maxSize;\n    private int front;\n    private int rear;\n\n    public ArrayQueue(int size) &#123;\n        this.maxSize &#x3D; size;\n        this.array &#x3D; new Object[size];\n        this.front &#x3D; 0;\n        this.rear &#x3D; -1;\n    &#125;\n\n    public boolean isEmpty() &#123; return rear &lt; front; &#125;\n    public boolean isFull() &#123; return rear &#x3D;&#x3D; maxSize - 1; &#125;\n    public int size() &#123; return rear - front + 1; &#125;\n\n    public void enqueue(T item) &#123;\n        if (isFull()) &#123;\n            System.out.println(&quot;队列已满，无法入队&quot;);\n            return;\n        &#125;\n        array[++rear] &#x3D; item;\n    &#125;\n\n    public T dequeue() &#123;\n        if (isEmpty()) &#123;\n            System.out.println(&quot;队列已空，无法出队&quot;);\n            return null;\n        &#125;\n        T item &#x3D; (T) array[front++];\n        return item;\n    &#125;\n\n    public T peek() &#123;\n        if (isEmpty()) &#123;\n            System.out.println(&quot;队列已空，无法查看队首元素&quot;);\n            return null;\n        &#125;\n        return (T) array[front];\n    &#125;\n\n    public static void main(String[] args) &#123;\n        ArrayQueue&lt;Integer&gt; queue &#x3D; new ArrayQueue&lt;&gt;(5);\n        queue.enqueue(1);\n        queue.enqueue(2);\n        queue.enqueue(3);\n        queue.enqueue(4);\n        queue.enqueue(5);\n\n        System.out.println(&quot;队首元素：&quot; + queue.peek()); &#x2F;&#x2F; 输出 1\n        System.out.println(&quot;队列大小：&quot; + queue.size()); &#x2F;&#x2F; 输出 5\n\n        while (!queue.isEmpty()) &#123;\n            System.out.print(queue.dequeue() + &quot; &quot;); &#x2F;&#x2F; 输出 1 2 3 4 5\n        &#125;\n    &#125;\n&#125;\n\n\n反转链表\n   class ListNode &#123;\n    int val;\n    ListNode next;\n\n    ListNode(int val) &#123;\n        this.val &#x3D; val;\n    &#125;\n&#125;\n\npublic class ReverseLinkedList &#123;\n    public ListNode reverse(ListNode head) &#123;\n        ListNode prev &#x3D; null;\n        ListNode current &#x3D; head;\n        \n        while (current !&#x3D; null) &#123;\n            ListNode nextNode &#x3D; current.next; &#x2F;&#x2F; 暂存下一个节点\n            current.next &#x3D; prev; &#x2F;&#x2F; 反转当前节点的指针方向\n            prev &#x3D; current; &#x2F;&#x2F; 更新prev为当前节点\n            current &#x3D; nextNode; &#x2F;&#x2F; 移动到下一个节点\n        &#125;\n        \n        return prev; &#x2F;&#x2F; 新的头节点\n    &#125;\n&#125;\n\n\n\nLFU：最不经常使用，Least Frequently Used\n   import java.util.*;\n\nclass LFUCache&lt;K, V&gt; &#123;\n    private final int capacity;\n    private Map&lt;K, V&gt; cache; &#x2F;&#x2F; 存储缓存的数据\n    private Map&lt;K, Integer&gt; freqMap; &#x2F;&#x2F; 存储数据的访问频率\n    private TreeMap&lt;Integer, LinkedHashSet&lt;K&gt;&gt; freqToKeys; &#x2F;&#x2F; 存储每个频率对应的数据集合\n    private int minFrequency; &#x2F;&#x2F; 记录最小访问频率\n\n    public LFUCache(int capacity) &#123;\n        this.capacity &#x3D; capacity;\n        cache &#x3D; new HashMap&lt;&gt;(capacity);\n        freqMap &#x3D; new HashMap&lt;&gt;(capacity);\n        freqToKeys &#x3D; new TreeMap&lt;&gt;();\n        minFrequency &#x3D; 0;\n    &#125;\n\n    public V get(K key) &#123;\n        if (!cache.containsKey(key)) &#123;\n            return null;\n        &#125;\n\n        &#x2F;&#x2F; 更新访问频率\n        int frequency &#x3D; freqMap.get(key);\n        freqMap.put(key, frequency + 1);\n\n        &#x2F;&#x2F; 更新freqToKeys\n        freqToKeys.get(frequency).remove(key);\n        if (freqToKeys.get(frequency).isEmpty()) &#123;\n            freqToKeys.remove(frequency);\n            if (frequency &#x3D;&#x3D; minFrequency) &#123;\n                minFrequency++;\n            &#125;\n        &#125;\n\n        &#x2F;&#x2F; 将数据移到更高频率的集合中\n        freqToKeys.computeIfAbsent(frequency + 1, k -&gt; new LinkedHashSet&lt;&gt;()).add(key);\n\n        return cache.get(key);\n    &#125;\n\n    public void put(K key, V value) &#123;\n        if (capacity &#x3D;&#x3D; 0) &#123;\n            return;\n        &#125;\n\n        &#x2F;&#x2F; 如果缓存已满，需要淘汰最不经常使用的数据\n        if (cache.size() &gt;&#x3D; capacity) &#123;\n            evict();\n        &#125;\n\n        &#x2F;&#x2F; 插入新数据\n        cache.put(key, value);\n        freqMap.put(key, 1);\n        freqToKeys.computeIfAbsent(1, k -&gt; new LinkedHashSet&lt;&gt;()).add(key);\n        minFrequency &#x3D; 1;\n    &#125;\n\n    private void evict() &#123;\n        if (cache.size() &#x3D;&#x3D; 0) &#123;\n            return;\n        &#125;\n\n        &#x2F;&#x2F; 获取最不经常使用的数据集合\n        LinkedHashSet&lt;K&gt; minFreqKeys &#x3D; freqToKeys.get(minFrequency);\n        if (minFreqKeys !&#x3D; null &amp;&amp; !minFreqKeys.isEmpty()) &#123;\n            K keyToRemove &#x3D; minFreqKeys.iterator().next();\n\n            &#x2F;&#x2F; 从各个数据结构中移除该数据\n            minFreqKeys.remove(keyToRemove);\n            cache.remove(keyToRemove);\n            freqMap.remove(keyToRemove);\n\n            if (minFreqKeys.isEmpty()) &#123;\n                freqToKeys.remove(minFrequency);\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\npublic class LFUCacheExample &#123;\n    public static void main(String[] args) &#123;\n        LFUCache&lt;Integer, String&gt; cache &#x3D; new LFUCache&lt;&gt;(2);\n        cache.put(1, &quot;One&quot;);\n        cache.put(2, &quot;Two&quot;);\n        System.out.println(cache.get(1)); &#x2F;&#x2F; 输出 &quot;One&quot;\n        cache.put(3, &quot;Three&quot;);\n        System.out.println(cache.get(2)); &#x2F;&#x2F; 输出 null，因为2被淘汰\n    &#125;\n&#125;\n\n\n\nLRU：最近最少使用，Least Recently Used\n   import java.util.*;\n\nclass LRUCache&lt;K, V&gt; &#123;\n    private final int capacity;\n    private LinkedHashMap&lt;K, V&gt; cache;\n\n    public LRUCache(int capacity) &#123;\n        this.capacity &#x3D; capacity;\n        cache &#x3D; new LinkedHashMap&lt;&gt;(capacity, 0.75f, true) &#123;\n            @Override\n            protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123;\n                return size() &gt; capacity;\n            &#125;\n        &#125;;\n    &#125;\n\n    public V get(K key) &#123;\n        return cache.getOrDefault(key, null);\n    &#125;\n\n    public void put(K key, V value) &#123;\n        cache.put(key, value);\n    &#125;\n\n    public void printCache() &#123;\n        for (Map.Entry&lt;K, V&gt; entry : cache.entrySet()) &#123;\n            System.out.println(entry.getKey() + &quot;: &quot; + entry.getValue());\n        &#125;\n    &#125;\n&#125;\n\npublic class LRUCacheExample &#123;\n    public static void main(String[] args) &#123;\n        LRUCache&lt;Integer, String&gt; cache &#x3D; new LRUCache&lt;&gt;(3);\n\n        cache.put(1, &quot;One&quot;);\n        cache.put(2, &quot;Two&quot;);\n        cache.put(3, &quot;Three&quot;);\n\n        cache.printCache();\n        System.out.println(&quot;-----------&quot;);\n\n        System.out.println(cache.get(2)); &#x2F;&#x2F; 输出 &quot;Two&quot;\n\n        cache.printCache();\n        System.out.println(&quot;-----------&quot;);\n\n        cache.put(4, &quot;Four&quot;);\n\n        cache.printCache();\n    &#125;\n&#125;\n\n跳表\n   import java.util.Random;\n\nclass SkipListNode &#123;\n    int value;\n    SkipListNode[] next;\n\n    public SkipListNode(int value, int level) &#123;\n        this.value &#x3D; value;\n        this.next &#x3D; new SkipListNode[level + 1];\n    &#125;\n&#125;\n\npublic class SkipList &#123;\n    private static final int MAX_LEVEL &#x3D; 16; &#x2F;&#x2F; 最大层数\n    private int level; &#x2F;&#x2F; 当前跳表的最大层数\n    private SkipListNode head; &#x2F;&#x2F; 头节点\n    private Random random; &#x2F;&#x2F; 用于随机层数的生成\n\n    public SkipList() &#123;\n        level &#x3D; 0;\n        head &#x3D; new SkipListNode(Integer.MIN_VALUE, MAX_LEVEL);\n        random &#x3D; new Random();\n    &#125;\n\n    &#x2F;&#x2F; 插入节点\n    public void insert(int value) &#123;\n        int newLevel &#x3D; randomLevel();\n        SkipListNode newNode &#x3D; new SkipListNode(value, newLevel);\n        SkipListNode[] update &#x3D; new SkipListNode[newLevel + 1];\n        SkipListNode current &#x3D; head;\n\n        &#x2F;&#x2F; 在每层查找合适的位置\n        for (int i &#x3D; level; i &gt;&#x3D; 0; i--) &#123;\n            while (current.next[i] !&#x3D; null &amp;&amp; current.next[i].value &lt; value) &#123;\n                current &#x3D; current.next[i];\n            &#125;\n            update[i] &#x3D; current;\n        &#125;\n\n        &#x2F;&#x2F; 插入节点\n        for (int i &#x3D; 0; i &lt;&#x3D; newLevel; i++) &#123;\n            newNode.next[i] &#x3D; update[i].next[i];\n            update[i].next[i] &#x3D; newNode;\n        &#125;\n\n        &#x2F;&#x2F; 更新跳表的层数\n        if (newLevel &gt; level) &#123;\n            level &#x3D; newLevel;\n        &#125;\n    &#125;\n\n    &#x2F;&#x2F; 删除节点\n    public void delete(int value) &#123;\n        SkipListNode[] update &#x3D; new SkipListNode[level + 1];\n        SkipListNode current &#x3D; head;\n\n        &#x2F;&#x2F; 在每层查找要删除的节点\n        for (int i &#x3D; level; i &gt;&#x3D; 0; i--) &#123;\n            while (current.next[i] !&#x3D; null &amp;&amp; current.next[i].value &lt; value) &#123;\n                current &#x3D; current.next[i];\n            &#125;\n            update[i] &#x3D; current;\n        &#125;\n\n        &#x2F;&#x2F; 删除节点\n        if (current.next[0] !&#x3D; null &amp;&amp; current.next[0].value &#x3D;&#x3D; value) &#123;\n            for (int i &#x3D; level; i &gt;&#x3D; 0; i--) &#123;\n                if (update[i].next[i] !&#x3D; null &amp;&amp; update[i].next[i].value &#x3D;&#x3D; value) &#123;\n                    update[i].next[i] &#x3D; update[i].next[i].next[i];\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n\n    &#x2F;&#x2F; 查找节点\n    public boolean search(int value) &#123;\n        SkipListNode current &#x3D; head;\n\n        &#x2F;&#x2F; 在每层查找节点\n        for (int i &#x3D; level; i &gt;&#x3D; 0; i--) &#123;\n            while (current.next[i] !&#x3D; null &amp;&amp; current.next[i].value &lt; value) &#123;\n                current &#x3D; current.next[i];\n            &#125;\n        &#125;\n\n        &#x2F;&#x2F; 判断是否找到节点\n        return current.next[0] !&#x3D; null &amp;&amp; current.next[0].value &#x3D;&#x3D; value;\n    &#125;\n\n    &#x2F;&#x2F; 随机生成节点的层数\n    private int randomLevel() &#123;\n        int level &#x3D; 0;\n        while (level &lt; MAX_LEVEL &amp;&amp; random.nextDouble() &lt; 0.5) &#123;\n            level++;\n        &#125;\n        return level;\n    &#125;\n&#125;\n\n\n\n\n\n2.算法2.1复杂度分析\n分析方法\n加法原则：总复杂度等于量级最大的那段代码的复杂度\n乘法原则：嵌套代码的复杂度等于嵌套内外的代码复杂度乘积\n其他方法：某一条语句执行的总次数；数据被访问的次数；使用递归树来分析\n\n\n空间复杂度\n不关注存储数据所需要的空间，而是关注算法所需要的额外存储消耗（循环、递归调用栈、辅助存储）\n由于现有题型大多以耗时为指标，所以尽可能使用==以空间换时间==的思想\n\n\n时间复杂度\n不看低阶和常数系数、加法取大、乘法取积\n分类：最好、最坏、平均\n\n\n\n2.2技巧\n双指针\n\n前缀和数组：原始数组不会被修改的情况下，频繁查询某个区间的累加和\n\n前缀和数组中两个元素的差，及这段区间的累加和\n\n示例：原数组{3,5,2,-1,4,1}；前缀和数组{0,3,8,10,8,12,13}\n\n\n二维前缀和\n\n递推公式\n\n\n主要应用：求解（x1，y1）-（x2，y2）子矩阵的和\n\n\n\n原数组\n1 2 4 3\n5 1 2 4\n6 3 5 9\n\n二维前缀和数组\n1  3  7  10\n6  9  15 22\n12 18 29 45  \n\n\n差分数组：频繁对原数组的某个区间的元素进行增减\n\n原理：对i→n的所有元素都加3，对j+1→n的所有元素都减3\n示例：原数组{8,2,6,3,1}；差分数组{8,-6,4,-3,-2}\n\n\n\n\n单调栈：满足单调性的栈结构\n\n插入过程：将一个元素插入单调栈时，为了维护栈的单调性，需要先弹出一些元素直到新插入的元素可以不破坏单调性\n\n伪代码\ninsert x\nwhile !sta.empty() &amp;&amp; sta.top()&lt;x\n    sta.pop()\nsta.push(x)\n\n\n\n\n并查集（Union-Find）：每个节点初始化为一棵树，不断合并成一颗树\nclass UF &#123;\n    &#x2F;&#x2F; 连通分量个数\n    private int count;\n    &#x2F;&#x2F; 存储每个节点的父节点\n    private int[] parent;\n\n    &#x2F;&#x2F; n 为图中节点的个数\n    public UF(int n) &#123;\n        this.count &#x3D; n;\n        parent &#x3D; new int[n];\n        for (int i &#x3D; 0; i &lt; n; i++) &#123;\n            parent[i] &#x3D; i;\n        &#125;\n    &#125;\n    \n    &#x2F;&#x2F; 将节点 p 和节点 q 连通\n    public void union(int p, int q) &#123;\n        int rootP &#x3D; find(p);\n        int rootQ &#x3D; find(q);\n        \n        if (rootP &#x3D;&#x3D; rootQ)\n            return;\n        \n        parent[rootQ] &#x3D; rootP;\n        &#x2F;&#x2F; 两个连通分量合并成一个连通分量\n        count--;\n    &#125;\n\n    &#x2F;&#x2F; 判断节点 p 和节点 q 是否连通\n    public boolean connected(int p, int q) &#123;\n        int rootP &#x3D; find(p);\n        int rootQ &#x3D; find(q);\n        return rootP &#x3D;&#x3D; rootQ;\n    &#125;\n\n    public int find(int x) &#123;\n        if (parent[x] !&#x3D; x) &#123;\n            parent[x] &#x3D; find(parent[x]);\n        &#125;\n        return parent[x];\n    &#125;\n\n    &#x2F;&#x2F; 返回图中的连通分量个数\n    public int count() &#123;\n        return count;\n    &#125;\n&#125;\n快速幂：为了在O(logn)的时间内计算a^n的技巧\n\n理论依据：a^(b+c) = a^b * a^c，与二分查找思想结合可以得出a^(2b) =a^b * a^b =  (a^b) ^2\n\n代码实现\n\n递归\nlong binpow(long a,long b)&#123;\n  if(b &#x3D;&#x3D; 0)&#123;\n    return 1;\n  &#125;\n  long res &#x3D; binpow(a, b&#x2F;2);\n  if(b % 2 &#x3D;&#x3D; 1)&#123;\n    return res * res * a; &#x2F;&#x2F;奇数次幂\n  &#125;else&#123;\n    return res * res; &#x2F;&#x2F;偶数次幂\n  &#125;\n&#125;\n非递归\nlong binpow(long a, long b)&#123;\n  long res &#x3D; 1;\n  while(b &gt; 0)&#123;\n    if((b &amp; 1) &#x3D;&#x3D; 1)&#123; &#x2F;&#x2F;当前位为1，则需要乘二进制幂，否则跳过此次\n      res &#x3D; res * a;\n    &#125;\n    a &#x3D; a*a;\n    b &gt;&gt;&#x3D; 1;\n  &#125;\n  return res;\n&#125;\n\n\n应用：计算 (x^n) mod m：取模运算不会干涉乘法，所以计算过程中直接取模就行\n\n另：根据费马小定理，如果m是一个质数，可以计算x^(n mod (m-1) )来加速算法过程\n\nlong binpow(long a, long b, long m)&#123;\n  a %&#x3D; m;\n  long res &#x3D; 1;\n  while(b &gt; 0)&#123;\n    if((b &amp; 1) &#x3D;&#x3D; 1)&#123;\n      res &#x3D; res * a % m;\n    &#125;\n    a &#x3D; a * a % m;\n    b &gt;&gt;&#x3D; 1;\n  &#125;\n  return res;\n&#125;\n\n\n前缀树（leetcode208 Trie树）\n\n代码示例\nclass Trie &#123;\n    private Trie[] children;\n    private boolean isEnd;\n\n    public Trie() &#123;\n        children &#x3D; new Trie[26];\n        isEnd &#x3D; false;\n    &#125;\n    \n    public void insert(String word) &#123;\n        Trie node &#x3D; this;\n        for (int i &#x3D; 0; i &lt; word.length(); i++) &#123;\n            char ch &#x3D; word.charAt(i);\n            int index &#x3D; ch - &#39;a&#39;;\n            if (node.children[index] &#x3D;&#x3D; null) &#123;\n                node.children[index] &#x3D; new Trie();\n            &#125;\n            node &#x3D; node.children[index];\n        &#125;\n        node.isEnd &#x3D; true;\n    &#125;\n    \n    public boolean search(String word) &#123;\n        Trie node &#x3D; searchPrefix(word);\n        return node !&#x3D; null &amp;&amp; node.isEnd;\n    &#125;\n    \n    public boolean startsWith(String prefix) &#123;\n        return searchPrefix(prefix) !&#x3D; null;\n    &#125;\n\n    private Trie searchPrefix(String prefix) &#123;\n        Trie node &#x3D; this;\n        for (int i &#x3D; 0; i &lt; prefix.length(); i++) &#123;\n            char ch &#x3D; prefix.charAt(i);\n            int index &#x3D; ch - &#39;a&#39;;\n            if (node.children[index] &#x3D;&#x3D; null) &#123;\n                return null;\n            &#125;\n            node &#x3D; node.children[index];\n        &#125;\n        return node;\n    &#125;\n&#125;\n\n\n线段树\n\n目的：用来维护区间信息的数据结构，可以在O(logN)的时间复杂度内实现单点修改、区间修改、区间查询（区间求和、求区间最大值、求区间最小值）等操作\n\n基本结构\n&#x2F;&#x2F; 对区间[s,t]递归建树\n&#x2F;&#x2F; int[] d &#x3D; new int[n*4];\nvoid build(int s, int t, int p)&#123;\n  if(s &#x3D;&#x3D; t)&#123;\n    d[p] &#x3D; a[s];\n    return;\n  &#125;\n  int m &#x3D; s + ((t - s) &gt;&gt; 1);\n  build(s,m,p*2);\n  build(m+1,t,p*2+1);\n  &#x2F;&#x2F;从下向上递归建树\n  d[p] &#x3D; d[p*2] + d[p*2+1];\n&#125;\n区间查询\nint getSum(int l, int r, int s, int t, int p)&#123;\n  &#x2F;&#x2F;[l,r]为查询区间，[s,t]为当前节点包含的区间，p为当前节点的编号\n  if(l &lt;&#x3D; s &amp;&amp; t &lt;&#x3D; r)&#123;\n    return d[p]; &#x2F;&#x2F;当前区间为查询区间的子集时直接返回当前节点的和\n  &#125;\n  int m &#x3D; s + ((t-s) &gt;&gt; 1);\n  int sum &#x3D; 0;\n  &#x2F;&#x2F;左儿子与查询区间有交集，递归查询左儿子\n  if(l &lt;&#x3D; m)&#123;\n    sum +&#x3D; getSum(l, r, s, m, p*2);\n  &#125;\n  &#x2F;&#x2F;右儿子与查询区间有交集，递归查询右儿子\n  if(r &gt; m)&#123;\n    sum +&#x3D; getSum(l, r, m+1, t, p*2+1);\n  &#125;\n  return sum;\n&#125;\n区间修改（存在标记的情况）\nvoid update(int l, int r, int c, int s, int t, int p)&#123;\n  &#x2F;&#x2F; [l, r] 为修改区间, c 为被修改的元素的变化量, [s, t] 为当前节点包含的区间, p为当前节点的编号\n  if(l &lt;&#x3D; s &amp;&amp;  t &lt;&#x3D; r)&#123;\n    d[p] +&#x3D; (t - s + 1) * c;\n    b[p] +&#x3D; c;\n    return;\n  &#125;\n  int m &#x3D; s + ((t - s) &gt;&gt; 1);\n  if (b[p] &amp;&amp; s !&#x3D; t) &#123;\n    &#x2F;&#x2F; 如果当前节点的懒标记非空,则更新当前节点两个子节点的值和懒标记值\n    d[p * 2] +&#x3D; b[p] * (m - s + 1);\n    d[p * 2 + 1] +&#x3D; b[p] * (t - m);\n    &#x2F;&#x2F; 将标记下传给子节点\n    b[p * 2] +&#x3D; b[p];\n    b[p * 2 + 1] +&#x3D; b[p];  \n    &#x2F;&#x2F; 清空当前节点的标记\n    b[p] &#x3D; 0;                                \n  &#125;\n  if (l &lt;&#x3D; m) &#123;\n    update(l, r, c, s, m, p * 2);\n  &#125;\n  if (r &gt; m) &#123;\n    update(l, r, c, m + 1, t, p * 2 + 1);\n  &#125;\n  d[p] &#x3D; d[p * 2] + d[p * 2 + 1];\n&#125;\n区间求和（存在标记的情况）\nint getsum(int l, int r, int s, int t, int p) &#123;\n  &#x2F;&#x2F; [l, r] 为查询区间, [s, t] 为当前节点包含的区间, p 为当前节点的编号\n  if (l &lt;&#x3D; s &amp;&amp; t &lt;&#x3D; r) return d[p];\n  &#x2F;&#x2F; 当前区间为询问区间的子集时直接返回当前区间的和\n  int m &#x3D; s + ((t - s) &gt;&gt; 1);\n  if (b[p]) &#123;\n    &#x2F;&#x2F; 如果当前节点的懒标记非空,则更新当前节点两个子节点的值和懒标记值\n    d[p * 2] +&#x3D; b[p] * (m - s + 1);\n    d[p * 2 + 1] +&#x3D; b[p] * (t - m);\n    &#x2F;&#x2F; 将标记下传给子节点\n    b[p * 2] +&#x3D; b[p];\n    b[p * 2 + 1] +&#x3D; b[p];  \n    &#x2F;&#x2F; 清空当前节点的标记\n    b[p] &#x3D; 0;                                \n  &#125;\n  int sum &#x3D; 0;\n  if (l &lt;&#x3D; m) sum &#x3D; getsum(l, r, s, m, p * 2);\n  if (r &gt; m) sum +&#x3D; getsum(l, r, m + 1, t, p * 2 + 1);\n  return sum;\n&#125;\n区间修改为某一个值而不是加上某一个值\nvoid update(int l, int r, int c, int s, int t, int p) &#123;\n  if (l &lt;&#x3D; s &amp;&amp; t &lt;&#x3D; r) &#123;\n    d[p] &#x3D; (t - s + 1) * c, b[p] &#x3D; c;\n    return;\n  &#125;\n  int m &#x3D; s + ((t - s) &gt;&gt; 1);\n  &#x2F;&#x2F; 额外数组储存是否修改值\n  if (v[p]) &#123;\n    d[p * 2] &#x3D; b[p] * (m - s + 1), d[p * 2 + 1] &#x3D; b[p] * (t - m);\n    b[p * 2] &#x3D; b[p * 2 + 1] &#x3D; b[p];\n    v[p * 2] &#x3D; v[p * 2 + 1] &#x3D; 1;\n    v[p] &#x3D; 0;\n  &#125;\n  if (l &lt;&#x3D; m) update(l, r, c, s, m, p * 2);\n  if (r &gt; m) update(l, r, c, m + 1, t, p * 2 + 1);\n  d[p] &#x3D; d[p * 2] + d[p * 2 + 1];\n&#125;\n\nint getsum(int l, int r, int s, int t, int p) &#123;\n  if (l &lt;&#x3D; s &amp;&amp; t &lt;&#x3D; r) return d[p];\n  int m &#x3D; s + ((t - s) &gt;&gt; 1);\n  if (v[p]) &#123;\n    d[p * 2] &#x3D; b[p] * (m - s + 1), d[p * 2 + 1] &#x3D; b[p] * (t - m);\n    b[p * 2] &#x3D; b[p * 2 + 1] &#x3D; b[p];\n    v[p * 2] &#x3D; v[p * 2 + 1] &#x3D; 1;\n    v[p] &#x3D; 0;\n  &#125;\n  int sum &#x3D; 0;\n  if (l &lt;&#x3D; m) sum &#x3D; getsum(l, r, s, m, p * 2);\n  if (r &gt; m) sum +&#x3D; getsum(l, r, m + 1, t, p * 2 + 1);\n  return sum;\n&#125;\n\n\n\n2.3算法思想\n排序\n\n基础排序算法\n\nO（n^2）\n\n冒泡排序：一对对比较，一对对交换\nvoid bubbleSort(int[] a,int n)&#123;\n    if(n &lt;&#x3D; 1) return;\n    for(int i &#x3D; 0; i &lt; n ; ++i)&#123;&#x2F;&#x2F;第几趟冒泡\n        boolean flag &#x3D; false;\n        for(int j &#x3D; 0; j &lt; n-i-1 ; ++j)&#123;\n            if(a[j] &gt; a[j+1])&#123;&#x2F;&#x2F;交换（相等不交换，所以是稳定的排序算法）\n                int temp &#x3D; a[j];\n                a[j] &#x3D; a[j+1];\n                a[j+1] &#x3D; temp;\n                flag &#x3D; true;\n            &#125;\n        &#125;\n        if(!flag) break;&#x2F;&#x2F;没有数据交换，提前结束\n    &#125;\n&#125;\n插入排序：分为已排和未排区间，取未排插入到已排。例：希尔排序\npublic static void insertionSort(int[] a, int n) &#123;\n    if (n &lt;&#x3D; 1) return;\n\n    for (int i &#x3D; 1; i &lt; n; ++i) &#123;\n        int value &#x3D; a[i];\n        int j &#x3D; i - 1;\n        &#x2F;&#x2F; 查找要插入的位置并移动数据\n        for (; j &gt;&#x3D; 0; --j) &#123;\n            if (a[j] &gt; value) &#123;\n                a[j + 1] &#x3D; a[j];\n            &#125; else &#123;\n                break;\n            &#125;\n        &#125;\n        a[j + 1] &#x3D; value;\n    &#125;\n&#125;\n选择排序：分为已排和未排区间，从未排选一个最小的插入到已排的\npublic void selectionSort(int[] a,int n)&#123;\n    if(n &lt;&#x3D; 1) return;\n    for(int i &#x3D; 0; i &lt; n-1; ++i)&#123;\n        int minPos &#x3D; i;\n        for(int j &#x3D; i; j &lt; n; ++j)&#123;\n            if(a[j] &lt; a[minPos])&#123;&#x2F;&#x2F;非稳定算法，因为换了位置\n                minPos &#x3D; j;\n            &#125;\n        &#125;\n        int temp &#x3D; a[i];\n        a[i] &#x3D; a[minPos];\n        a[minPos] &#x3D; temp;\n    &#125;\n&#125;\n希尔排序\n\n\n\nO（nlogn）\n\n归并排序：“分治思想”，分而治之，然后再合并\npublic class MergeSort &#123;\n    \n  &#x2F;&#x2F; 归并排序算法, a是数组，n表示数组大小\n  public static void mergeSort(int[] a, int n) &#123;\n    mergeSortInternally(a, 0, n-1);\n  &#125;\n\n  &#x2F;&#x2F; 递归调用函数\n  private static void mergeSortInternally(int[] a, int p, int r) &#123;\n    &#x2F;&#x2F; 递归终止条件\n    if (p &gt;&#x3D; r) return;\n\n    &#x2F;&#x2F; 取p到r之间的中间位置q,防止（p+r）的和超过int类型最大值\n    int q &#x3D; p + (r - p)&#x2F;2;\n    &#x2F;&#x2F; 分治递归\n    mergeSortInternally(a, p, q);\n    mergeSortInternally(a, q+1, r);\n\n    &#x2F;&#x2F; 将A[p...q]和A[q+1...r]合并为A[p...r]\n    merge(a, p, q, r);\n  &#125;\n\n  private static void merge(int[] a, int p, int q, int r) &#123;\n    int i &#x3D; p;\n    int j &#x3D; q+1;\n    int k &#x3D; 0; &#x2F;&#x2F; 初始化变量i, j, k\n    int[] tmp &#x3D; new int[r-p+1]; &#x2F;&#x2F; 申请一个大小跟a[p...r]一样的临时数组\n    while (i&lt;&#x3D;q &amp;&amp; j&lt;&#x3D;r) &#123;\n      if (a[i] &lt;&#x3D; a[j]) &#123;\n        tmp[k++] &#x3D; a[i++]; &#x2F;&#x2F; i++等于i:&#x3D;i+1\n      &#125; else &#123;\n        tmp[k++] &#x3D; a[j++];\n      &#125;\n    &#125;\n\n    &#x2F;&#x2F; 判断哪个子数组中有剩余的数据\n    int start &#x3D; i;\n    int end &#x3D; q;\n    if (j &lt;&#x3D; r) &#123;\n      start &#x3D; j;\n      end &#x3D; r;\n    &#125;\n\n    &#x2F;&#x2F; 将剩余的数据拷贝到临时数组tmp\n    while (start &lt;&#x3D; end) &#123;\n      tmp[k++] &#x3D; a[start++];\n    &#125;\n\n    &#x2F;&#x2F; 将tmp中的数组拷贝回a[p...r]\n    for (i &#x3D; 0; i &lt;&#x3D; r-p; ++i) &#123;\n      a[p+i] &#x3D; tmp[i];\n    &#125;\n  &#125;\n\n  &#x2F;**\n   * 合并(哨兵)\n   *&#x2F;\n  private static void mergeBySentry(int[] arr, int p, int q, int r) &#123;\n    int[] leftArr &#x3D; new int[q - p + 2];\n    int[] rightArr &#x3D; new int[r - q + 1];\n\n    for (int i &#x3D; 0; i &lt;&#x3D; q - p; i++) &#123;\n      leftArr[i] &#x3D; arr[p + i];\n    &#125;\n    &#x2F;&#x2F; 第一个数组添加哨兵（最大值）\n    leftArr[q - p + 1] &#x3D; Integer.MAX_VALUE;\n\n    for (int i &#x3D; 0; i &lt; r - q; i++) &#123;\n      rightArr[i] &#x3D; arr[q + 1 + i];\n    &#125;\n    &#x2F;&#x2F; 第二个数组添加哨兵（最大值）\n    rightArr[r-q] &#x3D; Integer.MAX_VALUE;\n\n    int i &#x3D; 0;\n    int j &#x3D; 0;\n    int k &#x3D; p;\n    while (k &lt;&#x3D; r) &#123;\n      &#x2F;&#x2F; 当左边数组到达哨兵值时，i不再增加，直到右边数组读取完剩余值，同理右边数组也一样\n      if (leftArr[i] &lt;&#x3D; rightArr[j]) &#123;\n        arr[k++] &#x3D; leftArr[i++];\n      &#125; else &#123;\n        arr[k++] &#x3D; rightArr[j++];\n      &#125;\n    &#125;\n  &#125;\n&#125;\n快速排序：选一个pivot，大的放左，小的放右\npublic class QuickSort &#123;\n\n  &#x2F;&#x2F; 快速排序，a是数组，n表示数组的大小\n  public static void quickSort(int[] a, int n) &#123;\n    quickSortInternally(a, 0, n-1);\n  &#125;\n\n  &#x2F;&#x2F; 快速排序递归函数，p,r为下标\n  private static void quickSortInternally(int[] a, int p, int r) &#123;\n    if (p &gt;&#x3D; r) return;\n\n    int q &#x3D; partition(a, p, r); &#x2F;&#x2F; 获取分区点\n    quickSortInternally(a, p, q-1);\n    quickSortInternally(a, q+1, r);\n  &#125;\n\n  private static int partition(int[] a, int p, int r) &#123;\n    int pivot &#x3D; a[r];\n    int i &#x3D; p;\n    for(int j &#x3D; p; j &lt; r; ++j) &#123;\n      if (a[j] &lt; pivot) &#123;\n        if (i &#x3D;&#x3D; j) &#123;\n          ++i;\n        &#125; else &#123;\n          int tmp &#x3D; a[i];\n          a[i++] &#x3D; a[j];\n          a[j] &#x3D; tmp;\n        &#125;\n      &#125;\n    &#125;\n\n    int tmp &#x3D; a[i];\n    a[i] &#x3D; a[r];\n    a[r] &#x3D; tmp;\n\n    System.out.println(&quot;i&#x3D;&quot; + i);\n    return i;\n  &#125;\n&#125;\n堆排序：先将数组原地建成一个堆，从下往上堆化，取堆顶元素，将下标n的元素放到堆顶，堆化\n\n二叉排序树排序\n\n\n\nO（n）\n\n计数排序：例：10G数据，100个桶\n\n基数排序：高考成绩排序，760个桶\n\n桶排序：10万个手机号码排序，从个位开始一位位进行桶或基数排序\n\n\n\n\n\n常见题型\n\n特殊排序：不是单纯的增减顺序，而是有一些特殊要求\nTop K：找到前K个大的，第K个大的……\n链表上的排序：数据结构由数组转换为链表，并进行排序\n排序预处理：排序只是问题的一部分预处理，可以运用库函数\n区间问题：（252题、56题） 先排序，再处理\n\n\n\n\n二分查找：大部分都是变形二分查找或二分答案，代码不长，但容易写对。难点在于：确定搜索区间，循环条件，区间更新，返回值\n\n查找区间永远是闭区间[low,high]\n\n循环条件永远是：low &lt;= high\n\n对于low == high的情况，必要的时候特殊处理，在while内部补充退出条件\n\n返回值永远是mid，而不是low，high\n\nlow、high的更新永远是low = mid + 1和high = mid - 1\n\n对于非确定性查找，使用前后探测法，来确定搜索区间（不用while，而只更新low或high）\n\n先处理命中情况，再处理在左右半部分查找的情况\n\n非确定查找：第一个、最后一个、第一个大于等于、最后一个小于等于、循环数组寻找最小值、寻找峰值\n\n\n\nbfs\n&#x2F;&#x2F; 计算从起点 start 到终点 target 的最近距离\nint BFS(Node start, Node target) &#123;\n    Queue&lt;Node&gt; q; &#x2F;&#x2F; 核心数据结构\n    Set&lt;Node&gt; visited; &#x2F;&#x2F; 避免走回头路\n    \n    q.offer(start); &#x2F;&#x2F; 将起点加入队列\n    visited.add(start);\n    int step &#x3D; 0; &#x2F;&#x2F; 记录扩散的步数\n\n    while (q not empty) &#123;\n        int sz &#x3D; q.size();\n        &#x2F;* 将当前队列中的所有节点向四周扩散 *&#x2F;\n        for (int i &#x3D; 0; i &lt; sz; i++) &#123;\n            Node cur &#x3D; q.poll();\n            &#x2F;* 划重点：这里判断是否到达终点 *&#x2F;\n            if (cur is target)\n                return step;\n            &#x2F;* 将 cur 的相邻节点加入队列 *&#x2F;\n            for (Node x : cur.adj()) &#123;\n                if (x not in visited) &#123;\n                    q.offer(x);\n                    visited.add(x);\n                &#125;\n            &#125;\n        &#125;\n        &#x2F;* 划重点：更新步数在这里 *&#x2F;\n        step++;\n    &#125;\n&#125;\ndfs\n\n递归\n\n代码技巧：千万不要试图想清楚整个递和归的执行过程，实际上是进入了一个思维误区\n\n怎么发现这个问题可以用递归来做：\n\n规模更小的问题，跟规模大点的问题，解决思路相同，但规模不同\n\n利用子问题的解可以组合得到原问题的解\n\n存在最小子问题，可以直接返回结果，即存在递归终止条件\n\n\n\n递归的正确编写姿势：\n\n我们可以假设子问题B,C已经解决，在此基础上思考如何解决原问题A，基于此，找递推公式+终止条件，然后翻译成代码\n\n\n\n\n时间复杂度和空间复杂度分析：\n\n时间复杂度：递推公式或者递归树\n空间复杂度：跟递归的函数调用栈最大深度成正比，即递归树的高度\n\n\n解题技巧：寻找重复结构，是否能将问题结构转化成结构相同，规模更小的子问题，然后写递推公式，包括递归终止条件，然后翻译成代码\n\n原问题解决思路和子问题解决思路是否一样\n\n子问题的解能否构造出原问题的解（递推公式）\n\n找到最小子问题（终止条件）\n\n\n\n\n\n回溯：回溯是递归的副产品，只要有递归就会有回溯，本质就是穷举+剪枝\n\nresult &#x3D; []\ndef backtrack(路径, 选择列表):\n    if 满足结束条件:\n        result.add(路径)\n        return\n    \n    for 选择 in 选择列表:\n        做选择\n        backtrack(路径, 选择列表)\n        撤销选择\ndfs\npublic List&lt;Integer&gt; dfs(int s,int t)&#123;\n        List&lt;Integer&gt; path &#x3D; new ArrayList&lt;&gt;();\n        path.add(s);\n        visited[s] &#x3D; true;\n        dfs_backtrack(s,t,path);\n        return resultPath;\n    &#125;\n\n    public void dfs_backtrack(int s,int t,List&lt;Integer&gt; path)&#123;\n        &#x2F;&#x2F;结束条件\n        if (s &#x3D;&#x3D; t)&#123;\n            resultPath &#x3D; new ArrayList&lt;&gt;(path);\n            return;\n        &#125;\n        for (int i &#x3D; 0; i &lt; adj[s].size(); i++) &#123;\n            int q &#x3D; adj[s].get(i);\n            if (!visited[q])&#123;\n                path.add(q);\n                visited[q] &#x3D; true;\n                dfs_backtrack(q,t,path);\n                path.remove(path.size()-1);\n            &#125;\n        &#125;\n    &#125;\n\n\ndp\n\n解题步骤\n\n可用回溯解决：使用穷举结果才能得到结果的问题（最值、可行、计数等）\n构建多阶段决策模型：看是否能将问题求解的过程分为多个阶段\n查看是否存在重复子问题：是否有多个路径到达同一状态\n定义状态：也就是如何记录每一阶段的不重复状态\n定义状态转移方程：也就是找到如何通过上一阶段的状态推导下一阶段的状态\n画状态转移表：辅助理解，验证正确性，确定状态转移的初始值\n\n\n代码结构\n# 自顶向下递归的动态规划\ndef dp(状态1, 状态2, ...):\n    for 选择 in 所有可能的选择:\n        # 此时的状态已经因为做了选择而改变\n        result &#x3D; 求最值(result, dp(状态1, 状态2, ...))\n    return result\n\n# 自底向上迭代的动态规划\n# 初始化 base case\ndp[0][0][...] &#x3D; base case\n# 进行状态转移\nfor 状态1 in 状态1的所有取值：\n    for 状态2 in 状态2的所有取值：\n        for ...\n            dp[状态1][状态2][...] &#x3D; 求最值(选择1，选择2...)\n0-1背包的最值、可行、计数\n\n最值1：有n个物品，选择其中一些物品装入背包，在不超过背包最大重量限制的前提下，背包中可装物品总重量的最大值是多少\n\n最值2：有n个物品，选择其中一些物品装入背包，正好装满背包所需物品最小个数（如果装不满，返回-1）\n\n可行：有n个物品，选择其中一些物品装入背包，能不能正好装满背包\n\n计数：有n个物品，选择其中一些物品装入背包，装满背包有多少种不同的装法\n\n\n\n完全背包（同一个物品可装n次）的最值、可行、计数\n\n背包可装物品总重量的最大值是多少\n是否能装满整个背包\n正好装满背包至少需要多少物品\n装满背包有多少种装法\n\n\n空间优化\n\n\n\n\n3.经典代码1.二叉树\n构建\n\n根据数组构建节点结构\npublic class Solution &#123;\n    static class TreeNode &#123;\n        int val;\n        TreeNode left;\n        TreeNode right;\n        public TreeNode(int x) &#123;\n            this.val &#x3D; x;\n            this.left &#x3D; null;\n            this.right &#x3D; null;\n        &#125;\n    &#125;\n    \n    &#x2F;**\n     * 根据数组构建二叉树\n     * @param arr 树的数组表示\n     * @return 构建成功后树的根节点\n     *&#x2F;\n    public TreeNode constructBinaryTree(final int[] arr) &#123;\n        &#x2F;&#x2F; 构建和原数组相同的树节点列表\n        List&lt;TreeNode&gt; treeNodeList &#x3D; arr.length &gt; 0 ? new ArrayList&lt;&gt;(arr.length) : null;\n        TreeNode root &#x3D; null;\n        &#x2F;&#x2F; 把输入数值数组，先转化为二叉树节点列表\n        for (int i &#x3D; 0; i &lt; arr.length; i++) &#123;\n            TreeNode node &#x3D; null;\n            if (arr[i] !&#x3D; -1) &#123; &#x2F;&#x2F; 用 -1 表示null\n                node &#x3D; new TreeNode(arr[i]);\n            &#125;\n            treeNodeList.add(node);\n            if (i &#x3D;&#x3D; 0) &#123;\n                root &#x3D; node;\n            &#125;\n        &#125;\n        &#x2F;&#x2F; 遍历一遍，根据规则左右孩子赋值就可以了\n        &#x2F;&#x2F; 注意这里 结束规则是 i * 2 + 1 &lt; arr.length，避免空指针\n        &#x2F;&#x2F; 为什么结束规则不能是i * 2 + 2 &lt; arr.length呢?\n        &#x2F;&#x2F; 如果i * 2 + 2 &lt; arr.length 是结束条件\n        &#x2F;&#x2F; 那么i * 2 + 1这个符合条件的节点就被忽略掉了\n        &#x2F;&#x2F; 例如[2,7,9,-1,1,9,6,-1,-1,10] 这样的一个二叉树,最后的10就会被忽略掉\n        for (int i &#x3D; 0; i * 2 + 1 &lt; arr.length; i++) &#123;\n            TreeNode node &#x3D; treeNodeList.get(i);\n            if (node !&#x3D; null) &#123;\n                &#x2F;&#x2F; 线性存储转连式存储关键逻辑\n                node.left &#x3D; treeNodeList.get(2 * i + 1);\n                &#x2F;&#x2F;  再次判断下 不忽略任何一个节点\n                if(i * 2 + 2 &lt; arr.length)\n                node.right &#x3D; treeNodeList.get(2 * i + 2);\n            &#125;\n        &#125;\n        return root;\n    &#125;\n&#125;\n直接构建邻接表\n\nArrayList&lt;Integer&gt;[] adjs &#x3D; new ArrayList[n];\nfor(int i &#x3D; 0; adjs.size(); i++)&#123;\n  adjs[i] &#x3D; new ArrayList&lt;&gt;();\n&#125;\nfor(int i &#x3D; 2; i &lt;&#x3D; n; i++)&#123;\n  adjs[father].add(son);\n&#125;\n图的构建\n&#x2F;&#x2F; 邻接表\n&#x2F;&#x2F; graph[x] 存储 x 的所有邻居节点\nList&lt;Integer&gt;[] graph;\n\n&#x2F;&#x2F; 邻接矩阵\n&#x2F;&#x2F; matrix[x][y] 记录 x 是否有一条指向 y 的边\nboolean[][] matrix;\n\n\n递归遍历\n&#x2F;&#x2F; 前序遍历·递归·LC144_二叉树的前序遍历\nclass Solution &#123;\n    public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123;\n        List&lt;Integer&gt; result &#x3D; new ArrayList&lt;Integer&gt;();\n        preorder(root, result);\n        return result;\n    &#125;\n\n    public void preorder(TreeNode root, List&lt;Integer&gt; result) &#123;\n        if (root &#x3D;&#x3D; null) &#123;\n            return;\n        &#125;\n        result.add(root.val);\n        preorder(root.left, result);\n        preorder(root.right, result);\n    &#125;\n&#125;\n&#x2F;&#x2F; 中序遍历·递归·LC94_二叉树的中序遍历\nclass Solution &#123;\n    public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123;\n        List&lt;Integer&gt; res &#x3D; new ArrayList&lt;&gt;();\n        inorder(root, res);\n        return res;\n    &#125;\n\n    void inorder(TreeNode root, List&lt;Integer&gt; list) &#123;\n        if (root &#x3D;&#x3D; null) &#123;\n            return;\n        &#125;\n        inorder(root.left, list);\n        list.add(root.val);             &#x2F;&#x2F; 注意这一句\n        inorder(root.right, list);\n    &#125;\n&#125;\n&#x2F;&#x2F; 后序遍历·递归·LC145_二叉树的后序遍历\nclass Solution &#123;\n    public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123;\n        List&lt;Integer&gt; res &#x3D; new ArrayList&lt;&gt;();\n        postorder(root, res);\n        return res;\n    &#125;\n\n    void postorder(TreeNode root, List&lt;Integer&gt; list) &#123;\n        if (root &#x3D;&#x3D; null) &#123;\n            return;\n        &#125;\n        postorder(root.left, list);\n        postorder(root.right, list);\n        list.add(root.val);             &#x2F;&#x2F; 注意这一句\n    &#125;\n&#125;\n非递归遍历\n&#x2F;&#x2F; 前序遍历顺序：中-左-右，入栈顺序：中-右-左\nclass Solution &#123;\n    public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123;\n        List&lt;Integer&gt; result &#x3D; new ArrayList&lt;&gt;();\n        if (root &#x3D;&#x3D; null)&#123;\n            return result;\n        &#125;\n        Stack&lt;TreeNode&gt; stack &#x3D; new Stack&lt;&gt;();\n        stack.push(root);\n        while (!stack.isEmpty())&#123;\n            TreeNode node &#x3D; stack.pop();\n            result.add(node.val);\n            if (node.right !&#x3D; null)&#123;\n                stack.push(node.right);\n            &#125;\n            if (node.left !&#x3D; null)&#123;\n                stack.push(node.left);\n            &#125;\n        &#125;\n        return result;\n    &#125;\n&#125;\n\n&#x2F;&#x2F; 中序遍历顺序: 左-中-右 入栈顺序： 左-右\nclass Solution &#123;\n    public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123;\n        List&lt;Integer&gt; result &#x3D; new ArrayList&lt;&gt;();\n        if (root &#x3D;&#x3D; null)&#123;\n            return result;\n        &#125;\n        Stack&lt;TreeNode&gt; stack &#x3D; new Stack&lt;&gt;();\n        TreeNode cur &#x3D; root;\n        while (cur !&#x3D; null || !stack.isEmpty())&#123;\n           if (cur !&#x3D; null)&#123;\n               stack.push(cur);\n               cur &#x3D; cur.left;\n           &#125;else&#123;\n               cur &#x3D; stack.pop();\n               result.add(cur.val);\n               cur &#x3D; cur.right;\n           &#125;\n        &#125;\n        return result;\n    &#125;\n&#125;\n\n&#x2F;&#x2F; 后序遍历顺序 左-右-中 入栈顺序：中-左-右 出栈顺序：中-右-左， 最后翻转结果\nclass Solution &#123;\n    public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123;\n        List&lt;Integer&gt; result &#x3D; new ArrayList&lt;&gt;();\n        if (root &#x3D;&#x3D; null)&#123;\n            return result;\n        &#125;\n        Stack&lt;TreeNode&gt; stack &#x3D; new Stack&lt;&gt;();\n        stack.push(root);\n        while (!stack.isEmpty())&#123;\n            TreeNode node &#x3D; stack.pop();\n            result.add(node.val);\n            if (node.left !&#x3D; null)&#123;\n                stack.push(node.left);\n            &#125;\n            if (node.right !&#x3D; null)&#123;\n                stack.push(node.right);\n            &#125;\n        &#125;\n        Collections.reverse(result);\n        return result;\n    &#125;\n&#125;\n层序遍历\n&#x2F;&#x2F; 102.二叉树的层序遍历\nclass Solution &#123;\n    public List&lt;List&lt;Integer&gt;&gt; resList &#x3D; new ArrayList&lt;List&lt;Integer&gt;&gt;();\n\n    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;\n        &#x2F;&#x2F;checkFun01(root,0);\n        checkFun02(root);\n\n        return resList;\n    &#125;\n\n    &#x2F;&#x2F;DFS--递归方式\n    public void checkFun01(TreeNode node, Integer deep) &#123;\n        if (node &#x3D;&#x3D; null) return;\n        deep++;\n\n        if (resList.size() &lt; deep) &#123;\n            &#x2F;&#x2F;当层级增加时，list的Item也增加，利用list的索引值进行层级界定\n            List&lt;Integer&gt; item &#x3D; new ArrayList&lt;Integer&gt;();\n            resList.add(item);\n        &#125;\n        resList.get(deep - 1).add(node.val);\n\n        checkFun01(node.left, deep);\n        checkFun01(node.right, deep);\n    &#125;\n\n    &#x2F;&#x2F;BFS--迭代方式--借助队列\n    public void checkFun02(TreeNode node) &#123;\n        if (node &#x3D;&#x3D; null) return;\n        Queue&lt;TreeNode&gt; que &#x3D; new LinkedList&lt;TreeNode&gt;();\n        que.offer(node);\n\n        while (!que.isEmpty()) &#123;\n            List&lt;Integer&gt; itemList &#x3D; new ArrayList&lt;Integer&gt;();\n            int len &#x3D; que.size();\n\n            while (len &gt; 0) &#123;\n                TreeNode tmpNode &#x3D; que.poll();\n                itemList.add(tmpNode.val);\n\n                if (tmpNode.left !&#x3D; null) que.offer(tmpNode.left);\n                if (tmpNode.right !&#x3D; null) que.offer(tmpNode.right);\n                len--;\n            &#125;\n\n            resList.add(itemList);\n        &#125;\n\n    &#125;\n&#125;\n翻转二叉树\n&#x2F;&#x2F;DFS递归\nclass Solution &#123;\n   &#x2F;**\n     * 前后序遍历都可以\n     * 中序不行，因为先左孩子交换孩子，再根交换孩子（做完后，右孩子已经变成了原来的左孩子），再右孩子交换孩子（此时其实是对原来的左孩子做交换）\n     *&#x2F;\n    public TreeNode invertTree(TreeNode root) &#123;\n        if (root &#x3D;&#x3D; null) &#123;\n            return null;\n        &#125;\n        invertTree(root.left);\n        invertTree(root.right);\n        swapChildren(root);\n        return root;\n    &#125;\n\n    private void swapChildren(TreeNode root) &#123;\n        TreeNode tmp &#x3D; root.left;\n        root.left &#x3D; root.right;\n        root.right &#x3D; tmp;\n    &#125;\n&#125;\n\n&#x2F;&#x2F;BFS\nclass Solution &#123;\n    public TreeNode invertTree(TreeNode root) &#123;\n        if (root &#x3D;&#x3D; null) &#123;return null;&#125;\n        ArrayDeque&lt;TreeNode&gt; deque &#x3D; new ArrayDeque&lt;&gt;();\n        deque.offer(root);\n        while (!deque.isEmpty()) &#123;\n            int size &#x3D; deque.size();\n            while (size-- &gt; 0) &#123;\n                TreeNode node &#x3D; deque.poll();\n                swap(node);\n                if (node.left !&#x3D; null) deque.offer(node.left);\n                if (node.right !&#x3D; null) deque.offer(node.right);\n            &#125;\n        &#125;\n        return root;\n    &#125;\n\n    public void swap(TreeNode root) &#123;\n        TreeNode temp &#x3D; root.left;\n        root.left &#x3D; root.right;\n        root.right &#x3D; temp;\n    &#125;\n&#125;\n二叉树的所有路径\n&#x2F;&#x2F;DFS递归\nclass Solution &#123;\n   &#x2F;**\n     * 前后序遍历都可以\n     * 中序不行，因为先左孩子交换孩子，再根交换孩子（做完后，右孩子已经变成了原来的左孩子），再右孩子交换孩子（此时其实是对原来的左孩子做交换）\n     *&#x2F;\n    public TreeNode invertTree(TreeNode root) &#123;\n        if (root &#x3D;&#x3D; null) &#123;\n            return null;\n        &#125;\n        invertTree(root.left);\n        invertTree(root.right);\n        swapChildren(root);\n        return root;\n    &#125;\n\n    private void swapChildren(TreeNode root) &#123;\n        TreeNode tmp &#x3D; root.left;\n        root.left &#x3D; root.right;\n        root.right &#x3D; tmp;\n    &#125;\n&#125;\n\n&#x2F;&#x2F;BFS\nclass Solution &#123;\n    public TreeNode invertTree(TreeNode root) &#123;\n        if (root &#x3D;&#x3D; null) &#123;return null;&#125;\n        ArrayDeque&lt;TreeNode&gt; deque &#x3D; new ArrayDeque&lt;&gt;();\n        deque.offer(root);\n        while (!deque.isEmpty()) &#123;\n            int size &#x3D; deque.size();\n            while (size-- &gt; 0) &#123;\n                TreeNode node &#x3D; deque.poll();\n                swap(node);\n                if (node.left !&#x3D; null) deque.offer(node.left);\n                if (node.right !&#x3D; null) deque.offer(node.right);\n            &#125;\n        &#125;\n        return root;\n    &#125;\n\n    public void swap(TreeNode root) &#123;\n        TreeNode temp &#x3D; root.left;\n        root.left &#x3D; root.right;\n        root.right &#x3D; temp;\n    &#125;\n&#125;\n前序和后序构造二叉树\nclass Solution &#123;\n    Map&lt;Integer, Integer&gt; map;  &#x2F;&#x2F; 方便根据数值查找位置\n    public TreeNode buildTree(int[] inorder, int[] postorder) &#123;\n        map &#x3D; new HashMap&lt;&gt;();\n        for (int i &#x3D; 0; i &lt; inorder.length; i++) &#123; &#x2F;&#x2F; 用map保存中序序列的数值对应位置\n            map.put(inorder[i], i);\n        &#125;\n\n        return findNode(inorder,  0, inorder.length, postorder,0, postorder.length);  &#x2F;&#x2F; 前闭后开\n    &#125;\n\n    public TreeNode findNode(int[] inorder, int inBegin, int inEnd, int[] postorder, int postBegin, int postEnd) &#123;\n        &#x2F;&#x2F; 参数里的范围都是前闭后开\n        if (inBegin &gt;&#x3D; inEnd || postBegin &gt;&#x3D; postEnd) &#123;  &#x2F;&#x2F; 不满足左闭右开，说明没有元素，返回空树\n            return null;\n        &#125;\n        int rootIndex &#x3D; map.get(postorder[postEnd - 1]);  &#x2F;&#x2F; 找到后序遍历的最后一个元素在中序遍历中的位置\n        TreeNode root &#x3D; new TreeNode(inorder[rootIndex]);  &#x2F;&#x2F; 构造结点\n        int lenOfLeft &#x3D; rootIndex - inBegin;  &#x2F;&#x2F; 保存中序左子树个数，用来确定后序数列的个数\n        root.left &#x3D; findNode(inorder, inBegin, rootIndex,\n                            postorder, postBegin, postBegin + lenOfLeft);\n        root.right &#x3D; findNode(inorder, rootIndex + 1, inEnd,\n                            postorder, postBegin + lenOfLeft, postEnd - 1);\n\n        return root;\n    &#125;\n&#125;\n前序和中序构造二叉树\nclass Solution &#123;\n    Map&lt;Integer, Integer&gt; map;\n    public TreeNode buildTree(int[] preorder, int[] inorder) &#123;\n        map &#x3D; new HashMap&lt;&gt;();\n        for (int i &#x3D; 0; i &lt; inorder.length; i++) &#123; &#x2F;&#x2F; 用map保存中序序列的数值对应位置\n            map.put(inorder[i], i);\n        &#125;\n\n        return findNode(preorder, 0, preorder.length, inorder,  0, inorder.length);  &#x2F;&#x2F; 前闭后开\n    &#125;\n\n    public TreeNode findNode(int[] preorder, int preBegin, int preEnd, int[] inorder, int inBegin, int inEnd) &#123;\n        &#x2F;&#x2F; 参数里的范围都是前闭后开\n        if (preBegin &gt;&#x3D; preEnd || inBegin &gt;&#x3D; inEnd) &#123;  &#x2F;&#x2F; 不满足左闭右开，说明没有元素，返回空树\n            return null;\n        &#125;\n        int rootIndex &#x3D; map.get(preorder[preBegin]);  &#x2F;&#x2F; 找到前序遍历的第一个元素在中序遍历中的位置\n        TreeNode root &#x3D; new TreeNode(inorder[rootIndex]);  &#x2F;&#x2F; 构造结点\n        int lenOfLeft &#x3D; rootIndex - inBegin;  &#x2F;&#x2F; 保存中序左子树个数，用来确定前序数列的个数\n        root.left &#x3D; findNode(preorder, preBegin + 1, preBegin + lenOfLeft + 1,\n                            inorder, inBegin, rootIndex);\n        root.right &#x3D; findNode(preorder, preBegin + lenOfLeft + 1, preEnd,\n                            inorder, rootIndex + 1, inEnd);\n\n        return root;\n    &#125;\n&#125;\n\n2.动态规划\n适用问题：回溯+重复子问题（重复状态），部分问题可以使用回溯+备忘录来解决\n\n构建多阶段决策模型：把每一层（每一阶段）重复的状态合并，只记录不同的状态，然后基于上一层（上一阶段）的状态集合，来指导下一层（下一阶段）的状态集合\n通过合并每一层重复的状态，保证每一层的状态个数不会超过某一常数w，避免回溯算法递归树中每层状态个数的指数级增长\n定义转移方程：不断迭代转移方程，并更新至数组对应位置（或临时变量）\n定义转移状态：适用数组会临时变量来存储上一层（上一阶段）的状态，并通过转移方程更新下一层（下一阶段）的状态\n\n\n解题步骤\n\n看是否可用回溯解决：使用穷举才能得到结果的问题，但是穷举耗时太大\n构建多阶段决策模型：看是否能将问题求解的过程分为多个阶段\n查看是否存在重复子问题：是否有多个路径到达同一状态\n定义状态：如何记录每一阶段的不重复状态\n定义状态转移方程：找到如何通过上一阶段的状态推导下一阶段的状态\n\n\n背包问题：0-1、完全、多重、二维费用、分组、有依赖的\n\n0-1背包：\n\n最值\n\n示例一：有n个物品，选择其中一些物品装入背包，在不超过背包最大重量限制的前提下，背包中可装物品总重量的最大值是多少\n\npublic int knapsack1(int[] weight, int n, int w)&#123;&#x2F;&#x2F;最值\n  boolean[][] dp &#x3D; new boolean[n][w+1];\n  dp[0][0] &#x3D; true;\n  if(weight[0] &lt;&#x3D; w)&#123;\n    dp[0][weight[0]] &#x3D; true;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; i++)&#123; &#x2F;&#x2F;动态规划状态转移\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      if(dp[i-1][j] &#x3D;&#x3D; true || (j-weight[i] &gt;&#x3D; 0 &amp;&amp; dp[i-1][j-weight[i]] &#x3D;&#x3D; true))&#123;\n        dp[i][j] &#x3D; true;\n      &#125;\n    &#125;\n  &#125;\n  for(int i &#x3D; w; i &gt;&#x3D; 0 ; i--)&#123;&#x2F;&#x2F;输出结果\n    if(dp[n-1][i] &#x3D;&#x3D; true) &#123;\n      return i;\n    &#125;\n  &#125;\n  return 0;\n&#125;\n示例二：有n个物品，选择其中一些物品装入背包，正好装满背包所需物品最小个数（如果装不满，返回-1）\n\npublic int knapsack3(int[] weight, int n, int w)&#123;&#x2F;&#x2F;最值\n  int[][] dp &#x3D; new int[n][w+1];&#x2F;&#x2F;记录到达某个状态，最少物品数量\n  for(int i &#x3D; 0; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      dp[i][j] &#x3D; Integer.MAX_VALUE-1;&#x2F;&#x2F;解决越界问题\n    &#125;\n  &#125;\n  dp[0][0] &#x3D; 0;\n  if(weight[0] &lt;&#x3D; w)&#123;\n    dp[0][weight[0]] &#x3D; 1;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123;&#x2F;&#x2F;动态规划状态转移\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      if(j-weight[i] &lt; 0)&#123;\n        dp[i][j] &#x3D; dp[i-1][j];\n      &#125;else&#123;\n        dp[i][j] &#x3D; Math.min(dp[i-1][j], dp[i-1][j-weight[i]] + 1);&#x2F;&#x2F;会有越界问题\n      &#125;\n    &#125;\n  &#125;\n  if(dp[n-1][w] &#x3D;&#x3D; Integer.MAX_VALUE) &#123;\n    return -1;\n  &#125;\n  return dp[n-1][w];\n&#125;\n\n\n可行\n\n示例：有n个物品，选择其中一些物品装入背包，能不能正好装满背包\n\npublic boolean kanpsack2(int[] weight, int n, int w)&#123;&#x2F;&#x2F;可行\n  boolean[][] dp &#x3D; new boolean[n][w+1];&#x2F;&#x2F;默认值false\n  dp[0][0] &#x3D; true;\n  if(weight[0] &lt;&#x3D; w)&#123;\n    dp[0][weight[0]] &#x3D; true;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123; &#x2F;&#x2F;动态规划状态转移\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      if(dp[i-1][j] &#x3D; true || (j-weight[i] &gt;&#x3D; 0 &amp;&amp; dp[i-1][j-weight[i]] &#x3D;&#x3D; true))&#123;\n        dp[i][j] &#x3D; true;\n      &#125;\n    &#125;\n  &#125;\n  return dp[n-1][w];\n&#125;\n\n\n计数\n\n示例：有n个物品，选择其中一些物品装入背包，装满背包有多少种不同的装法\n\npublic int knapsack4(int[] weight, int n, int w)&#123; &#x2F;&#x2F;计数\n  int[][] dp &#x3D; new int[n][w+1]; &#x2F;&#x2F;记录到达某个状态有几条路径\n  dp[0][0] &#x3D; 1;\n  if(weight[0] &lt;&#x3D; w)&#123;\n    dp[0][weight[0]] &#x3D; 1;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123; &#x2F;&#x2F;动态规划状态转移\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      if(j-weight[i] &lt; 0)&#123;\n        dp[i][j] &#x3D; dp[i-1][j];\n      &#125;else&#123;\n        dp[i][j] &#x3D; dp[i-1][j] + dp[i-1][j-weight[i]];\n      &#125;\n    &#125;\n  &#125;\n  return dp[n-1][w];\n&#125;\n\n\n\n\n完全背包：最值、可行、计数\n\n背包可装物品总重量的最大值是多少\npublic int wanquan_1(int[] weight, int n, int w)&#123;\n  boolean[][] dp &#x3D; new boolean[n][w+1];\n  for(int i &#x3D; 0; i &lt;&#x3D; w&#x2F;weight[0]; ++i)&#123;\n    dp[0][i+weight[0]] &#x3D; true;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      int k &#x3D; j&#x2F;weight[i];\n      for(int c &#x3D; 0; c &lt;&#x3D; k; ++c)&#123;\n        if(dp[i-1][j-c*weight[i]])&#123;\n          dp[i][j] &#x3D; true;\n          break;\n        &#125;\n      &#125;\n    &#125;\n  &#125;\n  for(int i &#x3D; w; i &gt;&#x3D; 0; --i)&#123;\n    if(dp[n-1][i] &#x3D;&#x3D; true)&#123;\n      return i;\n    &#125;\n  &#125;\n  return 0;\n&#125;\n是否能装满整个背包\npublic int wanquan_2(int[] weight, int n, int w)&#123;\n  boolean[][] dp &#x3D; new boolean[n][w+1];\n  for(int i &#x3D; 0; i &lt;&#x3D; w&#x2F;weight[0]; ++i)&#123;\n    dp[0][i+weight[0]] &#x3D; true;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      int k &#x3D; j&#x2F;weight[i];\n      for(int c &#x3D; 0; c &lt;&#x3D; k; ++c)&#123;\n        if(dp[i-1][j-c*weight[i]])&#123;\n          dp[i][j] &#x3D; true;\n          break;\n        &#125;\n      &#125;\n    &#125;\n  &#125;\n  return dp[n-1][w];\n&#125;\n正好装满背包至少需要多少物品\npublic int wanquan_3(int[] weight, int n, int w)&#123;\n  int[][] dp &#x3D; new int[n][w+1];\n  for(int i &#x3D; 0; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      dp[i][j] &#x3D; Integer.MAX_VALUE;\n    &#125;\n  &#125;\n  for(int i &#x3D; 0; i &lt;&#x3D; w&#x2F;weight[0]; ++i)&#123;\n    dp[0][i+weight[0]] &#x3D; i;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      int k &#x3D; j&#x2F;weight[i];\n      for(int c &#x3D; 0; c &lt;&#x3D; k; ++c)&#123;\n        if(dp[i-1][j-c*weight[i]] !&#x3D; Integer.MAX_VALUE &amp;&amp; dp[i-1][j-c*weight[i]]+c &lt; dp[i][j])&#123;\n          dp[i][j] &#x3D; dp[i-1][j-c*weight[i]] + c;\n          break;\n        &#125;\n      &#125;\n    &#125;\n  &#125;\n  return dp[n-1][w];\n&#125;\n装满背包有多少种装法\npublic int wanquan_4(int[] weight, int n, int w)&#123;\n  boolean[][] dp &#x3D; new boolean[n][w+1];\n  for(int i &#x3D; 0; i &lt;&#x3D; w&#x2F;weight[0]; ++i)&#123;\n    dp[0][i+weight[0]] &#x3D; 1;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      int k &#x3D; j&#x2F;weight[i];\n      for(int c &#x3D; 0; c &lt;&#x3D; k; ++c)&#123;\n        dp[i][j] +&#x3D; dp[i+1][j-c*weight[i]];\n      &#125;\n    &#125;\n  &#125;\n  return dp[n-1][w];\n&#125;\n\n\n0-1\n\n思考\n\n\n代码\npublic int knapsack(int[] weight, int n, int w)&#123;\n  boolean[][] dp &#x3D; new boolean[n][w+1]; &#x2F;&#x2F;默认为false\n  dp[0][0] &#x3D; true;\n  if(weight[0] &lt;&#x3D; w)&#123;\n    dp[0][weight[0]] &#x3D; true;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123; &#x2F;&#x2F;动态规划状态转移\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      if(dp[i-1][j] &#x3D;&#x3D; true)&#123;\n        dp[i][j] &#x3D; true;\n        if(j+weight[i] &lt;&#x3D; w)&#123;\n          dp[i][j+weight[i]] &#x3D; true;\n        &#125;\n      &#125;\n    &#125;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123; &#x2F;&#x2F;动态规划状态转移\n    for(itn j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      if(dp[i-1][j] &#x3D;&#x3D; true || (j-weight[i] &gt;&#x3D; 0 &amp;&amp; dp[i-1][j-weight[i]] &#x3D;&#x3D; true))&#123;\n        dp[i][j] &#x3D; true;\n      &#125;\n    &#125;\n  &#125;\n  for(int i &#x3D; w; i &gt;&#x3D; 0; --i)&#123;&#x2F;&#x2F;输出结果\n    if(dp[n-1][i] &#x3D;&#x3D; true)&#123;\n      return i;\n    &#125;\n  &#125;\n  return 0;\n&#125;\n\n\n二维背包\n\n思考\n\n\n代码\npublic int knapsack_2(int[] weight, int[] value, int n, int w)&#123;\n  int[][] dp &#x3D; new int[n][w+1];\n  for(int i &#x3D; 0; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      dp[i][j] &#x3D;&#x3D; Integer.MIN_VALUE;\n    &#125;\n  &#125;\n  dp[0][0] &#x3D; 0;\n  if(weight[0] &lt;&#x3D; w)&#123;\n    dp[0][weight[0]] &#x3D; value[0];\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      if(dp[i-1][j] &#x3D; Integer.MIN_VALUE)&#123;\n        continue;\n      &#125;\n      dp[i][j] &#x3D; Math.max(dp[i][j], dp[i-1][j]);\n      if(j+weight[i] &lt;&#x3D; w)&#123;\n        dp[i][j+weight[i]] &#x3D; Math.max(dp[i][j+weight[i]], dp[i-1][j] + value[i]);\n      &#125;\n    &#125;\n  &#125;\n  for(int i &#x3D; 1; i &lt; n; ++i)&#123;\n    for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n      if(dp[i-1][j] !&#x3D; Integer.MIN_VALUE)&#123;\n        dp[i][j] &#x3D; Math.max(dp[i][j], dp[i-1][j]);\n      &#125;\n      if(j-weight[i] &gt;&#x3D; 0 &amp;&amp; dp[i-1][j-weight[i]] !&#x3D; Integer.MIN_VALUE)&#123;\n        dp[i][j] &#x3D; Math.max(dp[i][j], dp[i-1][j-weight[i]] + value[i]);\n      &#125;\n    &#125;\n  &#125;\n  int res &#x3D; Integer.MIN_VALUE;\n  for(int j &#x3D; 0; j &lt;&#x3D; w; ++j)&#123;\n    if(res &lt; dp[n-1][j])&#123;\n      res &#x3D; dp[n-1][j];\n    &#125;\n  &#125;\n  return res;\n&#125;\n\n\n多重背包：装满背包有多少种装法\n\n\n\n\n路径问题\n\n打家劫舍和股票买卖：一般动态规划问题，上一个阶段做了什么决策，不影响下一个阶段的决策。但是打家劫舍&amp;股票买卖这类问题，上一个阶段的决策会影响下一个阶段的决策，所以，每个阶段需要记录不同的决策对应的最值，而不是一个全局的最值\n\n爬楼梯\n\n\n匹配问题\n\n\n空间优化：\n\n二维数组-&gt;滚动数组-&gt;一维数组\n\n问题：对于一组不同重量、不可分割的物品，选择其中一些物品装入背包，能不能正好装满背包\n\n\n\n\n\n3.海量数据处理\n使用Hash取余进行分治\n给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL\n首先遍历文件 a，对遍历到的 URL 求 hash(URL) % 1000 ，根据计算结果把遍历到的 URL 存储到 a0, a1, a2, …, a999，这样每个大小约为 300MB。使用同样的方法遍历文件 b，把文件 b 中的 URL 分别存储到文件 b0, b1, b2, …, b999 中。这样处理过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0, …, a999 对应 b999，不对应的小文件不可能有相同的 URL。那么接下来，我们只需要求出这 1000 对小文件中相同的 URL 就好了。接着遍历 ai( i∈[0,999] )，把 URL 存储到一个 HashSet 集合中。然后遍历 bi 中每个 URL，看在 HashSet 集合中是否存在，若存在，说明这就是共同的 URL，可以把这个 URL 保存到一个单独的文件中。\n\n\n有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)\n首先遍历大文件，对遍历到的每个词 x，执行 hash(x) % 5000 ，将结果为 i 的词存放到文件 ai 中。遍历结束后，我们可以得到 5000 个小文件。每个小文件的大小为 200KB 左右。如果有的小文件大小仍然超过 1MB，则采用同样的方式继续进行分解。接着统计每个小文件中出现频数最高的 100 个词。最简单的方式是使用 HashMap 来实现。其中 key 为词，value 为该词出现的频率。具体方法是：对于遍历到的词 x，如果在 map 中不存在，则执行 map.put(x, 1) ；若存在，则执行 map.put(x, map.get(x)+1) ，将该词频数加 1。上面我们统计了每个小文件单词出现的频数。接下来，我们可以通过维护一个小顶堆来找出所有词中出现频数最高的 100 个。具体方法是：依次遍历每个小文件，构建一个小顶堆，堆大小为 100。如果遍历到的词的出现次数大于堆顶词的出现次数，则用新词替换堆顶的词，然后重新调整为小顶堆，遍历结束后，小顶堆上的词就是出现频数最高的 100 个词。\n\n\n\n\n位图\n在 2.5 亿个整数中找出不重复的整数\n用 2 个 bit 来表示各个数字的状态：00 表示这个数字没出现过；01 表示这个数字出现过一次（即为题目所找的不重复整数）；10 表示这个数字出现了多次。那么这 232 个整数，总共所需内存为 232*2b=1GB。因此，当可用内存超过 1GB 时，可以采用位图法。假设内存满足位图法需求，进行下面的操作：遍历 2.5 亿个整数，查看位图中对应的位，如果是 00，则变为 01，如果是 01 则变为 10，如果是 10 则保持不变。遍历结束后，查看位图，把对应位是 01 的整数输出即可。\n\n\n给定 40 亿个不重复的没排过序的 unsigned int 型整数，然后再给定一个数，如何快速判断这个数是否在这 40 亿个整数当中\n由于 unsigned int 数字的范围是 [0, 1 &lt;&lt; 32)，我们用 1&lt;&lt;32=4,294,967,296 个 bit 来表示每个数字。初始位均为 0，那么总共需要内存：4,294,967,296b≈512M。我们读取这 40 亿个整数，将对应的 bit 设置为 1。接着读取要查询的数，查看相应位是否为 1，如果为 1 表示存在，如果为 0 表示不存在。\n\n\n布隆过滤器：快速检查一个元素是否属于一个集合的数据结构，基于哈希函数的位向量实现的（java.util.BitSet）\nadd(String element)：将元素添加到布隆过滤器中，通过多次哈希函数确定位于位图上的位置，并将这些位置设置为1。\ncontains(String element)：检查元素是否可能存在于布隆过滤器中。如果在所有哈希位置上都存在，则返回true；如果有任何一个位置不存在，则返回false。（不存在是一定的，存在是不一定的）\nhash(String element, int functionIndex)：使用多个哈希函数计算元素的哈希值。\n\n\n前缀树（Trie树）：常被用来统计字符串的出现次数，另外一个大的用途是字符串查找，判断是否有重复的字符串\n堆\n有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 20*500 个数中找出前 500 的数？\n首先建立大顶堆，堆的大小为数组的个数，即为 20，把每个数组最大的值存到堆中。接着删除堆顶元素，保存到另一个大小为 500 的数组中，然后向大顶堆插入删除的元素所在数组的下一个元素。重复上面的步骤，直到删除完第 500 个元素，也即找出了最大的前 500 个数。（为了在堆中取出一个数据后，能知道它是从哪个数组中取出的，从而可以从这个数组中取下一个值，可以把数组的指针存放到堆中，对这个指针提供比较大小的方法。）\n\n\n从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 (N+1)/2 个数；当样本数为偶数时，中位数为 第 N/2 个数与第 1+N/2 个数的均值。\n数据量小：维护两个堆，一个大顶堆，一个小顶堆。大顶堆中最大的数小于等于小顶堆中最小的数（一个堆保存一半数）；保证这两个堆中的元素个数的差不超过 1。若数据总数为偶数，当这两个堆建好之后，中位数就是这两个堆顶元素的平均值。当数据总数为奇数时，根据两个堆的大小，中位数一定在数据多的堆的堆顶。\n数据量大：顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中，且是在 f0 中，从小到大排列的第 1.5 亿个数与它后面的一个数的平均值。对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。\n\n\n\n\n\n附录\n@SuppressWarnings(&quot;unchecked&quot;)\n\nSometimes Java generics just doesn’t let you do what you want to, and you need to effectively tell the compiler that what you’re doing really will be legal at execution time.\n\n可选的值\n\n\n\nAll\nIt will suppress all warnings.\n解释\n\n\n\nCast\nSuppress the warning while casting from a generic type to a nonqualified type or the other way around.\n\n\n\nDeprecation\nIgnores when we’re using a deprecated(no longer important) method or type.\n使用了不赞成使用的类或方法时的警告\n\n\ndivzero\nSuppresses division by zero warning.\n\n\n\nempty\nIgnores warning of a statement with an empty body.\n\n\n\nunchecked\nIt doesn’t check if the data type is Object or primitive.\n例如使用集合时没有用泛型来指定集合保存的类型\n\n\nfallthrough\nIgnores fall-through on switch statements usually (if “break” is missing).\n当switch程序块直接通往下一种情况而没有break时的警告\n\n\nhiding\nIt suppresses warnings relative to locals that hide variable\n\n\n\nserial\nIt makes the compiler shut up about a missing serialVersionUID.\n在可序列化的类上缺少serialVersionUID定义时的警告\n\n\nfinally\nAvoids warnings relative to finally block that doesn’t return.\n任何 finally 子句不能正常完成时的警告\n\n\nunused\nTo suppress warnings relative to unused code.\n\n\n\n\n\n\nRuntime Error Hangup通常是因为程序在运行时被强制终止或意外终止导致的错误。这个错误通常出现在操作系统或程序遇到了无法处理的异常情况时。一些可能导致Runtime Error 0Hangup错误的原因包括：\n\n内存不足或堆栈溢出；\n访问无效的内存地址；\n文件操作失败或无效的文件指针；\n操作系统或其他软件的错误或冲突；\n程序代码错误或逻辑错误；\n程序被用户手动终止。\n\n\n笔试系统：输入输出学习链接（https://ac.nowcoder.com/acm/contest/5657#question）\n\n示例一：\n&#x2F;&#x2F; 有些输入可能是：\n&#x2F;&#x2F; 输入一个矩阵，每行以空格分隔。\n&#x2F;&#x2F; 3 2 3\n&#x2F;&#x2F; 1 6 5\n&#x2F;&#x2F; 7 8 9\nimport java.io.*;\nimport java.util.*;\n\nclass Solution &#123;\n  public void myFunc(ArrayList&lt;ArrayList&lt;Integer&gt;&gt; arr) &#123;\n    &#x2F;&#x2F; 使用自测数据按钮时调试用，正式提交时要删掉。\n    System.out.println(arr);\n  &#125;\n&#125;\npublic class Main\n&#123;\n  public static void main(String args[])\n  &#123;\n    Scanner cin &#x3D; new Scanner(System.in);\n    ArrayList&lt;ArrayList&lt;Integer&gt;&gt; arr &#x3D; new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;();\n    while(cin.hasNextLine())\n    &#123;\n      ArrayList&lt;Integer&gt; row &#x3D; new ArrayList&lt;Integer&gt;();\n      String line &#x3D; cin.nextLine();\n      if (line.length() &gt; 0) &#123;\n        String[] arrLine &#x3D; line.split(&quot; &quot;);\n        for (int i&#x3D;0; i&lt;arrLine.length; i++) &#123;\n          row.add(Integer.parseInt(arrLine[i]));\n        &#125;\n        arr.add(row);\n      &#125;\n    &#125;\n        \n    new Solution().myFunc(arr);\n  &#125;\n&#125;\n示例二：\n&#x2F;&#x2F;package main\n&#x2F;&#x2F;注意不要添加包名称，否则会报错。\n&#x2F;&#x2F; 不要自定义包名称，否则会报错，即不要添加package answer之类的语句；\n&#x2F;&#x2F; 您可以写很多个类，但是必须有一个类名为Main，并且为public属性，并且Main为唯一的public class；\n&#x2F;&#x2F; Main类的里面必须包含一个名字为&#39;main&#39;的静态方法（函数），这个方法是程序的入口。\n\nimport java.io.*;\nimport java.util.*;\nclass Solution &#123;\n  public int addab(int a, int b) &#123;\n    return a+b;\n  &#125;\n&#125;\npublic class Main\n&#123;\n  public static void main(String args[])\n  &#123;\n    Scanner cin &#x3D; new Scanner(System.in);\n    int a, b;\n    while(cin.hasNextInt())\n    &#123;\n      a &#x3D; cin.nextInt();\n      b &#x3D; cin.nextInt();\n      Solution s &#x3D; new Solution();\n      int c &#x3D; s.addab(a, b);\n      System.out.println(c);\n    &#125;\n  &#125;\n&#125;\n示例三：从在键盘上按Ctrl+Z。这样输入会读取到EOF，表示读取结束。\nwhile (sc.hasNextLine())&#123;\n\t\tScanner sc &#x3D; new Scanner(System.in);\n    String temp &#x3D; sc.nextLine();\n    String[] ss &#x3D; temp.trim().split(&quot; &quot;);\n    int num1 &#x3D; Integer.parseInt(ss[0]);\n    int num2 &#x3D; Integer.parseInt(ss[1]);\n    if (temp.isEmpty())&#123;\n        break;\n    &#125;\n    System.out.println(temp);\n&#125;\n\npublic class Main&#123;\n    public static void main(String[] args)&#123;\n        Scanner sc &#x3D; new Scanner(System.in);\n        int n &#x3D; sc.nextInt();\n        &#x2F;&#x2F;nextInt不会吸收掉换行符，后的nextLine会直接读取换行符，然后结束输入\n        sc.nextLine();\n        String temp &#x3D; sc.nextLine();\n        String[] data;\n        data &#x3D; temp.trim().split(&quot; &quot;);\n        Arrays.sort(data);\n        for(int i &#x3D; 0; i &lt; n; i++)&#123;\n            System.out.print(data[i]);\n            if(i !&#x3D; n-1)&#123;\n                System.out.print(&quot; &quot;);\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n","slug":"DataStructure","date":"2023-04-01T04:25:03.000Z","categories_index":"","tags_index":"algorithm","author_index":"Dajunnnnnn"}]