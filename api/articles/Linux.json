{"title":"Linux","uid":"3fe1ee3f3830128bf539e5f4ed9fbbe9","slug":"Linux","date":"2023-05-11T11:26:21.000Z","updated":"2023-08-05T14:16:00.722Z","comments":true,"path":"api/articles/Linux.json","keywords":null,"cover":[],"content":"<h1 id=\"Linux\"><a href=\"#Linux\" class=\"headerlink\" title=\"Linux\"></a>Linux</h1><h2 id=\"1-进程管理\"><a href=\"#1-进程管理\" class=\"headerlink\" title=\"1.进程管理\"></a>1.进程管理</h2><ol>\n<li><p>概念</p>\n<ul>\n<li><p>进程：进程是资源调度的基本单位，启动main函数就是启动一个JVM进程，main函数所在的线程是这个进程的主线程</p>\n<ul>\n<li><p>进程没有占用实际的物理内存空间的情况，这个状态就是<strong>挂起状态</strong></p>\n</li>\n<li><p>一个进程切换到另一个进程运行，称为<strong>进程的上下文切换</strong>，其中上下文包括CPU 寄存器、程序计数器，切换时保存在进程的 PCB（进程存在的唯一标识）中，切换的时机主要有时间片耗尽、资源不足、高优先级进程调度、主动Sleep、硬件中断</p>\n<ul>\n<li>进程切换涉及到更多的内容，包括整个进程的地址空间、全局变量、文件描述符等。因此，进程切换的开销通常比线程切换大</li>\n<li>线程切换只涉及到线程的堆栈、寄存器和程序计数器等，不涉及进程级别的资源，因此线程切换的开销较小</li>\n</ul>\n</li>\n<li><p>分配给进程的资源：虚拟内存、文件描述符、信号</p>\n</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230803135300213.png\" alt=\"image-20230803135300213\"></p>\n</li>\n<li><p>线程：线程是CPU调度的基本单位，线程间共享堆和方法区（代码段、数据段）资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈</p>\n<ul>\n<li><strong>用户线程（*User Thread*）</strong>：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li>\n<li><strong>内核线程（*Kernel Thread*）</strong>：在内核中实现的线程，是由内核操作系统管理的线程，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责；</li>\n<li><strong>轻量级进程（*LightWeight Process*）</strong>：在内核中来支持用户线程；</li>\n</ul>\n</li>\n<li><p>协程：由编程语言创建，又称为用户态线程；协程是异步非抢占式的，需要用户自己释放使用权来切换协程；线程数量在千万级别，而协程可以达到上万级别，因为线程是多核上并行，而协程是用来实现高并发的</p>\n</li>\n</ul>\n</li>\n<li><p>进程通信的方式：匿名管道、命名管道、信号、消息队列、共享内存、内存映射、套接字、信号量</p>\n<ul>\n<li>管道<ul>\n<li>匿名管道：Unix系统最古老的通信方式，通过在内核中维护一块内核缓冲区来实现通信，Linux系统中通过<code>pipi()</code>函数创建管道，会生成两个文件描述符，分别对应读端和写端，只能用于具有亲缘关系的进程间通信</li>\n<li>命名管道：为了解决匿名管道只能在具有亲缘关系的进程间通信的问题，通过将管道和一个路径名相关联，以FIFO的文件形式存在于文件系统中，没有亲缘关系的进程也可以像操作文件一样通过命名管道进行数据交换</li>\n</ul>\n</li>\n<li>信号：Linux系统最古老的通信方式，是一种异步通信的方式，信号可以导致一个正在运行的进程被另一个正在运行的进程中断，转而处理突发事件，是事件发生时对进程的通知机制</li>\n<li>消息队列：一个消息的链表，链表中的消息有特性格式和优先级，有对应权限的进程可以对其进行读写</li>\n<li>共享内存：允许两个或多个进程共享物理内存的同一块区域（称为段），由于一个共享内存段会成为一个进程用户空间的一部分，因此这种IPC机制无需内核介入，只需要一个进程将数据复制进共享内存中即可<ul>\n<li>共享内存：不同进程间共享的一段物理内存，所有进程都可以访问共享内存中的地址，改动对所有进程可见。优点是可以直接访问速度更快；缺点是需要额外的同步机制来互斥访问</li>\n</ul>\n</li>\n<li>内存映射：将磁盘文件的数据映射到内存，用户通过修改内存就能修改磁盘文件</li>\n<li>信号量：用于解决进程或线程之间并发执行是的同步问题，对信号量的操作主要有P操作和V操作</li>\n<li>Socket：对网络中不同主机上的应用进程之间进行双向通信的段点的抽象，提供了应用层进程利用网络协议交换数据的机制，用于网络中不同主机上的进程之间进行通信</li>\n</ul>\n</li>\n<li><p>进程调度</p>\n<ul>\n<li>算法<ul>\n<li>先来先服务（FCFS）：选最早</li>\n<li>短作业/进程优先（SJF/SPF）：选最短（平均等待时间、平均周转时间最少）</li>\n<li>优先级调度：选优先级最高（净：sys&gt;users、交互&gt;非交互、I/O&gt;CPU）</li>\n<li>高相应比优先（HRRN）：响应比最高<br>（等待时间+需服务时间）/需服务时间</li>\n<li>时间片轮转（RR）：分时OS、绝对可抢占</li>\n<li>多级反馈队列：1+3+5、“UNIX”、优先级高到低、时间片小到大（上无才执行下</li>\n</ul>\n</li>\n<li>不能调度（处理中断、临界区、屏蔽中断）；剥夺与非剥夺调度（早期批处理）【在进程处于临界区时，只要不破坏临界区资源使用规则就不影响处理机调度】</li>\n<li>评估指标：CPU利用率（忙碌时间/总时间）、系统吞吐量（完成作业数/总时间）、平均周转时间（提交到完成/n=（等待+执行）/n）、带权周转时间（作业周转时间/实际运行时间，越小越好必然大于1）、等待时间（等处理机状态）、响应时间（提交请求到首次响应）</li>\n</ul>\n</li>\n<li><p>死锁：并发执行线程需要加锁主要是为了保护共享数据，防止出现”竞态条件”</p>\n<ul>\n<li>死锁定义：多个进程因竞争资源而造成的一种僵局（互相等待）若无外力作用，这些进程都将无法向前推进<ul>\n<li>互斥：保证一个线程在临界区执行时，其他线程应该被阻止进入临界区</li>\n<li>同步：并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步</li>\n</ul>\n</li>\n<li>产生原因：竞争资源、进程推进非法</li>\n<li>必要条件：互斥访问临界区资源、请求和保持、不剥夺、环路等待（等待的进程成环）</li>\n<li>预防死锁：破坏互斥（资源共享使用）、破坏不剥夺、破坏请求和保持（预先静态分配）、破坏循环等待（顺序资源分配）（必要条件）</li>\n<li>避免死锁：安全状态（不一定是死锁状态）、银行家算法（必须知道将来的资源请求）、安全性算法</li>\n<li>检测死锁：利用死锁定理化简资源分配图（圆圈代表进程，框代表一类资源，一个圆代表一个该类资源，进程到资源为请求边，资源到进程为分配边）把圈都变成孤点</li>\n<li>解除死锁：资源剥夺、撤销进程、进程回退</li>\n<li>死锁检测：银行家算法<ul>\n<li>Max、Allocation、Need</li>\n<li>Work、Need、Allocation、W+A（分配一个写一行，一行一行写）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>同步</p>\n<ul>\n<li><p>信号量：操作系统提供的一种协调共享资源访问的方法，通常<strong>信号量表示资源的数量</strong>，对应的变量是一个整型（<code>sem</code>）变量，外，还有<strong>两个原子操作的系统调用函数来控制信号量的</strong>，分别是：</p>\n<ul>\n<li><em>P 操作</em>：将 <code>sem</code> 减 <code>1</code>，相减后，如果 <code>sem &lt; 0</code>，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；</li>\n<li><em>V 操作</em>：将 <code>sem</code> 加 <code>1</code>，相加后，如果 <code>sem &lt;= 0</code>（多个线程同时P后，即使有V，sem也会是负的），唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；</li>\n</ul>\n</li>\n<li><p>操作系统实现</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/640-20230805163119606.png\" alt=\"图片\"></p>\n</li>\n</ul>\n</li>\n<li><p>线程通信方式：Monitor、Condition</p>\n<ul>\n<li>在Java中,常用的线程通信方式有两种,分别是利用<code>Monitor</code>实现线程通信、利用<code>Condition</code>实现线程通信。线程同步是线程通信的前提,所以究竟采用哪种方式实现通信,取决于线程同步的方式。</li>\n<li>如果是采用<code>synchronized</code>关键字进行同步,则需要依赖<code>Monitor</code>（同步监视器）实现线程通信，Monitor就是锁对象。在synchronized同步模式下,锁对象可以是任意的类型,所以通信方法自然就被定义在Object类中了,这些方法包括：<code>wait()</code>、<code>notify()</code>、<code>notifyAll()</code>。一个线程通过<code>Monitor</code>调用<code>wait()</code>时,它就会释放锁并在此等待。当其他线程通过Monitor调用notify()时,则会唤醒在此等待的一个线程。当其他线程通过Monitor调用notifyAll()时,则会唤醒在此等待的所有线程。</li>\n<li>JDK 1.5新增了<code>Lock</code>接口及其实现类,提供了更为灵活的同步方式。如果是采用<code>Lock</code>对象进行同步,则需要依赖<code>Condition</code>实现线程通信，<code>Condition</code>对象是由<code>Lock</code>对象创建出来的,它依赖于<code>Lock</code>对象。<code>Condition</code>对象中定义的通信方法,与Object类中的通信方法类似,它包括<code>await()</code>、<code>signal()</code>、<code>signalAll()</code>。通过名字就能看出它们的含义了,当通过Condition调用<code>await()</code>时当前线程释放锁并等待,当通过Condition调用<code>signal()</code>时唤醒一个等待的线程,当通过Condition调用<code>signalAll()</code>时则唤醒所有等待的线程。</li>\n<li>线程同步是基于同步队列实现的,而线程通信是基于等待队列实现的。当调用等待方法时，即将当前线程加入等待队列。当调用通知方法时,即将等待队列中的一个或多个线程转移回同步队列。因为<code>synchronized</code>只有一个<code>Monitor</code>，所以它就只有一个等待队列。而<code>Lock</code>对象可以创建出多个<code>Condition</code>，所以它拥有多个等待队列。多个等待队列带来了极大的灵活性,所以基于<code>Condition</code>的通信方式更为推荐</li>\n<li>比如，在实现生产消费模型时，生产者要通知消费者、消费者要通知生产者。相反，不应该出现生产者通知生产者、消费者通知消费者这样的情况。如果使用<code>synchronized</code>实现这个模型，由于它只有一个等待队列,所以只能把生产者和消费者加入同一个队列,这就会导致生产者通知生产者、消费者通知消费者的情况出现。采用<code>Lock</code>实现这个模型时，由于它有多个等待队列，可以有效地将这两个角色区分开，就能避免出现这样的问题。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"2-内存管理\"><a href=\"#2-内存管理\" class=\"headerlink\" title=\"2.内存管理\"></a>2.内存管理</h2><ol>\n<li><p>虚拟地址与物理地址映射方式</p>\n<ul>\n<li><p>分段：将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息，段与段之间可以不相邻接。主要是为了程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护，反应程序的逻辑结构有利于段的共享</p>\n<ul>\n<li>会有外部内存碎片，可以通过内存交换（写入磁盘swap区再重新写回），但是因为磁盘读写速度所以效率很低</li>\n</ul>\n</li>\n<li><p>分页：用户程序的地址空间划分为若干个固定大小的页，内存空间分成若干个物理块，页和快的大小相等，可以将任一页放在任一块中。主要用于实现虚拟内存，从而获得更大的地址空间，可以解决内存碎片，提高内存利用率</p>\n<ul>\n<li>换入换出<ul>\n<li>当进程访问的虚拟地址在页表中查不到时，系统会产生一个<strong>缺页异常</strong>，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行</li>\n<li>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为<strong>换出</strong>（<em>Swap Out</em>）。一旦需要的时候，再加载进来，称为<strong>换入</strong>（<em>Swap In</em>）</li>\n</ul>\n</li>\n<li>多级页表：</li>\n<li>TLB：专门存放程序最常访问的页表项的 Cache，又称快表</li>\n</ul>\n</li>\n<li><p>段页式：段页式存储管理方式即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。系统同时配置段表和页表，每个进程一张段表，没个分段一张页表，利用段表和页表进行用户地址空间到物理内存空间的映射。</p>\n<ul>\n<li>段表项包括段号、页表长度、页表起始地址；页表项包括页号、块号。在进行地址转换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最终形成物理地址。</li>\n</ul>\n</li>\n<li><p>Linux实现：<strong>页式内存管理</strong>（由段式内存管理所映射而成的地址上再加上一层地址映射）</p>\n<ul>\n<li>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。</li>\n</ul>\n</li>\n<li><p>32位系统内存空间划分</p>\n<ul>\n<li>上图中的内存布局可以看到，代码段下面还有一段内存空间的（灰色部分），这一块区域是「保留区」，之所以要有保留区这是因为在大多数的系统里，我们认为比较小数值的地址不是一个合法地址，例如，我们通常在 C 的代码里会将无效的指针赋值为 NULL。因此，这里会出现一段不可访问的内存保留区，防止程序因为出现 bug，导致读或写了一些小内存地址的数据，而使得程序跑飞</li>\n<li>在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 <code>malloc()</code> 或者 <code>mmap()</code> ，就可以分别在堆和文件映射段动态分配内存<ul>\n<li>保留区：因为在大多数的系统里，认为比较小数值的地址不是一个合法地址，所以空出来不使用</li>\n<li>代码段，包括二进制可执行代码；</li>\n<li>数据段，包括已初始化的静态常量和全局变量；</li>\n<li>BSS 段，包括未初始化的静态变量和全局变量；</li>\n<li>堆段，包括动态分配的内存，从低地址开始向上增长；</li>\n<li>文件映射段，包括动态库、共享内存等，从低地址开始向上增长。</li>\n<li>栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 <code>8 MB</code>，增长顺序为从高到低</li>\n<li>内核空间：</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230803120541090.png\" alt=\"image-20230803120541090\"></p>\n</li>\n</ul>\n</li>\n<li><p>虚拟内存和物理内存</p>\n<ul>\n<li>物理内存：使用物理地址进行寻址，寻址的范围取决于CPU的地址线条数（如32位平台下寻址范围为2^32即4G），每次开启一个线程都要给4G物理内存，资源不够时没分配到资源的进程只能等待，并且资源不隔离导致数据不安全</li>\n<li>虚拟内存：让应用程序以为自己拥有连续的可用内存（连续完整的地址空间），实际上被分割成多个物理内存分片，还有部分存储在外部磁盘存储器上，在需要时进行数据交换</li>\n</ul>\n</li>\n<li><p>内存泄漏</p>\n<ul>\n<li>程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果</li>\n<li>避免内存泄漏：动态开辟内存空间、及时释放内存、使用智能指针，采用静态分析技术（LCLink、ccmalloc、Dmalloc、Electric Fence、Leaky、LeakTracer、MEMWATCH、Valgrind、KCachegrind）来进行检测</li>\n</ul>\n</li>\n<li><p>堆和栈的区别</p>\n<ul>\n<li>管理方式：堆手动控制，栈由编译器自动管理</li>\n<li>空间大小：栈小于堆，栈会出现OOM问题</li>\n<li>碎片问题：堆频繁的分配和释放会造成空间不连续，利用率低，栈不会</li>\n<li>增长方向：堆是向上的（内存地址增加），栈是向下的（内存地址减小）</li>\n<li>分配方式：堆都是动态分配的，没有静态分配的堆。栈有两种分配方式：静态分配和动态分配，静态分配是编译器完成的，比如局部变量的分配；动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，它的动态分配是由编译器实现的，无需我们手工实现</li>\n<li>分配效率：栈有寄存器、底层指令的支持，堆是由C/C++来提供的，根据算法在内存中找可用空间，所以堆的效率要比栈低的多</li>\n</ul>\n</li>\n<li><p>malloc</p>\n</li>\n<li><p>CPU Cache的数据写入</p>\n<ul>\n<li>写直达（Write Through）：把数据同时写入内存和 Cache 中，写入前会先判断数据是否已经在 CPU Cache 里面了<ul>\n<li>如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；</li>\n<li>如果数据没有在 Cache 里面，就直接把数据更新到内存里面。</li>\n</ul>\n</li>\n<li>写回（Write Back）：当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率</li>\n</ul>\n</li>\n<li><p>缓存一致性</p>\n<ul>\n<li><p>第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为<strong>写传播（*Write Propagation*）</strong>；</p>\n</li>\n<li><p>第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为<strong>事务的串行化（*Transaction Serialization*）</strong>。</p>\n</li>\n<li><p>实现</p>\n<ul>\n<li><p>总线嗅探：当 A 号 CPU 核心修改了 L1 Cache 中 i 变量的值，通过总线把这个事件广播通知给其他所有的核心，然后每个 CPU 核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的 L1 Cache 里面，如果 B 号 CPU 核心的 L1 Cache 中有该数据，那么也需要把该数据更新到自己的 L1 Cache</p>\n</li>\n<li><p>MESI协议：</p>\n<ul>\n<li><p>状态：Modified（已修改）、Exclusive（独占）、Shared（共享）、Invalidated（已失效）</p>\n</li>\n<li><p>状态流转</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/%20MESI%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E8%A1%A8%E6%A0%BC.png\" alt=\"img\"></p>\n</li>\n<li><p>示例</p>\n<ul>\n<li>当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的；</li>\n<li>然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的；</li>\n<li>当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。</li>\n<li>如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。</li>\n<li>如果 A 号 CPU 核心的 Cache 里的 i 变量对应的 Cache Line 要被「替换」，发现 Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-网络系统\"><a href=\"#3-网络系统\" class=\"headerlink\" title=\"3.网络系统\"></a>3.网络系统</h2><ol>\n<li>IO模型<ul>\n<li><p>同步阻塞IO（BIO）「jdk1.4之前支持」：服务端采用单线程，当accept一个请求后，在recv或send调用阻塞时，将无法accept其他请求，必须等待上一个请求被处理完；服务端采用多线程，当accept一个请求后，开启线程进行recv，通过多个线程可以完成并发处理，但是大量的线程占用大量的内存空间，并且线程切换会带来巨大的开销</p>\n<ul>\n<li>阻塞和非阻塞：数据未准备好时请求数据，等待数据就是阻塞，直接返回多次请求就是非阻塞</li>\n<li>同步与异步：同步模式由用户线程的内核态执行内核空间到用户空间的数据拷贝，异步模式由内核来执行数据拷贝执行完通知用户线程并将数据回调给用户线程</li>\n<li>阻塞读/写：执行read或send系统调用时，用户线程从用户态切换到内核态，执行用户空间拷贝到内核空间的Socket发送缓冲区之间的数据拷贝。读时如果没有数据则线程进入阻塞状态，直到有数据后唤醒线程；写时如果无法一次容纳所有的数据，则让出CPU，直到空间够用时执行写流程</li>\n</ul>\n</li>\n<li><p>同步非阻塞IO（NIO）「jdk1.4之后的java.nio包」：服务器accept一个请求后，加入文件描述符集合，每次轮询一遍文件描述符集合来recv数据，没有数据立即返回错误，每次轮询所有文件描述符很浪费时间</p>\n<ul>\n<li>阻塞IO的问题是一个线程只能处理一个连接，非阻塞IO就是为了解决这样的问题</li>\n<li>非阻塞读：当无数据时，系统调用立刻返回并带一个<code>EWOULDBLOCK</code> 或 <code>EAGAIN</code>错误，这个阶段用户线程不会阻塞也不会让出CPU，而是会继续轮训直到socket接收缓冲区中有数据为止</li>\n<li>非阻塞写：能写多少写多少，不用一次写完，写不下了返回已经写入的字节数，方便下一次轮训来写剩下的数据</li>\n</ul>\n</li>\n<li><p>IO多路复用（select、poll、epoll、aio、libevent、libuv）：见下</p>\n<ul>\n<li><p>在阻塞IO模型中一个连接就需要分配一个独立的线程去专门处理这个连接上的读写，到了IO多路复用模型中，多个连接可以复用这一个独立的线程去处理这多个连接上的读写，通过使用操作系统内核来执行轮训操作，减少系统调用和内核切换的次数</p>\n</li>\n<li><p>select：将轮询的操作交给了内核来完成，调用并阻塞在<code>select</code>系统调用上，并通过<code>select</code>将文件描述符<code>fd</code>数组（BitMap，1表示该fd上有读写事件）通过<code>select</code>系统调用传递给内核。<code>select</code>通过内核来轮询遍历<code>fd</code>数组，有数据来就设置为1否则设置为0，如果有新的数据来就将修改后的<code>fd</code>数组返回给用户线程。用户线程接触阻塞，开始遍历fd数组对值为1的scoket文件描述符发起系统调用。仍需要上下文切换和数据拷贝，还需要遍历结果，所以只能处理1000个左右的并发连接</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">&#x2F;&#x2F;select系统调用是在规定的超时时间内，监听（轮询）用户感兴趣的文件描述符集合上的可读,可写,异常三类事件\n&#x2F;&#x2F;这里的fd_set就是前边提到的fd数组，是一个BitMap结构\nint select(int maxfdp1,fd_set *readset,fd_set *writeset,fd_set *exceptset,const struct timeval *timeout)\n&#x2F;&#x2F;用户线程中重新遍历fd数组的过程中，需要用到的API\nvoid FD_ZERO(fd_set *fdset)  &#x2F;&#x2F;清空指定的文件描述符集合，即让fd_set中不在包含任何文件描述符\nvoid FD_SET(int fd, fd_set *fdset)  &#x2F;&#x2F;将一个给定的文件描述符加入集合之中\nint FD_ISSET(int fd, fd_set *fdset)  &#x2F;&#x2F;检查集合中指定的文件描述符是否可以读写。用户线程遍历文件描述符集合,调用该方法检查相应的文件描述符是否IO就绪\nvoid FD_CLR(int fd, fd_set *fdset)  &#x2F;&#x2F;将一个给定的文件描述符从集合中删除</code></pre></li>\n<li><p>poll：poll相当于是改进版的select，但是工作原理基本和select没有本质的区别</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">int poll(struct pollfd *fds, unsigned int nfds, int timeout)\nstruct pollfd &#123;\n    int   fd;         &#x2F;* 文件描述符 *&#x2F;\n    short events;     &#x2F;* 需要监听的事件 *&#x2F;\n    short revents;    &#x2F;* 实际发生的事件 由内核修改设置 *&#x2F;\n&#125;;  &#x2F;&#x2F;将BitMap结构改成pollfd，即没有固定长度的数组，这样就没有最大描述符数量的限制，只受限于系统文件描述符最大数量</code></pre></li>\n</ul>\n</li>\n<li><p>信号驱动的IO（SIGIO）</p>\n</li>\n<li><p>异步IO（POSIX的aio_functions）</p>\n<ul>\n<li>异步非阻塞IO，在进行IO操作时，不需要等待操作完成就可以进行其他操作，当操作完成后自动回调通知，jdk1.7之后java.nio包下的java.nio.channels.AsynchronousSocketChannel等。但是linux下AIO支持并不好并且相比NIO性能提升不明显，所以Netty在4.x舍弃了AIO</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Reactor模式和Proactor模式<ul>\n<li>Reactor模式：要求主线程只负责监听文件描述符上是否有事件发生，有的话立即将该事件通知工作线程，将socket可读可写事件方去请求队列，交给工作线程来处理，使用epoll实现的工作流程如下：<ul>\n<li>主线程向epoll内核事件表中注册socket上的读就绪事件</li>\n<li>可读<ul>\n<li>主线程调用<code>epoll_wait</code>等待socket上有数据可读</li>\n<li>当socket上有数据可读时，<code>epoll_wait</code>通知主线程，主线程将socket可读事件放入请求队列</li>\n<li>睡眠在请求队列上的某个工作线程被唤醒，它从socket读取数据，并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件</li>\n</ul>\n</li>\n<li>可写<ul>\n<li>当主线程调用<code>epoll_wait</code>等待socket可写</li>\n<li>当socket可写时，<code>epoll_wait</code>通知主线程。主线程将socket可写事件放入请求队列</li>\n<li>睡眠在请求队列上的某个工作线程被唤醒，它往 socket上写入服务器处理客户请求的结果</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Proactor模式</li>\n</ul>\n</li>\n<li>IO多路复用技术<ul>\n<li><p>select模型：采用轮询和遍历的方式，在客户端操作服务器时，会创建三种文件描述符（写描述符、读描述符、异常描述符），select会阻塞这三种文件描述符，等有数据可读、可写、异常或超时都会返回。然后通过遍历文件描述符集合来找到就绪的文件描述符，进行IO操作。由于每次都需要遍历所有文件描述符，所以性能随着描述符的增多而减小</p>\n<ul>\n<li>使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 <code>1024</code>，只能监听 0~1023 的文件描述符</li>\n</ul>\n</li>\n</ul>\n  <pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">int main()&#123;\n\t&#x2F;&#x2F;socket 建立、地址设置\n\tfd_set read_fs,write_set;\n\tstruct timeval timeout;\n\tint max &#x3D; 0;&#x2F;&#x2F;用于记录最大的fd，在轮询中时刻更新\n\t&#x2F;&#x2F;初始化比特位\n\tFD_ZERO（&amp;read_fs);\n\tFD_ZERO(&amp;write_fs);\n\t\n\tint nfds &#x3D; 0;&#x2F;&#x2F;记录就绪的事件，可以减少遍历的次数\n\twhile(1）&#123;\n\t&#x2F;&#x2F;阻塞获取，每次需要把fd从用户态拷贝到内核态\n\tnfds &#x3D; select(max+1, &amp;read_fd, &amp;write_fd, NULL, &amp;timeout);\n\t&#x2F;&#x2F;每次需要遍历所有fd，判断有无读写事件发生\n\tfor(int i &#x3D; 0; i &lt;&#x3D; max &amp;&amp; nfds; ++i)&#123;\n\t\tif(i &#x3D;&#x3D; listenfd)&#123;\n\t\t\t--nfds;\n\t\t\t&#x2F;&#x2F;处理accept事件\n\t\t\tFD_SET(i, &amp;read_fd);&#x2F;&#x2F;将客户端socket加入到集合中\n\t\t&#125;\n\t\tif(FD_ISSET(i, &amp;read_fd))&#123;\n\t\t\t--nfds;\n\t\t\t&#x2F;&#x2F;处理read事件\n\t\t&#125;\n\t\tif (FD_ISSET(i, &amp;write_fd)) &#123;\n\t\t\t --nfds;\n\t     &#x2F;&#x2F; 这里处理write事件\n    &#125;\n  &#125;\n&#125;</code></pre>\n\n<ul>\n<li><p>poll模型：poll模型的原理与select模型基本一致，也是轮询+遍历，区别在于poll采用链表的方式来存储文件描述符，同select一样，性能随着描述符的增多而减小</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">#include &lt;poll.h&gt;\n&#x2F;&#x2F; 数据结构\nstruct pollfd &#123;\n    int fd;                         &#x2F;&#x2F; 需要监视的文件描述符\n    short events;                   &#x2F;&#x2F; 需要内核监视的事件\n    short revents;                  &#x2F;&#x2F; 实际发生的事件\n&#125;;\n\n&#x2F;&#x2F; API\nint poll(struct pollfd fds[], nfds_t nfds, int timeout);</code></pre></li>\n<li><p>epoll模型：采用时间通知机制来触发相关的IO操作，没有文件描述符个数的限制，从用户态拷贝到内核态只需要一次。它主要通过系统底层的函数来注册、激活文件描述符，从而触发相关的IO操作，这样大大提高了提高性能（Redis、Nginx等，1G内存大概支持10万个句柄）</p>\n<ul>\n<li><p>特点</p>\n<ul>\n<li><p>将轮询改成了<strong>回调</strong>，提高了CPU执行效率、没有文件描述符数量限制、性能不会随文件描述符的增加而减小，内存拷贝（利用<strong>mmap</strong>文件映射内存加速与内核空间的消息传递，减少复制开销）</p>\n</li>\n<li><p>在内核里使用<strong>红黑树</strong>来关注进程所有待检测的 Socket，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。</p>\n</li>\n<li><p>解释io特别密集时 epoll 效率不高</p>\n<ul>\n<li>连接密集（短连接特别多），使用epoll的话，每一次连接需要发生epoll_wait-&gt;accpet-&gt;epoll_ctl调用，而使用select只需要select-&gt;accpet，减少了一次系统调用</li>\n<li>读写密集的话，如果收到数据，我们需要响应数据的话，使用epoll的情况下， read 完后也需要epoll_ctl 加入写事件，相比select多了一次系统调用</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Socket创建</p>\n<ul>\n<li>服务端线程调用<code>accept</code>后阻塞，在客户端连接并完成<code>TCP</code>三次握手之后，<code>kernel</code>创建一个对应的<code>socket</code>作为服务端与内核端通信的内核接口，并将<code>socket</code>保存在当前进程打开的文件列表（Linux内核中一切皆是文件）中管理起来</li>\n<li>进程中管理的文件列表结构：内核通过<code>fd_array</code>来进行组织管理，数组下标为文件描述符，数据中存放的是文件数据结构<code>file</code>。进程中打开的文件列表<code>fd_array</code>定义在内核数据结构<code>struct files_struct</code>中，在<code>struct fdtable</code>结构中有一个指针<code>struct file **fd</code>指向<code>fd_array</code></li>\n<li>用于封装文件元信息的内核数据结构<code>struct file</code>中的<code>private_data</code>指针指向具体的<code>Socket</code>结构。<code>struct file</code>中的<code>file_operations</code>属性定义了文件的操作函数，不同的文件类型，对应的<code>file_operations</code>是不同的，针对<code>Socket</code>文件类型，这里的<code>file_operations</code>指向<code>socket_file_ops</code>。在用户空间对<code>Socket</code>发起的读写等系统调用，进入内核首先会调用的是<code>Socket</code>对应的<code>struct file</code>中指向的<code>socket_file_ops</code>，如对<code>Socket</code>发起<code>write</code>写操作，在内核中首先被调用的就是<code>socket_file_ops</code>中定义的<code>sock_write_iter</code></li>\n<li>Socket内核结构：最先创建的是监听socket，之后另外创建新的socket专门用于客户端之间的网络通信，并将监听Socket中的Socket操作函数集合（inet_stream_ops）ops赋值到新的Socket的ops属性中。接着kernel会为已连接的socket创建file结构体并初始化，并把Socket文件操作函数集合（socket_file_ops）赋值给file中的f_ops指针。然后将struct socket中的file指针指向这个新分配申请的file结构体。然后调用socket-&gt;ops-&gt;accept，即inet_accept函数，该函数会在icsk_accept_queue（已完成三次握手）中查找是否有已经建立好的连接，如果有的话，直接从icsk_accept_queue中获取已经创建好的struct sock。并将这个struct sock对象赋值给struct socket中的sock指针（sock对象中定义了接收队列，发送队列，等待队列，数据就绪回调函数指针，内核协议栈操作函数集合）<ul>\n<li><code>inet_stream_ops</code>函数集合中存储给用户提供的接口，socket与内核协议栈之间的接口定义在<code>struct sock</code>中的<code>sk_port</code>指针上</li>\n<li><code>struct sock</code>中的等待队列中存放的是系统IO调用发生阻塞的进程<code>fd</code>，以及相应的回调函数</li>\n<li>对<code>Socket</code>发起的系统IO调用，在内核中首先会调用<code>Socket</code>的文件结构<code>struct file</code>中的<code>file_operations</code>文件操作集合，然后调用<code>struct socket</code>中的<code>ops</code>指向的<code>inet_stream_ops</code>socket操作函数，最终调用到<code>struct sock</code>中<code>sk_prot</code>指针指向的<code>tcp_prot</code>内核协议栈操作函数接口集合</li>\n</ul>\n</li>\n<li>当struct file，struct socket，struct sock这些核心的内核对象创建好之后，最后就是把socket对象对应的struct file放到进程打开的文件列表fd_array中。随后系统调用accept返回socket的文件描述符fd给用户程序。</li>\n</ul>\n</li>\n<li><p>阻塞IO中用户进程阻塞以及唤醒原理</p>\n<ul>\n<li>阻塞<ul>\n<li>首先我们在用户进程中对<code>Socket</code>进行<code>read</code>系统调用时，用户进程会从<code>用户态</code>转为<code>内核态</code></li>\n<li>在进程的<code>struct task_struct</code>结构找到<code>fd_array</code>，并根据<code>Socket</code>的文件描述符<code>fd</code>找到对应的<code>struct file</code>，调用<code>struct file</code>中的文件操作函数结合<code>file_operations</code>，<code>read</code>系统调用对应的是<code>sock_read_iter</code></li>\n<li>在<code>sock_read_iter</code>函数中找到<code>struct file</code>指向的<code>struct socket</code>，并调用<code>socket-&gt;ops-&gt;recvmsg</code>，这里我们知道调用的是<code>inet_stream_ops</code>集合中定义的<code>inet_recvmsg</code></li>\n<li>在<code>inet_recvmsg</code>中会找到<code>struct sock</code>，并调用<code>sock-&gt;skprot-&gt;recvmsg</code>,这里调用的是<code>tcp_prot</code>集合中定义的<code>tcp_recvmsg</code>函数</li>\n</ul>\n</li>\n<li>唤醒：<ul>\n<li>当软中断将<code>sk_buffer</code>放到<code>Socket</code>的接收队列上时，接着就会调用<code>数据就绪函数回调指针sk_data_ready</code>，前边我们提到，这个函数指针在初始化的时候指向了<code>sock_def_readable</code>函数</li>\n<li>在<code>sock_def_readable</code>函数中会去获取<code>socket-&gt;sock-&gt;sk_wq</code>等待队列。在<code>wake_up_common</code>函数中从等待队列<code>sk_wq</code>中找出<code>一个</code>等待项<code>wait_queue_t</code>，回调注册在该等待项上的<code>func</code>回调函数（<code>wait_queue_t-&gt;func</code>）,创建等待项<code>wait_queue_t</code>是我们提到，这里注册的回调函数是<code>autoremove_wake_function</code>，即epoll的回调函数</li>\n<li>在<code>autoremove_wake_function</code>函数中，根据等待项<code>wait_queue_t</code>上的<code>private</code>关联的<code>阻塞进程fd</code>调用<code>try_to_wake_up</code>唤醒阻塞在该<code>Socket</code>上的进程</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>相关的系统调用</p>\n<ul>\n<li><p>epoll_create：系统启动的时候，在Linux内核里面申请一个B+树结构的文件系统，然后返回epoll对象（一个文件描述符）用来后续使用</p>\n</li>\n<li><p>epoll_ctl：每新建一个连接的时候，会同步更新epoll对象中的文件描述符，并且绑定一个callback函数，通过此调用向epoll对象中添加、删除、修改感兴趣的事件，返回0表示成功</p>\n</li>\n<li><p>epoll_wait：轮询所有的callback集合（红黑树），并触发相应的IO操作，通过此调用收集在epoll监控中已发生的事件</p>\n</li>\n<li><p>工作流程</p>\n<ul>\n<li>通过epoll_create创建epoll对象，此时epoll对象的内核结构包含就绪链表和红黑树，就绪队列是用于保存所有读写事件到来的socket。红黑树用于保存所有待检测的socket</li>\n<li>通过 epoll_crt 将待检测的socket，加入到红黑树中，并注册一个事件回调函数，当有事件到来的之后，会调用这个回调函数，进而通知到 epoll 对象</li>\n<li>调用 epoll_wait 等待事件的发生，当内核检测到事件发生后，调用该socket注册的回调函数，执行回调函数就能找到socket对应的epoll对象，然后会将事件加入到epoll对象的绪队列中，最后将就绪队列返回给应用层</li>\n</ul>\n</li>\n<li><p>示意图</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230805145256292-20230805145427091-20230805150049935.png\" alt=\"image-20230805145256292\"></p>\n</li>\n</ul>\n</li>\n<li><p>epoll水平触发（LT）和边缘触发（ET）的区别</p>\n<ul>\n<li>Level Triggered（LT）水平触发：只要有数据就会触发，只要这个 fd 还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作<ul>\n<li>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，<strong>服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束</strong>，目的是告诉我们有数据需要读取；</li>\n<li>如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作</li>\n</ul>\n</li>\n<li>Edge Triggered（ET）边缘触发：只有数据到来，才触发，只会提示一次，直到下次数据流入<ul>\n<li>使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，<strong>服务器端只会从 epoll_wait 中苏醒一次</strong>，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</li>\n<li>如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会<strong>循环</strong>从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，<strong>边缘触发模式一般和非阻塞 I/O 搭配使用</strong>，程序会一直执行 I/O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>代码示例</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">#include &lt;sys&#x2F;epoll.h&gt;\n\n&#x2F;&#x2F; 每一个epoll对象都有一个独立的eventpoll结构体\n&#x2F;&#x2F; 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件\n&#x2F;&#x2F; epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可\nstruct eventpoll &#123;\n    &#x2F;*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*&#x2F;\n    struct rb_root  rbr;\n    &#x2F;*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*&#x2F;\n    struct list_head rdlist;\n&#125;;\n\n&#x2F;&#x2F;在epoll中，对于每一个事件，都会建立一个epitem结构体\nstruct epitem&#123;\n    struct rb_node  rbn;&#x2F;&#x2F;红黑树节点\n    struct list_head    rdllink;&#x2F;&#x2F;双向链表节点\n    struct epoll_filefd  ffd;  &#x2F;&#x2F;事件句柄信息\n    struct eventpoll *ep;    &#x2F;&#x2F;指向其所属的eventpoll对象\n    struct epoll_event event; &#x2F;&#x2F;期待发生的事件类型\n&#125;\n\n&#x2F;&#x2F; API\nint epoll_create(int size); &#x2F;&#x2F; 内核中间加一个 eventpoll 对象，把所有需要监听的 socket 都放到 ep 对象中\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); &#x2F;&#x2F; epoll_ctl 负责把 socket 增加、删除到内核红黑树\n&#x2F;&#x2F; 当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可\nint epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);&#x2F;&#x2F; epoll_wait 负责检测可读队列，没有可读 socket 则阻塞进程</code></pre></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Nginx的IO模型：支持多种并发模型，自动选择最高效的模型，也可以使用use指令在配置文件中显示指定某个并发模型，如下所示<ul>\n<li>select：编译时，所用平台没有更高效的并发模型时，select被自动编译</li>\n<li>poll：标准并发模型，同select一样，所用平台没有更高效的并发模型时，pol被自动编译</li>\n<li>epoll：IO多路复用，高效并发模型，Linux2.6+可以使用</li>\n<li>kequeue：IO多路复用，高效并发模型，可在 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0, and Mac OS X 平台中使用</li>\n<li>/dev/poll：高效并发模型，可在 Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+, and Tru64 UNIX 5.1A+ 平台使用</li>\n<li>eventport：建议 使用/dev/poll替代</li>\n</ul>\n</li>\n<li>Redis的IO模型：Redis跑在单线程中，所有操作都是按照顺序线性执行的，为了防止IO阻塞整个Redis进程，所以使用IO多路复用技术。Redis的IO复用技术基于epoll实现，另外提供了select和kqueue的实现</li>\n</ol>\n<h2 id=\"附录\"><a href=\"#附录\" class=\"headerlink\" title=\"附录\"></a>附录</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Shell/Python脚本、网络编程、多线程编程</p></blockquote>\n<h3 id=\"1-Termianl\"><a href=\"#1-Termianl\" class=\"headerlink\" title=\"1.Termianl\"></a>1.Termianl</h3><ol>\n<li>目录结构：/bin：命令、/etc：系统管理所需要的配置文件和子目录、/home：用户的主目录、/lib：系统最基本的动态连接共享库、/opt：额外安装软件所摆放的目录、/root：管理员主目录、/sbin：管理员使用的命令、/tmp：存放临时文件、/usr：用户的应用程序和文件、/var：存不断扩充的文件，如日志文件</li>\n<li>命令<ul>\n<li><p>文件管理：ls、ll、cd、pwd、mkdir、rmdir、rm、cp、mv、touch、chown、chmod、tar、</p>\n</li>\n<li><p>文档编辑：cat、tac、nl、more、less、head、tail、grep（文本搜索）、awk（自定义函数或正则表达式）、sed（批量编辑文本文件）</p>\n</li>\n<li><p>进程监控：<code>su</code>、<code>sudo</code>、<code>kill</code>（<code>kill -9 pid</code>）、管道命令、<code>ps</code>（<code>ps -ef | more</code>进程信息）、<code>top</code>（实时显示进程信息）、<code>lsof</code>（查看某一文件的进程信息）、<code>free</code>（查看内存使用情况，如进程、CPU占用率、内存信息）、<code>df</code>（磁盘使用量）、<code>iostat</code>（I/O设备状态）、<code>vmstat</code>（虚拟内存状态）、du（磁盘使用情况）</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/640.jpeg\" alt=\"图片\"></p>\n</li>\n<li><p>网络监控：<code>iperf</code>（查看带宽和网络）、<code>netstat</code>（查看占用端口的进程）、<code>traceroute</code>（数据包路径）、<code>ping</code>（测试与主机的连通性）、</p>\n</li>\n<li><p>其它：strace、dtrace、systemtap、uname、history</p>\n</li>\n</ul>\n</li>\n<li>Shell脚本</li>\n<li>Vim编辑器</li>\n<li>常见系统调用<ul>\n<li>文件管理：creat、open、close、lseek（定位）、read、write</li>\n<li>进程管理：fork、execve（执行新二进制文件）、waitpid（等待子进程结束）、clone、exit</li>\n<li>内存管理：brk、mmap（内存映射）</li>\n<li>进程间通信：<ul>\n<li>消息队列：msgget（创建队列）、msgsnd（发送消息）、msgrcv（接收消息）</li>\n<li>共享内存：shmget（创建共享内存）、shmat（将共享内存映射到内存空间）</li>\n<li>信号量：sem_wait(抢占信号量)、sem_post（释放信号量）</li>\n</ul>\n</li>\n<li>网络通信：socket、bind、connect、listen、accept</li>\n<li>信号处理：kill、signaction</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"2-系统调用\"><a href=\"#2-系统调用\" class=\"headerlink\" title=\"2.系统调用\"></a>2.系统调用</h3><ol>\n<li><p>malloc：通过两种系统调用申请堆内存（虚拟内存），malloc()本身不是系统调用</p>\n<ul>\n<li><p>方式一（用户分配的内存小于 128 KB）：通过 brk() 系统调用将堆顶指针向高地址移动，获得新的内存空间</p>\n<ul>\n<li>频繁通过 mmap 分配的内存，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大，所以通过brk系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中，等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了</li>\n<li>频繁使用brk，会导致堆内产生越来越多不可用的碎片，导致“内存泄露”，这种“泄露”现象使用 valgrind 是无法检测出来的</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230803121030798.png\" alt=\"image-20230803121030798\"></p>\n</li>\n<li><p>方式二（用户分配的内存大于 128 KB）：通过 mmap() 系统调用在文件映射区域分配内存（私有匿名映射，从文件映射区“偷”了一块内存）</p>\n<ul>\n<li>malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节，保存了该内存块的描述信息，当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小，从而知道释放多大的内存</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230803121146099.png\" alt=\"image-20230803121146099\"></p>\n</li>\n<li><p>其它</p>\n<ul>\n<li>malloc() 在分配内存的时候，并不按用户预期申请的字节数来分配内存空间大小，而是<strong>会预分配更大的空间作为内存池</strong></li>\n<li>free()<ul>\n<li>malloc 通过 <strong>brk()</strong> 方式申请的内存，free 释放内存的时候，<strong>并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用</strong>；</li>\n<li>malloc 通过 <strong>mmap()</strong> 方式申请的内存，free 释放内存的时候，<strong>会把内存归还给操作系统，内存得到真正的释放</strong>。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li></li>\n</ol>\n<h3 id=\"3-实战\"><a href=\"#3-实战\" class=\"headerlink\" title=\"3.实战\"></a>3.实战</h3><ol>\n<li><p>操作系统保护模式和实模式</p>\n<ul>\n<li><strong>实模式</strong>将整个物理内存看成分段的区域，程序代码和数据位于不同区域，系统程序和用户程序并没有区别对待，而且每一个指针都是指向实际的物理地址。这样一来，用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并修改了内容，那么对于这个被修改的系统程序或用户程序，其后果就很可能是灾难性的。再者，随着软件的发展，1M的寻址空间已经远远不能满足实际的需求了。最后，对处理器多任务支持需求也日益紧迫，所有这些都促使新技术的出现</li>\n<li>为了克服实模式下的内存非法访问问题，并满足飞速发展的内存寻址和多任务需求，处理器厂商开发出<strong>保护模式</strong>。在保护模式中，除了内存寻址空间大大提高；提供了硬件对多任务的支持；<strong>物理内存地址也不能直接被程序访问，程序内部的地址(虚拟地址)要由操作系统转化为物理地址去访问，程序对此一无所知</strong>。至此，进程(程序的运行态)有了严格的边界，任何其他进程根本没有办法访问不属于自己的物理内存区域，甚至在自己的虚拟地址范围内也不是可以任意访问的，因为有一些虚拟区域已经被放进一些公共系统运行库。这些区域也不能随便修改，若修改就会有出现linux中的段错误，或Windows中的非法内存访问对话框</li>\n</ul>\n</li>\n<li><p>内存回收：系统内存紧张时会进行内存回收，主要回收以下两类</p>\n<ul>\n<li><strong>文件页</strong>（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，<strong>回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存</strong></li>\n<li><strong>匿名页</strong>（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们<strong>回收的方式是通过 Linux 的 Swap 机制</strong>，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了</li>\n<li>文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。<ul>\n<li><strong>active_list</strong> 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；</li>\n<li><strong>inactive_list</strong> 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>从 a 文件 copy 到另外一个目录， b 作为一个从 a 目录 copy 到一个 b 目录这样的一个文件，操作过程中间包含了哪些系统调用？这里面执行了多少次拷贝的动作？</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230805213706849.png\" alt=\"image-20230805213706849\"></p>\n<ul>\n<li>第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。</li>\n<li>第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。</li>\n<li>第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核缓冲区里，这个过程依然还是由 CPU 搬运的。</li>\n<li>第四次拷贝，把内核缓冲区里的数据，拷贝到磁盘，这个过程又是由 DMA 搬运的。</li>\n</ul>\n</li>\n<li><p>PageCache</p>\n<ul>\n<li>缓存一些比较常访问的文件到缓存中，这样子的话它就能减少两次从内核空间拷贝的过程，就是来减少查询这个内容的时间</li>\n<li>当用户对文件进行读写时，实际上是对文件的 <code>页缓存</code> 进行读写。所以对文件进行读写操作时，会分以下两种情况进行处理：<ul>\n<li>当从文件中读取数据时，如果要读取的数据所在的页缓存已经存在，那么就直接把页缓存的数据拷贝给用户即可。否则，内核首先会申请一个空闲的内存页（页缓存），然后从文件中读取数据到页缓存，并且把页缓存的数据拷贝给用户。</li>\n<li>当向文件中写入数据时，如果要写入的数据所在的页缓存已经存在，那么直接把新数据写入到页缓存即可。否则，内核首先会申请一个空闲的内存页（页缓存），然后从文件中读取数据到页缓存，并且把新数据写入到页缓存中。对于被修改的页缓存，内核会定时把这些页缓存刷新到文件中。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n","text":"Linux1.进程管理 概念 进程：进程是资源调度的基本单位，启动main函数就是启动一个JVM进程，main函数所在的线程是这个进程的主线程 进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态 一个进程切换到另一个进程运行，称为进程的上下文切换，其中上下文包括CPU 寄...","link":"","photos":[],"count_time":{"symbolsCount":"21k","symbolsTime":"19 mins."},"categories":[],"tags":[{"name":"tools","slug":"tools","count":2,"path":"api/tags/tools.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Linux\"><span class=\"toc-text\">Linux</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86\"><span class=\"toc-text\">1.进程管理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86\"><span class=\"toc-text\">2.内存管理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F\"><span class=\"toc-text\">3.网络系统</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%99%84%E5%BD%95\"><span class=\"toc-text\">附录</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-Termianl\"><span class=\"toc-text\">1.Termianl</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8\"><span class=\"toc-text\">2.系统调用</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-%E5%AE%9E%E6%88%98\"><span class=\"toc-text\">3.实战</span></a></li></ol></li></ol></li></ol>","author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"JVM","uid":"0b1381c4a63c09e41167c5168339035a","slug":"JVM","date":"2023-07-30T02:35:00.000Z","updated":"2023-08-05T06:33:33.004Z","comments":true,"path":"api/articles/JVM.json","keywords":null,"cover":[],"text":"JVM1.编译执行 如何实现跨平台：通过不同平台的JVM实现来将相同的一个Class文件翻译成适配不同机器的机器语言用于执行，即使打包成可还行文件仍需要JVM的支持 Java程序的执行过程 JAVA源代码编译成字节码；字节码校验并把JAVA程序通过类加载器加载到JVM内存中，在加...","link":"","photos":[],"count_time":{"symbolsCount":"29k","symbolsTime":"26 mins."},"categories":[],"tags":[],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Spring Family","uid":"0eecce2180060832c1ffa34a76f3eb3b","slug":"Spring","date":"2023-05-06T05:09:43.000Z","updated":"2023-08-05T13:23:19.915Z","comments":true,"path":"api/articles/Spring.json","keywords":null,"cover":[],"text":"Spring 1.IOC1.基础知识 BeanFactory：提供了一种高级配置，能够管理任何类型对象，BeanFactory是ApplicationContext的父接口，ApplicationContext接口的实现类主要有ClassPathXmlApplicationCon...","link":"","photos":[],"count_time":{"symbolsCount":"98k","symbolsTime":"1:29"},"categories":[],"tags":[{"name":"tools","slug":"tools","count":2,"path":"api/tags/tools.json"}],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}