{"title":"SpringCloudAlibaba","uid":"f73517cb09427c414a5d9f458e1d07c7","slug":"SpringCloudAlibaba","date":"2023-09-25T12:56:45.000Z","updated":"2023-09-25T13:39:44.256Z","comments":true,"path":"api/articles/SpringCloudAlibaba.json","keywords":null,"cover":[],"content":"<h2 id=\"1-微服务\"><a href=\"#1-微服务\" class=\"headerlink\" title=\"1.微服务\"></a>1.微服务</h2><p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/6.png\" alt=\"6\"></p>\n<ol>\n<li><p>What：微服务（Microservices）是一种软件架构风格，将一个大型应用程序划分为一组小型、自治且松耦合的服务。每个微服务负责执行特定的业务功能，并通过轻量级通信机制（如HTTP）相互协作。每个微服务可以独立开发、部署和扩展，使得应用程序更加灵活、可伸缩和可维护。在微服务的架构演进中，一般可能会存在这样的演进方向：单体式–&gt;服务化–&gt;微服务</p>\n<ol>\n<li>单体服务（Monolithic Service）是一种传统的软件架构方式，将整个应用程序作为一个单一的、紧耦合的单元进行开发和部署。单体服务通常由多个模块组成，这些模块共享同一个数据库和代码库。然而，随着应用程序规模的增长，单体服务可能变得庞大且难以维护，且部署和扩展困难。</li>\n<li>SOA（Service-Oriented Architecture，面向服务的架构）是一种软件架构设计原则，强调将应用程序拆分为相互独立的服务，通过标准化的接口进行通信。SOA关注于服务的重用性和组合性，但并没有具体规定服务的大小。</li>\n<li>微服务是在SOA的基础上进一步发展而来，是一种特定规模下的服务拆分和部署方式。微服务架构强调将应用程序拆分为小型、自治且松耦合的服务，每个服务都专注于特定的业务功能。这种架构使得应用程序更加灵活、可伸缩和可维护。<ol>\n<li>微服务是一种特定的架构风格，而SOA是一种设计原则。微服务可以看作是对SOA思想的一种具体实践方式，但并不等同于SOA。</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>微服务带来的问题</p>\n<ol>\n<li>系统复杂性增加：一个服务拆成了多个服务，整体系统的复杂性增加，需要处理服务之间的通信、部署、监控和维护等方面的复杂性。</li>\n<li>服务间通信开销：微服务之间通过网络进行通信，传递数据需要额外的网络开销和序列化开销，可能导致性能瓶颈和增加系统延迟。</li>\n<li>数据一致性和事务管理：每个微服务都有自己的数据存储，数据一致性和跨服务的事务管理变得更加复杂，需要额外解决分布式事务和数据同步的问题。</li>\n<li>部署和运维复杂性：微服务架构涉及多个独立部署的服务，对于部署、监控和容错机制的要求更高，需要建立适当的部署管道和自动化工具，以简化部署和运维过程。</li>\n<li>团队沟通和协作成本：每个微服务都由专门的团队负责，可能增加团队之间的沟通和协作成本。需要有效的沟通渠道和协作机制，确保服务之间的协调和一致性。</li>\n<li>服务治理和版本管理：随着微服务数量的增加，服务的治理和版本管理变得更加复杂。需要考虑服务的注册发现、负载均衡、监控和故障处理等方面，以确保整个系统的可靠性和稳定性。</li>\n<li>分布式系统的复杂性：微服务架构涉及构建和管理分布式系统，而分布式系统本身具有一些固有的挑战，如网络延迟、分布式一致性和容错性。</li>\n</ol>\n</li>\n<li><p>常见解决方案：Spring Cloud Alibaba（Nacos、Sentiel、Seata、RocketMQ、Dubbo）</p>\n</li>\n<li><p>微服务有哪些组件</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/7.png\" alt=\"7\"></p>\n<ol>\n<li><p>注册中心：服务注册、服务发现、负载均衡、故障恢复、服务治理</p>\n<ol>\n<li>Eureka和ZooKeeper的最大区别是一个支持<code>AP</code>，一个支持<code>CP</code>，Nacos既支持既支持<code>AP</code>，也支持<code>CP</code>。</li>\n</ol>\n<ul>\n<li><p>对比</p>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>Eureka</th>\n<th>ZooKeeper</th>\n<th>Nacos</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>开发公司</td>\n<td>Netflix</td>\n<td>Apache 基金会</td>\n<td>阿里巴巴</td>\n</tr>\n<tr>\n<td>CAP</td>\n<td>AP（可用性和分区容忍性）</td>\n<td>CP（一致性和分区容忍性）</td>\n<td>既支持AP，也支持CP</td>\n</tr>\n<tr>\n<td>功能</td>\n<td>服务注册与发现</td>\n<td>分布式协调、配置管理、分布式锁</td>\n<td>服务注册与发现、配置管理、服务管理</td>\n</tr>\n<tr>\n<td>定位</td>\n<td>适用于构建基于 HTTP 的微服务架构</td>\n<td>通用的分布式协调服务框架</td>\n<td>适用于微服务和云原生应用</td>\n</tr>\n<tr>\n<td>访问协议</td>\n<td>HTTP</td>\n<td>TCP</td>\n<td>HTTP/DNS</td>\n</tr>\n<tr>\n<td>自我保护</td>\n<td>支持</td>\n<td>-</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>数据存储</td>\n<td>内嵌数据库、多个实例形成集群</td>\n<td>ACID 特性的分布式文件系统 ZAB 协议</td>\n<td>内嵌数据库、MySQL 等</td>\n</tr>\n<tr>\n<td>健康检查</td>\n<td>Client Beat</td>\n<td>Keep Alive</td>\n<td>TCP/HTTP/MYSQL/Client Beat</td>\n</tr>\n<tr>\n<td>特点</td>\n<td>简单易用、自我保护机制</td>\n<td>高性能、强一致性</td>\n<td>动态配置管理、流量管理、灰度发布等</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n</li>\n<li><p>配置中心：配置信息存储、注册配置信息、获取配置信息、监听配置变化</p>\n<ol>\n<li>微服务架构中的每个服务通常都需要一些配置信息，例如数据库连接地址、服务端口、日志级别等。这些配置可能因为不同环境、不同部署实例或者动态运行时需要进行调整和管理。微服务的实例一般非常多，如果每个实例都需要一个个地去做这些配置，那么运维成本将会非常大，这时候就需要一个集中化的配置中心，去管理这些配置。</li>\n</ol>\n</li>\n<li><p>远程调用：见Feign</p>\n<ol>\n<li><p>HTTP和RPC的区别：一些RPC框架比如gRPC，底层传输协议其实也是用的HTTP2，包括Dubbo3，也兼容了gRPC，使用了HTTP2作为传输层的一层协议。</p>\n<ul>\n<li><p>HTTP（Hypertext Transfer Protocol）是一种应用层协议，主要强调的是网络通信；</p>\n</li>\n<li><p>RPC（Remote Procedure Call，远程过程调用）是一种用于分布式系统之间通信的协议，强调的是服务之间的远程调用。</p>\n</li>\n<li><p>HTTP和RPC对比</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>HTTP</th>\n<th>RPC</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>定义</td>\n<td>HTTP（超文本传输协议）是一种用于传输超文本的协议。</td>\n<td>RPC（远程过程调用）是一种用于实现分布式系统中不同节点之间通信的协议。</td>\n</tr>\n<tr>\n<td>通信方式</td>\n<td>基于请求-响应模型，客户端发送请求，服务器返回响应。</td>\n<td>基于方法调用模型，客户端调用远程方法并等待结果。</td>\n</tr>\n<tr>\n<td>传输协议</td>\n<td>基于TCP协议，可使用其他传输层协议如TLS/SSL进行安全加密。</td>\n<td>可以使用多种传输协议，如TCP、UDP等。</td>\n</tr>\n<tr>\n<td>数据格式</td>\n<td>基于文本，常用的数据格式有JSON、XML等。</td>\n<td>可以使用各种数据格式，如二进制、JSON、Protocol Buffers等。</td>\n</tr>\n<tr>\n<td>接口定义</td>\n<td>使用RESTful风格的接口进行定义，常用的方法有GET、POST、PUT、DELETE等。</td>\n<td>使用IDL（接口定义语言）进行接口定义，如Protocol Buffers、Thrift等。</td>\n</tr>\n<tr>\n<td>跨语言性</td>\n<td>支持跨语言通信，可以使用HTTP作为通信协议实现不同语言之间的通信。</td>\n<td>支持跨语言通信，可以使用IDL生成不同语言的客户端和服务端代码。</td>\n</tr>\n<tr>\n<td>灵活性</td>\n<td>更加灵活，适用于不同类型的应用场景，如Web开发、API调用等。</td>\n<td>更加高效，适用于需要高性能和低延迟的分布式系统。</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n</li>\n<li><p>见Feign</p>\n</li>\n</ol>\n</li>\n<li><p>服务网关：API网关（API Gateway）是一种中间层服务器，用于集中管理、保护和路由对后端服务的访问。它充当了客户端与后端服务之间的入口点，提供了一组统一的接口来管理和控制API的访问。</p>\n<ol>\n<li>路由转发：API网关根据请求的URL路径或其他标识，将请求路由到相应的后端服务。通过配置路由规则，可以灵活地将请求分发给不同的后端服务。</li>\n<li>负载均衡：API网关可以在后端服务之间实现负载均衡，将请求平均分发到多个实例上，提高系统的吞吐量和可扩展性。</li>\n<li>安全认证与授权：API网关可以集中处理身份验证和授权，确保只有经过身份验证的客户端才能访问后端服务。它可以与身份提供者（如OAuth、OpenID Connect）集成，进行用户认证和授权操作。</li>\n<li>缓存：API网关可以缓存后端服务的响应，减少对后端服务的请求次数，提高系统性能和响应速度。</li>\n<li>监控与日志：API网关可以收集和记录请求的指标和日志，提供实时监控和分析，帮助开发人员和运维人员进行故障排查和性能优化。</li>\n<li>数据转换与协议转换：API网关可以在客户端和后端服务之间进行数据格式转换和协议转换，如将请求从HTTP转换为WebSocket，或将请求的参数进行格式转换，以满足后端服务的需求。</li>\n<li>API版本管理：API网关可以管理不同版本的API，允许同时存在多个API版本，并通过路由规则将请求正确地路由到相应的API版本上。</li>\n</ol>\n</li>\n<li><p>Spring Cloud Gateway</p>\n<ol>\n<li><p>组件</p>\n<ol>\n<li><strong>Route（路由）</strong>：路由是Spring Cloud Gateway的基本构建块，它定义了请求的匹配规则和转发目标。通过配置路由，可以将请求映射到后端的服务实例或URL上。路由规则可以根据请求的路径、方法、请求头等条件进行匹配，并指定转发的目标URI。</li>\n<li><strong>Predicate（断言）</strong>：断言用于匹配请求的条件，如果请求满足断言的条件，则会应用所配置的过滤器。Spring Cloud Gateway提供了多种内置的断言，如Path（路径匹配）、Method（请求方法匹配）、Header（请求头匹配）等，同时也支持自定义断言。</li>\n<li><strong>Filter（过滤器）</strong>：过滤器用于对请求进行处理和转换，可以修改请求、响应以及执行其他自定义逻辑。Spring Cloud Gateway提供了多个内置的过滤器，如请求转发、请求重试、请求限流等。同时也支持自定义过滤器，可以根据需求编写自己的过滤器逻辑。</li>\n</ol>\n</li>\n<li><p>重要概念</p>\n<ol>\n<li><strong>Gateway Handler（网关处理器）</strong>：网关处理器是Spring Cloud Gateway的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。</li>\n<li><strong>Gateway Filter Chain（网关过滤器链）</strong>：网关过滤器链由一系列过滤器组成，按照配置的顺序依次执行。每个过滤器可以在请求前、请求后或请求发生错误时进行处理。过滤器链的执行过程可以修改请求、响应以及执行其他自定义逻辑。</li>\n</ol>\n</li>\n<li><p>工作流程</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/8.png\" alt=\"8\"></p>\n</li>\n</ol>\n</li>\n<li><p>链路追踪：见Sleuth</p>\n</li>\n<li><p>分布式事务：见Seata</p>\n</li>\n<li><p>运维</p>\n<ol>\n<li><p>服务监控：使用Prometheus和Grafana来实现整个微服务集群的监控和告警</p>\n<ol>\n<li>Prometheus：Prometheus 是一个开源的监控系统，具有灵活的数据模型和强大的查询语言，能够收集和存储时间序列数据。它可以通过HTTP协议定期拉取微服务的指标数据，并提供可扩展的存储和查询功能。</li>\n<li>Grafana：Grafana 是一个开源的可视化仪表板工具，可以与 Prometheus 结合使用，创建实时和历史数据的仪表板。Grafana 提供了丰富的图表和可视化选项，可以帮助用户更好地理解和分析微服务的性能和状态。</li>\n</ol>\n</li>\n<li><p>日志收集：ELK，</p>\n<p>Elasticsearch</p>\n<p>提供数据存储和检索能力，</p>\n<p>Logstash</p>\n<p>负责将日志收集到ES，</p>\n<p>Kibana</p>\n<p>负责日志数据的可视化分析。</p>\n<ol>\n<li>组件<ul>\n<li><strong>Elasticsearch</strong>：Elasticsearch是一个分布式搜索和分析引擎，用于存储和索引大量的日志数据。它提供了快速的搜索和聚合功能，可以高效地处理大规模的日志数据。</li>\n<li><strong>Logstash</strong>：Logstash是一个用于收集、过滤和转发日志数据的工具。它可以从各种来源（如文件、网络、消息队列等）收集日志数据，并对数据进行处理和转换，然后将其发送到Elasticsearch进行存储和索引。</li>\n<li><strong>Kibana</strong>：Kibana是一个用于日志数据可视化和分析的工具。它提供了丰富的图表、仪表盘和搜索功能，可以帮助用户实时监控和分析日志数据，发现潜在的问题和趋势。</li>\n</ul>\n</li>\n<li>收集流程<ul>\n<li>在每个微服务中配置日志输出：将微服务的日志输出到标准输出（stdout）或日志文件。</li>\n<li>使用Logstash收集日志：配置Logstash收集器，通过配置输入插件（如文件输入、网络输入等）监听微服务的日志输出，并进行过滤和处理。</li>\n<li>将日志数据发送到Elasticsearch：配置Logstash的输出插件，将经过处理的日志数据发送到Elasticsearch进行存储和索引。</li>\n<li>使用Kibana进行可视化和分析：通过Kibana连接到Elasticsearch，创建仪表盘、图表和搜索查询，实时监控和分析微服务的日志数据。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>服务容灾</p>\n<ol>\n<li>服务雪崩：在微服务中，假如一个或者多个服务出现故障，如果这时候，依赖的服务还在不断发起请求，或者重试，那么这些请求的压力会不断在下游堆积，导致下游服务的负载急剧增加。不断累计之下，可能会导致故障的进一步加剧，可能会导致级联式的失败，甚至导致整个系统崩溃，这就叫服务雪崩。<ol>\n<li>服务高可用部署：确保各个服务都具备高可用性，通过冗余部署、故障转移等方式来减少单点故障的影响。</li>\n<li>限流和熔断：对服务之间的请求进行限流和熔断，以防止过多的请求涌入导致后端服务不可用。</li>\n<li>缓存和降级：合理使用缓存来减轻后端服务的负载压力，并在必要时进行服务降级，保证核心功能的可用性。</li>\n</ol>\n</li>\n<li>服务熔断：服务熔断是微服务架构中的容错机制，用于保护系统免受服务故障或异常的影响。当某个服务出现故障或异常时，服务熔断可以快速隔离该服务，确保系统稳定可用。它通过监控服务的调用情况，当错误率或响应时间超过阈值时，触发熔断机制，后续请求将返回默认值或错误信息，避免资源浪费和系统崩溃。服务熔断还支持自动恢复，重新尝试对故障服务的请求，确保服务恢复正常后继续使用。<ol>\n<li>Resilience4j：轻量级服务熔断库，提供类似于Hystrix的功能，具有更好的性能和更简洁的API，可与Spring Cloud其他组件无缝集成</li>\n</ol>\n</li>\n<li>服务降级：服务降级是也是一种微服务架构中的容错机制，用于在系统资源紧张或服务故障时保证核心功能的可用性。当系统出现异常情况时，服务降级会主动屏蔽一些非核心或可选的功能，而只提供最基本的功能，以确保系统的稳定运行。通过减少对资源的依赖，服务降级可以保证系统的可用性和性能。它可以根据业务需求和系统状况来制定策略，例如替换耗时操作、返回默认响应、返回静态错误页面等。<ol>\n<li>Sentinel：阿里巴巴开源的流量控制和熔断降级组件，提供实时监控、流量控制、熔断降级等功能，与Spring Cloud Alibaba生态系统紧密集成</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>短链系统：设定好映射规则，实现好解密流程，即可把请求的短链转发到对应的URI上</p>\n<ul>\n<li>怎么设计一个短链地址，要考虑跨机房部署问题</li>\n<li>你说要哈希算法生成短链，会存在什么问题（哈希冲突），该怎么解决？（可以用布隆过滤器，但是不好控制，而且仍存在hash冲突）</li>\n<li>有没有更好的方案？（自增序列算法，每次接收一个长链，就分配一个ID，转成62进制再拼到短域后面）</li>\n<li>存在的问题？（自增id方案如果用雪花算法，可能存在机器时钟回拨的问题，导致id重复，说到这里，我终于明白那家伙为什么说要考虑跨机房部署问题）</li>\n<li>该怎么解决？（用Redis做自增id生成器，性能高，但要考虑持久性的问题；或者改造雪花算法，通过改造workId解决时钟回拨的问题）</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"1-Nacos\"><a href=\"#1-Nacos\" class=\"headerlink\" title=\"1.Nacos\"></a>1.Nacos</h2><ol>\n<li><p>注册中心对比</p>\n<ol>\n<li><p>常见问题</p>\n<ol>\n<li><p>消费者如何及时知道生产者的变更</p>\n<ul>\n<li>发布订阅模式（Zookeeper）：服务消费者能够实时监控服务更新状态，通常采用监听器以及回调机制</li>\n<li>主动拉取策略（Eureka）：服务的消费者定期调用注册中心提供的服务获取接口获取最新的服务列表并更新本地缓存</li>\n</ul>\n</li>\n<li><p>负载均衡策略</p>\n<ul>\n<li>服务端的负载均衡典型代表是Nginx、客户端的负载均衡典型代表是Ribbon。服务端的负载均衡，给服务提供者更强的流量控制权，但是无法满足不同的消费者希望使用不同负载均衡策略的需求；客户端的负载均衡则提供了这种灵活性，并对用户扩展提供更加友好的支持。但是客户端负载均衡策略如果配置不当，可能会导致服务提供者出现热点，或者压根就拿不到任何服务提供者</li>\n<li>常见负载均衡算法：轮询法、随机法、哈希算法、加权轮询法、加权随机法、最小连接数法</li>\n</ul>\n</li>\n<li><p>Apollo与Nacos效率对比</p>\n<ul>\n<li><strong>单机读场景：</strong>客户端测试程序通过部署多台机器，每台机器开启多个线程从配置中心读取不同的配置（3000个）。Nacos QPS可以达到15000，Apollo分为读内存缓存和从数据库中读两种方式，从数据库中读能达到7500，从内存读缓存性能可以达到9000QPS。Spring Cloud Config使用jGit读写Git，由于有客户端限制，单机读能力被限制在7QPS</li>\n<li><strong>3节点读场景：</strong>将配置中心的压测节点数都部署成3个节点。Nacos QPS可以达到45000 QPS，Apollo读内存缓存可以达到27000 QPS。Nacos和Apollo由于读场景各个节点是独立的，基本就是单机读场景的3倍关系。Spring Cloud Config三个节点读能力可以到达21QPS</li>\n<li><strong>单机写场景：</strong>同样的方式，多台机器同时在配置中心修改不同的配置。Nacos QPS可以达到1800，Apollo未使用默认的数据库连接池（10）QPS只能达到800 QPS（CPU未压满），调整连接池至100可以达到1100 QPS（CPU压满）。Git在提交同一个项目的时候会加锁，单机Git写能在5QPS左右，Spring Cloud Config在使用的时候以一个项目作为数据源，写能力受到Git限制</li>\n<li><strong>3节点写场景：</strong>同样的方式，将配置中心的压测节点数都部署成3个节点。Nacos QPS可以达到6000，Apollo可以达到3300 QPS（CPU压满），此时MySQL数据库因为配置较高，未成为性能瓶颈。Spring Cloud Config三个节点时候，Git也是一个节点，写QPS为5</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Apollo</th>\n<th>Nacos</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>单机读</td>\n<td>9000</td>\n<td>15000</td>\n</tr>\n<tr>\n<td>单机写</td>\n<td>1100</td>\n<td>1800</td>\n</tr>\n<tr>\n<td>3节点读</td>\n<td>27000</td>\n<td>45000</td>\n</tr>\n<tr>\n<td>3节点写</td>\n<td>3300</td>\n<td>5600</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li><p>常见注册中心</p>\n<ol>\n<li><p>Zookeeper</p>\n<ul>\n<li>基础<ul>\n<li>三种角色：Leader（同一时间只有一个，发起并维护与其它角色间的心跳，响应写操作并广播给其他服务器）、Follower（响应Leader心跳，可以处理读请求、有投票权）、Observer（与Follower类似，但无投票权）</li>\n<li>四种节点：PERSISTENT-持久节点（一直存在）、EPHEMERAL-临时节点（与客户端绑定）、PERSISTENT_SEQUENTIAL-持久顺序节点（增加了顺序属性，维护自增整形数字）、EPHEMERAL_SEQUENTIAL-临时顺序节点</li>\n<li>一种机制：Zookeeper的Watch机制（一种推拉结合的模式），一旦服务端感知主题变了，那么只会发送一个事件类型和节点信息给关注的客户端，而不会包括具体的变更内容，所以事件本身是轻量级的，这就是推的部分；然后，收到变更通知的客户端需要自己去拉变更的数据，这就是拉的部分</li>\n</ul>\n</li>\n<li>如何实现注册中心：Zookeeper可以充当一个服务注册表（Service Registry），让多个服务提供者形成一个集群，让服务消费者通过服务注册表获取具体的服务访问地址（ip+端口）去访问具体的服务提供者<ul>\n<li>每当一个服务提供者部署后都要将自己的服务注册到zookeeper的某一路径上: <strong>/{service}/{version}/{ip:port}</strong></li>\n<li>进行服务注册，就是在Zookeeper中创建了一个Znode节点，该节点存储了该服务的IP、端口、调用方式(协议、序列化方式)等，由服务提供者创建，服务消费者通过获取节点信息定位到服务提供者真正IP，发起调用</li>\n<li>如果创建的是临时节点，那么当创建临时节点的客户端会话因超时或发生异常而关闭时，该节点也相应在 ZooKeeper 服务器上被删除，剔除或者上线的时候会触发Zookeeper的Watch机制，会发送消息给消费者，因此就做到消费者信息的及时更新</li>\n</ul>\n</li>\n<li>Zookeeper从设计上来说的话整体遵循的CP的原则，在任何时候对 Zookeeper 的访问请求能得到一致的数据结果，同时系统对网络分区具备容错性，在使用 Zookeeper 获取服务列表时，如果此时的 Zookeeper 集群中的 Leader 宕机了，该集群就要进行 Leader 的选举，又或者 Zookeeper 集群中半数以上服务器节点不可用（例如有三个节点，如果节点一检测到节点三挂了 ，节点二也检测到节点三挂了，那这个节点才算是真的挂了)，那么将无法处理该请求。所以说，Zookeeper 不能保证服务可用性</li>\n</ul>\n</li>\n<li><p>Consul</p>\n<ul>\n<li><p>特点：服务注册和发现、健康检查、key/value存储、安全服务通信、多数据中心</p>\n</li>\n<li><p>在单个数据中心中，Consul分为Client和Server两种节点（所有的节点也被称为Agent），Server节点保存数据，Client负责健康检查及转发数据请求到Server；Server节点有一个Leader和多个Follower，Leader节点会将数据同步到Follower，Server的数量推荐是3个或者5个，在Leader挂掉的时候会启动选举机制产生一个新的Leader</p>\n</li>\n<li><p>集群内的Consul节点通过gossip协议（流言协议）维护成员关系，也就是说某个节点了解集群内现在还有哪些节点，这些节点是Client还是Server。单个数据中心的流言协议同时使用TCP和UDP通信，并且都使用8301端口。跨数据中心的流言协议也同时使用TCP和UDP通信，端口使用8302</p>\n</li>\n<li><p>集群内数据的读写请求既可以直接发到Server，也可以通过Client使用RPC转发到Server，请求最终会到达Leader节点，在允许数据延时的情况下，读请求也可以在普通的Server节点完成，集群内数据的读写和复制都是通过TCP的8300端口完成</p>\n</li>\n<li><p>应用外注册</p>\n<ul>\n<li><p><strong>Registrator</strong>：一个开源的第三方服务管理器项目，它通过监听服务部署的 Docker 实例是否存活，来负责服务提供者的注册和销毁</p>\n</li>\n<li><p><strong>Consul Template</strong>：定时从注册中心服务端获取最新的服务提供者节点列表并刷新 LB 配置（比如 Nginx 的 upstream），这样服务消费者就通过访问 Nginx 就可以获取最新的服务提供者信息,达到动态调节负载均衡的目的</p>\n</li>\n<li><p>我们用Registrator来监控每个Server的状态。当有新的Server启动的时候，Registrator会把它注册到Consul这个注册中心上。由于Consul Template已经订阅了该注册中心上的服务消息，此时Consul注册中心会将新的Server信息推送给Consul Template，Consul Template则会去修改nginx.conf的配置文件，然后让Nginx重新载入配置以达到自动修改负载均衡的目的</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925205833693.png\" alt=\"image-20230925205833693\"></p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Kubernetes</p>\n<ul>\n<li>在Kubernetes中，会将组成应用的容器组合成一个逻辑单元以更易管理和发现，通过Kubernetes能够进行应用的自动化部署和扩缩容</li>\n<li>特性：自动化装箱、自愈能力、水平扩容、服务发现和负载均衡、自动发布和回滚、保密和配置管理、存储编排</li>\n<li>架构组成<ul>\n<li>Master Node：作为控制节点，对集群进行调度管理，Master主要由三部分构成:<ul>\n<li><strong>Api Server</strong>相当于 K8S 的网关，所有的指令请求都必须经过 Api Server;</li>\n<li><strong>Kubernetes调度器</strong>，使用调度算法，把请求资源调度到某个 Node 节点;</li>\n<li><strong>Controller控制器</strong>，维护 K8S 资源对象（CRUD：添加、删除、更新、修改）;</li>\n<li><strong>ETCD存储资源对象</strong>（可以服务注册、发现等等）;</li>\n</ul>\n</li>\n<li>Worker Node：作为真正的工作节点，运行业务应用的容器；Worker Node主要包含五部分:<ul>\n<li>Docker是运行容器的基础环境，容器引擎;</li>\n<li>Kuberlet 执行在 Node 节点上的资源操作，Scheduler 把请求交给Api ，然后 Api Sever 再把信息指令数据存储在 ETCD 里，于是 Kuberlet 会扫描 ETCD 并获取指令请求，然后去执行;</li>\n<li>Kube-proxy是代理服务，起到负载均衡作用；</li>\n<li>Fluentd采集日志;</li>\n<li>Pod：Kubernetes 管理的基本单元（最小单元)，Pod 内部是容器。Kubernetes 不直接管理容器，而是管理 Pod;</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>主要功能：充当微服务的注册中心、服务配置、服务总线组件，</p>\n<ol>\n<li><p>架构图：provider对外暴露服务，consumer调用provider的服务，均需要使用<code>@EnableDiscoveryClient</code>来开启服务注册发现的功能</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925205902107.png\" alt=\"image-20230925205902107\"></p>\n</li>\n<li><p>服务注册与服务调用实现：可以使用Ribbon的负载均衡来调用provider</p>\n<ol>\n<li><p>创建RestTemplate，使用<code>@LoadBalanced</code>注解标注开启负载均衡</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925205918146.png\" alt=\"image-20230925205918146\"></p>\n</li>\n<li><p>直接使用注册到nacos的中的服务名作为访问地址调用服务，<code>serviceUrl</code>是配置文件中的<code>serviceUrl.nacos-provider=http://nacos-provider</code>，其中<code>nacos-provider</code>即provider在nacos注册的名字</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925205933547.png\" alt=\"image-20230925205933547\"></p>\n</li>\n</ol>\n</li>\n<li><p>配置管理实现：可以使用命名空间（namespace）来解决多环境隔离问题、可以使用配置集（Group）来区分不同业务系统的相同配置、使用共享配置实现配置复用</p>\n<ol>\n<li><p>添加maven依赖、增加配置文件（指定当前环境、nacos地址和配置内容格式）</p>\n<pre class=\"line-numbers language-yaml\" data-language=\"yaml\"><code class=\"language-yaml\">spring:\n  application:\n    name: nacos-config\n    ## 当前环境，这个和dataId有关-&gt; $&#123;prefix&#125;-$&#123;spring.profiles.active&#125;.$&#123;file-extension&#125;\n  profiles:\n    active: dev\n  cloud:\n    nacos:\n      config:\n        ## nacos的地址，作为配置中心\n        server-addr: 127.0.0.1:8848\n        ## 配置内容的数据格式，目前只支持 properties 和 yaml 类型，这个和dataId有关-&gt; $&#123;prefix&#125;-$&#123;spring.profiles.active&#125;.$&#123;file-extension&#125;\n        file-extension: properties\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        ## yml文件中存在特殊字符，必须用单引号包含，否则启动报错\n        include: &#39;*&#39;</code></pre></li>\n<li><p>dataId：一个配置的唯一标识，取值格式为<code>$&#123;prefix&#125;-$&#123;spring.profiles.active&#125;.$&#123;file-extension&#125;</code></p>\n<ul>\n<li><code>prefix</code>：前缀，默认为<code>spring.application.name</code>，也可以通过配置项 <code>spring.cloud.nacos.config.prefix</code>来配置</li>\n<li><code>spring.profiles.active</code>：即为当前环境对应的 profile。当 <code>spring.profiles.active</code>为空时，对应的连接符<code>-</code>也将不存在，dataId 的拼接格式变成 <code>$&#123;prefix&#125;.$&#123;file-extension&#125;</code><ul>\n<li><code>spring.profiles.active=dev</code>：本地开发环境</li>\n<li><code>spring.profiles.active=test</code>：测试环境</li>\n<li><code>spring.profiles.active=prod</code>：生产环境</li>\n</ul>\n</li>\n<li><code>file-exetension</code> 为配置内容的数据格式，可以通过配置项 <code>spring.cloud.nacos.config.file-extension</code> 来配置。目前只支持 <code>properties</code> 和 <code>yaml</code> 类型。</li>\n</ul>\n</li>\n<li><p>添加配置：在Nacos页面，添加一个config.version的配置，发布之后就可以使用</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925210040644.png\" alt=\"image-20230925210040644\"></p>\n</li>\n<li><p>获取Nacos中的配置：使用原生注解<code>@Value()</code>直接读取即可</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925210052456.png\" alt=\"image-20230925210052456\"></p>\n</li>\n<li><p>使用Nacos自动刷新配置：添加原生注解<code>@RefreshScope</code></p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925210107496.png\" alt=\"image-20230925210107496\"></p>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>Nacos集群</p>\n<ol>\n<li><p>集群架构图</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925210131944.png\" alt=\"image-20230925210131944\"></p>\n</li>\n<li><p>实现步骤</p>\n<ol>\n<li><p>修改端口号：<code>application.properties</code>中的<code>server.port</code></p>\n</li>\n<li><p>复制<code>cluster.conf.example</code></p>\n</li>\n<li><p>修改数据源：在MySQL中新建一个数据库，执行Nacos的SQL脚本（<code>nacos-mysql.sql</code>），修改<code>application.properties</code>中的数据源</p>\n</li>\n<li><p>修改nginx的conf</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">upstream nacos&#123;\n\t\tserver 172.16.1.84:8848;\n\t\tserver 172.16.1.84:8849;\n\t\tserver 172.16.1.84:8850;\n\t &#125;\n\t \n\t server&#123;\n\t\tlisten 80;\n\t\tlocation &#x2F; &#123;\n\t\t\tproxy_pass &lt;http:&#x2F;&#x2F;nacos&gt;;\n\t\t&#125;\n\t &#125;</code></pre></li>\n<li><p>在项目中配置server-addr</p>\n<ul>\n<li><p>直连Nacos</p>\n<pre class=\"line-numbers language-yaml\" data-language=\"yaml\"><code class=\"language-yaml\">spring:\n  application:\n    ## 指定服务名称，在nacos中的名字\n    name: nacos-provider\n  cloud:\n    nacos:\n      discovery:\n        # nacos的服务地址，nacos-server中IP地址:端口号\n        server-addr: 172.16.1.84:8848,172.16.1.84:8849,172.16.1.84:8850</code></pre></li>\n<li><p>通过Nginx</p>\n<pre class=\"line-numbers language-yaml\" data-language=\"yaml\"><code class=\"language-yaml\">spring:\n  application:\n    ## 指定服务名称，在nacos中的名字\n    name: nacos-provider\n  cloud:\n    nacos:\n      discovery:\n        # nacos的服务地址，nacos-server中IP地址:端口号\n        server-addr: 172.16.1.84:8848,172.16.1.84:8849,172.16.1.84:8850</code></pre></li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>Nacos是CP还是AP</p>\n<ol>\n<li>CAP的概念<ul>\n<li>一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）</li>\n<li>可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）</li>\n<li>分区容错性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。</li>\n</ul>\n</li>\n<li>一般分布式系统都是先保证P，剩下的C和A的取舍，不同的注册中心遵循的CAP也是不同的<ul>\n<li>Zookeeper：保证CP，放弃可用性；一旦zookeeper集群中master节点宕了，则会重新选举leader，这个过程可能非常漫长，在这过程中服务不可用</li>\n<li>Eureka：保证AP，放弃一致性；Eureka集群中的各个节点都是平等的，一旦某个节点宕了，其他节点正常服务（一旦客户端发现注册失败，则将会连接集群中其他节点），虽然保证了可用性，但是每个节点的数据可能不是最新的</li>\n<li>Nacos：同时支持CP和AP，默认是AP，可以切换；AP模式下以临时实例注册，CP模式下服务永久实例注册</li>\n</ul>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"2-OpenFeign\"><a href=\"#2-OpenFeign\" class=\"headerlink\" title=\"2.OpenFeign\"></a>2.OpenFeign</h2><ol>\n<li><p>What：</p>\n<ol>\n<li>Feign是一个声明式的Web服务客户端，它简化了使用基于HTTP的远程服务的开发。Feign是在RestTemplate 和 Ribbon的基础上进一步封装，使用RestTemplate实现Http调用（不必手动使用RestTemplate调服务，而是定义一个接口并标注注解即可），使用Ribbon实现负载均衡。但已经停止迭代</li>\n<li>OpenFeign是springcloud在Feign的基础上支持了SpringMVC的注解，如<code>@RequestMapping</code>等等。OpenFeign的<code>@FeignClient</code>可以解析SpringMVC的<code>@RequestMapping</code>注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务</li>\n</ol>\n</li>\n<li><p>特点：</p>\n<ol>\n<li><p>声明式API：Feign允许开发者使用简单的注解来定义和描述对远程服务的访问。通过使用注解，开发者可以轻松地指定URL、HTTP方法、请求参数、请求头等信息，使得远程调用变得非常直观和易于理解</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">@FeignClient(name &#x3D; &quot;example&quot;, url &#x3D; &quot;&lt;https:&#x2F;&#x2F;api.example.com&gt;&quot;)\npublic interface ExampleService &#123;\n    @GetMapping(&quot;&#x2F;endpoint&quot;)\n    String getEndpointData();\n&#125;</code></pre></li>\n<li><p>集成负载均衡：Feign集成了Ribbon负载均衡器，可以自动实现客户端的负载均衡。它可以根据服务名和可用实例进行动态路由，并分发请求到不同的服务实例上，提高系统的可用性和可伸缩性</p>\n</li>\n<li><p>容错机制：Feign支持集成Hystrix容错框架，可以在调用远程服务时提供容错和断路器功能。当远程服务不可用或响应时间过长时，Feign可以快速失败并返回预设的响应结果，避免对整个系统造成级联故障</p>\n</li>\n</ol>\n</li>\n<li><p>相关问题</p>\n<ul>\n<li>为什么Feign第一次调用耗时很长：主要原因是由于Ribbon的懒加载机制，当第一次调用发生时，Feign会触发Ribbon的加载过程，包括从服务注册中心获取服务列表、建立连接池等操作，这个加载过程会增加首次调用的耗时。可以在应用启动时预热Feign客户端，自动触发一次无关紧要的调用，来提前加载Ribbon和其他相关组件。这样，就相当于提前进行了第一次调用。</li>\n<li>Feign怎么做负载均衡：在Feign中，负载均衡是通过集成Ribbon来实现的。Ribbon通过从服务注册中心获取可用服务列表，并通过负载均衡算法选择合适的服务实例进行请求转发，实现客户端的负载均衡。</li>\n</ul>\n</li>\n<li><p>Feign和Dubbo对比</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Feign</th>\n<th>Dubbo</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>定义</td>\n<td>Feign是一个声明式的Web服务客户端，用于简化HTTP API的调用。</td>\n<td>Dubbo是一个分布式服务框架，用于构建面向服务的微服务架构。</td>\n</tr>\n<tr>\n<td>通信方式</td>\n<td>基于HTTP协议，使用RESTful风格的接口进行定义和调用。</td>\n<td>基于RPC协议，支持多种序列化协议如gRPC、Hessian等。</td>\n</tr>\n<tr>\n<td>服务发现</td>\n<td>通常结合服务注册中心（如Eureka、Consul）进行服务发现和负载均衡。</td>\n<td>通过ZooKeeper、Nacos等进行服务注册和发现，并提供负载均衡功能。</td>\n</tr>\n<tr>\n<td>服务治理</td>\n<td>不直接提供服务治理功能，需要结合其他组件或框架进行服务治理。</td>\n<td>提供服务注册与发现、负载均衡、容错机制、服务降级等服务治理功能。</td>\n</tr>\n<tr>\n<td>跨语言性</td>\n<td>支持跨语言通信，可以使用HTTP作为通信协议实现不同语言之间的通信。</td>\n<td>支持跨语言通信，通过Dubbo的IDL生成不同语言的客户端和服务端代码。</td>\n</tr>\n<tr>\n<td>生态系统</td>\n<td>集成了Spring Cloud生态系统，与Spring Boot无缝集成。</td>\n<td>拥有完整的生态系统，包括注册中心、配置中心、监控中心等组件。</td>\n</tr>\n<tr>\n<td>适用场景</td>\n<td>适用于构建RESTful风格的微服务架构，特别适合基于HTTP的微服务调用。</td>\n<td>适用于构建面向服务的微服务架构，提供更全面的服务治理和容错机制。</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>实践</p>\n<ol>\n<li><a href=\"https://mp.weixin.qq.com/s/YJu2oN-qxtpShrmHlyrByw\">https://mp.weixin.qq.com/s/YJu2oN-qxtpShrmHlyrByw</a></li>\n</ol>\n</li>\n</ol>\n<h2 id=\"3-Seata\"><a href=\"#3-Seata\" class=\"headerlink\" title=\"3.Seata\"></a>3.Seata</h2><ol>\n<li><p>CAP定理：指的是在一个分布式系统中，不可能同时满足以下三点</p>\n<ol>\n<li><strong>一致性（Consistency）：</strong>指强一致性，在写操作完成后开始的任何读操作都必须返回该值，或者后续写操作的结果。也就是说，在一致性系统中，一旦客户端将值写入任何一台服务器并获得响应，那么之后client从其他任何服务器读取的都是刚写入的数据。一致性保证了不管向哪台服务器写入数据，其他的服务器能实时同步数据</li>\n<li><strong>可用性（Availability）：</strong>可用性（高可用）是指：每次向未崩溃的节点发送请求，总能保证收到响应数据（允许不是最新数据）</li>\n<li><strong>分区容忍性（Partition tolerance）：</strong>分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，也就是说，服务器<strong>A</strong>和<strong>B</strong>发送给对方的任何消息都是可以放弃的，也就是说A和B可能因为各种意外情况，导致无法成功进行同步，分布式系统要能容忍这种情况。除非整个网络环境都发生了故障。</li>\n</ol>\n</li>\n<li><p>BASE理论：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性</p>\n<ol>\n<li><strong>BA(Basic Available)基本可用：</strong>整个系统在某些不可抗力的情况下，仍然能够保证“可用性”，即一定时间内仍然能够返回一个明确的结果。这里是属于基本可用。基本可用和高可用的区别：<ol>\n<li>“一定时间”可以适当延长 当举行大促（比如秒杀）时，响应时间可以适当延长</li>\n<li>给部分用户返回一个降级页面，给部分用户直接返回一个<strong>降级页面</strong>，从而缓解服务器压力。但要注意，返回降级页面仍然是返回明确结果。</li>\n</ol>\n</li>\n<li><strong>S(Soft State)柔性状态：</strong>称为柔性状态，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统不同节点的数据副本之间进行数据同步的过程存在延时。</li>\n<li><strong>E(Eventual Consisstency)最终一致性：</strong>同一数据的不同副本的状态，可以不需要实时一致，但一定要保证经过一定时间后仍然是一致的。</li>\n</ol>\n</li>\n<li><p>一致性分类</p>\n<ol>\n<li><strong>强一致性：</strong>系统中的某个数据被成功更新后，后续任何对该数据的读取操作都将得到更新后的值。也称为：原子一致性（Atomic Consistency）、线性一致性（Linearizable Consistency）。简言之，在任意时刻，所有节点中的数据是一样的。例如，对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。</li>\n<li><strong>弱一致性：**系统中的某个数据被更新后，后续对该数据的读取操作**可能**得到更新后的值，也可能是更改前的值。但即使过了</strong>不一致时间窗口**这段时间后，后续对该数据的读取也不一定是最新值。所以说，可以理解为数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。例如12306买火车票，虽然最后看到还剩下几张余票，但是只要选择购买就会提示没票了，这就是弱一致性。</li>\n<li>**最终一致性：**是弱一致性的**特殊**形式，存储系统保证在没有新的更新的条件下，最终所有的访问都是最后更新的值。不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。</li>\n</ol>\n</li>\n<li><p>分布式事务解决方案</p>\n<ol>\n<li><p>2PC：二阶段提交协议（Two-phase Commit，即 2PC）是常用的分布式事务解决方案，即将事务的提交过程分为两个阶段来进行处理。保证了数据的强一致，但是性能不好，都宕机会一直阻塞下去，无法保证数据一致（都宕机则失败），实现复杂</p>\n<ol>\n<li>准备阶段（投票阶段）：由事务的协调者（发起者）发起询问参与者（执行者）是否可以提交事务，但是这一阶段并未提交事务<ul>\n<li>协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待答复</li>\n<li>各参与者执行事务操作，将 undo 和 redo 信息记入事务日志中（但不提交事务）</li>\n<li>如参与者执行成功，给协调者反馈<strong>同意</strong>，否则反馈<strong>中止</strong></li>\n</ul>\n</li>\n<li>提交阶段：协调者发起正式提交事务的请求，当所有参与者都回复同意时，则意味着完成事务<ul>\n<li>协调者节点向所有参与者节点发出<strong>正式提交</strong>(<code>commit</code>)的请求。</li>\n<li>参与者节点正式完成操作，并释放在整个事务期间内占用的资源。</li>\n<li>参与者节点向协调者节点发送<strong>ack完成</strong>消息。</li>\n<li>协调者节点收到所有参与者节点反馈的<strong>ack完成</strong>消息后，完成事务。</li>\n</ul>\n</li>\n<li>回滚阶段：如果任意一个参与者节点在第一阶段返回的消息为终止，或者协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时，那么这个事务将会被回滚<ul>\n<li>协调者节点向所有参与者节点发出<strong>回滚操作</strong>(<code>rollback</code>)的请求。</li>\n<li>参与者节点利用阶段1写入的undo信息执行回滚，并释放在整个事务期间内占用的资源。</li>\n<li>参与者节点向协调者节点发送<strong>ack回滚完成</strong>消息。</li>\n<li>协调者节点受到所有参与者节点反馈的<strong>ack回滚完成</strong>消息后，取消事务。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>3PC：三阶段提交协议，是二阶段提交协议的改进版本，主要有两个改动点，一是在协调者和参与者中都引入超时机制，二是在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。相对于2PC，降低了阻塞范围，避免了协调者单点宕机问题，但是仍有数据不一致问题</p>\n<ol>\n<li><strong>CanCommit阶段：</strong>3PC的<code>CanCommit</code>阶段其实和2PC的准备阶段很像。协调者向参与者发送<code>commit</code>请求（事务询问），参与者如果可以提交就返回Yes响应，否则返回No响应（响应反馈）。</li>\n<li><strong>PreCommit阶段：</strong>协调者根据参与者的反应情况来决定是否可以进行事务的<code>PreCommit</code>操作。根据响应情况，有以下两种可能。<ul>\n<li>假如所有参与者均反馈 yes，协调者预执行事务。<ul>\n<li>发送预提交请求 ：协调者向参与者发送<code>PreCommit</code>请求，并进入准备阶段</li>\n<li>事务预提交 ：参与者接收到<code>PreCommit</code>请求后，会执行事务操作，并将<code>undo</code>和<code>redo</code>信息记录到事务日志中（但不提交事务）</li>\n<li>响应反馈 ：如果参与者成功的执行了事务操作，则返回<strong>ACK</strong>响应，同时开始等待最终指令。</li>\n</ul>\n</li>\n<li>假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。<ul>\n<li>发送中断请求 ：协调者向所有参与者发送<code>abort</code>请求。</li>\n<li>中断事务 ：参与者收到来自协调者的<code>abort</code>请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>doCommit阶段：</strong>该阶段进行真正的事务提交，也可以分为以下两种情况。进入阶段 3 后，无论是协调者出现问题，或者协调者与参与者网络出现问题，都会导致参与者无法接收到协调者发出的 do Commit 请求或 abort 请求。此时，参与者都会在等待超时之后，继续执行事务提交<ul>\n<li>执行提交<ul>\n<li>发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送<code>doCommit</code>请求。</li>\n<li>事务提交 参与者接收到<code>doCommit</code>请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。</li>\n<li>响应反馈 事务提交完之后，向协调者发送ack响应。</li>\n<li>完成事务 协调者接收到所有参与者的ack响应之后，完成事务。</li>\n</ul>\n</li>\n<li>中断事务：任何一个参与者反馈 no，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务<ul>\n<li>发送中断请求 如果协调者处于工作状态，向所有参与者发出 abort 请求</li>\n<li>事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。</li>\n<li>反馈结果 参与者完成事务回滚之后，向协调者反馈ACK消息</li>\n<li>中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>TCC（事务补偿）：TCC（Try Confirm Cancel）方案是一种应用层面侵入业务的两阶段提交。是目前最火的一种柔性事务方案，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。相对于传统事务机制，在性能上有很大提升，并且保证数据的最终一致性，解决了单点故障问题提高了可靠性，但是需要侵入业务代码，耦合度较高</p>\n<ol>\n<li>第一阶段：Try（尝试），主要是对业务系统做检测及资源预留 <strong>(加锁，锁住资源)</strong></li>\n<li>第二阶段：本阶段根据第一阶段的结果，决定是执行confirm还是cancel，Confirm 和 Cancel 操作满足幂等性，如果 Confirm 或 Cancel 操作执行失败，将会不断重试直到执行完成<ul>\n<li>Confirm（确认）：执行真正的业务（执行业务，释放锁），Try阶段执行成功并开始执行 <code>Confirm</code>阶段时，默认 <code>Confirm</code>阶段是不会出错的</li>\n<li>Cancle（取消）：是预留资源的取消（出问题，释放锁）</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>本地消息表：最初是由 eBay 提出，核心思路是将分布式事务拆分成本地事务进行处理。通过在事务主动发起方额外新建事务消息表，事务发起方处理业务和记录事务消息在本地事务中完成，轮询事务消息表的数据发送事务消息，事务被动方基于消息中间件消费事务消息表中的事务。方案轻量易实现，占用系统资源</p>\n<ol>\n<li>处理步骤<ul>\n<li>事务主动方在同一个本地事务中处理业务和写消息表操作</li>\n<li>事务主动方通过消息中间件，通知事务被动方处理事务通知事务待消息。消息中间件可以基于 Kafka、RocketMQ 消息队列，事务主动方主动写消息到消息队列，事务消费方消费并处理消息队列中的消息。</li>\n<li>事务被动方通过消息中间件，通知事务主动方事务已处理的消息。</li>\n<li>事务主动方接收中间件的消息，更新消息表的状态为已处理。</li>\n</ul>\n</li>\n<li>容错处理<ul>\n<li>当步骤一处理出错，由于还在事务主动方的本地事务中，直接回滚即可</li>\n<li>当步骤二、三处理出错，由于事务主动方本地保存了消息，只需要轮询消息重新通过消息中间件发送，事务被动方重新读取消息处理业务即可。</li>\n<li>如果是业务上处理失败，事务被动方可以发消息给事务主动方回滚事务</li>\n<li>如果事务被动方已经消费了消息，事务主动方需要回滚事务的话，需要发消息通知事务主动方进行回滚事务。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>MQ事务方案（可靠消息事务）：基于 MQ 的分布式事务方案其实是对本地消息表的封装，将本地消息表基于 MQ 内部，其他方面的协议基本与本地消息表一致。耦合度较低，但是一次消息需要两次网络请求(half 消息 + commit/rollback 消息)</p>\n<ol>\n<li><p>整体流程</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925213143279.png\" alt=\"image-20230925213143279\"></p>\n</li>\n<li><p><strong>正常情况：事务主动方发消息</strong></p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/1.png\" alt=\"1\"></p>\n<ul>\n<li>步骤①：发送方向 MQ 服务端(MQ Server)发送 half 消息。</li>\n<li>步骤②：MQ Server 将消息持久化成功之后，向发送方 ack 确认消息已经发送成功。</li>\n<li>步骤③：发送方开始执行本地事务逻辑。</li>\n<li>步骤④：发送方根据本地事务执行结果向 MQ Server 提交二次确认（commit 或是 rollback）。</li>\n<li>步骤⑤：MQ Server 收到 commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 rollback 状态则删除半消息，订阅方将不会接受该消息。</li>\n</ul>\n</li>\n<li><p><strong>异常情况：事务主动方消息恢复</strong></p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/2.png\" alt=\"2\"></p>\n<ul>\n<li>步骤⑤：MQ Server 对该消息发起消息回查。</li>\n<li>步骤⑥：发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li>\n<li>步骤⑦：发送方根据检查得到的本地事务的最终状态再次提交二次确认。</li>\n<li>步骤⑧：MQ Server基于 commit/rollback 对消息进行投递或者删除。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>Saga 事务</p>\n</li>\n</ol>\n</li>\n<li><p>Seata支持哪些模式的分布式事务</p>\n<ol>\n<li><p>AT（Atomikos）模式：AT模式是Seata默认支持的模式，也是最常用的模式之一。在AT模式下，Seata通过在业务代码中嵌入事务上下文，实现对分布式事务的管理。Seata会拦截并解析业务代码中的SQL语句，通过对数据库连接进行拦截和代理，实现事务的管理和协调。</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925213312027.png\" alt=\"image-20230925213312027\"></p>\n</li>\n<li><p>TCC（Try-Confirm-Cancel）模式：TCC模式是一种基于补偿机制的分布式事务模式。在TCC模式中，业务逻辑需要实现Try、Confirm和Cancel三个阶段的操作。Seata通过调用业务代码中的Try、Confirm和Cancel方法，并在每个阶段记录相关的操作日志，来实现分布式事务的一致性。</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/3.png\" alt=\"3\"></p>\n</li>\n<li><p>SAGA模式：SAGA模式是一种基于事件驱动的分布式事务模式。在SAGA模式中，每个服务都可以发布和订阅事件，通过事件的传递和处理来实现分布式事务的一致性。Seata提供了与SAGA模式兼容的Saga框架，用于管理和协调分布式事务的各个阶段。</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925213347668.png\" alt=\"image-20230925213347668\"></p>\n</li>\n<li><p>XA模式：XA模式是一种基于两阶段提交（Two-Phase Commit）协议的分布式事务模式。在XA模式中，Seata通过与数据库的XA事务协议进行交互，实现对分布式事务的管理和协调。XA模式需要数据库本身支持XA事务，并且需要在应用程序中配置相应的XA数据源。</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/4.png\" alt=\"4\"></p>\n</li>\n</ol>\n</li>\n<li><p>Seata实现原理</p>\n<ol>\n<li>核心组件<ol>\n<li><strong>事务协调器（Transaction Coordinator）</strong>：事务协调器负责协调和管理分布式事务的整个过程。它接收事务的开始和结束请求，并根据事务的状态进行协调和处理。事务协调器还负责记录和管理事务的全局事务 ID（Global Transaction ID）和分支事务 ID（Branch Transaction ID）。</li>\n<li><strong>事务管理器（Transaction Manager）</strong>：事务管理器负责全局事务的管理和控制。它协调各个分支事务的提交或回滚，并保证分布式事务的一致性和隔离性。事务管理器还负责与事务协调器进行通信，并将事务的状态变更进行持久化。</li>\n<li><strong>资源管理器（Resource Manager）</strong>：资源管理器负责管理和控制各个参与者（Participant）的事务操作。它与事务管理器进行通信，并根据事务管理器的指令执行相应的事务操作，包括提交和回滚。</li>\n</ol>\n</li>\n<li>两阶段提交（Two-Phase Commit）协议<ol>\n<li>一阶段：在事务提交的过程中，首先进行预提交阶段。事务协调器向各个资源管理器发送预提交请求，资源管理器执行相应的事务操作并返回执行结果。在此阶段，业务数据和回滚日志记录在同一个本地事务中提交，并释放本地锁和连接资源。</li>\n<li>二阶段：在预提交阶段成功后，进入真正的提交阶段。此阶段主要包括提交异步化和回滚反向补偿两个步骤：<ul>\n<li>提交异步化：事务协调器发出真正的提交请求，各个资源管理器执行最终的提交操作。这个阶段的操作是非常快速的，以确保事务的提交效率。</li>\n<li>回滚反向补偿：如果在预提交阶段中有任何一个资源管理器返回失败结果，事务协调器发出回滚请求，各个资源管理器执行回滚操作，利用一阶段的回滚日志进行反向补偿。</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>事务执行流程<ol>\n<li>事务发起方（Transaction Starter）发起全局事务：事务发起方是指发起分布式事务的应用程序或服务。它向Seata的事务协调器发送全局事务的开始请求，生成全局事务ID（Global Transaction ID）。</li>\n<li>事务协调器创建全局事务记录：事务协调器接收到全局事务的开始请求后，会为该事务创建相应的全局事务记录，并生成分支事务ID（Branch Transaction ID）。</li>\n<li>分支事务注册：事务发起方将全局事务ID和分支事务ID发送给各个参与者（Participant），即资源管理器。参与者将分支事务ID注册到本地事务管理器，并将事务的执行结果反馈给事务协调器。</li>\n<li>执行业务逻辑：在分布式事务的上下文中，各个参与者执行各自的本地事务，即执行业务逻辑和数据库操作。</li>\n<li>预提交阶段：事务发起方向事务协调器发送预提交请求，事务协调器将预提交请求发送给各个参与者。</li>\n<li>执行本地事务确认：参与者接收到预提交请求后，执行本地事务的确认操作，并将本地事务的执行结果反馈给事务协调器。</li>\n<li>全局事务提交或回滚：事务协调器根据参与者反馈的结果进行判断，如果所有参与者的本地事务都执行成功，事务协调器发送真正的提交请求给参与者，参与者执行最终的提交操作；如果有任何一个参与者的本地事务执行失败，事务协调器发送回滚请求给参与者，参与者执行回滚操作。</li>\n<li>完成全局事务：事务协调器接收到参与者的提交或回滚结果后，根据结果更新全局事务的状态，并通知事务发起方全局事务的最终结果。</li>\n</ol>\n</li>\n<li><strong>全局事务ID和分支事务ID是怎么传递的？：</strong>全局事务ID和分支事务ID在分布式事务中通过上下文传递的方式进行传递。常见的传递方式包括参数传递、线程上下文传递和消息中间件传递。具体的传递方式可以根据业务场景和技术选型进行选择和调整。</li>\n<li><strong>Seata的事务回滚是怎么实现的？</strong>Seata的事务回滚是通过回滚日志实现的。每个参与者在执行本地事务期间生成回滚日志，记录了对数据的修改操作。当需要回滚事务时，事务协调器向参与者发送回滚请求，参与者根据回滚日志中的信息执行撤销操作，将数据恢复到事务开始前的状态。回滚日志的管理和存储是Seata的核心机制，可以选择将日志存储在不同的介质中。通过回滚日志的持久化和恢复，Seata确保了事务的一致性和恢复性。</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"4-Sleuth-Zipkin\"><a href=\"#4-Sleuth-Zipkin\" class=\"headerlink\" title=\"4.Sleuth+Zipkin\"></a>4.Sleuth+Zipkin</h2><ol>\n<li><p>链路追踪：在微服务中，有的山下游可能有十几个服务，如果某一环出了问题，排查起来非常困难，所以，就需要进行链路追踪，来帮助排查问题。通过链路追踪，可以可视化地追踪请求从一个微服务到另一个微服务的调用情况。除了排查问题，链路追踪黑还可以帮助优化性能，可视化依赖关系、服务监控和告警。常见链路追踪技术如下：</p>\n<ol>\n<li>Zipkin：Zipkin 是一个开源的分布式实时追踪系统，由 Twitter 开发并贡献给开源社区。Spring Cloud Sleuth 提供了与 Zipkin 的集成，可以通过在微服务中添加相应的依赖和配置，将追踪信息发送到 Zipkin 服务器，并通过 Zipkin UI 进行可视化展示和查询。</li>\n<li>Jaeger：Jaeger 是 Uber 开源的分布式追踪系统，也被纳入了 CNCF（云原生计算基金会）的维护。通过使用 Spring Cloud Sleuth 和 Jaeger 客户端库，可以将追踪信息发送到 Jaeger 并进行可视化展示和查询。</li>\n<li>SkyWalking：Apache SkyWalking 是一款开源的应用性能监控与分析系统，提供了对 Java、.NET 和 Node.js 等语言的支持。它可以与 Spring Cloud Sleuth 集成，将追踪数据发送到 SkyWalking 服务器进行可视化展示和分析。</li>\n</ol>\n</li>\n<li><p>Spring Cloud Sleuth实现了一种分布式的服务链路跟踪解决方案，通过使用Sleuth可以让我们快速定位某个服务的问题。简单来说，Sleuth相当于调用链监控工具的客户端，集成在各个微服务上，负责产生调用链监控数据。</p>\n<ol>\n<li><strong>Span</strong>：基本的工作单元，相当于链表中的一个节点，通过一个唯一ID标记它的开始、具体过程和结束。我们可以通过其中存储的开始和结束的时间戳来统计服务调用的耗时。除此之外还可以获取事件的名称、请求信息等。</li>\n<li><strong>Trace</strong>：一系列的Span串联形成的一个树状结构，当请求到达系统的入口时就会创建一个唯一ID（traceId），唯一标识一条链路。这个traceId始终在服务之间传递，直到请求的返回，那么就可以使用这个traceId将整个请求串联起来，形成一条完整的链路。</li>\n<li>Annotation：一些核心注解用来标注微服务调用之间的事件，重要的几个注解如下：<ol>\n<li>**cs(Client Send)**：客户端发出请求，开始一个请求的生命周期</li>\n<li><strong>sr（Server Received）</strong>：服务端接受请求并处理；<strong>sr-cs = 网络延迟 = 服务调用的时间</strong></li>\n<li><strong>ss（Server Send）</strong>：服务端处理完毕准备发送到客户端；<strong>ss - sr = 服务器上的请求处理时间</strong></li>\n<li><strong>cr（Client Reveived）</strong>：客户端接受到服务端的响应，请求结束；<strong>cr - sr = 请求的总时间</strong></li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>Zipkin：Twitter 的一个开源项目，基于Google Dapper实现，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现</p>\n<ol>\n<li><p>架构图</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925213508314.png\" alt=\"image-20230925213508314\"></p>\n</li>\n<li><p>核心组件</p>\n<ol>\n<li><strong>Collector</strong>：收集器组件，它主要用于处理从外部系统发送过来的跟踪信息，将这些信息转换为Zipkin内部处理的 Span 格式，以支持后续的存储、分析、展示等功能</li>\n<li><strong>Storage</strong>：存储组件，它主要对处理收集器接收到的跟踪信息，默认会将这些信息存储在内存中，我们也可以修改此存储策略，通过使用其他存储组件将跟踪信息存储到数据库中</li>\n<li><strong>RESTful API</strong>：API 组件，它主要用来提供外部访问接口。比如给客户端展示跟踪信息，或是外接系统访问以实现监控等</li>\n<li><strong>UI</strong>：基于API组件实现的上层应用。通过UI组件用户可以方便而有直观地查询和分析跟踪信息</li>\n</ol>\n</li>\n<li><p>zipkin分为服务端和客户端，服务端主要用来收集跟踪数据并且展示，客户端主要功能是发送给服务端，微服务的应用也就是客户端，这样一旦发生调用，就会触发监听器将sleuth日志数据传输给服务端</p>\n</li>\n<li><p><strong>zipKin的数据传输方式如何切换？：</strong>zipkin默认的传输方式是HTTP，但是这里存在一个问题，一旦传输过程中客户端和服务端断掉了，那么这条跟踪日志信息将会丢失。当然zipkin还支持<strong>MQ</strong>方式的传输，支持消息中间件有如下几种：ActiveMQ、RabbitMQ、Kafka，使用MQ方式传输不仅能够保证消息丢失的问题，还能提高传输效率，<strong>生产中推荐MQ传输方式</strong>。</p>\n</li>\n<li><p><strong>zipkin如何持久化？：</strong>zipkin的信息默认是存储在内存中，服务端一旦重启信息将会丢失，但是zipkin提供了可插拔式的存储。zipkin支持以下四种存储方式：内存：服务重启将会失效，不推荐；MySQL：数据量越大性能较低；Elasticsearch：主流的解决方案，推荐使用；Cassandra：技术太牛批，用的人少，自己选择，不过官方推荐</p>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"5-Sentinel\"><a href=\"#5-Sentinel\" class=\"headerlink\" title=\"5.Sentinel\"></a>5.Sentinel</h2><ol>\n<li><p>Sentinel怎么实现限流的：Sentinel通过动态管理限流规则，根据定义的规则对请求进行限流控制。具体实现步骤如下</p>\n<ol>\n<li><p>定义资源：在Sentinel中，资源可以是URL、方法等，用于标识需要进行限流的请求。</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">&#x2F;&#x2F; 原本的业务方法.\n@SentinelResource(blockHandler &#x3D; &quot;blockHandlerForGetUser&quot;)\npublic User getUserById(String id) &#123;\n    throw new RuntimeException(&quot;getUserById command failed&quot;);\n&#125;\n\n&#x2F;&#x2F; blockHandler 函数，原方法调用被限流&#x2F;降级&#x2F;系统保护的时候调用\npublic User blockHandlerForGetUser(String id, BlockException ex) &#123;\n    return new User(&quot;admin&quot;);\n&#125;</code></pre></li>\n<li><p>配置限流规则：在Sentinel的配置文件中定义资源的限流规则。规则可以包括资源名称、限流阈值、限流模式（令牌桶或漏桶）等。</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">private static void initFlowQpsRule() &#123;\n    List&lt;FlowRule&gt; rules &#x3D; new ArrayList&lt;&gt;();\n    FlowRule rule1 &#x3D; new FlowRule();\n    rule1.setResource(resource);\n    &#x2F;&#x2F; Set max qps to 20\n    rule1.setCount(20);\n    rule1.setGrade(RuleConstant.FLOW_GRADE_QPS);\n    rule1.setLimitApp(&quot;default&quot;);\n    rules.add(rule1);\n    FlowRuleManager.loadRules(rules);\n&#125;</code></pre></li>\n<li><p>监控流量：Sentinel会监控每个资源的流量情况，包括请求的QPS（每秒请求数）、线程数、响应时间等。</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925213604975.png\" alt=\"image-20230925213604975\"></p>\n</li>\n<li><p>限流控制：当请求到达时，Sentinel会根据资源的限流规则判断是否需要进行限流控制。如果请求超过了限流阈值，则可以进行限制、拒绝或进行其他降级处理。</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/5.png\" alt=\"5\"></p>\n</li>\n</ol>\n</li>\n<li><p><strong>Sentinel采用的是什么限流算法：</strong>Sentinel使用滑动窗口限流算法来实现限流。滑动窗口限流算法是一种基于时间窗口的限流算法。它将一段时间划分为多个时间窗口，并在每个时间窗口内统计请求的数量。通过动态地调整时间窗口的大小和滑动步长，可以更精确地控制请求的通过速率。</p>\n</li>\n<li><p><strong>Sentinel怎么实现集群限流：</strong>Sentinel利用了Token Server和Token Client的机制来实现集群限流。开启集群限流后，Client向Token Server发送请求，Token Server根据配置的规则决定是否限流。</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230925213644598.png\" alt=\"image-20230925213644598\"></p>\n</li>\n</ol>\n","feature":true,"text":"1.微服务 What：微服务（Microservices）是一种软件架构风格，将一个大型应用程序划分为一组小型、自治且松耦合的服务。每个微服务负责执行特定的业务功能，并通过轻量级通信机制（如HTTP）相互协作。每个微服务可以独立开发、部署和扩展，使得应用程序更加灵活、可伸缩和可维...","link":"","photos":[],"count_time":{"symbolsCount":"25k","symbolsTime":"23 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E5%BE%AE%E6%9C%8D%E5%8A%A1\"><span class=\"toc-text\">1.微服务</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-Nacos\"><span class=\"toc-text\">1.Nacos</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-OpenFeign\"><span class=\"toc-text\">2.OpenFeign</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-Seata\"><span class=\"toc-text\">3.Seata</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4-Sleuth-Zipkin\"><span class=\"toc-text\">4.Sleuth+Zipkin</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-Sentinel\"><span class=\"toc-text\">5.Sentinel</span></a></li></ol>","author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"Dubbo","uid":"0ca9a116507ce2deadb100db49d2064a","slug":"Dubbo","date":"2023-09-02T02:38:57.000Z","updated":"2023-09-18T10:50:05.073Z","comments":true,"path":"api/articles/Dubbo.json","keywords":null,"cover":[],"text":"Dubbo RPC RPC（Remote Procedure Call）全称为远程过程调用，用于解决不同服务器之间两个方法的互相调用问题，并且通过网络编程来传递方法调用所需要的参数，通过RPC来简化底层网络编程（如TCP连接的建立）、规划化参数序列化反序列化等问题，使得这个过程就...","link":"","photos":[],"count_time":{"symbolsCount":"26k","symbolsTime":"23 mins."},"categories":[],"tags":[],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}