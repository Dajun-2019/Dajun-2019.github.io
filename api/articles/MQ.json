{"title":"MQ","uid":"f8ef4e10e9f952ff4ed3590ecc45cea3","slug":"MQ","date":"2023-08-07T05:45:26.000Z","updated":"2023-09-24T12:17:24.475Z","comments":true,"path":"api/articles/MQ.json","keywords":null,"cover":[],"content":"<h1 id=\"MQ\"><a href=\"#MQ\" class=\"headerlink\" title=\"MQ\"></a>MQ</h1><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>中间件（Middleware）：是一类提供系统软件和应用软件之间连接、便于软件各部件之间的沟通的软件，应用软件可以借助中间件在不同的技术架构之间共享信息与资源。常用中间件有消息队列、RPC 框架、分布式组件（分布式事务、分布式Session、分布式Id）、HTTP 服务器（Tomcat、Nginx）、缓存服务、任务调度框架（xxl-job）、配置中心、数据库层的分库分表和数据迁移工具</p></blockquote>\n<h2 id=\"1-MQ基础\"><a href=\"#1-MQ基础\" class=\"headerlink\" title=\"1.MQ基础\"></a>1.MQ基础</h2><ol>\n<li><p>消息队列的优缺点</p>\n<ul>\n<li>优点<ul>\n<li><strong>异步处理</strong><ul>\n<li><strong>减少响应时间</strong>：虽然可以减少处理时间，但是需要业务配合，在数据校验并写入数据库后才能返回业务处理成功的消息</li>\n<li><strong>降低系统耦合</strong>：生产者（客户端）发送消息到消息队列中去，接受者（服务端）处理消息，需要消费的系统直接去消息队列取消息进行消费即可而不需要和其他系统有耦合</li>\n</ul>\n</li>\n<li><strong>流量削峰</strong>：先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉</li>\n</ul>\n</li>\n<li>缺点<ul>\n<li><strong>系统可用性降低：</strong> 需要额外考虑消息丢失或MQ宕机的情况</li>\n<li><strong>系统复杂性提高：</strong> 需要保证消息无重复消费、无丢失、消息传递的顺序合理</li>\n<li><strong>一致性问题：</strong> 如果消费者并没有正确消费消息就会导致数据不一致的情况</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>JMS和AMQP</p>\n<ul>\n<li>JMS：Java消息队列服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输，JMS API 是一个消息服务的标准或者说是规范<ul>\n<li>消息类型：<code>StreamMessage</code>（Java 原始值的数据流）、<code>MapMessage</code>（键-值对）、<code>TextMessage</code>（字符串对象）、<code>ObjectMessage</code>（一个序列化的 Java 对象）、<code>BytesMessage</code>（一个字节的数据流）</li>\n<li>消息模型：点到点（P2P）模型、发布/订阅（Pub/Sub）模型</li>\n<li>应用：<strong>ActiveMQ</strong></li>\n</ul>\n</li>\n<li>AMQP：高级消息队列协议（Advanced Message Queuing Protocol）是一个提供统一消息服务的应用层标准，兼容JMS，仅支持byte[]（二进制）消息类型<ul>\n<li>消息类型：direct exchange；fanout exchange；topic change；headers exchange；system exchange（本质来讲，后四种和 JMS 的 pub/sub 模型没有太大差别，仅是在路由机制上做了更详细的划分）</li>\n<li>应用：<strong>RabbitMQ</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>RPC与MQ的区别</p>\n<ul>\n<li><strong>从用途来看</strong>：RPC将调用远程服务方法简化成调用本地方法，MQ主要用来降低系统耦合性、实现任务异步、有效地进行流量削峰</li>\n<li><strong>从通信方式来看</strong>：RPC 是双向直接网络通讯，MQ是单向引入中间载体的网络通讯</li>\n<li><strong>从架构上来看</strong>：MQ需要把消息存储起来，RPC 则没有这个要求</li>\n<li><strong>从请求处理的时效性来看</strong>：通过 RPC 发出的调用一般会立即被处理，存放在MQ中的消息并不一定会立即被处理</li>\n</ul>\n</li>\n<li><p>消息模型</p>\n<ul>\n<li><p>生产者-消费者模型与发布订阅模型：生产者-消费者模型适用于单消费者的环境，当有多个消费者的时候就会产生消费者的竞争关系，所以出现了发布订阅模型，发布者将消息发送到主题（Topic，即消息容器）中，然后订阅该主题的订阅者就可以收到发送者发送的消息了</p>\n</li>\n<li><p>RabbitMQ消息模型：RabbitMQ新增了一个交换器组件（主要有4种），生产者发送消息的时候会指定一个 RoutingKey ,当 RoutingKey 和 BindingKey一样的时候就会被发送的对应的队列中去</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831164311030.png\" alt=\"image-20230831164311030\"></p>\n</li>\n<li><p>Kafka消息模型</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831164236499.png\" alt=\"image-20230831164236499\"></p>\n</li>\n</ul>\n</li>\n<li><p>技术选型</p>\n<ul>\n<li>按照不同的业务诉求进行选择，如消息挤压、消费重试、延迟消息、顺序消息、消息归档、预发消息等场景</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Kafka</th>\n<th>RabbitMQ</th>\n<th>RocketMQ</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>资料文档</td>\n<td>中等</td>\n<td><strong>多</strong></td>\n<td>少</td>\n</tr>\n<tr>\n<td>开发语言</td>\n<td>Scala</td>\n<td>Erlang</td>\n<td>Java</td>\n</tr>\n<tr>\n<td>支持的协议</td>\n<td>自定义（基于TCP）</td>\n<td>AMQP</td>\n<td>自定义</td>\n</tr>\n<tr>\n<td>消息存储</td>\n<td>内存、磁盘、数据库；支持大量堆积</td>\n<td>内存、磁盘；支持少量堆积</td>\n<td><strong>磁盘；支持大量堆积</strong></td>\n</tr>\n<tr>\n<td>消息事务</td>\n<td>支持</td>\n<td>支持</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>负载均衡</td>\n<td>支持</td>\n<td><strong>支持的不好</strong></td>\n<td>支持</td>\n</tr>\n<tr>\n<td>集群方式</td>\n<td>天然的‘Leader-Slave’无状态集群</td>\n<td><strong>支持简单集群 对高级集群模式支持不好</strong></td>\n<td>常用 多对’Master-Slave’ 模式</td>\n</tr>\n<tr>\n<td>管理界面</td>\n<td>一般</td>\n<td>好</td>\n<td>有管理后台</td>\n</tr>\n<tr>\n<td>可用性</td>\n<td>非常高（分布式）</td>\n<td>高（主从）</td>\n<td>非常高（分布式）</td>\n</tr>\n<tr>\n<td>消息重复</td>\n<td>支持at least once、at most once</td>\n<td><strong>支持at least once、at most once</strong></td>\n<td>支持at least once</td>\n</tr>\n<tr>\n<td>吞吐量TPS</td>\n<td>极大</td>\n<td>比较大</td>\n<td>大</td>\n</tr>\n<tr>\n<td>订阅形式和消息分发</td>\n<td>发布订阅模式</td>\n<td><strong>direct、topic、Headers和fanout</strong></td>\n<td><strong>发布订阅模式</strong></td>\n</tr>\n<tr>\n<td>顺序消息</td>\n<td>支持</td>\n<td><strong>不支持</strong></td>\n<td><strong>支持</strong></td>\n</tr>\n<tr>\n<td>消息确认</td>\n<td>支持</td>\n<td>支持</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>消息回溯</td>\n<td>支持指定分区offset位置的回溯</td>\n<td><strong>不支持</strong></td>\n<td><strong>支持指定时间点的回溯</strong></td>\n</tr>\n<tr>\n<td>消息重试</td>\n<td>不支持</td>\n<td><strong>不支持</strong></td>\n<td>支持</td>\n</tr>\n<tr>\n<td>并发度</td>\n<td>并发度高</td>\n<td>并发度极高</td>\n<td>并发度高</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n<h2 id=\"2-Kafka\"><a href=\"#2-Kafka\" class=\"headerlink\" title=\"2.Kafka\"></a>2.Kafka</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>LinkedIn 开源的一个分布式流式处理平台，已经成为 Apache 顶级项目，早期被用来用于处理海量的日志，后面才慢慢发展成了一款功能全面的高性能消息队列</p></blockquote>\n<ol>\n<li><p>基础</p>\n<ul>\n<li>优势：极致的性能（每秒处理千万级别的消息）、生态系统兼容性（大数据和流计算）</li>\n<li>主要功能：<strong>消息队列（</strong>发布和订阅消息流）、<strong>容错的持久方式存储记录消息流</strong>（把消息持久化到磁盘）、<strong>流式处理平台</strong>（流式处理类库，在消息发布的时候进行处理）</li>\n<li>架构模式：Kafka 是一个分布式系统，由通过高性能 TCP 网络协议进行通信的服务器和客户端组成，可以部署在在本地和云环境中的裸机硬件、虚拟机和容器上</li>\n<li>重大改进：在 Kafka 2.8 之前，Kafka 最被大家诟病的就是其重度依赖于 Zookeeper 做元数据管理和集群的高可用。在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构</li>\n</ul>\n</li>\n<li><p>消息模型</p>\n<ol>\n<li><p>最开始使用的是队列模型：一对一模式，生产者需要知道具体消费者个数然后去复制对应数量的消息队列，但是违背了<strong>解耦</strong>这一原则</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831144101172.png\" alt=\"image-20230831144101172\"></p>\n</li>\n<li><p>发布-订阅模型：使用<strong>主题（Topic）</strong> 作为消息通信载体，类似于<strong>广播模式</strong>。发布者发布一条消息，该消息通过主题传递给所有的订阅者（广播后订阅的用户收不到该条消息）</p>\n<ul>\n<li><p>名词：<strong>Producer（生产者）</strong>、<strong>Consumer（消费者）</strong></p>\n<ul>\n<li><strong>Broker（代理）</strong> ：可以看做一个独立的Kafka实例，多个可以组成Kafka Cluster</li>\n<li><strong>Topic（主题）</strong>：Producer 将消息发送到特定的Topic(主题)，Consumer 通过订阅特定的 Topic(主题) 来消费消息</li>\n<li><strong>Partition（分区）</strong>：Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker</li>\n</ul>\n</li>\n<li><p>模型图</p>\n<img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831165135509.png\" alt=\"image-20230831165135509\" style=\"zoom:50%;\" /></li>\n<li></li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>多副本机制</p>\n<ul>\n<li>Partition中的多个副本之间有一个leader、和若干follower。发送的消息会被发送到leader，然后follower才从leader中拉去信息进行同步</li>\n<li>producer和consumer只与leader交互，其它follower只是leader的拷贝，follower的存在只是为了保证消息存储的安全性，在旧leader宕机时被选举为新leader（与leader同步程度达不到要求的无法参加leader的竞选）</li>\n<li>优势：一个Topic可以有多个Partition，各个Partition可以分布在不同的Broker上（<strong>并发能力</strong>），每个Partition可以指定对应的Replica数（<strong>容灾能力</strong>）</li>\n</ul>\n</li>\n<li><p>消息的顺序性保证</p>\n<ul>\n<li>Partition内部有序保证：消息存储在Topic的Partition中，每次消息添加都会使用尾加法，所以Kafka可以保证Partition内部的消息有序</li>\n<li>消息参数：Kafka 中发送 1 条消息的时候，可以指定 topic、partition、key、data 4 个参数</li>\n<li>Partition外部顺序保证：1个 Topic 只对应1个 Partition；或者发送消息的时候指定 key/Partition（同一个key的消息可以保证只发送到同一个 partition）</li>\n</ul>\n</li>\n<li><p>保证信息不丢失：增加异步的回调方法感知消息是否丢失、利用Producer的重试机制</p>\n<ul>\n<li><p>Kafka防止消息丢失的方式</p>\n<ul>\n<li><p>消息持久化：Kafka将消息持久化到磁盘，确保消息的可靠性和持久性。在消息写入磁盘之前会先写入缓存中，如果有故障，可以从缓存或磁盘中恢复数据避免消息的丢失。另外可以创建一个单独的Task表，表中专门写MQ消息记录，用于发送失败重试等，这样可以统一管理</p>\n</li>\n<li><p>同步副本机制：Kafka基于分布式的同步副本机制，能够通过给每个副本分配分区的方式来防止消息丢失。这种方式可以避免某个分区的副本所在的节点宕机或者网络故障等情况，还能够确保消费者所有副本都被读取到，从而避免消息的丢失</p>\n</li>\n<li><p>Replication factor：在Kafka集群中，可以配置副本的数量。如果要求高可靠性，可以提高副本数量，这样即使某个Broker出现故障，也可以使用其他Broker上的副本进行恢复，从而避免消息丢失</p>\n</li>\n<li><p>消费者接收确认（consumer ACKs）：消费者可以通过在读取完消息后发送反馈确认信息，告诉Kafka消息已经被成功读取。如果消费者没有确认信息，则在消息超时后，Kafka将重新推送一次消息给消费者。这种方式可以防止消息在消费者读取之前被错误地删除</p>\n</li>\n<li><p>日志压缩：Kafka支持对日志进行压缩操作，可以节省磁盘空间并提高处理性能，同时也可以防止消息丢失</p>\n</li>\n</ul>\n</li>\n<li><p>解决</p>\n<ul>\n<li><p>异步回调方法</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future &#x3D; \n  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tkafkaTemplate.send(topic, o);\nfuture.addCallback(\n  result -&gt; logger.info(&quot;生产者成功发送消息到topic:&#123;&#125; partition:&#123;&#125;的消息&quot;, \n  result.getRecordMetadata().topic(),       \t  \t\n  result.getRecordMetadata().partition()),\n  ex -&gt; logger.error(&quot;生产者发送消失败，原因：&#123;&#125;&quot;,\n  ex.getMessage())\n); </code></pre></li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>重试机制；为 Producer 的<code>retries</code>（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次 3 次一下子就重试完了</li>\n<li>补偿消息<ul>\n<li>数据库记录MQ状态，所有超时n分钟的消息将状态更改为发送失败状态，基于落库记录添加worker扫描补偿MQ消息，对于库存扣减的MQ也可以通过二次记录缓存，worker定时批量更新数据库，避免较高MQ给数据库带来压力</li>\n<li>具体SQL语句：使用<code>set value = value - 1</code>而不是<code>set value = xxx</code>，后续的MQ会把库存更新的更小；或者使用<code>set value = xxx where value &gt; xxx</code>，只有更新的值比原有的值小，才更新，否则不更新，防止MQ是乱序消费的</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-RocketMQ\"><a href=\"#3-RocketMQ\" class=\"headerlink\" title=\"3.RocketMQ\"></a>3.RocketMQ</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>alibaba开源的一款云原生“消息、事件、流”实时数据处理平台，借鉴了 Kafka，已经成为 Apache 顶级项目。</p></blockquote>\n<ol>\n<li><p>基础</p>\n<ul>\n<li>在传统的分布式计算环境中，常常会出现由于某个单机节点的性能瓶颈，消息队列本质上是提供了一种非常合理的任务分配策略，通过将任务分给消费者实现异步和分布式处理，提高整个集群的性能</li>\n<li>消息队列有着经典的三大应用场景：<strong>解耦（消息订阅）、异步（流程耗时）</strong>和<strong>削峰填谷（流量激增）</strong></li>\n<li>核心特性：云原生（K8s 友好）、高吞吐（万亿级吞吐保证）、流处理（提供轻量、高扩展、高性能和丰富功能的流计算引擎）、金融级稳定性、架构极简（零外部依赖，Shared-nothing 架构）、生态友好</li>\n</ul>\n</li>\n<li><p>消息模型</p>\n<ol>\n<li><p><code>NameServer</code>（注册中心）：Broker将自己的信息注册到NameServer中，消费者和生产者通过查询NameServer获取Broker信息（定期更新），并与对应的Broker进行通信</p>\n<ul>\n<li>在每个NameServer节点内部都维护着所有 <strong>Broker</strong> 的地址列表，所有 <strong>Topic</strong> 和 Topic 对应 <strong>Queue</strong> 的信息等</li>\n<li>路由信息管理：通过去中心化的方式进行集群部署，<strong>单个 Broker 和所有 NameServer 保持长连接</strong> ，并且在每隔 30 秒 <code>Broker</code> 会向所有 <code>Nameserver</code> 发送心跳，心跳包含了自身的 <code>Topic</code> 配置信息</li>\n</ul>\n</li>\n<li><p><code>Topic</code> （主题）：代表一类消息，比如订单消息，物流消息等等</p>\n<ul>\n<li>主题中存在多个队列（提高并发能力），生产者每次生产消息之后是指定主题中的某个队列发送消息的</li>\n<li>一个队列只会被一个消费组的一个消费者消费，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费</li>\n<li>不同消费组可以同时消费同一个队列中的消息，只需要每个消费组在每个队列上维护一个消费位置，用来记录消费过的信息，消费完后不删除消息</li>\n</ul>\n</li>\n<li><p><code>Broker</code>（消息队列服务器）：负责消息的存储、投递和查询，保证服务的高可用，生产者生产消息并传送到Broker，消费者从Broker拉去消息并消费</p>\n<ul>\n<li><p>一个Topic分布在多个Broker上，一个Broker可以配置多个Topic，是多对多的关系</p>\n<img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831204750089.png\" alt=\"image-20230831204750089\" style=\"zoom: 33%;\" /></li>\n<li><p>提供了主从部署模式，slave定期从master同步数据（同步刷盘或异步刷盘），如果master宕机，则slave提供消费服务，但是不能写入消息</p>\n<ul>\n<li>在 master 宕机时，同步副本集中的其余节点会自动选举出新的 master 代替工作（==Raft 协议==）</li>\n<li>Broker 默认采用的是==同步双写==的方式，消息写入 master 成功后，master 会等待 slave 同步数据成功后才向 Producer 返回成功 ACK ，即 Master 与 Slave 都要写入成功后才会返回成功 ACK</li>\n<li>broker 节点可以按照处理的数据相同划分成副本组，同一组 master 和 slave 的关系可以通过指定相同 brokerName，不同的 ==brokerId== 来定义，brokerId 为 0 标识 master，非 0 是 slave</li>\n</ul>\n</li>\n<li><p>每个broker服务器会与每一个NameServer服务器建立长连接，并注册topic信息到NameServer中</p>\n</li>\n</ul>\n</li>\n<li><p><code>Producer Group</code> （生产者组）：代表某一类的生产者，比如我们有多个秒杀系统作为生产者，这多个合在一起就是一个 <code>Producer Group</code> 生产者组，它们一般生产相同的消息</p>\n<ul>\n<li>Producer支持分布式集群方式部署，与NameServer随机一个节点建立长连接，定时从NameServer获取topic路由信息，与master broker建立长连接，定时发送心跳，不与slave建立连接</li>\n<li>Producer需要向Broker发送消息的时候，需要先从NameServer获取关于Broker的路由信息，然后通过轮询的方式向每个队列中生产数据（负载均衡）<ul>\n<li>查询本地缓存是否存储了 TopicPublishInfo ，否则从 NameServer 获取</li>\n<li>根据负载均衡选择策略获取待发送队列并轮训访问</li>\n<li>获取消息队列对应的 broker 实际 IP</li>\n<li>设置消息 Unique ID ，zip 压缩消息</li>\n<li>消息校验（长度等），发送消息</li>\n</ul>\n</li>\n<li>消息发送时如果出现失败，默认会重试 2 次，在重试时会尽量避开刚刚接收失败的 Broker，而是选择其它 Broker 上的队列进行发送，从而提高消息发送的成功率</li>\n</ul>\n</li>\n<li><p><code>Consumer Group</code> （消费者组）：代表某一类的消费者，比如我们有多个短信系统作为消费者，这多个合在一起就是一个 <code>Consumer Group</code> 消费者组，它们一般消费相同的消息</p>\n<ul>\n<li>Consumer支持分布式集群方式部署，支持push推、pull拉两种模式对消息进行消费，同时也支持集群方式和广播方式的消费，提供了实时订阅机制<ul>\n<li>广播消费：Producer 向一些队列轮流发送消息，队列集合称为 Topic，每一个 Consumer 实例消费这个 Topic 对应的所有队列</li>\n<li>集群消费：多个 Consumer 实例平均消费这个 Topic 对应的队列集合</li>\n<li>广播模式下一条消息会发送给同一消费组的所有消费者；集群模式下只会发送给一个消费者</li>\n</ul>\n</li>\n<li>Consumer通过NameServer获取所有Broker的路由信息后，向Broker发送pull请求来获取消息</li>\n<li>集群模式下有一点需要注意：消费队列负载机制遵循一个通用的思想，一个消息队列同时只允许被一个消费者消费，一个消费者可以消费多个消费队列。因此当 Consumer 的数量大于队列的数量，会有部分 Consumer 分配不到队列，这些分配不到队列的 Consumer 机器不会有消息到达</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831203538617.png\" alt=\"image-20230831203538617\"></p>\n</li>\n<li><p>相关问题</p>\n<ol>\n<li><p>消息顺序：通过Hash取模将需要有序的消息发送到同一个队列中</p>\n</li>\n<li><p>重复消费</p>\n<ul>\n<li>出现的时机<ul>\n<li>发送时消息重复【消息 Message ID 不同】：MQ Producer 发送消息时，消息已成功发送到服务端并完成持久化，此时网络闪断或者客户端宕机导致服务端应答给客户端失败。如果此时 MQ Producer 意识到消息发送失败并尝试再次发送消息，MQ 消费者后续会收到两条内容相同但是 Message ID 不同的消息</li>\n<li>投递时消息重复【消息 Message ID 相同】：MQ Consumer 消费消息场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。为了保证消息至少被消费一次，MQ 服务端将在网络恢复后再次尝试投递之前已被处理过的消息，MQ 消费者后续会收到两条内容相同并且 Message ID 也相同的消息</li>\n</ul>\n</li>\n<li>解决办法<ul>\n<li>写入Redis：因为Redis的key和value天然支持幂等</li>\n<li>插入MySQL：通过数据库的唯一键来保证重复数据不会被插入多条</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>消息丢失：RocketMQ避免消息丢失的机制主要包括重试、冗余消息存储。在生产者的消息投递失败时，默认会重试两次。消费者消费失败时，广播模式下，消费失败仅返回 ConsumeConcurrentlyStatus.RECONSUME_LATER ，而不会重试。在未指定顺序消息的集群模式下，消费失败的消息会进入重试队列自动重试，默认最大重试次数为 16 。在顺序消费的集群模式下，消费失败会使得当前队列暂停消费，并重试到成功为止</p>\n</li>\n<li><p>消息堆积：限流降级、检查是否消费者出现了大量的消费错误、增加消费者实例的同时增加每个主题的队列数量（因为消费者和队列一一对应）</p>\n</li>\n<li><p>消息回溯（Consumer重新消费已消费成功的消息）：因为在RocketMQ中，已经消费过的消息仍然需要保留，支持按照时间回溯消费，并且时间维度精确到毫秒</p>\n</li>\n<li><p>消费失败：当出现消费失败的消息时，Broker 会为每个消费者组设置一个重试队列。当一条消息初次消费失败，消息队列会自动进行消费重试。达到最大重试次数后，若消费仍然失败，此时会将该消息发送到死信队列。对于死信消息，通常需要开发人员进行手动处理</p>\n</li>\n</ol>\n</li>\n<li><p>消息链路</p>\n<ol>\n<li>producer 指定 broker 和 queue 发送消息 msg </li>\n<li>broker 接收消息，并完成缓存、刷盘和生成摘要（同时根据 tag 和 user properties 对 msg 进行打标）等操作</li>\n<li>consumer 每隔一段时间（ pullInterval ）从 broker 端的（根据服务端消息过滤模式 tag 或 sql 过滤后）获取一定量的消息到本地消息队列中（单线程）</li>\n<li>consumer 按照配置并发分配上述队列消息并执行消费方法；</li>\n<li>consumer 返回 broker 消费结果并重置消费位点；</li>\n</ol>\n</li>\n<li><p>消息种类</p>\n<ul>\n<li><p>普通消息：可选择同步、异步或单向发送</p>\n<ul>\n<li>同步：Producer 发出一条消息后，会在收到 MQ 返回的 ACK 之后再发送下一条消息</li>\n<li>异步：Producer 发出消息后无需等待 MQ 返回 ACK ，直接发送下一条消息</li>\n<li>单向： Producer 仅负责发送消息，不等待，MQ 也不返回 ACK</li>\n</ul>\n</li>\n<li><p>顺序消息：只支持同一个queue的顺序消息，且同一个queue只能被一台机器的一个线程消费，如果想要支持全局消息，那需要将该 topic 的 queue 的数量设置为 1，牺牲了可用性</p>\n<ul>\n<li>全局顺序：对于指定的一个 Topic ，所有消息按照严格的先入先出的顺序进行发布和消费 （同一个 queue）</li>\n<li>分区顺序：对于一个指定的 Topic ，所有消息根据 sharding key 进行分区，同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费，分区之间彼此独立</li>\n</ul>\n</li>\n<li><p>消息事务：事务消息加上事务反查机制</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831210952098.png\" alt=\"image-20230831210952098\"></p>\n<ul>\n<li>发送方向 MQ 服务端发送消息</li>\n<li>MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功，此时消息为半消息</li>\n<li>发送方开始执行本地事务逻辑</li>\n<li>发送方根据本地事务执行结果向 MQ Server 提交二次确认（Commit 或是 Rollback），MQ Server 收到 Commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 Rollback 状态则删除半消息，订阅方将不会接受该消息</li>\n<li>在断网或者是应用重启的特殊情况下，上一步骤中提交的二次确认最终未到达 MQ Server，经过固定时间后 MQ Server 将对该消息发起消息回查<ul>\n<li>反查机制：如果消息是 half 消息，将备份原消息的主题与消息消费队列，然后<strong>改变主题</strong>为 RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费 half 类型的消息，<strong>然后 RocketMQ 会开启一个定时任务，从 Topic 为 RMQ_SYS_TRANS_HALF_TOPIC 中拉取消息进行消费</strong>，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息</li>\n</ul>\n</li>\n<li>发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果</li>\n<li>发送方根据检查得到的本地事务的最终状态再次提交二次确认，MQ Server 仍按照步骤 4 对半消息进行操作</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>刷盘机制</p>\n<ol>\n<li><p>同步刷盘和异步刷盘（设置 <code>Broker</code> 的参数 <code>FlushDiskType</code> 为<code>ASYNC_FLUSH</code> 或<code>SYNC_FLUSH</code>）</p>\n<ul>\n<li><p><strong>同步刷盘</strong>对 <code>MQ</code> 消息可靠性来说是一种不错的保障，但是 <strong>性能上会有较大影响</strong> ，一般地适用于金融等特定业务场景</p>\n</li>\n<li><p><strong>异步刷盘</strong>往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行，<strong>降低了读写延迟</strong> ，提高了<code>MQ</code>的性能和吞吐量，一般适用于发验证码等对于消息保证要求不太高的业务场景，<strong>只有在 <code>Broker</code> 意外宕机的时候会丢失部分数据</strong></p>\n<img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831215335580.png\" alt=\"image-20230831215335580\" style=\"zoom:50%;\" /></li>\n</ul>\n</li>\n<li><p>同步复制和异步复制：同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的 <code>Borker</code> 主从模式下，<strong>主节点返回消息给客户端的时候是否需要同步从节点</strong></p>\n<ul>\n<li>同步复制：也叫 “同步双写”，也就是说，<strong>只有消息同步双写到主从节点上时才返回写入成功</strong></li>\n<li>异步复制：<strong>消息写入主节点之后就直接返回写入成功</strong> ，主节点挂掉后，消费者可以自动切换到从节点进行消费（仅消费，不只是生产）<ul>\n<li>主节点同步消息到从节点过程中，如果主节点宕机，就会少一部分消息，可以切换到从节点进行消费（仅能消费），但是会出现短暂的消息不一致的情况，在主节点重启后，会继续复制中断未复制的消息</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>存储机制：消息存储在生产者和消费者之间的一个消息代理（Message Broker）上</p>\n<ul>\n<li><p>不同的消息存储方式对比</p>\n<ul>\n<li>AcviveMQ使用队列表来存储消息，依靠轮训和加锁的方式检查和处理信息，QPS高的时候会导致B+树索引层级深，影响查询效率</li>\n<li>KV数据库使用LSM树作为索引结构，对读性能有较大牺牲，消息队列常常会因为失败重试，所以不适合</li>\n<li>﻿RocketMQ/Kafka/RabbitMQ 等消息队列会采用顺序写的日志结构，将消息刷盘至文件系统作持久化。顺序写日志文件可以避免频繁的随机访问而导致的性能问题，而且利于延迟写入等优化手段，能够快速保存日志</li>\n</ul>\n</li>\n<li><p><code>CommitLog</code>：<strong>消息主体以及元数据的存储主体</strong>，存储 <code>Producer</code> 端写入的消息主体内容，消息内容不是定长的。</p>\n<ul>\n<li><p>单个文件大小默认 1G ，文件名长度为 20 位，左边补零，剩余为起始偏移量，比如 00000000000000000000 代表了第一个文件，起始偏移量为 0，文件大小为 1G=1073741824；当第一个文件写满了，第二个文件为 00000000001073741824，起始偏移量为 1073741824，以此类推</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230915190801797.png\" alt=\"image-20230915190801797\"></p>\n</li>\n<li><p>消息主要是<strong>顺序写入日志文件</strong>，当文件满了，写入下一个文件</p>\n</li>\n<li><p><strong>内存映射机制</strong>：<code>CommitLog</code> 文件要设计成固定大小的长度</p>\n</li>\n</ul>\n</li>\n<li><p><code>ConsumeQueue</code>：消息消费队列，<strong>引入的目的主要是提高消息消费的性能</strong></p>\n<ul>\n<li><p>由于<code>RocketMQ</code> 是基于主题 <code>Topic</code> 的订阅模式，消息消费是针对主题进行的，如果要遍历 <code>commitlog</code> 文件中根据 <code>Topic</code> 检索消息是非常低效的。<code>Consumer</code> 即可根据 <code>ConsumeQueue</code> 来查找待消费的消息，RocketMQ会启动一个ReputMessageService每隔1ms生成一次Consume queue和其它索引文件</p>\n</li>\n<li><p><code>ConsumeQueue</code>（逻辑消费队列）<strong>作为消费消息的索引</strong>，保存了指定 <code>Topic</code> 下的队列消息在 <code>CommitLog</code> 中的<strong>起始物理偏移量 <code>offset</code> ，消息大小 <code>size</code> 和消息 <code>Tag</code> 的 <code>HashCode</code> 值。ConsumeQueue 文件可以看成是基于 <code>topic</code> 的 <code>commitlog</code> 索引文件</strong></p>\n</li>\n<li><p><code>consumequeue</code> 文件夹的组织方式如下：topic/queue/file 三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样 <code>consumequeue</code> 文件采取定长设计，每一个条目共 20 个字节，分别为 8 字节的 <code>commitlog</code> 物理偏移量、4 字节的消息长度、8 字节 tag <code>hashcode</code>，单个文件由 30W 个条目组成，可以像数组一样随机访问每一个条目，每个 <code>ConsumeQueue</code>文件大小约 5.72M；</p>\n</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230915190423181.png\" alt=\"image-20230915190423181\"></p>\n</li>\n<li><p><code>IndexFile</code>：<code>IndexFile</code>（索引文件）提供了一种可以通过 key 或时间区间来查询消息的方法</p>\n<ul>\n<li>查找时，可以根据消息的 key 计算 hash 槽的位置，hash 槽中存储着 Index 条目的位置，可以根据这个 index 条目获得一个链表（尾），每个 index 条目包含在 CommitLog 上的消息主体的物理偏移量</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230915191057793.png\" alt=\"image-20230915191057793\"></p>\n</li>\n<li><p>RocketMQ与Kafka对比</p>\n<ul>\n<li><p><code>RocketMQ</code> 采用的是 <strong>混合型的存储结构</strong> ，即为 <code>Broker</code> 单个实例下所有的队列共用一个日志数据文件来存储消息</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831215351880-20230831220434736.png\"></p>\n</li>\n<li><p>Kafka 会为每个 topic (事件的组织和存储单位，一个 topic 可以对应多个生产者和多个消费者) 划分出一个分区日志，便于根据 topic 顺序消费，消息被读取后不会立刻删除，可以持久存储，但 topic 数量增加的时候，broker 的分区文件数量增大，会使得本来速度很快的顺序写变成随机写（不同文件之间移动），性能大幅下降。</p>\n</li>\n<li><p>RocketMQ不分 <code>Topic</code> 意味着有更大的几率获取 <strong>成批</strong> 的消息进行数据写入，但也会带来一个麻烦就是读取消息的时候需要遍历整个大文件，这是非常耗时的，所以，在RocketMQ中又使用了ConsumeQueue作为每个队列的索引文件来<strong>提升读取消息的效率</strong>。可以直接根据队列的消息序号，计算出索引的全局位置（索引序号*索引固定⻓度 20），然后直接读取这条索引，再根据索引中记录的消息的全局位置，找到消息</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n</li>\n<li></li>\n</ol>\n<h2 id=\"4-RabbitMQ\"><a href=\"#4-RabbitMQ\" class=\"headerlink\" title=\"4.RabbitMQ\"></a>4.RabbitMQ</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>采用 Erlang 语言实现 AMQP(Advanced Message Queuing Protocol，高级消息队列协议）的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息</p></blockquote>\n<ol>\n<li><p>架构模型</p>\n<ul>\n<li><p><strong>Producer(生产者)</strong> 、<strong>Consumer(消费者)</strong> </p>\n</li>\n<li><p>**Exchange(交换器)**：RabbitMQ收到的消息首先会经过Exchange，由Exchange决定消息被分配到哪个对应的Queue中，如果路由失败则会返回给Producer或者直接丢弃</p>\n<ul>\n<li>Exchange有4种不同的类型并分别对应四种不同的路由策略（direct、fanout、topic、headers）<ul>\n<li>direct（默认）：把消息路由到那些 <strong>BindingKey 与 RoutingKey 完全匹配的 Queue 中</strong>，常用在处理有优先级的任务，给优先级高的任务分配更多的资源</li>\n<li>fanout：把所有发送到该Exchange的消息路由到所有与他绑定的Queue中，不做任何判断，处理速度最快，常用来广播消息</li>\n<li>topic：扩展了direct类型，将BindingKey和RoutingKey规定为”.”分割的字符串，并提供“*”（1个）和“#”（0个或多个）用作模糊匹配</li>\n<li>headers（不推荐）：根据发送的消息内容中的headers属性进行匹配，性能很差</li>\n</ul>\n</li>\n<li><strong>RoutingKey(路由键)<strong>：生产者将消息发给交换器的时候，会指定一个</strong>RoutingKey</strong>，用来指定这个消息的路由规则（RoutingKey需要结合Exchange类型和BindingKey来使用）</li>\n<li>**BindingKey(绑定建)**：通过BindingKey来将Exchange和Queue关联起来，当BindingKey与RoutindKey相匹配时，消息会被路由到对应的队列中（需要交换器类型支持此机制）</li>\n</ul>\n</li>\n<li><p>**Queue(消息队列)**：用来保存消息直到发送给消费者，一个消息可投入一个或多个队列，并且一直保存在队列里面等待消费者取走，多个消费者可以订阅同一个队列（使用轮询方式平分，每个消费者一个，避免重复消费）</p>\n</li>\n<li><p><strong>Broker（消息中间件的服务节点）</strong>：RabbitMQ服务节点或者服务实例，可以看作一台RabbitMQ服务器</p>\n</li>\n<li><p>模型架构图示例：</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230831220633188.png\" alt=\"image-20230831220633188\"></p>\n</li>\n</ul>\n</li>\n<li><p>消息传输方式：</p>\n<ul>\n<li>TCP与信道：由于 TCP 链接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈，所以 RabbitMQ 使用信道的方式来传输数据</li>\n<li><strong>信道（Channel）</strong>：生产者、消费者与 RabbitMQ 通信的渠道，建立在 TCP 链接上的虚拟链接，且每条 TCP 链接上的信道数量没有限制。可以在一条 TCP 链接上建立成百上千个信道来达到多个线程处理，这个 TCP 被多个线程共享，每个信道在 RabbitMQ 都有唯一的 ID，保证了信道私有性，每个信道对应一个线程使用</li>\n</ul>\n</li>\n<li><p>部署方式</p>\n<ul>\n<li><strong>单机模式：</strong>Demo 级别</li>\n<li><strong>普通集群模式：</strong>在每台机器上启动1个RabbitMQ实例，创建的Queue只会放在一个RabbitMQ实例上，但是每个实例都同步Queue的元数据用于查找每个Queue所在实例。消费的时候，如果连接到了另外一个实例，则此实例会从Queue所在实例拉去数据过来，使用多个节点进行读写操作，提高吞吐量</li>\n<li><strong>镜像集群模式：</strong>高可用模式，创建的Queue无论元数据还是Queue里的消息都会存在多个实例上，每个RabbitMQ节点都有这个Queue的一个完整镜像。每次写信息到Queue中，都会自动把消息同步到多个实例的Queue上，可以通过管理控制台指定要求数据同步到所有节点或者同步到指定数量的节点。当任何一个机器宕机了，Consumer还可以去其它节点上消费数据，但是性能开销很大，导致网络带宽压力很重</li>\n</ul>\n</li>\n<li><p>进阶使用</p>\n<ul>\n<li><p><strong>死信队列</strong>：DLX，全称为Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列</p>\n<ul>\n<li>产生的原因：消息被拒（<code>Basic.Reject /Basic.Nack</code>) 且 <code>requeue = false</code>；消息 TTL 过期；队列满了无法再添加</li>\n</ul>\n</li>\n<li><p><strong>延迟队列</strong>：存储对应的延迟消息，消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费，有以下两种实现方式</p>\n<ul>\n<li>使用 RabbitMQ 的死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）</li>\n<li>在 RabbitMQ 3.5.7 及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能（插件依赖 Erlang/OPT 18.0 及以上）</li>\n</ul>\n</li>\n<li><p><strong>优先级队列</strong>：通过<code>x-max-priority</code>参数来实现优先级队列。不过，当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义</p>\n</li>\n</ul>\n</li>\n<li><p>消息相关问题</p>\n<ul>\n<li><p><strong>消息的可靠性：</strong></p>\n<ul>\n<li>生产者到 RabbitMQ：事务机制和 Confirm 机制（两者是互斥的）</li>\n<li>RabbitMQ 自身：持久化、集群、普通模式、镜像模式</li>\n<li>RabbitMQ 到消费者：basicAck 机制、死信队列、消息补偿机制</li>\n</ul>\n</li>\n<li><p><strong>消息顺序性</strong>：</p>\n<ul>\n<li>拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点</li>\n<li>或者一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理</li>\n</ul>\n</li>\n<li><p><strong>消息队列的延时以及过期失效</strong>：设置过期时间、临时丢失后续批量重新导入</p>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"5-MQ进阶\"><a href=\"#5-MQ进阶\" class=\"headerlink\" title=\"5.MQ进阶\"></a>5.MQ进阶</h2><ol>\n<li><p>为什么使用消息队列：结合自己的系统里类似的场景来叙述，一个模块调用了多个模块</p>\n<ul>\n<li>解耦：多个下游系统使用一个核心系统的数据时，使用消息队列可以在增减下游系统时不用更改核心系统的代码，直接消费消息队列里的A输入的数据</li>\n<li>异步：核心系统调用不同存储系统存储数据时，不用等待存储操作完成，可以将数据输入到消息队列中，然后直接返回响应，由消息队列与存储系统继续协调</li>\n<li>削峰：MySQL最多响应2k个请求，可以把过多的请求存储在消息队列中，然后MySQL每秒拉去2k个请求，防止MySQL因为请求过多而崩溃</li>\n</ul>\n</li>\n<li><p>如何保证消息队列组件的高可用</p>\n<ul>\n<li>RabbitMQ：镜像集群模式（高可用性）<ul>\n<li>无论是元数据还是queue里的消息都会存放在多个实例上并且都是完整镜像， 每次写消息到queue的时候，都会自动把消息同步到多个实例的queue上</li>\n<li>通过后台的管理控制台，新增一个策略（镜像集群模式），指定的时候可以要求数据同步到所有节点，也可以要求同步到指定数量的节点，再次创建queue的时候就会自动将数据同步到其他节点上</li>\n<li>缺点：通信的性能开销很大；扩展性不好，对于负载大的queue新的机器也会包含这个queue的所有数据，没办法平衡负载</li>\n</ul>\n</li>\n<li>Kafka：由多个broker组成，每个broker是一个节点；每创建一个topic，这个topic可以被划分为多个partition，每个partition可以存在于不同的broker上，每个partition存放一部分数据<ul>\n<li>Kafka0.8之后的HA机制：每个partition的数据都会同步到其它机器上，形成自己的repllica副本，所有replica副本会选举出一个leader出来，其它replica就是follower，所有生产者和消费者都跟这个leader交互。不能随意读写每个follower，因为需要保证数据一致性问题，但是Kafka会均匀地将一个partition的所有replica分布在不同的机器上，提高容错性</li>\n<li>写的时候，leader会负责把数据同步到所有follower上（leader直接写盘，然后其它follower主动从follower来pull数据，同步好数据后向leader发送ack，leader收到所有follower的ack后返回写成功的消息给生产者）；读的时候直接读leader上的数据（当leader读取到所有follower的ack后才会向消费者返回消息）</li>\n<li>如果某个broker宕机了，此时会从follower中重新选举一个新的leader出来</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>消息的重复消费问题（幂等）</p>\n<ol>\n<li><p>问题示例：Kafka使用offset来表示当前consumer消费完的消息的序号，consumer会定期提交自己消费过的offset，保证重启的时候会从上次消费到的offset来继续消费，但是异常宕机时会丢失这一段时间消费了但未提交offset的消息消费记录，导致重启的时候会再次消费一次，如果下游系统没有考虑到重复消费问题就无法保证幂等姓，导致数据出错</p>\n</li>\n<li><p>保证幂等性的方法（结合业务）</p>\n<ul>\n<li><p>写入有主键的数据库（MySQL）时，可以先根据主键查询一下，如果数据都有了就不insert而是进行update</p>\n</li>\n<li><p>写Redis时，因为每次都是set，有天然的幂等性</p>\n</li>\n<li><p>向队列中的每条信息加一个全局唯一的id，在收到信息后，先查询是否消费过再决定是否处理</p>\n</li>\n<li><p>将 <code>enable.auto.commit</code>参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：什么时候提交 offset 合适？</p>\n<ul>\n<li>处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样</li>\n<li>拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底</li>\n</ul>\n</li>\n<li><p>使用Redis缓存MQ的消费记录（记录12h），消费前如果缓存没有记录，可以查询数据库，消费后进行缓存记录，对于金融、订单、支付等场景，必须使用数据库防重字段做强一致性拦截处理（双重保证）</p>\n</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>消息的丢失问题</p>\n<ol>\n<li><p>RabbitMQ</p>\n<ul>\n<li><p>生产者：事务机制（吞吐量会下降）、confirm模式（队列处理了会返回ack，否则调用nack接口的回调函数告知失败），前者是同步的后者是异步的，并且两种模式并不共存</p>\n<ul>\n<li><p>confirm实现代码，一共三种：普通、批量、异步</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">&#x2F;&#x2F;普通confirm\nchannel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\nif (!channel.waitForConfirms()) &#123;\n    &#x2F;&#x2F; 消息发送失败\n    &#x2F;&#x2F; ...\n&#125;\n&#x2F;&#x2F;批量confirm\nchannel.confirmSelect();\nfor (int i &#x3D; 0; i &lt; batchCount; ++i) &#123;\n    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\n&#125;\nif (!channel.waitForConfirms()) &#123;\n    &#x2F;&#x2F; 消息发送失败\n    &#x2F;&#x2F; ...\n&#125;\n&#x2F;&#x2F;异步confirm\nSortedSet&lt;Long&gt; confirmSet &#x3D; Collections.synchronizedSortedSet(new TreeSet&lt;Long&gt;());\nchannel.confirmSelect();\nchannel.addConfirmListener(new ConfirmListener() &#123;\n    public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123;\n        if (multiple) &#123;\n            confirmSet.headSet(deliveryTag + 1).clear();\n        &#125; else &#123;\n            confirmSet.remove(deliveryTag);\n        &#125;\n    &#125;\n\n    public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123;\n        System.out.println(&quot;Nack, SeqNo: &quot; + deliveryTag + &quot;, multiple: &quot; + multiple);\n        if (multiple) &#123;\n            confirmSet.headSet(deliveryTag + 1).clear();\n        &#125; else &#123;\n            confirmSet.remove(deliveryTag);\n        &#125;\n    &#125;\n&#125;);\n\nwhile (true) &#123;\n    long nextSeqNo &#x3D; channel.getNextPublishSeqNo();\n    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\n    confirmSet.add(nextSeqNo);\n&#125;</code></pre></li>\n</ul>\n</li>\n<li><p>消息队列：开启Rabbit的持久化（也会有小概率丢失，还没持久化到磁盘上消息就丢失了），首先在创建queue时将其设置为持久化，保证RabbitMQ持久化queue的元数据；然后在发送消息的时候将消息的deliveryMode设置为2，保证消息也被持久化到磁盘上</p>\n</li>\n<li><p>消费者：关闭RabbitMQ的自动ack，在消费者消费完消息后再通过api来返回ack。消费者在声明队列时可以指定noAck参数，当noAck=false时，RabbitMQ 会等待消费者显式发回 ack 信号后，才从内存（和磁盘，如果是持久化消息）中移去消息。否则，一旦消息被消费者消费，RabbitMQ 会在队列中立即删除它</p>\n</li>\n</ul>\n</li>\n<li><p>Kafka</p>\n<ul>\n<li>消费者：可能因为自动提及offset机制提前提交了还未处理的消息的offset，所以可以关闭自动提交机制；但如果提交offset前系统崩溃会导致重复消费，则可以通过幂等性相关的方法来处理</li>\n<li>消息队列：某个broker宕机会重新选举partition的leader，新旧leader会有数据处理不一致的情况，造成数据丢失。可以设置如下四个参数来解决，保证leader切换时数据不会丢失<ul>\n<li>给 topic 设置 <code>replication.factor</code> 参数：这个值必须大于 3，要求每个 partition 必须有至少 2 个副本</li>\n<li>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower，一般推荐设置成 <strong>replication.factor = min.insync.replicas + 1</strong></li>\n<li>在 producer 端设置 <code>acks=all</code> ：这个是要求每条数据，必须是<strong>写入所有 replica 之后，才能认为是写成功了</strong></li>\n<li>在 producer 端设置 <code>retries=MAX</code> （很大很大很大的一个值，无限次重试的意思）：这个是<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</li>\n</ul>\n</li>\n<li>生产者：设置了<code>acks=all</code>后，一定不会丢失，因为所有follower都确定收到了消息</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>消息的顺序性</p>\n<ul>\n<li>RabbitMQ<ul>\n<li>数据错乱的场景：一个queue多个consumer时，不同consumer同时消费有顺序的消息，无法保证哪个consumer先执行完成</li>\n<li>解决：拆分多个queue，每个queue一个consumer，会造成吞吐量下降</li>\n</ul>\n</li>\n<li>Kafka<ul>\n<li>数据错乱的场景：一个topic和三个partition时，生产者写的时候可以指定一个key，相同key的数据会被分到同一个partition中，并且是有序的；但是当消费者是多线程的模式来并发处理消息时，消费消息的顺序就无法保证了</li>\n<li>解决：写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>消息积压</p>\n<ul>\n<li>大量消息在 mq 里积压了几个小时了还没解决（紧急扩容）<ul>\n<li>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉</li>\n<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量</li>\n<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 queue</li>\n<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据</li>\n<li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息</li>\n</ul>\n</li>\n<li>mq 中的消息过期失效了<ul>\n<li>直接丢弃数据，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了</li>\n</ul>\n</li>\n<li>mq 都快写满了<ul>\n<li>如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，<strong>消费一个丢弃一个，都不要了</strong>，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>消费失败</p>\n<ul>\n<li>原因：消息被拒绝后并且消息没有重新入队、消息超时未消费、达到最大队列长度</li>\n<li>RabbitMQ：当普通队列中有死信时，RabbitMQ就会自动将这个消息重新发不到设置的死信交换机去，然后被路由到死信队列，可以监听死信队列中的消息做相应的处理</li>\n<li>Kafka：<ul>\n<li>Kafka提供了一种称为“消费组”的机制来处理消息的消费，每个消费者组都有一个唯一的组ID，Kafka会将一个主题下的消息分发给该主题的每个消费组（每个消费组对应一个消费组内的多个消费者）中的一个消费者进行消费，这样每个消费组内的所有消费者都会收到相同主题下的全部信息</li>\n<li>在消费组中，只有一个消费者能消费同一分区的消息，如果消费者在消费消息是失败，Kafka会将该分区的消息再次分配给同一组中的其它消费者。这样的机制保证了消息的可靠性和可重试性</li>\n<li>除了重试，Kafka还提供了一些其它的机制来处理信息消费失败的情况。例如，可以开启自动提交消费进度或手动提交消费进度，这样在消费者再次运行时，可以从上次消费的进度开始继续消费。另外，Kafka也有死信队列，可以将消费失败的信息发送到专门的队列中进行处理，避免消息的丢失</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>怎么解决消息队列上的消息堆压？</p>\n<ul>\n<li>自身场景下，消息堆压是暂时的，消息堆压只是突发状况，就算不额外处理，随着时间流逝也可消费完毕。 </li>\n<li>假如存在持续性消息堆压，可以考虑临时增加消费者的数量，提升消费者的消费能力。 </li>\n<li>如果是线上突发问题，要临时扩容，增加消费端的数量，与此同时，降级一些非核心的业务。通过扩容和降级承担流量，这是为了表明你对应急问题的处理能力。其次，才是排查解决异常问题，如通过监控，日志等手段分析是否消费端的业务逻辑代码出现了问题，优化消费端的业务处理逻辑。</li>\n</ul>\n</li>\n</ol>\n","feature":true,"text":"MQ 中间件（Middleware）：是一类提供系统软件和应用软件之间连接、便于软件各部件之间的沟通的软件，应用软件可以借助中间件在不同的技术架构之间共享信息与资源。常用中间件有消息队列、RPC 框架、分布式组件（分布式事务、分布式Session、分布式Id）、HTTP 服务器（...","link":"","photos":[],"count_time":{"symbolsCount":"21k","symbolsTime":"19 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#MQ\"><span class=\"toc-text\">MQ</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-MQ%E5%9F%BA%E7%A1%80\"><span class=\"toc-text\">1.MQ基础</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-Kafka\"><span class=\"toc-text\">2.Kafka</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-RocketMQ\"><span class=\"toc-text\">3.RocketMQ</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4-RabbitMQ\"><span class=\"toc-text\">4.RabbitMQ</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-MQ%E8%BF%9B%E9%98%B6\"><span class=\"toc-text\">5.MQ进阶</span></a></li></ol></li></ol>","author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Dubbo","uid":"0ca9a116507ce2deadb100db49d2064a","slug":"Dubbo","date":"2023-09-02T02:38:57.000Z","updated":"2023-09-18T10:50:05.073Z","comments":true,"path":"api/articles/Dubbo.json","keywords":null,"cover":[],"text":"Dubbo RPC RPC（Remote Procedure Call）全称为远程过程调用，用于解决不同服务器之间两个方法的互相调用问题，并且通过网络编程来传递方法调用所需要的参数，通过RPC来简化底层网络编程（如TCP连接的建立）、规划化参数序列化反序列化等问题，使得这个过程就...","link":"","photos":[],"count_time":{"symbolsCount":"26k","symbolsTime":"23 mins."},"categories":[],"tags":[],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Internet","uid":"f00c07cb09e8c5144602456ae7f0f75a","slug":"Internet","date":"2023-08-02T14:26:24.000Z","updated":"2023-09-24T12:16:22.336Z","comments":true,"path":"api/articles/Internet.json","keywords":null,"cover":[],"text":"Internet1.网络层 IP 查看IP地址：ifconfig、ip addr scope：如果是global，则此张网卡是可以对外开放的，可以接受各个地方的包；对于lo来说事host，说明这张网卡仅仅可以供本机相互通信 lo全称是loopback，又称环回接口，往往会被分配到...","link":"","photos":[],"count_time":{"symbolsCount":"35k","symbolsTime":"31 mins."},"categories":[],"tags":[],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}