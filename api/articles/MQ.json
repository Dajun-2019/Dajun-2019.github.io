{"title":"MQ","uid":"f8ef4e10e9f952ff4ed3590ecc45cea3","slug":"MQ","date":"2023-07-30T08:42:34.000Z","updated":"2023-07-30T08:44:34.863Z","comments":true,"path":"api/articles/MQ.json","keywords":null,"cover":[],"content":"<h2 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h2><ol>\n<li><p>消息模型</p>\n<ol>\n<li><p>生产者-消费者模型与发布订阅模型：生产者-消费者模型适用于单消费者的环境，当有多个消费者的时候就会产生消费者的竞争关系，所以出现了发布订阅模型，发布者将消息发送到主题（Topic，即消息容器）中，然后订阅该主题的订阅者就可以收到发送者发送的消息了</p>\n</li>\n<li><p>RabbitMQ的消息模型：RabbitMQ新增了一个交换器组件，常用的有如下四种，生产者发送消息的时候会指定一个 RoutingKey ,当 RoutingKey 和 BindingKey，一样的时候就会被发送的对应的队列中去</p>\n<ol>\n<li>fanout：该交换器收到的信息会被发送到所有与该交换器绑定的队列中</li>\n<li>direct：direct 会根据发送消息的 RoutingKey ，然后发送到和 RoutingKey 匹配的 BindingKey 对应的队列中去</li>\n<li>topic：topic 中在direct的基础之上做了扩展，引入了模糊匹配机制，BindingKey 中主要通过 * 和 # ,用于模糊匹配，* 表示一个单词，# 代表任意0个或多个单词</li>\n<li>headers：不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中 headers 属性进行匹配</li>\n<li>Default Exchange：如果不指定 Exchange ,在手动创建一个队列时，后台会自动将这个队列绑定到一个名称为空的 <code>Direct Exchange</code> 上，绑定 RoutingKey 与队列名称相同。通过使用这个默认的交换器，可以省略掉 RoutingKey 的绑定，直接使用队列即可，在某些场景可以简化代码</li>\n</ol>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230730164418327.png\" alt=\"image-20230730164418327\"></p>\n</li>\n<li><p>Kafka的消息类型</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230730164433342.png\" alt=\"image-20230730164433342\"></p>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"进阶知识\"><a href=\"#进阶知识\" class=\"headerlink\" title=\"进阶知识\"></a>进阶知识</h2><ol>\n<li><p>为什么使用消息队列：结合自己的系统里类似的场景来叙述，一个模块调用了多个模块</p>\n<ol>\n<li>解耦：多个下游系统使用一个核心系统的数据时，使用消息队列可以在增减下游系统时不用更改核心系统的代码，直接消费消息队列里的A输入的数据</li>\n<li>异步：核心系统调用不同存储系统存储数据时，不用等待存储操作完成，可以将数据输入到消息队列中，然后直接返回响应，由消息队列与存储系统继续协调</li>\n<li>削峰：MySQL最多响应2k个请求，可以把过多的请求存储在消息队列中，然后MySQL每秒拉去2k个请求，防止MySQL因为请求过多而崩溃</li>\n</ol>\n</li>\n<li><p>如何保证消息队列组件的高可用</p>\n<ol>\n<li>RabbitMQ：有三种模式，分别是单机模式（Demo）、普通集群模式（创建的queue只会放在一个实例上，访问的实例上没有时，会从相应实例拉取）、镜像集群模式（高可用性，见下）<ol>\n<li>无论是元数据还是queue里的消息都会存放在多个实例上并且都是完整镜像， 每次写消息到queue的时候，都会自动把消息同步到多个实例的queue上</li>\n<li>通过后台的管理控制台，新增一个策略（镜像集群模式），指定的时候可以要求数据同步到所有节点，也可以要求同步到指定数量的节点，再次创建queue的时候就会自动将数据同步到其他节点上</li>\n<li>缺点：通信的性能开销很大；扩展性不好，对于负载大的queue新的机器也会包含这个queue的所有数据，没办法平衡负载</li>\n</ol>\n</li>\n<li>Kafka：由多个broker组成，每个broker是一个节点；每创建一个topic，这个topic可以被划分为多个partition，每个partition可以存在于不同的broker上，每个partition存放一部分数据<ol>\n<li>Kafka0.8之后的HA机制：每个partition的数据都会同步到其它机器上，形成自己的repllica副本，所有replica副本会选举出一个leader出来，其它replica就是follower，所有生产者和消费者都跟这个leader交互。不能随意读写每个follower，因为需要保证数据一致性问题，但是Kafka会均匀地将一个partition的所有replica分布在不同的机器上，提高容错性</li>\n<li>写的时候，leader会负责把数据同步到所有follower上（leader直接写盘，然后其它follower主动从follower来pull数据，同步好数据后向leader发送ack，leader收到所有follower的ack后返回写成功的消息给生产者）；读的时候直接读leader上的数据（当leader读取到所有follower的ack后才会向消费者返回消息）</li>\n<li>如果某个broker宕机了，此时会从follower中重新选举一个新的leader出来</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>消息的重复消费问题（幂等）</p>\n<ol>\n<li>问题示例：Kafka使用offset来表示当前consumer消费完的消息的序号，consumer会定期提交自己消费过的offset，保证重启的时候会从上次消费到的offset来继续消费，但是异常宕机时会丢失这一段时间消费了但未提交offset的消息消费记录，导致重启的时候会再次消费一次，如果下游系统没有考虑到重复消费问题就无法保证幂等姓，导致数据出错</li>\n<li>保证幂等性的方法（结合业务）<ol>\n<li>写入有主键的数据库（MySQL）时，可以先根据主键查询一下，如果数据都有了就不insert而是进行update</li>\n<li>写Redis时，因为每次都是set，有天然的幂等性</li>\n<li>其它：向队列中的每条信息加一个全局唯一的id，在收到信息后，先查询是否消费过再决定是否处理</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>消息的丢失问题</p>\n<ol>\n<li><p>RabbitMQ</p>\n<ol>\n<li><p>生产者：事务机制（吞吐量会下降）、confirm模式（队列处理了会返回ack，否则调用nack接口的回调函数告知失败），前者是同步的后者是异步的，并且两种模式并不共存</p>\n<ul>\n<li><p>confirm实现代码，一共三种：普通、批量、异步</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">&#x2F;&#x2F;普通confirm\nchannel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\nif (!channel.waitForConfirms()) &#123;\n    &#x2F;&#x2F; 消息发送失败\n    &#x2F;&#x2F; ...\n&#125;\n&#x2F;&#x2F;批量confirm\nchannel.confirmSelect();\nfor (int i &#x3D; 0; i &lt; batchCount; ++i) &#123;\n    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\n&#125;\nif (!channel.waitForConfirms()) &#123;\n    &#x2F;&#x2F; 消息发送失败\n    &#x2F;&#x2F; ...\n&#125;\n&#x2F;&#x2F;异步confirm\nSortedSet&lt;Long&gt; confirmSet &#x3D; Collections.synchronizedSortedSet(new TreeSet&lt;Long&gt;());\nchannel.confirmSelect();\nchannel.addConfirmListener(new ConfirmListener() &#123;\n    public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123;\n        if (multiple) &#123;\n            confirmSet.headSet(deliveryTag + 1).clear();\n        &#125; else &#123;\n            confirmSet.remove(deliveryTag);\n        &#125;\n    &#125;\n\n    public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123;\n        System.out.println(&quot;Nack, SeqNo: &quot; + deliveryTag + &quot;, multiple: &quot; + multiple);\n        if (multiple) &#123;\n            confirmSet.headSet(deliveryTag + 1).clear();\n        &#125; else &#123;\n            confirmSet.remove(deliveryTag);\n        &#125;\n    &#125;\n&#125;);\n\nwhile (true) &#123;\n    long nextSeqNo &#x3D; channel.getNextPublishSeqNo();\n    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());\n    confirmSet.add(nextSeqNo);\n&#125;</code></pre></li>\n</ul>\n</li>\n<li><p>消息队列：开启Rabbit的持久化（也会有小概率丢失，还没持久化到磁盘上消息就丢失了），首先在创建queue时将其设置为持久化，保证RabbitMQ持久化queue的元数据；然后在发送消息的时候将消息的deliveryMode设置为2，保证消息也被持久化到磁盘上</p>\n</li>\n<li><p>消费者：关闭RabbitMQ的自动ack，在消费者消费完消息后再通过api来返回ack。消费者在声明队列时可以指定noAck参数，当noAck=false时，RabbitMQ 会等待消费者显式发回 ack 信号后，才从内存（和磁盘，如果是持久化消息）中移去消息。否则，一旦消息被消费者消费，RabbitMQ 会在队列中立即删除它</p>\n</li>\n</ol>\n</li>\n<li><p>Kafka</p>\n<ol>\n<li>消费者：可能因为自动提及offset机制提前提交了还未处理的消息的offset，所以可以关闭自动提交机制；但如果提交offset前系统崩溃会导致重复消费，则可以通过幂等性相关的方法来处理</li>\n<li>消息队列：某个broker宕机会重新选举partition的leader，新旧leader会有数据处理不一致的情况，造成数据丢失。可以设置如下四个参数来解决，保证leader切换时数据不会丢失<ul>\n<li>给 topic 设置 <code>replication.factor</code> 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本</li>\n<li>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower</li>\n<li>在 producer 端设置 <code>acks=all</code> ：这个是要求每条数据，必须是<strong>写入所有 replica 之后，才能认为是写成功了</strong>。</li>\n<li>在 producer 端设置 <code>retries=MAX</code> （很大很大很大的一个值，无限次重试的意思）：这个是<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</li>\n</ul>\n</li>\n<li>生产者：设置了<code>acks=all</code>后，一定不会丢失，因为所有follower都确定收到了消息</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>消息的顺序性</p>\n<ol>\n<li>RabbitMQ<ol>\n<li>数据错乱的场景：一个queue多个consumer时，不同consumer同时消费有顺序的消息，无法保证哪个consumer先执行完成</li>\n<li>解决：拆分多个queue，每个queue一个consumer，会造成吞吐量下降</li>\n</ol>\n</li>\n<li>Kafka<ol>\n<li>数据错乱的场景：一个topic和三个partition时，生产者写的时候可以指定一个key，相同key的数据会被分到同一个partition中，并且是有序的；但是当消费者是多线程的模式来并发处理消息时，消费消息的顺序就无法保证了</li>\n<li>解决：写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>消息积压</p>\n<ol>\n<li><strong>大量消息在 mq 里积压了几个小时了还没解决（紧急扩容）</strong><ol>\n<li>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉</li>\n<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量</li>\n<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 queue</li>\n<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据</li>\n<li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息</li>\n</ol>\n</li>\n<li><strong>mq 中的消息过期失效了</strong><ol>\n<li>直接丢弃数据，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上 12 点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了</li>\n</ol>\n</li>\n<li><strong>mq 都快写满了</strong><ol>\n<li>如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，<strong>消费一个丢弃一个，都不要了</strong>，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n","feature":true,"text":"基础知识 消息模型 生产者-消费者模型与发布订阅模型：生产者-消费者模型适用于单消费者的环境，当有多个消费者的时候就会产生消费者的竞争关系，所以出现了发布订阅模型，发布者将消息发送到主题（Topic，即消息容器）中，然后订阅该主题的订阅者就可以收到发送者发送的消息了 Rabbit...","link":"","photos":[],"count_time":{"symbolsCount":"5.9k","symbolsTime":"5 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86\"><span class=\"toc-text\">基础知识</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E9%98%B6%E7%9F%A5%E8%AF%86\"><span class=\"toc-text\">进阶知识</span></a></li></ol>","author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"SpringCloud","uid":"2fdfe1e1ace8a4912a23a4cbc1c92824","slug":"SpringCloud","date":"2023-07-31T10:29:44.000Z","updated":"2023-07-31T10:53:24.069Z","comments":true,"path":"api/articles/SpringCloud.json","keywords":null,"cover":[],"text":"Spring Cloud1.Consul 特性：服务发现、健康检查、KV存储（服务配置）、多数据中心支持、安全的服务间通信（加密） 配置一些依赖和端口信息， 2.Sleuth+Zipkin Sleuth 用于分布式链路追踪，他能追踪请求和消息从而可以将消息与相应的日志条目相关联，...","link":"","photos":[],"count_time":{"symbolsCount":"9.9k","symbolsTime":"9 mins."},"categories":[],"tags":[],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Tools","uid":"7092a7d1e2affc5f0cb3af30af9d1e19","slug":"Tools","date":"2023-07-30T02:37:14.000Z","updated":"2023-07-30T08:42:12.780Z","comments":true,"path":"api/articles/Tools.json","keywords":null,"cover":[],"text":"1.markdown 框架 多级标题：#与后面文本有一个空格，标题行前后建议空行 Markdown HTML # Heading level 1 Heading level 1 ## Heading level 2 Heading level 2 ### Heading leve...","link":"","photos":[],"count_time":{"symbolsCount":"16k","symbolsTime":"15 mins."},"categories":[],"tags":[],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}