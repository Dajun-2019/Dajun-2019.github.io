{"title":"MySQL","uid":"838ae74e3a76757d637de803a615bfd9","slug":"MySQL","date":"2023-04-27T10:54:53.000Z","updated":"2023-05-18T00:19:11.603Z","comments":true,"path":"api/articles/MySQL.json","keywords":null,"cover":[],"content":"<h1 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h1><h2 id=\"1-SQL语法\"><a href=\"#1-SQL语法\" class=\"headerlink\" title=\"1.SQL语法\"></a>1.SQL语法</h2><ol>\n<li><p>数据库概念：数据库（DB）、数据库管理系统（DBMS）、数据库系统（软件+数据库+DBA）、数据库管理员（DBA）、元祖（tuple 一行）、码（列）、候选码（唯一标识元祖）、主码（主键）、外码（另一表的主键）、主属性（候选码中的属性）、非主属性、注释（##，–，/* */）、SQL语句不区分大小写（MySQL 在 Windows 下不区分大小写，但在 Linux 下默认是区分大小写）</p>\n</li>\n<li><p>表设计</p>\n<ul>\n<li>E-R图（Entity Relationship Diagram 实体+属性+联系「1:1, 1:N, M:N」）</li>\n<li>范式<ul>\n<li>1NF：强调列的原子性，列不可再分</li>\n<li>2NF：1NF基础上，表必须有一个主键+非主键列不能部分依赖主键</li>\n<li>3NF：2NF基础上，非主键列必须不能传递依赖主键</li>\n<li>BCNF：关系模式中每一个决定因素都包含候选键，只要A能决定B，A内部就必须有主键列</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>常见数据类型</p>\n<ul>\n<li>整数类型：（TINYINT(1)、SMALLINT(2)、MEDIUMINT(3)、INT(4)、BIGINT(8)）</li>\n<li>小数类型：浮点数（FLOAT、DOUBLE）、定点数（DECIMAL、NUMERIC）</li>\n<li>字符串类型：CHAR、VARCHAR、BLOB、TEXT<ul>\n<li>VARCHAR：可变长度最大为65535、存储附加元信息、超出长度返回警告（CHAR直接截断）</li>\n<li>InnoDB会将长度超过768字节的定长字段存储为变长字段，可以跨页存储。例如：CHAR(255)在utf8mb4字符集（字符编码可能超过3字节）下可能会被存储成变长字段</li>\n<li>CHAR会截断尾空格，VARCHAR不会，插入没有尾空格的数据时，使用=查找时有没有尾空格都可以查出数据（自动补空格），但是用like查找时查不出没有空格的</li>\n</ul>\n</li>\n<li>日期类型：DATE（<code>YYYY-MM-DD</code>）、TIME（<code>hh:mm:ss[.fraction]</code>）、DATETIME（<code>YYYY-MM-DD hh:mm:ss[.fraction]</code>）、TIMESTAMP（从1970年开始的秒数）、YEAR（<code>YYYY</code>）<ul>\n<li>不要用字符串存储日期：占用空间大、查询慢（逐个字符进行比对）、无法用日期相关的函数</li>\n<li>数值型时间戳：这种存储方式的具有 Timestamp 类型的所具有一些优点，并且使用它的进行日期排序以及对比等操作的效率会更高，跨系统也很方便；缺点是可读性太差，无法直观的看到具体时间</li>\n<li><code>Datetime</code>和 <code>Timestamp</code>是 MySQL 提供的两种比较相似的保存时间的数据类型，通常会首选<code>Timestamp</code><ul>\n<li><code>DateTime</code> 类型没有时区信息，导致服务器更换地址的时候，数据库读出的时间有错误</li>\n<li><code>Timestamp</code> 类型字段的值会随着服务器时区的变化而变化，自动换算成相应的时间，在不同时区，查询同一条记录值会不一样</li>\n<li><code>Timestamp</code> 只需要使用 4 个字节的存储空间，但是 <code>DateTime</code> 需要耗费 8 个字节的存储空间。但是，这样同样造成了一个问题，Timestamp 表示的时间范围更小（1970年到2037年）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>基础SQL语句</p>\n<ul>\n<li>数据定义语言（DDL）：<code>CREATE</code>、<code>ALTER</code>、<code>DROP</code>、<code>USE</code>、<code>ADD</code><ul>\n<li>操作对象：视图（<code>VIEW</code>）、表（<code>TABLE</code>）、索引（<code>INDEX</code>）</li>\n<li>修饰约束：<code>NOT NULL</code>、<code>UNIQUE</code>、<code>PRIMARY KEY</code>、<code>FOREIGN KEY</code>、<code>CHECK</code>、<code>DEFULT</code>、<code>KEY</code></li>\n</ul>\n</li>\n<li>数据操纵语言（DML）：<code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code>、<code>SELECT</code><ul>\n<li>约束：<code>DISTINCT</code>返回不同值、<code>LIMIT</code>限制返回行数、<code>ORDER BY</code>排序（<code>ASC</code>升序、<code>DESC</code>降序）</li>\n<li>子查询：子查询可以嵌入 <code>SELECT</code>、<code>INSERT</code>、<code>UPDATE</code>和 <code>DELETE</code>语句中（需要放入<code>()</code>中），也可以和 <code>=</code>、<code>&lt;</code>、<code>&gt;</code>、<code>&lt;&gt;</code>、<code>&gt;=</code>、<code>&lt;=</code>、<code>IN</code>、<code>BETWEEN</code>、<code>EXISTS</code>、<code>LIKE（%或_）</code>、<code>AND</code>、<code>OR</code>、<code>NOT</code>等运算符一起使用</li>\n<li>分组：<code>group by</code>、聚合（<code>count</code>，<code>max</code>，<code>sum</code>，<code>avg</code>忽律null行）、<code>having</code>用于对汇总的 <code>group by</code>结果进行过滤</li>\n<li>连接：<code>join…on…</code>、<code>join…using…</code>（列名相同）、<code>join</code>默认是<code>inner join</code>（还有<code>left join</code>、<code>right join</code>、<code>full join</code>、<code>self join</code>需命名一个表、<code>cross join</code>笛卡尔积）<ul>\n<li>straight_join 让 MySQL 使用固定的连接方式执行查询</li>\n</ul>\n</li>\n<li>组合：<code>UNION</code>运算符将两个或更多查询的结果组合起来，并生成一个结果集，其中包含来自<code>UNION</code>中参与查询的提取行</li>\n</ul>\n</li>\n<li>事务控制语言：<code>COMMIT</code>、<code>ROLLBACK</code><ul>\n<li>不能回退 <code>SELECT</code>语句，回退 <code>SELECT</code>语句也没意义；也不能回退 <code>CREATE</code>和 <code>DROP</code>语句；默认每一条语句都当成一个事务进行提交</li>\n<li>当出现 <code>START TRANSACTION</code>语句时，会关闭隐式提交；当 <code>COMMIT</code>或 <code>ROLLBACK</code>语句执行后，事务会自动关闭，重新恢复隐式提交</li>\n<li>通过 <code>set autocommit=0</code>可以取消自动提交，直到 <code>set autocommit=1</code>才会提交；<code>autocommit</code>标记是针对每个连接而不是针对服务器</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>进阶SQL语句</p>\n<ul>\n<li><p>show processlist</p>\n<ul>\n<li>command（查看连接状态）：sleep（空闲连接）、</li>\n<li>state：</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mysql&gt; show processlist;\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------+\n| Id | User            | Host      | db   | Command | Time   | State                  | Info        |\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------+\n|  5 | event_scheduler | localhost | NULL | Daemon  | 610663 | Waiting on empty queue | NULL         |\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------+</code></pre></li>\n<li><p>delimiter</p>\n</li>\n<li><p>explain：并不会真的执行语句，而是通过查询优化器对语句进行分析，找出最优的查询方案，并显示对应的信息</p>\n<ul>\n<li><p><code>type</code>表的访问方法</p>\n<ul>\n<li>system：这种类型要求数据库表中只有一条数据，是const类型的一个特例，一般情况下是不会出现的</li>\n<li>const：通过一次索引就能找到数据，一般用于主键或唯一索引作为条件，这类扫描效率极高，速度非常快</li>\n<li>eq_ref：常用于主键或唯一索引扫描，一般指使用主键的关联查询</li>\n<li>ref : 常用于非主键和唯一索引扫描</li>\n<li>ref_or_null：这种连接类型类似于ref，区别在于MySQL会额外搜索包含NULL值的行</li>\n<li>index_merge：使用了索引合并优化方法，查询使用了两个以上的索引</li>\n<li>unique_subquery：类似于eq_ref，条件用了in子查询</li>\n<li>index_subquery：区别于unique_subquery，用于非唯一索引，可以返回重复值</li>\n<li>range：常用于范围查询，比如：between … and 或 In 等操作</li>\n<li>index：全索引扫描</li>\n<li>ALL：全表扫描</li>\n</ul>\n</li>\n<li><p><code>possible_keys</code>可能用到的索引，一般配合<code>possible_keys</code>列一起看</p>\n</li>\n<li><p><code>key</code>实际用到的索引</p>\n</li>\n<li><p><code>rows</code>MySQL预计要读取的行数，对InnoDB表来说是个估计值</p>\n</li>\n<li><p><code>filtered</code>按表条件过滤后，留存的记录数的百分比，即存储引擎返回的数据在经过过滤后，剩下满足条件的记录数的比例</p>\n</li>\n<li><p><code>Extra</code> </p>\n<ul>\n<li>Using filesort：表示按文件排序，一般是在指定的排序和索引排序不一致的情况才会出现。一般见于order by语句</li>\n<li>Using index ：表示是否用了覆盖索引</li>\n<li>Using temporary: 表示是否使用了临时表，性能特别差，需要重点优化。一般多见于group by语句，或者union语句</li>\n<li>Using where : 表示使用了where条件过滤</li>\n<li>Using index condition：MySQL5.6之后新增的索引下推。在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<pre><code> <pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mysql&gt; explain select * from t where a between 10000 and 20000;\n+--+-----------+-----+----------+----+-------------+---+-------+---+----+--------+------------------+\n|id|select_type|table|partitions|type|possible_keys|key|key_len|ref|rows|filtered|Extra    |\n+----+---------+-----+----------+----+-------------+------+---------+------+-------+----------+-----------------------+\n| 1| SIMPLE    | t   | NULL     |range| a          | a | 5     | NULL | 10001 | 100.00 | Using index condition |</code></pre>\n</code></pre>\n<ul>\n<li><p>通过查询 sys库的 schema_unused_indexes视图来查询哪些索引从未被使用</p>\n</li>\n<li><p>kill</p>\n<ul>\n<li>kill query + 线程 id：终止这个线程中正在执行的语句<ul>\n<li>把session的运行状态改成THD::KILL_QUERY（将变量 killed 赋值为THD::KILL_QUERY），给session的执行线程发信号</li>\n<li>session语句中执行到预埋点后才可以终止语句逻辑，处于等待状态的必须是可唤醒的等待</li>\n</ul>\n</li>\n<li>kill connection + 线程 id：断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的</li>\n<li>kill query + 线程 id失效的情况：show processlist的时候，看到Command列显示为 killed<ul>\n<li>线程没有执行到判断线程状态的逻辑<ul>\n<li>等行锁时使用<code>pthread_cond_timedwait</code>函数，虽然可被唤醒但是唤醒后的执行逻辑并没有判断线程状态</li>\n<li>由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态</li>\n</ul>\n</li>\n<li>终止逻辑耗时较长<ul>\n<li>超大事务执行期间被 kill：这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长</li>\n<li>大查询回滚：如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长</li>\n<li>DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久</li>\n</ul>\n</li>\n<li>直接在客户端通过 Ctrl+C 命令也无法终止：由于 MySQL 是停等协议，所以这个线程执行的语句还没有返回的时候，再往这个连接里面继续发命令也是没有用的。实际上，执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 kill query 命令</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-基础知识\"><a href=\"#2-基础知识\" class=\"headerlink\" title=\"2.基础知识\"></a>2.基础知识</h2><h3 id=\"1-基础架构\"><a href=\"#1-基础架构\" class=\"headerlink\" title=\"1.基础架构\"></a>1.基础架构</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>客户端+server层+存储引擎，其中server层包括五部分，连接器（身份权限验证）、查询缓存（键值对，易失效，8.0移除）、分析器（词法分析+语法分析，返回出错位置）、优化器（选择索引，按照最优方案执行）、执行器（检验表权限，操作引擎，返回结果）</p></blockquote>\n<ol>\n<li><p>查询语句执行流程；客户端验证登陆并通过TCP三次握手==连接==服务端，提交的执行语句经过分析器进行词法分析和语法分析通过后，提交给优化器来生成最优的执行方案，最后交给引擎来具体执行</p>\n<ul>\n<li>查询缓存不命中的情况    <ul>\n<li>任何两个查询在任何字符上的不同都会导致缓存不命中</li>\n<li>如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL 库中的系统表，其查询结果也不会被缓存</li>\n<li>表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效</li>\n</ul>\n</li>\n<li>客户端长时间（<code>wait_timeout</code>）没有命令时，连接器会自动断开</li>\n<li>数据传输（net_buffer）：服务端不保存一个完整的结果集，而是将取到的每一行写入net_buffer中，写满就发送然后清空；如果发送函数返回<code>EAGAIN</code>或<code>WSAEWOULDBLOCK</code>，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送<ul>\n<li>MySQL 客户端发送请求后，接收服务端返回结果的方式有两种，默认使用第一种，加上<code>-quick</code>后使用第二种<ul>\n<li>一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果用 API 开发，对应的就是 mysql_store_result 方法</li>\n<li>另一种是不缓存，读一个处理一个。如果用 API 开发，对应的就是 mysql_use_result 方法</li>\n</ul>\n</li>\n<li>对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，建议使用<code>mysql_store_result</code>这个接口，直接把查询结果保存到本地内存，否则使用<code>mysql_use_result</code>接口</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>更新语句执行流程：查询缓存，调用引擎API写入数据，InnoDB通过==两阶段提交==记录日志，流程为redo log（prepare）-&gt;binlog-&gt;redo log（commit）</p>\n<ul>\n<li>异常时：有prepare，但没有binlog，则回滚事务；由prepare、binlog，但没有commit，则提交事务恢复数据</li>\n<li>非两阶段提交：先写redo log然后宕机，虽然可以通过redo log恢复数据，但是通过binlog备份的时候会丢失数据；先写binlog然后宕机，本地无法通过redo log恢复数据，通过binlog备份时会多出一条事务</li>\n<li>change buffer：当有更新操作，如果数据页在内存中，则直接更新数据页；如果数据页不在内存中，则会将更新操作先缓存在change buffer中。在后续数据页读入到内存中时执行merger操作，即将change buffer内的更改同步到数据页<ul>\n<li>使用场景：适用于普通索引，但唯一索引需要每次都取数据确定唯一性；适用于写多读少的情况（merge操作少）</li>\n<li>change buffer和redo log：redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>存储引擎对比</p>\n<ul>\n<li><p>MyISAM 不支持==事务==（MVCC+Next-Key Lock区间锁）和==行级锁==，而且最大的缺陷就是崩溃后无法安全恢复（只有binlog无==redo log==）</p>\n</li>\n<li><p>Memory引擎：主要用于内存临时表的场景（没有并发问题、不许持久化数据、主备库之间不冲突）</p>\n<ul>\n<li><p>索引组织形式</p>\n<ul>\n<li>InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，称为索引组织表（Index Organizied Table），整体结构为B+树，数据有序存放，数据位置变化时只需要改主键索引，查找需要回表</li>\n<li>Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，称为堆组织表（Heap Organizied Table），整体结构为hash表，数据按写入顺序存放，数据位置变化时需要改所有索引</li>\n<li>使用b树索引：<code>alter table t1 add index a_btree_index using btree (id);</code></li>\n</ul>\n</li>\n<li><p>InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同</p>\n</li>\n<li><p>生产环境不使用内存表的原因：内存表不支持行锁，只支持表锁；数据库重启后，所有内存表都会被清空</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>文件目录结构</p>\n<ul>\n<li><p>每创建一个database，都会在/var/lib/mysql目录下创建一个以数据库名字为名的目录，然后保存表结构和表数据的文件都放在这个目录下，如下图（名为my_test的数据库下有一个名为t_order的表）</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/640.png\" alt=\"图片\"></p>\n</li>\n<li><p>数据库名（my_test）目录下的具体文件（以t_order表为例）</p>\n<ul>\n<li>db.out：用来存储当前数据库的默认字符集和字符校验规则</li>\n<li>t_order.frm：t_order的表结构会保存在这个文件，MySQL中建立的每一张表都会生成一个.frm文件，用来保存表的元数据信息，如表结构定义</li>\n<li>t_order.ibd：t_order的表数据会保存在这个文件中，表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。由参数 innodb_file_per_table 控制的，5.6.6之后默认是1，即存放在独占表空间文件（文件名：表名字.ibd）中</li>\n</ul>\n</li>\n</ul>\n</li>\n<li></li>\n</ol>\n<h3 id=\"2-日志\"><a href=\"#2-日志\" class=\"headerlink\" title=\"2.日志\"></a>2.日志</h3><ol>\n<li>redo log<ul>\n<li>定义：InnoDB特有的，组织成大小为4*1GB（文件组）的一个环形缓冲区，使用两个指针记录位置，write pos（下一次写入位置）+ check point（等待擦除的位置），满了之后就阻塞等待，主要用于MySQL崩溃（实例挂了/宕机）后的恢复</li>\n<li>redo log buffer：查询和删除都是直接操作Buffer Pool中的数据页，更新时记录到<code>redo log buffer</code>中，然后刷盘到<code>redo log</code><ul>\n<li>记录条目：“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”</li>\n<li>刷盘时机：<code>innodb_flush_log_at_trx_commit </code>参数确定何时刷新、一个后台定时线程每秒刷新、<code>redo log buffer</code>占用的空间即将达到 <code>innodb_log_buffer_size</code>一半时刷新</li>\n</ul>\n</li>\n<li>写入流程：</li>\n</ul>\n</li>\n<li>binlog<ul>\n<li>定义：server层的通用模块，与redo log记录物理日志（在哪个数据页上做了什么）不同，binlog记录逻辑日志，即语句的原始逻辑（在哪个表上做了什么），并且不会覆盖已有日志，直接写入新文件。主要用于数据备份和主从数据同步<ul>\n<li>格式；<code>statement</code>（SQL语句原文）、<code>row</code>（SQL语句+数据）、<code>mixed</code>（MySQL选择用哪一个）</li>\n</ul>\n</li>\n<li><code>binlog cache</code>：事务执行过程中，先把日志写到<code>binlog cache</code>，事务提交的时候，再把<code>binlog cache</code>写到<code>binlog</code>文件中。通过<code>binlog_cache_size</code>确定空间大小，一个事务的binlog不能被拆开，空间不够时需要暂存到磁盘上<ul>\n<li>数据先write到文件系统的page cache，再fsync到磁盘，由参数<code>sync_binlo</code>g控制write和fsync的时机</li>\n</ul>\n</li>\n<li>为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中</li>\n</ul>\n</li>\n<li>undo log<ul>\n<li>用途：用于事务执行异常时进行回滚、提供MVCC机制需要的历史版本数据<ul>\n<li>回滚日志先于数据持久化到磁盘上，在事务执行中宕机也可以回滚已执行的一半事务</li>\n</ul>\n</li>\n<li>确保事务的原子性，用于回滚事务，同时提供mvcc下的非锁定读</li>\n</ul>\n</li>\n<li>慢查询日志<ul>\n<li>记录了执行时间超过long_query_time（默认10s，通常设置为1s）的所有查询语句，在解决SQL慢查询的时候经常用到</li>\n<li>命令：开启（<code>SET GLOBAL slow slow_query_log=ON</code>）、查看状态（<code>show variables like “slow_query_log”; </code>）</li>\n</ul>\n</li>\n<li>中转日志（relay log）：用于主从复制场景下，slave通过io线程拷贝master的bin log后本地生成的日志</li>\n</ol>\n<h3 id=\"3-锁\"><a href=\"#3-锁\" class=\"headerlink\" title=\"3.锁\"></a>3.锁</h3><ol>\n<li>全局锁：<code>Flush tables with read lock;</code>，主要用于做主库逻辑备份，其它全库备份方法如下<ul>\n<li><code>mysqldump</code>+<code>–single-transaction</code>：在一致性读隔离级别开启一个事务，来确保拿到一致性视图，通过MVCC来保证数据可正常更新，需要引擎支持一致性读级别（InnoDB支持MyISAM不支持）</li>\n<li><code>set global readonly=true</code>：可以让全库进入只读状态，但一方面readonly会有其他用处这样改有副作用，另一方面数据库异常后不自动改此值，导致数据库一直不可写（全局锁自动释放）</li>\n</ul>\n</li>\n<li>表级锁（MyISAM、InnoDB）：针对非索引字段加锁，对当前操作的整张表加锁，实现简单，资源消耗少，不会出现死锁，但是高并发下效率低<ul>\n<li>表锁：<code>lock tables t1 read, t2 write;</code><ul>\n<li>可以使用<code>unlock tables</code>主动释放锁，也可以在客户端断开的时候自动释放，所以建议把可能影响并发度的锁尽量往后放</li>\n<li>lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象，比如线程A执行上面的示例语句，线程B写t1、读写t2都会被阻塞；线程A解锁前也只能读t1、读写t2</li>\n<li>意向锁：用表锁的时候快速判断表中的记录是否有行锁，意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁（意向共享锁、意向排他锁）</li>\n</ul>\n</li>\n<li>元数据锁（MDL）：MDL 不需要显式使用，在访问一个表的时候会被自动加上，语句执行开始时申请，但是在整个事务提交后才释放（可以通过加超时机制防止阻塞太多后续命令）<ul>\n<li>在MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁</li>\n<li>读锁之间不互斥，因此可以有多个线程同时对一张表增删改查；读写锁之间、写锁之间是互斥的，因此两个线程同时给一个表加字段，其中一个要等另一个执行完才能开始执行</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>行级锁（InnoDB）：针对索引字段进行加锁，只针对当前操作的行记录进行加锁，锁粒度小、并发度高、锁开销大，会出现死锁<ul>\n<li>两阶段锁：行锁是在需要的时候加上去的，但是要等事务结束时才释放</li>\n<li>行锁是针对索引字段加的锁，如果where语句中字段没有命中唯一索引或者索引失效时，会导致扫描全表，对表中的所有行记录加锁，但有的时候即使用了索引，也会全表扫描（优化器的原因）</li>\n<li>InnoDB有哪几类行锁：<code>REPEATABLE-READ</code>隔离级别下，默认使用<code>Next-Key Lock</code>，操作的索引是唯一索引或主键时，优化降级为<code>Record Lock</code><ul>\n<li><strong>记录锁（Record Lock）</strong> ：也被称为记录锁，属于单个行记录上的锁</li>\n<li><strong>间隙锁（Gap Lock）</strong> ：锁定一个范围，不包括记录本身。跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作，两个间隙锁之间不存在冲突关系<ul>\n<li>两个线程都拿到了同一间隙锁，然后在执行插入时等待对方的间隙锁，这就导致了同样的语句因为间隙锁的存在会锁住更大的范围而产生死锁</li>\n</ul>\n</li>\n<li><strong>临键锁（Next-Key Lock）</strong> ：Record Lock+Gap Lock，锁定一个范围，包含记录本身，主要目的是为了解决幻读问题。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁<ul>\n<li>每个 next-key lock 是前开后闭区间，对于正无穷使用了一个不存在的最大值 supremum 代替（保证闭区间）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-事务\"><a href=\"#4-事务\" class=\"headerlink\" title=\"4.事务\"></a>4.事务</h3><ol>\n<li><p>基础概念</p>\n<ul>\n<li>ACID属性：Atomic、Consistency、Isolation、Durability（AID是手段，C是目的）</li>\n<li>并发带来的问题：脏读（读后被回滚）、丢失修改（写后被覆盖）、不可重复读（两次读结果不同）、幻读（第二次读到的行数多了）<ul>\n<li>解决幻读的方法：提升事务隔离级别到可序列化、可重复读级别下添加表锁或添加<code>Next-key Lock</code>（记录锁+间隙锁）、隔离级别降到读提交并将binlog改成row格式（记录更改前后数据）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>MVCC</p>\n<ul>\n<li>原理：实现依赖==隐藏字段==、==Read View==、==undo log==。在内部实现中，InnoDB 通过数据行的DB_TRX_ID（事务id）和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改<ul>\n<li>MySQL 中每条记录在更新的时候都会同时记录一条回滚操作（在回滚日志中，在没有比该条日志更旧的read-view后自动删除），记录上的最新值，通过回滚操作，都可以得到前一个状态的值</li>\n<li>MVCC解决部分幻读：MVCC只能解决读取数据是的幻读（当前事务读取时，不受其他事务修改的影响），但是不能解决写入时的幻读（需要MVCC+锁、或者可串行化事务隔离级别）</li>\n<li>与间隙锁的对比：间隙锁锁定索引范围而非实际数据的锁，MVCC与间隙锁的目的都是保证数据库的并发访问安全性，但是MVCC的优势是没有用到锁，性能比间隙锁更好</li>\n</ul>\n</li>\n<li>相关字段<ul>\n<li>InnoDB为每一行添加了三个隐藏字段<ul>\n<li><code>DB_TRX_ID（6字节）</code>：表示最后一次插入或更新该行的事务 id</li>\n<li><code>DB_ROLL_PTR（7字节）</code>回滚指针，指向该行的 <code>undo log</code></li>\n<li><code>DB_ROW_ID（6字节）</code>：如果没有设置主键且该表没有唯一非空索引时，<code>InnoDB</code> 会使用该 id 来生成聚簇索引</li>\n</ul>\n</li>\n<li>Read View：用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”<ul>\n<li><code>m_low_limit_id</code>：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见</li>\n<li><code>m_up_limit_id</code>：活跃事务列表 <code>m_ids</code> 中最小的事务 ID，如果 <code>m_ids</code> 为空，则 <code>m_up_limit_id</code> 为 <code>m_low_limit_id</code>。小于这个 ID 的数据版本均可见</li>\n<li><code>m_ids</code>：<code>Read View</code> 创建时其他未提交的活跃事务 ID 列表。创建 <code>Read View</code>时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。<code>m_ids</code> 不包括当前事务自己和已提交的事务（正在内存中）</li>\n<li><code>m_creator_trx_id</code>：创建该 <code>Read View</code> 的事务 ID</li>\n</ul>\n</li>\n<li>undo-log：事务回滚时恢复数据，分为两类<ul>\n<li><code>insert undo log</code>：指在 <code>insert</code>操作中产生的 <code>undo log</code>。因为 <code>insert</code>操作的记录只对事务本身可见，对其他事务不可见，故该 <code>undo log</code>可以在事务提交后直接删除。不需要进行 <code>purge</code>操作</li>\n<li><code>update undo log</code>：<code>update</code>或 <code>delete</code>操作中产生的 <code>undo log</code>。该 <code>undo log</code>可能需要提供 <code>MVCC</code>机制，因此不能在事务提交时就进行删除。提交时放入 <code>undo log</code>链表，等待 <code>purge线程</code>进行最后的删除</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>底层实现（未完待续）：数据可达性算法</li>\n</ul>\n</li>\n<li><p>事务隔离机制：读未提交、读已提交、可重复读（默认级别）、可序列化</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">SET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL [READ UNCOMMITTED|READ COMMITTED|REPEATABLE READ|SERIALIZABLE]</code></pre>\n\n<ul>\n<li>避免长事务的方式：通过information_schema.innodb_trx表监控事务的持续时间、增加undo表空间、通过配置参数max_execution_time指定事务执行的最长时间、利用pt工具监控长事务</li>\n<li>可重复读与幻读<ul>\n<li>标准的SQL隔离级别定义里，可重复读是不可以防止幻读的，但是InnoDB实现的可重复读隔离级别可以解决幻读问题</li>\n<li>快照读（一致性非锁定读）：由MVCC机制保证不出现幻读<ul>\n<li>RR/RC级别select默认是快照读（RC级别读锁定行最新快照数据，RR级别读事务开始的数据）、读取到的行正在执行update或delete则不等待锁释放直接读取快照</li>\n</ul>\n</li>\n<li>当前读（锁定读）：由<code>Next-Key Lock</code>加锁来防止幻读<ul>\n<li>select加锁（<code>lock in share mode</code>共享锁、<code>for update</code>排他锁）是当前读、<code>update</code>、<code>insert</code>、<code>delete</code></li>\n<li>RR级别：扫描到的数据都会加行锁和间隙锁，并在commit时释放</li>\n<li>RC级别：扫描到的数据都会加行锁，但不满足条件的数据，不需等到commit，扫描完就释放</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"5-索引\"><a href=\"#5-索引\" class=\"headerlink\" title=\"5.索引\"></a>5.索引</h3><ol>\n<li>B+树：索引的底层数据结构，InnoDB中每个节点使用一个页（page），页的大小为16KB，元数据占128字节，一条记录大约16字节，对于非叶节点，可以存1000条记录，对于叶节点，假设可以存100条数据，综上，对于一颗3层B+树，可以存储1亿条记录，充分利用局部性原理减少IO次数<ul>\n<li>其它索引结构：<code>Hash索引</code>不支持顺序和范围查询、<code>二叉查找树</code>容易不平衡、<code>平衡二叉树</code>由于旋转耗时，删树数据时效率很低、<code>红黑树</code>效率高但是高度太高增加IO次数、B树节点过大增加IO次数</li>\n<li>B树和B+树的区别：B+树非叶子不存数据、叶子节点有一条引用链指向其它相邻叶子节点所以可直接对链表进行遍历、B+树查到叶子才返回数据可在非叶子节点中重复出现</li>\n<li>Hash索引和B+树索引的区别：B+树可以进行范围查询、B+树支持联合索引的最左匹配原则、B+树支持order by排序、B+树支持like进行模糊查询；但Hash索引在等值查询上比B+树高效<ul>\n<li>范围查询：比如要查主键在[1,17]之间的记录。二次查询，先查找1所在的叶子节点的记录位置，再查找17所在的叶子节点记录的位置（就是16所处的位置），然后顺序地从1遍历链表直到16所在的位置</li>\n<li>前缀匹配模糊查询。假设主键是一个字符串类型，要查询where Key like abc%，其实可以转化成一个范围查询Key in [abc,abcz]。当然，如果是后缀匹配模糊查询，或者诸如where Key like %abc%这样的中间匹配，则没有办法转化成范围查询，只能挨个遍历</li>\n<li>Hash索引缺点：容易导致全表扫描，因为可能存在不同的key经过hash运算后值相同；索引列上的值相同的话，易造成hash冲突，效率低下</li>\n</ul>\n</li>\n<li>MyISAM和InnoDB引擎对B+树的不同实现<ul>\n<li>MyISAM中，叶子节点的data域存放的是数据记录的地址，需要通过改地址读取对应的数据记录</li>\n<li>InnoDB中，索引文件和数据文件是分离的，数据文件是以主键为索引的key形成的树，叶子节点保存了完整的数据，其他的索引的叶子节点存储的是主键的值。所以通过主键查找直接能找到数据，通过其他索引只能找到对应主键，然后再根据主键去数据文件找。所以建议使用单调的字段作为主键，防止造成主索引频繁分裂（B+树的插入机制）</li>\n<li>索引结构和数据一起存放的索引称为聚簇索引，如InnoDB的主键索引；索引结构和数据分开存放的索引称为非聚簇索引，如InnoDB的辅助索引</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>主键索引（聚簇索引，clustered index）和非主键索引（二级索引，secondary index）<ul>\n<li>主键索引：加速查询 + 列值唯一（不可以有 NULL）+ 表中只有一个，查询速度快但更新代价大，所以一般都是不可修改的<ul>\n<li>当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在 null 值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键</li>\n<li>建表语句里一定要有自增主键，只有在类似于哈希表的数据表中才会使用业务字段直接锁主键</li>\n<li>重建主键索引的方法：直接删除重建会使得所有非主键索引都失效，推荐方法为用空的alter操作，比如<code>ALTER TABLE t1 ENGINE = InnoDB;</code>这样子就会原地重建表结构</li>\n</ul>\n</li>\n<li>非主键索引：叶子节点存储的数据是主键，需要根据主键去主键索引在搜索一次（回表），更新代价小但需要回表<ul>\n<li>唯一索引：加速查询 + 列值唯一（可以有 NULL），主要为了保证属性列的数据的唯一性</li>\n<li>普通索引：仅加速查询，允许重复、允许为NULL、允许创建多个</li>\n<li>前缀索引(Prefix)：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符（<code>alter table SUser add index index2(email(6));</code>）<ul>\n<li>倒序索引：<code>select field_list from t where id_card = reverse(&#39;input_id_card_string&#39;);</code></li>\n<li>前缀索引对覆盖索引的影响：使用前缀索引就用不上覆盖索引对查询性能的优化了，因为无法确定前缀索引是否截断了完整信息</li>\n</ul>\n</li>\n<li>全文索引：对文本的内容进行分词，进行搜索。目前只有 <code>CHAR</code>、<code>VARCHAR</code> ，<code>TEXT</code> 列上可以创建全文索引。一般不会使用，效率较低，通常使用搜索引擎如 ElasticSearch 代替</li>\n</ul>\n</li>\n<li>为什么不推荐使用外键和级联（主键改外键需要跟着改）：不适用高并发、分库分表不友好、增加复杂性（外键约束、业务变化）<ul>\n<li>外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度</li>\n<li>增加了复杂性：<ul>\n<li>每次做 DELETE 或者 UPDATE 都必须考虑外键约束，会导致开发的时候很痛苦, 测试数据极为不方便;</li>\n<li>外键的主从关系是定的，假如那天需求有变化，数据库中的这个字段根本不需要和其他表有关联的话就会增加很多麻烦</li>\n</ul>\n</li>\n<li>对分库分表不友好：因为分库分表下外键是无法生效的</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>联合索引及相关优化：覆盖索引、最左前缀匹配原则、索引下推<ul>\n<li>联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并，<code>实现为ALTER TABLE cus_order ADD INDEX id_score_name(score, name);</code><ul>\n<li><code>覆盖索引</code>：一个索引叶子节点数据包含（或者说覆盖）所有需要查询的字段的值，可以不用二次查询，比如在非主键索引查记录的主键可以不用回表</li>\n<li><code>最左前缀匹配原则</code>：在使用联合索引时，MySQL会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到范围查询（如**<code>&gt;</code><strong>、</strong><code>&lt;</code>**）才会停止匹配。所以在使用联合索引时，可以将区分度高的字段放在最左边，这样可以过滤掉更多数据</li>\n<li><code>索引下推</code>：MySQL 5.6 版本中提供的一项索引优化功能，可以在索引遍历过程中，对索引中包含的字段（联合索引）先做判断，过滤掉不符合条件的记录，减少回表次数</li>\n</ul>\n</li>\n<li>非主键索引默认与主键建立联合索引，可以减少需要的联合索引个数</li>\n<li>大表如何添加索引<ul>\n<li>不可以随便添加索引的原因：给表添加索引的时候，会对表加锁，会使得对表的增删改查失效</li>\n<li>先创建一张跟原表A数据结构相同的表B，在新表上添加新索引，将原表A数据导入到新表B并将更新表B名字</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-进阶知识\"><a href=\"#3-进阶知识\" class=\"headerlink\" title=\"3.进阶知识\"></a>3.进阶知识</h2><h3 id=\"1-索引选择\"><a href=\"#1-索引选择\" class=\"headerlink\" title=\"1.索引选择\"></a>1.索引选择</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>选择合适的字段创建索引（不为NULL、被频繁查询、被作为条件查询、频繁需要排序的、频繁用于连接的）；频繁用于更新的字段不适合建立索引，维护索引的成本很高；索引数量不能过多，避免冗余索引；不适合建立索引（数据量少、更新频繁、区分度低、已经有联合索引、用不到的字段）</p></blockquote>\n<ol>\n<li><p>索引选择：</p>\n<ul>\n<li><p>指标</p>\n<ul>\n<li><p>预估扫描行数：show index的cardinality列反应的是索引的基数（索引上不同值个数），通过使用采样统计选择M个数据页，统计每个页面上不同值个数，然后求求平均再乘索引的页面数得到索引的基数（变更的数据行超过1/M时重新统计）</p>\n<ul>\n<li><p><code>analyze table tableName;</code>：当索引的统计信息不对时，可以用来重新统计索引信息</p>\n</li>\n<li><p>MySQL有两种存储索引统计的方式通过设置参数 innodb_stats_persistent 的值来选择：</p>\n<ul>\n<li>设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10</li>\n<li>设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>是否需要回表：选择不需要回表的作为索引</p>\n</li>\n<li><p>是否需要再次排序：选择已排序列为索引</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>引导优化器选择索引的方法<ul>\n<li>采用 force index 强行选择一个索引：<code>select * from t force index(a) where a between 10000 and 20000;</code><ul>\n<li>修改语句，引导 MySQL 使用我们期望的索引：在保证业务正确的前提下，进行一些优化：如<code>order by b limit 1</code> 改为 <code>order by b,a limit 1</code>，可以使其使用a为索引</li>\n<li>新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引</li>\n</ul>\n</li>\n<li>通过查询sys库的<code>schema_unused_indexes</code>视图来查询哪些索引从未被使用</li>\n</ul>\n</li>\n</ul>\n<ol start=\"2\">\n<li><p>对索引字段进行函数操作，优化器会放弃走树搜索功能</p>\n<ul>\n<li><p>条件字段函数操作：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定</p>\n<ul>\n<li><p>问题SQL：<code>select count(*) from tradelog where month(t_modified)=7;</code></p>\n</li>\n<li><p>原因：对索引字段做函数操作（包括+1操作），可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能，但是不代表放弃这个索引，而是继续根据之前指标来确定索引</p>\n</li>\n<li><p>改进：把 SQL 语句改成基于字段本身的范围查询，这样优化器就能用上 t_modified 索引的快速定位能力了，否则需要进行全表扫描</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">mysql&gt; select count(*) from tradelog where\n    -&gt; (t_modified &gt;&#x3D; &#39;2016-7-1&#39; and t_modified&lt;&#39;2016-8-1&#39;) or\n    -&gt; (t_modified &gt;&#x3D; &#39;2017-7-1&#39; and t_modified&lt;&#39;2017-8-1&#39;) or \n    -&gt; (t_modified &gt;&#x3D; &#39;2018-7-1&#39; and t_modified&lt;&#39;2018-8-1&#39;);</code></pre></li>\n</ul>\n</li>\n<li><p>隐式类型转换</p>\n<ul>\n<li>问题SQL：<code>select * from tradelog where tradeid=110717;</code></li>\n<li>原因：tradeid字段是varchar(32)，输入的参数确实整型，所以需要做类型转换，这里的类型转换规则是字符串和数组做比较，将字符串转换成数字<ul>\n<li>对于优化器来说，上面的语句相当于：<code>select * from tradelog where CAST(tradid AS signed int) = 110717;</code>，即对索引字段使用了函数，优化器放弃走树搜索功能</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>隐式字符编码转换</p>\n<ul>\n<li><p>问题SQL：<code>select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;</code>，其中<code>tradelog</code></p>\n<p>字符集为<code>utf8mb4</code>，<code>trade_detail</code>字符集为<code>utf8</code></p>\n<ul>\n<li>底层：<code>select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;</code></li>\n<li>改进：<code>select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2;</code></li>\n</ul>\n</li>\n<li><p>原因：两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引，导致<code>tradelog</code>查处一行后去<code>trade_detail</code>查时使用的全表扫描</p>\n<ul>\n<li>字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较</li>\n<li>因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，在跟另一表中的字段进行比较</li>\n</ul>\n</li>\n<li><p>不会出现问题的SQL：<code>select operator from tradelog where traideid =$R4.tradeid.value;</code></p>\n<ul>\n<li>底层：<code>select operator from tradelog where traideid =CONVERT($R4.tradeid.value USING utf8mb4);</code></li>\n<li>这里的 CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>索引失效的情况</p>\n<ul>\n<li><p>使用 <code>SELECT *</code> 进行查询;</p>\n</li>\n<li><p>创建了组合索引，但查询条件未遵守最左匹配原则;</p>\n</li>\n<li><p>在索引列上进行计算（如，+、-、*、/）、函数、类型转换等操作;</p>\n</li>\n<li><p>以 <code>%</code> 开头的 LIKE 查询比如 <code>like &#39;%abc&#39;</code>;</p>\n</li>\n<li><p>查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;</p>\n</li>\n<li><p>发生隐式转换</p>\n<ul>\n<li><p>问题：下面四条语句中，第3条比1、2、4慢很多</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">1: SELECT * FROM &#96;test1&#96; WHERE num1 &#x3D; 10000;\n2: SELECT * FROM &#96;test1&#96; WHERE num1 &#x3D; &#39;10000&#39;;\n3: SELECT * FROM &#96;test1&#96; WHERE num2 &#x3D; 10000;\n4: SELECT * FROM &#96;test1&#96; WHERE num2 &#x3D; &#39;10000&#39;;</code></pre></li>\n<li><p>定义：当操作符与不同类型的操作数一起使用时，会发生类型转换以使操作数兼容。某些转换是隐式发生的。例如，MySQL 会根据需要自动将字符串转换为数字，反之亦然</p>\n<ul>\n<li>根据文档：语句2和语句3的两边被转换成了浮点数来比较<ul>\n<li>其中语句2都转换成了浮点数进行比较，转换结果是唯一确定的（都是10000），不影响索引使用</li>\n<li>语句3虽然都转换成了10000，但是除了‘10000’可以转换成10000，‘01000’也可以，所以不是唯一的，不可用索引</li>\n<li>转换规则<ul>\n<li><strong>不以数字开头</strong>的字符串都将转换为<code>0</code>。如<code>&#39;abc&#39;</code>、<code>&#39;a123bc&#39;</code>、<code>&#39;abc123&#39;</code>都会转化为<code>0</code>；</li>\n<li><strong>以数字开头的</strong>字符串转换时会进行截取，从第一个字符截取到第一个非数字内容为止。比如<code>&#39;123abc&#39;</code>会转换为<code>123</code>，<code>&#39;012abc&#39;</code>会转换为<code>012</code>也就是<code>12</code>，<code>&#39;5.3a66b78c&#39;</code>会转换为<code>5.3</code>，其他同理</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>两列数据做比较，即使两列都创建了索引，索引也会失效</p>\n</li>\n<li><p>查询条件是is null时正常走索引，使用is not null时，不走索引</p>\n</li>\n<li><p>当查询条件为大于等于、in等范围查询时，根据查询结果占全表数据比例的不同，优化器有可能会放弃索引，进行全表扫描</p>\n</li>\n<li><p>mysql 估计使用全表扫描要比使用索引快，则不使用索引</p>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"2-缓存\"><a href=\"#2-缓存\" class=\"headerlink\" title=\"2.缓存\"></a>2.缓存</h3><ol>\n<li><p>刷脏页：InnoDB使用buffer pool管理内存，当内存数据页与磁盘不一样时就称为脏页，需要合适的时机刷新到磁盘上同步数据</p>\n<ul>\n<li><p>刷脏页的时机</p>\n<ul>\n<li>InnoDB 的 redo log 写满了。系统会停止所有更新操作，把checkpoint往前推进，将扫到的redo log字段对应的数据页flush到磁盘上，redo log留出空间可以继续写</li>\n<li>系统内存不足需要淘汰掉内存中的页时，如果该页是脏页则需要将数据同步到磁盘上，保证每个数据页不论在内存中还是磁盘上，都是正确的数据（在内存的数据页，其磁盘的就是旧值）</li>\n<li>MySQL 认为系统“空闲”的时候（见缝插针刷新脏页）、MySQL 正常关闭的时候（刷新所有脏页，再次启动时直接读磁盘）</li>\n</ul>\n</li>\n<li><p>InnoDB刷脏页的控制策略</p>\n<ul>\n<li><p>影响性能的情况：一个查询要更新的脏页个数太多；日志写满更新全部堵住，写性能跌为0</p>\n</li>\n<li><p>刷盘速度：X * max(F1(M), F2(N))</p>\n<ul>\n<li><p>innodb_io_capacity：告诉 InnoDB 现在的磁盘能力，可以设置成磁盘的IOPS，假设当前为（X）</p>\n</li>\n<li><p>innodb_max_dirty_pages_pct：==脏页比例==上限，默认是75%，InnoDB会根据当前脏页比例（假设为M，计算方式 如下），算出一个0到100之间的数字（F1(M)）</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">mysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME &#x3D; &#39;Innodb_buffer_pool_pages_dirty&#39;;\nselect VARIABLE_VALUE into @b from global_status where VARIABLE_NAME &#x3D; &#39;Innodb_buffer_pool_pages_total&#39;;\nselect @a&#x2F;@b; #即Innodb_buffer_pool_pages_dirty&#x2F;Innodb_buffer_pool_pages_total</code></pre></li>\n<li><p>==redo log写盘速度==：根据写入日志的序号和checkpoint序号之间的差值（假设为N），计算出另一个0到100之间的数字（F2(N)）</p>\n</li>\n</ul>\n</li>\n<li><p>脏页选择算法：改进的LRU算法</p>\n<ul>\n<li>按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域，前面是young区域，LRU_old指向old区域第一块</li>\n<li>young区域：访问后放到young头部，新数据插入到LRU-old处</li>\n<li>old区域：在LRU中存在超过1s，移到链表头部；否则保持不变（很快失效的不会被保存很久）。所以短时间多次访问一个表不会让其它缓存失效</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>邻居刷新机制：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷（innodb_flush_neighbors = 1时启用，0时关闭）</p>\n</li>\n</ul>\n</li>\n<li><p>标记删除：从5.6.6开始每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中，删除的记录不会直接在B+树中删除，而是标记删除并等待被复用，所以经过大量删除的表可能存在空洞，通过重建表来收缩空洞减少内存消耗</p>\n<ul>\n<li>原理：新建一个表B，表A的数据按顺序插入到B中，这个过程需要全程拿MDL写锁（需要移动数据，下面的Online DDL不需要移动数据，数据存放在<code>tmp_file</code>临时文件中）</li>\n<li>Online DDL：MySQL5.6引入，可以在重建表的过程中，保证表A上的更新操作不被阻塞：使用日志文件（row log）记录所有A的操作（<code>alter table t engine=innodb,ALGORITHM=inplace;</code>）</li>\n<li><code>analyze table t</code> 不是重建表，只是通过那MDL读锁并重新统计；而 <code>optimize table t </code>等于 recreate+analyze</li>\n</ul>\n</li>\n<li><p>临时表</p>\n<ul>\n<li>特点<ul>\n<li>可以使用各种引擎类型，使用InnoDB引擎/MyISAM引擎就写到磁盘上，否则使用Memory引擎写到内存上，支持自动回收</li>\n<li>一个临时表只能被创建它的session访问，对其他线程不可见，不同session的临时表可重名<ul>\n<li>创建一个名为<code>\\#sql&#123;进程 id&#125;_&#123;线程 id&#125;_ 序列号.frm</code>的文件，所以可重名</li>\n</ul>\n</li>\n<li>可以与普通表同名，同名时除了show tables外，都显示临时表，如show create、增删改查等语句<ul>\n<li>内存中每个表都对应一个<code> table_def_key</code>，普通表的值为库名 + 表名，临时表的值外加了<code>server_id+thread_id</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>用途：因为不用担心重名冲突，所以常被用在复杂查询的优化过程（sort buffer、join buffer）<ul>\n<li>分库分表的跨库查询：把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作</li>\n</ul>\n</li>\n<li>日志记录<ul>\n<li>临时表 redolog：不记录，因为崩溃之后，临时表全没了，也不需要恢复</li>\n<li>undolog：需要记录，5.6之前是和普通表放一块的；5.7之后放在临时表空间的</li>\n<li>binlog：row格式不用记，statement/mix需要记录，但不记录<ul>\n<li>主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。所以，这时候我们就需要在主库上再写一个 DROP TEMPORARY TABLE 传给备库执行</li>\n<li>线程是session级别的且binlog_fotmat=row时，drop table 临时表不会传过去，因为row模式从库没有临时表</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>内部临时表<ul>\n<li>如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；</li>\n<li>join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；</li>\n<li>如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"3-加锁规则\"><a href=\"#3-加锁规则\" class=\"headerlink\" title=\"3.加锁规则\"></a>3.加锁规则</h3><ol>\n<li>查询长时间不返回<ul>\n<li>阻塞<ul>\n<li>可以使用 <code>show processlist</code>命令查看当前执行的语句是否在等待锁</li>\n<li>通过查询 sys.schema_table_lock_waits 这张表（<code>select blocking_pid from sys.schema_table_lock_waits;</code>），就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可</li>\n</ul>\n</li>\n<li>等flush<ul>\n<li>通过<code>select * from information_schema.processlist where id=1;</code>语句查看是否在等flush</li>\n<li>MySQL 里面对表做 flush 操作的用法，一般有以下两个<code>flush tables t with read lock;</code> 和<code>flush tables with read lock;</code>，但是这两条语句一般都执行很快，<code>waiting for table flush</code>状态可能是有一个flush tables命令被别的语句堵住</li>\n</ul>\n</li>\n<li>等行锁<ul>\n<li>通过<code>select * from t sys.innodb_lock_waits where locked_table=&#39;</code>test<code>.</code>t<code>&#39;\\\\G</code>来查询谁占着这个写锁</li>\n</ul>\n</li>\n<li>不断回滚<ul>\n<li>使用带lock in share mode的SQL语句，是当前读，而不带这个的SQL语句会使用undolog，不断回滚找到自己的视图，这样速度会很慢</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>加锁规则（5.x 系列 &lt;=5.7.24，8.0 系列 &lt;=8.0.13）<ul>\n<li>原则 1：加锁的基本单位是 next-key lock（前开后闭区间）</li>\n<li>原则 2：查找过程中访问到的对象才会加锁</li>\n<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁</li>\n<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁</li>\n<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止</li>\n</ul>\n</li>\n<li>死锁解除：方法一是设定超时时间（innodb_lock_wait_timeout）、方法二是发起死锁检测（innodb_deadlock_detect=on），主动回滚死锁链条中的某一事务、方法三是控制并发度、方法四是确保业务一定不死锁，产生了就回滚、方法五是将一个总账户分成多个小账户来提高并发度（需要业务控制逻辑正确）</li>\n</ol>\n<h3 id=\"4-日志配置\"><a href=\"#4-日志配置\" class=\"headerlink\" title=\"4.日志配置\"></a>4.日志配置</h3><ol>\n<li>双1配置<ul>\n<li>定义：<code>sync_binlog</code> 和 <code>innodb_flush_log_at_trx_commit</code> 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog</li>\n<li>日志逻辑序列号（log sequence number）：单调递增，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。</li>\n<li>组提交：一个事务提交的时候，使用组里的现有事务作为LSN，并将现有事务一起写入磁盘中。所以在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好</li>\n</ul>\n</li>\n<li>如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？<ul>\n<li>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险</li>\n<li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志</li>\n<li>将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据</li>\n</ul>\n</li>\n<li>主备同步（未完待续）</li>\n</ol>\n<h3 id=\"5-SQL语句\"><a href=\"#5-SQL语句\" class=\"headerlink\" title=\"5.SQL语句\"></a>5.SQL语句</h3><ol>\n<li><p>count(*)</p>\n<ul>\n<li>MyISAM每个表缓存此值，但是InnoDB每次都需要重新计算，因为MVCC机制，每个版本的表不同，一个表记录一个值没有意义</li>\n<li>优化：将此值保存在数据库的一张表里，通过事务机制来保证数据更改的并发问题（使用Redis缓存不是原子操作有并发问题）</li>\n<li>不同的count用法：server层要什么就给什么、InnoDB只给必要的值、优化器之优化了count(*)的语义为“取行数”<ul>\n<li>对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加</li>\n<li>对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加</li>\n<li>对于 count(字段) 来说，<ul>\n<li>如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，字段肯定不能为 null 可以直接按行累加</li>\n<li>如果这个“字段”定义允许为 null，那么执行的时候，字段有可能是 null，需要把值取出来再判断一下，不是 null 才累加</li>\n</ul>\n</li>\n<li> count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加（效率最高）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>order by：通过<code>max_length_for_sort_data</code>参数来决定排序方法，需要的一行数据小于此值时使用全字段排序，大于则使用rowid 排序</p>\n<ul>\n<li>全字段排序：通过索引取出满足条件的记录的所需字段，放入名为<code>sort_buffer</code>的内存中，然后进行快速排序或外部归并排序（取决于<code>sort_buffer_size</code>的大小，不够则使用磁盘里的临时文件来辅助）</li>\n<li>rowid排序：放入<code>sort_buffer </code>的字段，只有要排序的列（即 name 字段）和主键 id，排序完后按照顺序返回原表中取出所需的其它字段</li>\n<li>优化：建立联合索引（另一字段有序），覆盖索引（不用回表）来使得查询不用每次都排序<ul>\n<li>使用<code>SELECT * FROM information_schema.OPTIMIZER_TRACE\\\\G</code>来查看相关数据<ul>\n<li><code>number_of_tmp_files</code>：看到使用的临时文件数量</li>\n<li><code>sort_mode</code>：packed_additional_fields（使用实际大小申请内存）、rowid（使用rowid排序）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>显示随机消息：<code>select word from words order by rand() limit 3;</code>随机拿出的值是需要放到临时表中存储的，大小超过tmp_table_size参数使用order by的InnoDB表的排序方式，小于tmp_table_size参数则使用内存临时表和rowid方法来排序（不用回表）</p>\n<ul>\n<li>当limit限制的行数所占用的内存小于sort_buffer_size时，会选择优先级队列排序算法（堆排序），大于sort_buffer_size时，使用外部归并排序算法</li>\n<li>优化方法<ul>\n<li>方法一：取得这个表的主键 id 的最大值 M 和最小值 N；用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N；取不小于 X 的第一个 ID 的行（结果不是严格随机的，但是效率高）</li>\n<li>方法二：取得整个表的行数，并记为 C；取得 Y = floor(C * rand())（ floor 函数在这里的作用，就是取整数部分）；再用 limit Y,1 取得一行（结果是严格随机的，但是效果低于方法一）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>drop（删除表）、delete（清除记录）、truncate（清空表中数据）的区别</p>\n<ul>\n<li>用法不同<ul>\n<li>drop：丢弃数据，如<code>drop table 表名</code>，直接将表删除掉，不但数据会删除，表的结构也会删除</li>\n<li>truncate：清空数据，如<code>truncate table 表名</code>，只删除表中的数据，再插入数据的时候自增长 id 又从 1 开始，在清空表中数据的时候使用</li>\n<li>delete：删除数据，如<code>delete from 表名 where 列名=值</code>，删除某一行的数据，如果不加 <code>where</code>子句和<code>truncate table 表名</code>作用类似</li>\n</ul>\n</li>\n<li>drop和truncate属于DDL（数据定义）语句，操作立即生效，不能回滚，而delete是DML（数据操作语言）语句，如果放到rollback片段中，事务提交之后才会生效</li>\n<li>执行速度不同：一般来说：drop&gt;truncate&gt;delete<ul>\n<li><code>delete</code>命令执行的时候会产生数据库的<code>binlog</code>日志，而日志记录是需要消耗时间的，但是也有个好处方便数据回滚恢复</li>\n<li><code>truncate</code>命令执行的时候不会产生数据库日志，因此比<code>delete</code>要快。除此之外，还会把表的自增值重置和索引恢复到初始大小等</li>\n<li><code>drop</code>命令会把表占用的空间全部释放掉</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>join</p>\n<ul>\n<li>Index Nested-Loop Join：先从表1取1行数据，然后取出join字段去表2中查找，取出满足条件的行，并且表2该join字段有索引，可以走树搜索过程<ul>\n<li>驱动表是走全表扫描，而被驱动表是走树搜索，所以让小表做驱动表更快</li>\n<li>小表确定：在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表</li>\n<li>Batched Key Access算法：<code>set optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;</code><ul>\n<li>Multi-Range Read 优化原理：join得到多个返回值时，先放入read_rnd_buffer进行排序，然后批量返回进行顺序查找</li>\n<li>使用join_buffer来暂存数据用于排序</li>\n<li>BNL算法转成BKA算法：直接在被驱动表上建索引（数据存到临时表再加索引），这时就可以使用NLJ算法，然后使用 BKA 算法了</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Simple Nested-Loop Join：先从表1取1行数据，然后取出join字段去表2中查找，取出满足条件的行，但是表2该join字段没有索引，需要走全表扫描，效率低，所以被驱动表没有可用索引时使用下面的join方法</li>\n<li>Block Nested-Loop Join：把表 t1 的数据读入线程内存 join_buffer 中，扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回<ul>\n<li>join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，就分段放</li>\n<li>内存判断次数是不受选择哪个表作为驱动表影响的。而考虑到扫描行数还是应该选择小表来作为驱动表</li>\n<li>缺点：多次扫描一个表，虽然有优化后的LRU算法，但是如果是冷表就会有问题<ul>\n<li>冷表的数据量小于整个 Buffer Pool 的 3/8：多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部</li>\n<li>冷表很大：由于我们的 join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页，很可能在 1 秒之内就被淘汰了。这样，就会导致这个 MySQL 实例的 Buffer Pool 在这段时间内，young 区域的数据页没有被合理地淘汰，业务正常访问的数据页，没有机会进入 young 区域</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>group by</p>\n<ul>\n<li><p>如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">select id%10 as m, count(*) as c from t1 group by m order by null;</code></pre></li>\n<li><p>尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort</p>\n</li>\n<li><p>如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过调大 tmp_table_size 参数，避免用到磁盘临时表；</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">set tmp_table_size&#x3D;1024;\nselect id%100 as m, count(*) as c from t1 group by m order by null limit 10;</code></pre></li>\n<li><p>如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;</code></pre></li>\n</ul>\n</li>\n</ol>\n<h3 id=\"6-紧急操作\"><a href=\"#6-紧急操作\" class=\"headerlink\" title=\"6.紧急操作\"></a>6.紧急操作</h3><ol>\n<li><p>短期临时提升性能</p>\n<ul>\n<li><p>短连接风暴：正常执行流程是创建短连接，执行少量的SQL，然后断开。但是在连接数暴涨（超过<code>max_connections</code>参数）时，系统就会拒绝接下来的连接请求，返回<code>“Too many connections”</code></p>\n<ul>\n<li>方法一：先处理掉那些占着连接但是不工作的线程，通过<code>kill connection + id;</code>主动断开不需要的连接，类似于实现设置连接的<code>wait_timeout</code>参数，空闲过久则断开连接<ul>\n<li>安全删除：通过<code>show processlist;</code>查找sleep的线程，通过查 <code>information_schema</code> 库的 <code>innodb_trx</code> 表看对应事务具体的状态</li>\n<li>断开的连接会返回<code>“ERROR 2013 (HY000): Lost connection to MySQL server during query”</code>，需要业务系统发起新的连接请求，否则业务认为MySQL一直没恢复</li>\n</ul>\n</li>\n<li>方法二：减少连接过程的消耗<ul>\n<li>跳过权限验证的方法：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>慢查询性能问题：在上线前使用慢查询日志记录所有语句的执行过程，看看<code>Rows_examined</code>字段是否与预期一致</p>\n<ul>\n<li><p>索引没有设计好：通过紧急创建索引，直接执行alter table语句，可以使用下面的方法，或者使用<code>gh-ost</code>这样的方案</p>\n<ul>\n<li>在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引</li>\n<li>执行主备切换；这时候主库是 B，备库是 A</li>\n<li>在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引</li>\n</ul>\n</li>\n<li><p>SQL 语句没写好：5.7开始提供query_rewrite功能，可以把输入的一种语句改写成另一种模式，如下所示</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">#改写 select * from t where id + 1 &#x3D; 10000\nmysql&gt; insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (&quot;select * from t where id + 1 &#x3D; ?&quot;, &quot;select * from t where id &#x3D; ? - 1&quot;, &quot;db1&quot;);\nmysql&gt; call query_rewrite.flush_rewrite_rules();</code></pre></li>\n<li><p>MySQL 选错了索引：使用查询重写功能，给原来的语句加上 force index</p>\n</li>\n</ul>\n</li>\n<li><p>QPS（每秒查询数）突增：由于业务突然出现高峰，或应用程序bug所导致，解决方案如下</p>\n<ul>\n<li>一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉</li>\n<li>如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0</li>\n<li>如果这个新增的功能跟主体功能是部署在一起的，那么只能通过处理语句来限制，可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成”select 1”返回</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>误删数据</p>\n<ul>\n<li>使用 delete 语句误删数据行：用 Flashback 工具通过闪回把数据恢复回来；原理是通过修改binlog的内容，拿回原库重放；前提是确保 binlog_format=row 和 binlog_row_image=FULL<ul>\n<li>不建议直接在主库上执行这些操作，恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库</li>\n<li>事前预防：把 sql_safe_updates 参数设置为 on（没有where时会报错）；代码上线前，必须经过 SQL 审计</li>\n<li>使用 truncate /drop table 和 drop database 命令删除的数据，就无法通过 Flashback 来恢复了，因为binlog没有每一条记录</li>\n</ul>\n</li>\n<li>使用 drop database 语句误删数据库：使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog<ul>\n<li>跳过误操作的语句<ul>\n<li>先用<code>–stop-position </code>参数执行到误操作之前的日志，然后再用<code>–start-position</code>从误操作之后的日志继续执行；</li>\n<li>实例使用了 GTID 模式，通过<code>set gtid_next=gtid1;begin;commit;</code>跳过改语句；</li>\n</ul>\n</li>\n<li>一种加速方法：在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，跳过增量日志的读取过程<ul>\n<li>在 start slave 之前，先通过执行<code>﻿﻿change replication filter replicate_do_table = (tbl_name)</code>命令，就可以让临时库只同步误操作的表，这样做也可以用上并行复制技术，来加速整个数据恢复过程</li>\n<li>在接入线上备库的从库时, 需要先将误删除的gtid先设置跳过, 然后利用主从同步的并行复制技术，来加速整个数据恢复过程</li>\n</ul>\n</li>\n<li>预防方法<ul>\n<li>搭建延迟复制的备库，通过<code>CHANGE MASTER TO MASTER_DELAY = N</code>命令，可以指定这个备库持续保持跟主库有 N 秒的延迟</li>\n<li>账号分离：只给业务开发 DML 权限，而不给 truncate/drop 权限</li>\n<li>制定操作规范：在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响后再删除这张表</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>使用 rm 命令误删整个 MySQL 实例<ul>\n<li>对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>快速复制一张表</p>\n<ul>\n<li><p>使用 mysqldump 命令将数据导出成一组 INSERT 语句</p>\n<ul>\n<li>–single-transaction 的作用是，在导出数据的时候不需要对表 db1.t 加表锁，而是使用 START TRANSACTION WITH CONSISTENT SNAPSHOT 的方法；</li>\n<li>–add-locks 设置为 0，表示在输出的文件结果里，不增加” LOCK TABLES t WRITE;” ；</li>\n<li>–no-create-info 的意思是，不需要导出表结构；</li>\n<li>–set-gtid-purged=off 表示的是，不输出跟 GTID 相关的信息；</li>\n<li>–result-file 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的</li>\n</ul>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">mysqldump -h$host -P$port -u$user --add-locks&#x3D;0 --no-create-info --single-transaction  --set-gtid-purged&#x3D;OFF db1 t --where&#x3D;&quot;a&gt;900&quot; --result-file&#x3D;&#x2F;client_tmp&#x2F;t.sql\n\n# 将这些 INSERT 语句放到 db2 库里去执行\nmysql -h127.0.0.1 -P13000  -uroot db2 -e &quot;source &#x2F;client_tmp&#x2F;t.sql&quot;</code></pre></li>\n<li><p>导出和导入 CSV 文件:</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">select * from db1.t where a&gt;900 into outfile &#39;&#x2F;server_tmp&#x2F;t.csv&#39;;\nload data infile &#39;&#x2F;server_tmp&#x2F;t.csv&#39; into table db2.t;</code></pre></li>\n<li><p>物理拷贝方法</p>\n</li>\n</ul>\n</li>\n<li><p>慢sql排查</p>\n<ul>\n<li>如果是在项目中，可以通过SpringAOP去查询这个接口运行的时间</li>\n<li>如果是一个sql，可以通过explain的指令去查这个sql的执行计划</li>\n<li>可通过开启mysql的慢日志查询，设置好时间阈值，进行捕获</li>\n</ul>\n</li>\n</ol>\n","text":"MySQL1.SQL语法 数据库概念：数据库（DB）、数据库管理系统（DBMS）、数据库系统（软件+数据库+DBA）、数据库管理员（DBA）、元祖（tuple 一行）、码（列）、候选码（唯一标识元祖）、主码（主键）、外码（另一表的主键）、主属性（候选码中的属性）、非主属性、注释（...","link":"","photos":[],"count_time":{"symbolsCount":"30k","symbolsTime":"27 mins."},"categories":[],"tags":[{"name":"database","slug":"database","count":2,"path":"api/tags/database.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#MySQL\"><span class=\"toc-text\">MySQL</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-SQL%E8%AF%AD%E6%B3%95\"><span class=\"toc-text\">1.SQL语法</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86\"><span class=\"toc-text\">2.基础知识</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">1.基础架构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E6%97%A5%E5%BF%97\"><span class=\"toc-text\">2.日志</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-%E9%94%81\"><span class=\"toc-text\">3.锁</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#4-%E4%BA%8B%E5%8A%A1\"><span class=\"toc-text\">4.事务</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-%E7%B4%A2%E5%BC%95\"><span class=\"toc-text\">5.索引</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-%E8%BF%9B%E9%98%B6%E7%9F%A5%E8%AF%86\"><span class=\"toc-text\">3.进阶知识</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E7%B4%A2%E5%BC%95%E9%80%89%E6%8B%A9\"><span class=\"toc-text\">1.索引选择</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E7%BC%93%E5%AD%98\"><span class=\"toc-text\">2.缓存</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-%E5%8A%A0%E9%94%81%E8%A7%84%E5%88%99\"><span class=\"toc-text\">3.加锁规则</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#4-%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE\"><span class=\"toc-text\">4.日志配置</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-SQL%E8%AF%AD%E5%8F%A5\"><span class=\"toc-text\">5.SQL语句</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-%E7%B4%A7%E6%80%A5%E6%93%8D%E4%BD%9C\"><span class=\"toc-text\">6.紧急操作</span></a></li></ol></li></ol></li></ol>","author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Go","uid":"8aa9bb0438939ce2b4a00f1a6ea1e9e5","slug":"Go","date":"2023-05-04T04:42:41.000Z","updated":"2023-05-04T06:50:29.873Z","comments":true,"path":"api/articles/Go.json","keywords":null,"cover":[],"text":"GO1.运行前准备 源码结构 GOROOT：Go 语言安装根目录的路径，也就是 GO 语言的安装路径 GOPATH：若干工作区目录的路径。是我们自己定义的工作空间（workspace），go源码文件（.go）、归档文件（.a）、可执行文件都存在此处 go源码文件需要保存在GOPA...","link":"","photos":[],"count_time":{"symbolsCount":"25k","symbolsTime":"23 mins."},"categories":[],"tags":[{"name":"language","slug":"language","count":4,"path":"api/tags/language.json"}],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Kubernetes","uid":"e929ee8c2d932d4d8650d036d3438f62","slug":"Kubernetes","date":"2023-04-20T12:35:42.000Z","updated":"2023-05-11T04:20:36.201Z","comments":true,"path":"api/articles/Kubernetes.json","keywords":null,"cover":[],"text":"Kubernetes（未完待续） Kubernetes 是一个生产级别的容器编排平台和集群管理系统，不仅能够创建、调度容器，还能够监控、管理服务器，它凝聚了 Google 等大公司和开源社区的集体智慧，从而让中小型公司也可以具备轻松运维海量计算节点——也就是“云计算”的能力。 1...","link":"","photos":[],"count_time":{"symbolsCount":"8.7k","symbolsTime":"8 mins."},"categories":[],"tags":[{"name":"tools","slug":"tools","count":4,"path":"api/tags/tools.json"}],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}