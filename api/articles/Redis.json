{"title":"Redis","uid":"a978a5e93d8e6628e9f4ee713be55be8","slug":"Redis","date":"2023-05-04T10:00:34.000Z","updated":"2023-05-04T10:04:45.250Z","comments":true,"path":"api/articles/Redis.json","keywords":null,"cover":[],"content":"<h1 id=\"Redis\"><a href=\"#Redis\" class=\"headerlink\" title=\"Redis\"></a>Redis</h1><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Redis是一个高性能（内存+Reactor+优化的数据结构）的开源键值数据库，其value支持丰富的数据类型（string、hash、set、list、zset「有序集合」），具有数据可持久化、支持master-slave备份、读写性能高（MySQL的QPS大概1w左右，Redis读11w次/s，写8w次/s）等特点，其单个操作是原子性的，多个连续操作支持事务</p></blockquote>\n<h2 id=\"1-高性能\"><a href=\"#1-高性能\" class=\"headerlink\" title=\"1.高性能\"></a>1.<strong>高性能</strong></h2><h3 id=\"1-数据结构\"><a href=\"#1-数据结构\" class=\"headerlink\" title=\"1.数据结构\"></a><strong>1.数据结构</strong></h3><ol>\n<li><p>数据类型及其应用</p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>简介</th>\n<th>特性</th>\n<th>场景</th>\n<th>大小</th>\n<th>底层数据结构</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>String</td>\n<td>二进制安全</td>\n<td>可以包含任何数据（字符串、整数、浮点数、图片的base64编码、序列化后的对象）</td>\n<td>1.存储数据；2.计数（单位时间请求数，单位时间访问数）</td>\n<td>一个键最大能存储 512MB</td>\n<td>SDS（简单动态字符串）</td>\n</tr>\n<tr>\n<td>Hash</td>\n<td>键值对集合,即编程语言中的Map类型</td>\n<td>适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)</td>\n<td>1.存储、读取、修改用户属性；2.对象数据存储（用户信息、文章信息、购物车信息）</td>\n<td>每个 hash 可以存储 2^32 -1 键值对（4294967295）</td>\n<td>LinkedLIst ZipList</td>\n</tr>\n<tr>\n<td>List</td>\n<td>链表(双向链表)</td>\n<td>增删快,提供了操作某一段元素的API</td>\n<td>1、最新消息排行等功能(比如朋友圈的时间线) 2、消息队列</td>\n<td>列表最多可存储 2^32 - 1 元素（4294967295）</td>\n<td>ZipList HashTable；3.2后使用QuickList</td>\n</tr>\n<tr>\n<td>Set</td>\n<td>哈希表实现,元素不重复</td>\n<td>1、添加、删除、查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作</td>\n<td>1、共同好友 2、利用唯一性，统计访问网站的所有独立ip 3、好友推荐时，根据tag求交集，大于某个阈值就可以推荐</td>\n<td>集合中最大的成员数为 2^32 - 1（4294967295）</td>\n<td>ZipList Intset</td>\n</tr>\n<tr>\n<td>Sorted Set</td>\n<td>将Set中的元素增加一个权重参数score,元素按score有序排列</td>\n<td>数据插入集合时，已经进行天然排序。类似于Set，但是多了一个权重参数score，使得集合中的元素能够按score进行有序排列，还可以通过score的范围来获取元素的列表</td>\n<td>1、排行榜 2、带权重的消息队列</td>\n<td>—</td>\n<td>ZipList SkipList</td>\n</tr>\n<tr>\n<td>Bitmap</td>\n<td>位存储</td>\n<td>存储连续的二进制数字，可以看成是存储0/1的数组，数组下标称为offset（活跃用户统计）</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>HyperLogLogs</td>\n<td>基数统计</td>\n<td>基数计数概率算法为了节省内存并不会直接存储元数据，而是通过一定的概率统计方法预估基数值（集合中包含元素的个数）</td>\n<td>主要用于数据量巨大的计数场景（热门网站每日访问ip数统计），只存估计值</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Geospatial</td>\n<td>地理位置</td>\n<td>基于Sorted Set实现，将经纬度信息通过GeoHash算法转换成一个整数，将这个整数作为Sorted Set的score使用（实现附近的人功能）</td>\n<td>主要用于存储地理位置信息</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n</li>\n<li><p>数据结构对应命令</p>\n<ul>\n<li><p>命令行方式（<a href=\"https://www.runoob.com/redis/redis-tutorial.html%E3%80%81https://redis.io/commands/%EF%BC%89\">https://www.runoob.com/redis/redis-tutorial.html、https://redis.io/commands/）</a></p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>命令</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>string</td>\n<td>SET、GET、EXIST、STRLEN、DEL、MSET、MGET、INCR、DECR、EXPIRE、SETNX、TTL</td>\n</tr>\n<tr>\n<td>list</td>\n<td>LPUSH、LPOP、RPUSH、RPOP、LRANGE（实现分页）、LLEN</td>\n</tr>\n<tr>\n<td>hash</td>\n<td>HSET、HSETNX、HMSET、HGET、HMGET、HGETALL（所有）、HEXIXTS、HDEL、HLEN、HINCRBY（增加多少）</td>\n</tr>\n<tr>\n<td>set</td>\n<td>SADD、SMEMBERS（内容）、SCARD（数量）、SISMEMBER（有无）、求交/并/差集（SINTER、SUNION、SDIFF）、SPOP key count、SRANDMEMBER key count</td>\n</tr>\n<tr>\n<td>zset</td>\n<td>ZADD、ZCARD、ZSCORE、ZINTERSTORE（一共三个）、ZRANGE、ZREVRANGE、ZREVRANK</td>\n</tr>\n<tr>\n<td>key</td>\n<td>SET key value、DEL key、EXISTS key（seconds）、TTL key、TYPE key</td>\n</tr>\n<tr>\n<td>pub/sub</td>\n<td>PUBLISH channel message、SUBSCRIBE channel、UNSUBSCRIBE channel</td>\n</tr>\n<tr>\n<td>事务</td>\n<td>MULTI（开始）、EXEC（执行）、DISCARD（取消）、WATCH、UNWATCH</td>\n</tr>\n<tr>\n<td>其它</td>\n<td>PING、PONG、QUIT、AUTH password、INFO、FLUSHALL、BGSAVE、BGREWRITEAOF</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>使用批量操作减少网络传输</p>\n<ul>\n<li>Redis每条命令都会通过网络与服务器交互，可以使用批量操作命令（mget、hmget），但是在Redis Cluster下无法保证所有key都在同一个hash slot上，但仍个减少网络交互耗时</li>\n<li>对于不支持批量操作的命令，可以用pipeline将一批Redis命令封装成一组（非原子操作），但是需要控制批量传输的元素个数，避免网络传输的数据量大，同前一点一样，在Redis Cluster会有问题</li>\n</ul>\n</li>\n<li><p>Jedis方式（<a href=\"https://redis.io/commands/%EF%BC%89\">https://redis.io/commands/）</a></p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">import redis.clients.jedis.Jedis;\n \n import java.util.List;\n import java.util.Set;\n \n public class redisDemo &#123;\n     public static void main(String[] args) &#123;\n         Jedis jedis &#x3D; new Jedis(&quot;localhost&quot;,6379);\n         &#x2F;&#x2F;ping下，看看是否通的\n &#x2F;&#x2F;        System.out.println(&quot;Server is running: &quot; + jedis.ping());\n         &#x2F;&#x2F;String\n         jedis.set(&quot;foo&quot;, &quot;bar&quot;);\n         String value &#x3D; jedis.get(&quot;foo&quot;);\n         &#x2F;&#x2F;List，双端队列可设置为阻塞获取，可返回&#x2F;删除一个范围内的元素，可通过索引设置元素\n         jedis.lpush(&quot;mylist&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         jedis.rpush(&quot;mylist&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         List&lt;String&gt; mylist &#x3D; jedis.lrange(&quot;mylist&quot;, 0, -1);&#x2F;&#x2F;0表示第一个，-1表示最后一个\n         System.out.println(mylist);\n         &#x2F;&#x2F;Set\n         jedis.sadd(&quot;myset&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         jedis.sadd(&quot;myset2&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;);\n         Set&lt;String&gt; setdiff &#x3D; jedis.sdiff(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;差集\n         Set&lt;String&gt; setinter &#x3D; jedis.sinter(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;交集\n         Set&lt;String&gt; sunion &#x3D; jedis.sunion(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;并集\n         &#x2F;&#x2F;Hash\n         jedis.hset(&quot;myhash&quot;, &quot;a&quot;, &quot;b&quot;);\n &#x2F;&#x2F;        jedis.hincrBy(&quot;myhash&quot;, &quot;a&quot;, 1);&#x2F;&#x2F;a的值加1\n         &#x2F;&#x2F;Sorted Set\n         jedis.zadd(&quot;myzset&quot;, 1, &quot;a&quot;);\n         jedis.zadd(&quot;myzset&quot;, 2, &quot;b&quot;);\n         jedis.zadd(&quot;myzset&quot;, 3, &quot;c&quot;);\n         jedis.zlexcount(&quot;myzset&quot;, &quot;-&quot;, &quot;+&quot;);&#x2F;&#x2F;返回有序集合中指定区间内成员的数量\n         jedis.zlexcount(&quot;myzset&quot;, &quot;[b&quot;, &quot;[c&quot;);&#x2F;&#x2F;返回有序集合中指定区间(b到c)内成员的数量\n \n     &#125;\n &#125;</code></pre></li>\n</ul>\n</li>\n<li><p>底层原理</p>\n<ol>\n<li><p>全局哈希：实现从键到值的访问，具体的数据再根据值的类型不同进行不同的查找（默认使用两个全局哈希表）</p>\n<ul>\n<li>哈希冲突解决方法：拉链法，增加next指针，缺点是冲突越多在链上的查找越慢</li>\n<li>rehash：增加hash表长度，减少单个桶中的元素数量，rehash的过程包括以下三步<ul>\n<li>给hash表2分配更大的空间</li>\n<li>把hash表1的数据重新映射到hash表2，会产生大量的数据拷贝，导致Redis的线程阻塞，所以使用渐进式rehash<ul>\n<li>Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries</li>\n<li>处理请求：渐进式rehash过程中，使用两个hash表，t1和t2。针对查找操作，先在t1里面查找，如果没找到就去t2里查找；针对插入操作，一律保存到t2里，保证t1数据只减不增</li>\n</ul>\n</li>\n<li>释放hash表1的空间，表1留作下一次rehash使用</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/1cc8eaed5d1ca4e3cdbaa5a3d48dfb5f.jpg\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/1cc8eaed5d1ca4e3cdbaa5a3d48dfb5f.jpg\"></p>\n</li>\n<li><p>压缩列表</p>\n<ul>\n<li>类似于一个数组，不同之处是在表头有三个字段lbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。</li>\n<li>查找：查找头尾元素复杂度是O(1)，查找其它元素复杂度是O(N)</li>\n</ul>\n</li>\n<li><p>跳表</p>\n<ul>\n<li>在链表的基础上，增加了多级索引，通过索引位置的几个跳转就可以实现数据的快速定位，查找的复杂度是O(logN)</li>\n</ul>\n</li>\n<li><p>String的底层实现</p>\n<ul>\n<li>针对初始化的长度决定用多少字节的struct（支持1、2、4、8），可以减少内存的使用，数据用<code>char buf[]</code>存储</li>\n<li>相比于c语言的字符串<ul>\n<li>拼接时会先考虑内存空间，防止内存溢出</li>\n<li>使用<code>len</code>保存了当前字符串的长度，计算长度的时间复杂度是O(1)的</li>\n<li>减少内存分配次数：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）</li>\n<li>二进制安全：C 语言中的字符串以空字符<code>\\\\\\\\0</code>作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题</li>\n</ul>\n</li>\n<li>String 还是 Hash 存储对象数据更好<ul>\n<li>String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合</li>\n<li>String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合</li>\n<li>在绝大部分情况，使用 String 来存储对象数据即可</li>\n</ul>\n</li>\n</ul>\n</li>\n<li></li>\n</ol>\n</li>\n</ol>\n<h3 id=\"2-线程模型和epoll网络框架\"><a href=\"#2-线程模型和epoll网络框架\" class=\"headerlink\" title=\"2.线程模型和epoll网络框架\"></a><strong>2.线程模型和epoll网络框架</strong></h3><ol>\n<li>单线程机制<ul>\n<li>原因：多线程在并发访问共享资源是需要额外的机制，产生不必要的开销，在机制不够细粒度时，会产生并行变串行的情况</li>\n<li>单线程高效：内存上进行数据操作、高效的数据结构、多路复用机制</li>\n<li>6.0版本的多线程：为了提高网络IO读写性能，这部分时Redis的一个性能瓶颈，多线程默认是禁用的，不建议开启</li>\n</ul>\n</li>\n<li>基于多路复用的高性能I/O模型<ul>\n<li>传统做法：阻塞IO模型<ul>\n<li>为了处理一个 Get 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）</li>\n<li>其中的accept、recv操作都是潜在的阻塞点，如果发生阻塞，Redis就不能再响应其它请求</li>\n</ul>\n</li>\n<li>基于多路复用的高性能I/O模型（select/epoll）<ul>\n<li>Redis向内核注册事件和对应的事件回调函数，由内核来同时保存并监听多个套接字（FD）上的连接请求或数据请求，一旦有请求到达，通过select/epoll提供的基于事件的回调机制（不同事件的不同处理函数）来实现。select/epoll在检测到FD上有请求到达时（事件发生），就将对应事件插入到事件队列中，Redis一直在对事件队列进行处理（如调用epoll_wait函数取事件队列的数据），这样就不会阻塞在某一具体的请求上了</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>事务：不支持原子性、不支持回滚、每条命令都与服务器交互，所以不推荐使用Redis的事务<ul>\n<li>Redis 可以通过MULTI（开始事务），EXEC（执行事务），DISCARD（取消事务） 和 WATCH 等命令来实现事务功能<ul>\n<li>通过**<code>WATCH</code>**命令监听指定的 Key，当调用 <code>EXEC</code>命令执行事务时，如果一个被 <code>WATCH</code>命令监视的 Key 被 <strong>其他客户端/Session</strong> 修改的话，整个事务都不会被执行</li>\n<li>不过，如果 <strong>WATCH</strong>与 <strong>事务</strong>在同一个 Session 里，并且被 <strong>WATCH</strong>监视的 Key 被修改的操作发生在事务内部，这个事务是可以被执行成功</li>\n</ul>\n</li>\n<li>Redis事务不支持原子性：Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）</li>\n<li>除了不满足原子性之外，事务中的每条命令都会与 Redis 服务器进行网络交互，这是比较浪费资源的行为。明明一次批量执行多个命令就可以了，这种操作实在是看不懂。因此，Redis 事务是不建议在日常开发中使用的</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"3-内存管理\"><a href=\"#3-内存管理\" class=\"headerlink\" title=\"3.内存管理\"></a><strong>3.内存管理</strong></h3><ol>\n<li><p>内存管理</p>\n<ul>\n<li><p>设置过期时间：内存有限，保存所有数据迟早会OOM</p>\n<ul>\n<li>Redis 中除了字符串类型有自己独有设置过期时间的命令 <code>setex</code> 外，其他方法都需要依靠 <code>expire</code> 命令来设置过期时间 。另外， <code>persist</code> 命令可以移除一个键的过期时间</li>\n<li>很多时候业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效，使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多</li>\n</ul>\n</li>\n<li><p>如何判断数据过期（过期字典）</p>\n<ul>\n<li>通过过期字典（可看作hash表）来保存数据过期的时间，过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）</li>\n<li>过期数据的删除策略：Redis采用定期删除+惰性删除，对于漏掉的过期key使用内存淘汰机制<ul>\n<li><strong>惰性删除</strong> ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。</li>\n<li><strong>定期删除</strong> ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响</li>\n</ul>\n</li>\n<li>大量key集中过期的问题<ul>\n<li>给 key 设置随机过期时间</li>\n<li>开启 lazy-free（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程（不建议使用）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Redis 内存淘汰机制</p>\n<ul>\n<li><strong>volatile-lru（least recently used）</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</li>\n<li><strong>volatile-ttl</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li>\n<li><strong>volatile-random</strong>：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li>\n<li><strong>allkeys-lru（least recently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）</li>\n<li><strong>allkeys-random</strong>：从数据集（server.db[i].dict）中任意选择数据淘汰</li>\n<li><strong>no-eviction</strong>：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧</li>\n<li><strong>volatile-lfu（7.0版 least frequently used）</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰</li>\n<li><strong>allkeys-lfu（7.0版 least frequently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key</li>\n</ul>\n</li>\n<li><p>内存碎片</p>\n<ul>\n<li><p>产生的原因</p>\n<ul>\n<li>Redis 存储存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间（预分配、对其分配）</li>\n<li>频繁修改 Redis 中的数据，当 Redis 中的某个数据删除时，Redis 通常不会轻易释放内存给操作系统</li>\n</ul>\n</li>\n<li><p>查看内存碎片率（&gt;1.5才需要清理）</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">redis-cli -p 6379 info | grep mem_fragmentation_ratio</code></pre></li>\n<li><p>如何清理：Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">config set activedefrag yes\n\n###具体清理shi\n# 内存碎片占用空间达到 500mb 的时候开始清理\nconfig set active-defrag-ignore-bytes 500mb\n# 内存碎片率大于 1.5 的时候开始清理\nconfig set active-defrag-threshold-lower 50\n\n###减少对Redis性能的影响\n# 内存碎片清理所占用 CPU 时间的比例不低于 20%\nconfig set active-defrag-cycle-min 20\n# 内存碎片清理所占用 CPU 时间的比例不高于 50%\nconfig set active-defrag-cycle-max 50</code></pre></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>三种常用的缓存读写策略：旁路缓存、读写穿透、异步缓存</p>\n<ul>\n<li><p>Cache Aside Pattern（旁路缓存）：同时维护db和cache，并且以db的结果为准</p>\n<ul>\n<li><p>读取数据流程</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150159435.png\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150159435.png\"></p>\n</li>\n<li><p>写数据中的问题</p>\n<ul>\n<li><p>正确方式：先更新db，在直接删除cache</p>\n</li>\n<li><p>问题一：</p>\n<p>在写数据的过程中，可以先删除 cache ，后更新 db 么？</p>\n<ul>\n<li>回答：会有数据不一致的问题，在删除cache和更新db的过程中，如果有请求从db读取，会读到旧数据</li>\n</ul>\n</li>\n<li><p>问题二：</p>\n<p>在写数据的过程中，先更新 db，后删除 cache 就没有问题了么？</p>\n<ul>\n<li>在请求读取数据后，将新数据写入到缓存这个过程中，如果有请求更新db，那么读取数据的请求插入到cache中的就是旧数据</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>旁路缓存模式的缺陷：</p>\n<ul>\n<li>首次请求数据一定不在cache中：提前缓存热点数据</li>\n<li>写操作比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率<ul>\n<li>数据库和缓存数据强一致场景 ：更新 db 的时候同样更新 cache，不过需要加一个锁/分布式锁来保证更新 cache 的时候不存在线程安全问题</li>\n<li>可以短暂地允许数据库和缓存数据不一致的场景 ：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小</li>\n</ul>\n</li>\n<li>保证缓存和数据库数据的一致性（更新数据库成功，但删除缓存这一步失败的情况）<ul>\n<li><strong>增加 cache 更新重试机制</strong>： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Read/Write Through Pattern（读写穿透）：将cache视为主要数据存储，cache服务负责将数据读取和写入db（很少用），对于首次请求不在cache中的问题，可以提前缓存热点数据</p>\n<ul>\n<li><p>写</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150211551.png\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150211551.png\"></p>\n</li>\n<li><p>读</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150231993.png\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150231993.png\"></p>\n</li>\n</ul>\n</li>\n<li><p>Write Behind Pattern（异步缓存写入）</p>\n<ul>\n<li>与读写穿透类似，都是cache负责db的读写，但是读写穿透是同步更新cache和db，而异步缓存写入更新缓存后，不直接更新db，改为异步批量的方式更新db</li>\n<li>开发中很少见，因为会有数据一致性的问题（没写入db就丢失），应用场景主要是消息队列中消息的异步写入磁盘、MySQL的Innodb Buffer Pool机制</li>\n<li>异步缓存写入下db的写性能非常高，非常适合一些数据经常变化又对数据一致性要求不高的场景，比如浏览量、点赞量</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>缓存相关问题</p>\n<ul>\n<li><p>缓存穿透</p>\n<ul>\n<li><p>大量请求的 key 是不合理的，<strong>根本不存在于缓存中，也不存在于数据库中</strong>。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了</p>\n</li>\n<li><p>解决一：做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等</p>\n</li>\n<li><p>解决二：布隆过滤器，非常方便的判断一个给定的数据是否存在于海量数据中</p>\n<ul>\n<li><p>把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程</p>\n</li>\n<li><p>误判：布隆过滤器说存在，则可能不存；但是说不存在则一定不存在</p>\n<ul>\n<li>计算哈希值，将位数组中对应下标设置为1；判断时检查位数组对应值是否是1（不同字符串可能哈希出来的位置相同）</li>\n</ul>\n</li>\n<li><p>使用**<code>docker redis bloomfilter</code>**</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">➜  ~ docker run -p 6379:6379 --name redis-redisbloom redislabs&#x2F;rebloom:latest\n➜  ~ docker exec -it redis-redisbloom bash\nroot@21396d02c252:&#x2F;data# redis-cli\n127.0.0.1:6379&gt;</code></pre></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>缓存击穿</p>\n<ul>\n<li>请求的 key 对应的是热点数据，该数据存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了<ul>\n<li>如：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力</li>\n</ul>\n</li>\n<li>解决办法<ul>\n<li>设置热点数据永不过期或者过期时间比较长</li>\n<li>针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期</li>\n<li>请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>缓存雪崩</p>\n<ul>\n<li>缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力<ul>\n<li>如：数据库中的大量数据在同一时间过期，这个时候突然有大量的请求需要访问这些过期的数据。这就导致大量的请求直接落到数据库上，对数据库造成了巨大的压力</li>\n</ul>\n</li>\n<li>解决办法<ul>\n<li>针对Redis服务不可用的情况：采用Redis集群、限流避免同时处理大量请求</li>\n<li>针对热点缓存失效的情况：设置不同失效时间、设置二级缓存</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"2-高可靠\"><a href=\"#2-高可靠\" class=\"headerlink\" title=\"2.高可靠\"></a><strong>2.高可靠</strong></h2><h3 id=\"1-数据持久化\"><a href=\"#1-数据持久化\" class=\"headerlink\" title=\"1.数据持久化\"></a><strong>1.数据持久化</strong></h3><ol>\n<li>AOF<ul>\n<li>写后日志：首先执行命令写入内存，然后再将命令记录到日志中。与传统数据库的写前（WAL）日志相比，避免了额外的检查开销，并且不会阻塞当前的命令（但会阻塞后一条命令）。但是在写入日之前宕机会丢失日志</li>\n<li>写回策略：控制一个写命令执行完后AOF日志写回磁盘的时机，即appendfsync配置项的三个可选值<ul>\n<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；可以保证不丢失数据，但是回影响主线程性能</li>\n<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘</li>\n<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘，会有数据丢失的风险</li>\n</ul>\n</li>\n<li>AOF重写机制：防止AOF文件过大，故障恢复时恢复过程缓慢<ul>\n<li>Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入（将多个命令合并成一个命令）</li>\n<li>AOF使用后台子线程bgrewriteaof来完成，避免阻塞主线程：重写时fork出后台bgrewriteaof子线程，通过拷贝父进程的页表的方式共享父进程的内存数据的方式来共享父进程的数据<ul>\n<li>写时复制：避免一次性大量拷贝给子进程造成的长时间阻塞问题，在父进程写入操作是一个已经存在的key时，父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间（否则子进程读完，父进程修改，就会丢失这一次修改的数据）</li>\n</ul>\n</li>\n<li>两次日志写入：在重写过程中，新请求会先写入到原AOF文件的缓冲区中，然后写入到重写日志的缓冲区，在重写机制结束后再合并到AOF重写日志中（但是需要上面的写时复制来保证数据不会丢失修改）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>RDB<ul>\n<li>AOF在故障恢复的时候需要逐一执行命令，恢复时间长，所以提出了RDB内存快照的方式来高效的恢复，提供了两个命令<ul>\n<li>save：在主线程中执行，会导致阻塞</li>\n<li>bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置</li>\n</ul>\n</li>\n<li>写时复制：在执行快照的同时，正常处理写操作<ul>\n<li>由父进程fork出bgsave子进程，然后开始读取主线程的内存数据，并写入到RDB文件中，在主线程有写入请求时，这块数据会被复制一份，然后主线程在数据副本上进行修改，bgsave子进程继续将原来的数据写入RDB文件</li>\n</ul>\n</li>\n<li>优化<ul>\n<li>增量快照：一直做全量快照，虽然bgsave执行时不阻塞主线程，但是会对磁盘造成压力，而且fork操作本身也会阻塞主线程。通过记录修改的元数据信息来做增量快照，但是又会产生大量的额外空间开销</li>\n<li>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照：内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>如何选择 RDB 和 AOF？<ul>\n<li>RDB 比 AOF 优秀的地方<ul>\n<li>RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会必 RDB 文件大很多。当 AOF 变得太大时，Redis 能够在后台自动重写 AOF。新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。不过， Redis 7.0 版本之前，如果在重写期间有写入命令，AOF 可能会使用大量内存，重写期间到达的所有写入命令都会写入磁盘两次。</li>\n<li>使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。</li>\n</ul>\n</li>\n<li>AOF 比 RDB 优秀的地方<ul>\n<li>RDB 的数据安全性不如 AOF，没有办法实时或者秒级持久化数据。生成 RDB 文件的过程是比较繁重的， 虽然 BGSAVE 子进程写入 RDB 文件的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。AOF 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，操作轻量。</li>\n<li>RDB 文件是以特定的二进制格式保存的，并且在 Redis 版本演进中有多个版本的 RDB，所以存在老版本的 Redis 服务不兼容新版本的 RDB 格式的问题。</li>\n<li>AOF 以一种易于理解和解析的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。比如，如果执行<code>FLUSHALL</code>命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态</li>\n</ul>\n</li>\n<li>由于 RDB 和 AOF 各有优势，于是，Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 <code>aof-use-rdb-preamble</code> 开启）。如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"2-主从复制\"><a href=\"#2-主从复制\" class=\"headerlink\" title=\"2.主从复制\"></a><strong>2.主从复制</strong></h3><ol>\n<li>使用主从库模式，通过增加副本冗余量，将一份数据同时保存在多个实例上。主从库之间采用读写分离的方式，主库和从库同时支持读操作，写操作通过主库执行然后同步到从库<ul>\n<li>不采用主从库读写分离：需要加锁或实例间协商的方式完成修改，带来更大的开销</li>\n</ul>\n</li>\n<li>主从库模式的建立<ul>\n<li>启动多个Redis实例时，他们相互之间通过replicaof命令形成主库和从库的关系，按照三个阶段完成第一次同步<ul>\n<li>第一阶段：从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了<ul>\n<li>具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID（实例的随机ID，第一次设置为？）和复制进度offset（-1表示第一次复制）两个参数</li>\n<li>主库收到 psync 命令后，会用 FULLRESYNC 响应命令（全量复制）带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。</li>\n</ul>\n</li>\n<li>第二阶段：主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的RDB文件<ul>\n<li>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空</li>\n<li>在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作</li>\n</ul>\n</li>\n<li>第三阶段：主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>优化<ul>\n<li>主从级联模式分担全量复制时的主库压力：主库需要进行两个耗时操作，生成RDB文件和传输RDB文件，如果从库数量过多就会忙于fork子进程生成RDB文件，通过主-从-从模式将主库的压力分担下去，让一些从库不再和主库交互，只和级联的从库进行写操作同步，减轻主库上的压力</li>\n<li>基于长连接的命令传播：主从库完成全量复制后，会一直维护一个网络连接，主库通过这个连接将后续命令同步给从库</li>\n<li>增量复制：主从库间网络断了，2.8之前进行全量复制，2.8之后采用部分增量复制仍需全量同步，4.0版本后进行增量同步<ul>\n<li>repl_backlog_buffer缓冲区：repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置<ul>\n<li>当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区</li>\n<li>主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距</li>\n</ul>\n</li>\n<li>注意事项<ul>\n<li>通过reolid和replid2来判断主从切换的时候，新的master和slave是否曾经属于同一个主库，如果属于可进行增量同步的尝试</li>\n<li>master同步速度必须比slave快，且不能超过环形缓冲区大小，否则还是要进行全量同步操作</li>\n<li>repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致，可以通过调整 repl_backlog_size 这个参数来避免</li>\n<li>一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制</li>\n<li>每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"3-哨兵机制\"><a href=\"#3-哨兵机制\" class=\"headerlink\" title=\"3.哨兵机制\"></a><strong>3.哨兵机制</strong></h3><ol>\n<li><p>哨兵机制：在Redis主从集群中，实现主从库自动切换的机制，有效地解决了三个问题（主库判活、从库升级为主库、新主库同步消息到从库和客户端），即监控、选主和通知三个任务</p>\n<ul>\n<li>监控：哨兵在运行时周期性的给所有的主从库发送PING命令，检测他们是否仍在运行，如果从库规定时间内没响应，则标记为下线状态（主观下线）；如果主库规定时间内也没有响应，则开始自动切换主库的流程（主观下线）<ul>\n<li>客观下线：主观下线如果是误判（网络压力大、主库压力大），会产生额外的通信和计算开销，所以选择多哨兵实例的哨兵集群的方式来减少误判率</li>\n<li>客观下线的标准：当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”，但是这个数量标准可以通过设置来指定</li>\n<li>哨兵领导者：哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换</li>\n</ul>\n</li>\n<li>选主：在已有从库中，通过一定的规则（筛选+打分）选择一个从库实例，将其升级为主库<ul>\n<li>筛选<ul>\n<li>判断从库的当前在线状态：从库仍在运行</li>\n<li>判断之前的网络状态：使用配置项down-after-milliseconds * 10，down-after-milliseconds是从库断连的最大连接超时时间，如果down-after-milliseconds内从库都没有连接上则认为主从节点断连，如果从库从运行到现在一共断连次数超过10次，则认为从库网络状况不好（在sentinel.conf中配置）</li>\n</ul>\n</li>\n<li>打分：按照三个规则依次打分（从库优先级、从库复制进度以及从库 ID 号），只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。<ul>\n<li>第一轮：优先级最高的从库得分高，通过 slave-priority 配置项配置</li>\n<li>第二轮：和旧主库同步程度最接近的从库得分高，repl_backlog_buffer缓冲区的位置，主为master_repl_offset，副为slave_repl_offset，选择复制最快的（选slave_repl_offset最大的）</li>\n<li>第三轮：ID 号小的从库得分高，每个实例都会有一个 ID，类似于从库的编号</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>通知：在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让他们执行repliicaof命令，和新主库建立连接并进行数据复制。同时，哨兵还会把新主库的连接信息发送给客户端，让它们把请求操作发到新主库上<ul>\n<li>通知客户端：哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端</li>\n<li>如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。 所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>哨兵集群</p>\n<ul>\n<li><p>基于 pub/sub 机制的哨兵集群组成：不同哨兵通过___sentine__:hello频道来相互发现、实现互相通信</p>\n<ul>\n<li>主库和哨兵：哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口</li>\n<li>从库和哨兵：哨兵向主库发送 INFO 命令后可以知道从库的IP地址和端口</li>\n</ul>\n</li>\n<li><p>基于 pub/sub 机制的客户端事件通知</p>\n<ul>\n<li><p>从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件</p>\n</li>\n<li><p>重要频道使用：客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，可以在客户端执行订阅命令（SUBSCRIBE [下面的频道]），来获取不同的事件消息</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/4e9665694a9565abbce1a63cf111f725.jpg\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/4e9665694a9565abbce1a63cf111f725.jpg\"></p>\n</li>\n</ul>\n</li>\n<li><p>由哪个哨兵执行主从切换</p>\n<ul>\n<li>任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票<ul>\n<li>要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds</li>\n</ul>\n</li>\n<li>一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的<ul>\n<li>需要同时满足：拿到半数以上的赞成票（选举Leader），并且票数需要大于quorum值（判读客观下线）</li>\n</ul>\n</li>\n<li>此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader<ul>\n<li>如果一轮投票没选出来Leader，哨兵集群就等待一段时间（哨兵故障转移超时时间的2倍），再重新选举</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>相关问题：</p>\n<ul>\n<li>哨兵机制能防止脑裂吗<ul>\n<li>master和两个slave节点因网络问题被隔离时，所有写入到master的数据都会丢失（网络恢复后master节点会变为新master的slave）</li>\n<li>解决办法<ul>\n<li>min-replicas-to-write 1：配置写master至少写入的slave数量，0表示关闭此功能，3个节点的情况下，可以配置为1</li>\n<li>min-replicas-max-lag 10：配制master多长时间无法得到从节点的响应，就认为这个节点失联，失联则停止新的写入命令请求</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Raft协议</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-高可扩展\"><a href=\"#3-高可扩展\" class=\"headerlink\" title=\"3.高可扩展\"></a><strong>3.高可扩展</strong></h2><h3 id=\"1-数据分片\"><a href=\"#1-数据分片\" class=\"headerlink\" title=\"1.数据分片\"></a><strong>1.数据分片</strong></h3><ol>\n<li>单实例：使用RDB进行持久化时，fork子进程的用时与Redis数据量是正相关的，所以采用切片/分片集群，同时启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分为多份，每一份用一份实例来保存<ul>\n<li>Redis在单机情况下支持多个数据库（同一个访问密码，FLUSHALL可以同时清空所有数据），每个数据库对外都是一个从0开始的递增数字命名，Redis默认支持16个数据库。并且可以随时使用SELECT命令更换数据库</li>\n</ul>\n</li>\n<li>Redis Cluster：用于实现切片集群的方案，方案中规定了数据分片和实例的对应关系<ul>\n<li>哈希槽：一个切片集群共有16384个哈希槽，根据键值对的key，按照CEC16算法计算一个16bit的值，然后与16384取模确定对应的哈希槽。哈希槽默认被均分到Redis实例上，也可以通过命令来配置（cluster meet、cluster addslots）<ul>\n<li>为什么Redis Cluster的哈希槽是16384个：CRC16算法可以产生16位（65536），但是只用了14位（16384）<ul>\n<li>通过bitmap来维护哈希槽信息，如果该位为1，则表示这个哈希槽属于这个节点，哈希槽长度为2048（16384/8）。哈希槽总数越少，bitmap填充率越小，压缩效果越好</li>\n<li>正常的心跳包会携带一个节点的完整配置，也就是说会包含当前节点负责的哈希槽的信息，如果是65536则需要8k的空间，内存占用过高</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>客户端如何定位数据所在实例<ul>\n<li>Redis会把自己的哈希槽发给和他相连接的其他实例，来完成哈希槽分配信息的扩散，客户端会把哈希槽信息缓存在本地</li>\n<li>变化：集群中增减Redis实例、为了负载均衡重新划分，重新划分完后实例间使用上面的方式扩散信息</li>\n</ul>\n</li>\n<li>重定向<ul>\n<li>当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回MOVED命令响应结果，这个结果中就包含了新实例的访问地址</li>\n<li>数据迁移过程中的请求：如果不在本地，则返回ASK报错信息返回新地址，客户端给新地址发送ASKING命令在发送数据请求命令（如果不发ASKING直接请求则会报错，因为新实例上还没有管理这个槽位）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Gossip协议：Redis Cluster中的节点的通信方式，cluster.h定义了所有消息类型和消息结构</li>\n</ol>\n<h3 id=\"2-负载均衡\"><a href=\"#2-负载均衡\" class=\"headerlink\" title=\"2.负载均衡\"></a><strong>2.负载均衡</strong></h3><h2 id=\"补充\"><a href=\"#补充\" class=\"headerlink\" title=\"补充\"></a>补充</h2><ol>\n<li>Redis阻塞的9种情况<ol>\n<li>命令阻塞：使用复杂度为O(n)的命令，由于n过大导致客户端阻塞，常见命令如下<ul>\n<li>keys * ：获取所有的 key 操作</li>\n<li>Hgetall：返回哈希表中所有的字段和</li>\n<li>smembers：返回集合中的所有成员</li>\n</ul>\n</li>\n<li>SAVE阻塞：Redis在达到sava配置中的触发条件时，会进行RDB快照，调用fork函数完成临时文件的写入；但是手动执行save命令会在主线程中执行，阻塞主线程</li>\n<li>AOF相关<ul>\n<li>同步持久化：当Redis直接记录AOF日志时，如果有大量的写操作，并且配置为同步持久化（appendfsync always），则会因为写磁盘操作耗时，阻塞主线程</li>\n<li>AOF重写：fork出子线程后，Reds会维护一个AOF重写缓冲区用来记录创建新AOF文件期间的所有写命令，创建完AOF文件后会将缓冲区内容追加到新AOF文件末尾时会产生阻塞</li>\n<li>AOF日志：AOF日志采用先执行命令后记录日志，减少了命令的检查开销，但是因为AOF日志在主线程执行，所以AOF日志写入磁盘时会因磁盘写压力大而阻塞后续操作</li>\n</ul>\n</li>\n<li>大key问题<ul>\n<li>大key：不是指key大，而是key对应的value很大，大 key 造成的阻塞问题如下：<ul>\n<li>客户端超时阻塞：由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>\n<li>引发网络阻塞：每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>\n<li>阻塞工作线程：如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>\n</ul>\n</li>\n<li>查找大key：在从节点上使用<code>--bigkeys</code>参数查找大 key、使用 SCAN 命令来查找大 key、通过分析 RDB 文件来找出 big key（前提是 Redis 采用的是 RDB 持久化，开源工具有<code>rdb_bigkeys</code>）</li>\n<li>删除大key：<ul>\n<li>释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，<strong>操作系统需要把释放掉的内存块插入一个空闲内存块的链表</strong>，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会<strong>阻塞</strong>当前释放内存的应用程序</li>\n<li>所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis <strong>主线程的阻塞</strong>，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常</li>\n<li>删除大 key 时建议采用分批次删除和异步删除的方式进行。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>清空数据库：清空数据库和上面bigkey删除也是同样道理，flushdb、flushall 也涉及到删除和释放所有的键值对，也是 Redis 的阻塞点</li>\n<li>集群扩容：Redis集群可以进行节点的动态扩缩容，为了保证迁移的一致性，迁移的所有操作都是同步操作。执行迁移时，两端的 Redis 均会进入时长不等的阻塞状态，对于小Key，该时间可以忽略不计，但如果一旦 Key 的内存使用过大，严重的时候会触发集群内的故障转移，造成不必要的切换</li>\n</ol>\n</li>\n<li></li>\n</ol>\n","feature":true,"text":"Redis Redis是一个高性能（内存+Reactor+优化的数据结构）的开源键值数据库，其value支持丰富的数据类型（string、hash、set、list、zset「有序集合」），具有数据可持久化、支持master-slave备份、读写性能高（MySQL的QPS大概1w...","link":"","photos":[],"count_time":{"symbolsCount":"20k","symbolsTime":"18 mins."},"categories":[],"tags":[{"name":"database","slug":"database","count":2,"path":"api/tags/database.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Redis\"><span class=\"toc-text\">Redis</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E9%AB%98%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">1.高性能</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">1.数据结构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%92%8Cepoll%E7%BD%91%E7%BB%9C%E6%A1%86%E6%9E%B6\"><span class=\"toc-text\">2.线程模型和epoll网络框架</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86\"><span class=\"toc-text\">3.内存管理</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-%E9%AB%98%E5%8F%AF%E9%9D%A0\"><span class=\"toc-text\">2.高可靠</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96\"><span class=\"toc-text\">1.数据持久化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6\"><span class=\"toc-text\">2.主从复制</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">3.哨兵机制</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-%E9%AB%98%E5%8F%AF%E6%89%A9%E5%B1%95\"><span class=\"toc-text\">3.高可扩展</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87\"><span class=\"toc-text\">1.数据分片</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1\"><span class=\"toc-text\">2.负载均衡</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%A1%A5%E5%85%85\"><span class=\"toc-text\">补充</span></a></li></ol></li></ol>","author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"IO模型","uid":"5df101b423a7ec5d76d6e555835fbe7b","slug":"IO模型","date":"2023-05-04T07:19:59.000Z","updated":"2023-05-04T07:48:57.379Z","comments":true,"path":"api/articles/IO模型.json","keywords":null,"cover":null,"text":"IO模型1.IO多路复用2.Java的IO模型3.其它1.Redis的IO模型2.Nginx的IO模型3.","link":"","photos":[],"count_time":{"symbolsCount":53,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}