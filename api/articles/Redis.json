{"title":"Redis","uid":"a978a5e93d8e6628e9f4ee713be55be8","slug":"Redis","date":"2023-05-04T10:00:34.000Z","updated":"2023-08-05T12:24:23.474Z","comments":true,"path":"api/articles/Redis.json","keywords":null,"cover":[],"content":"<h1 id=\"Redis\"><a href=\"#Redis\" class=\"headerlink\" title=\"Redis\"></a>Redis</h1><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Redis是一个<strong>高性能</strong>（内存+Reactor+优化的数据结构）的开源键值数据库，其value支持丰富的<strong>数据类型</strong>（string、hash、set、list、zset「有序集合」），具有数据<strong>可持久化</strong>（AOF+RDB）、支持master-slave备份、读写性能高（MySQL的QPS大概1w左右，Redis读11w次/s，写8w次/s）等特点，其单个操作是<strong>原子性</strong>的，多个连续操作支持事务，常用于<strong>缓存，消息队列、分布式锁等场景</strong></p></blockquote>\n<h2 id=\"1-高性能\"><a href=\"#1-高性能\" class=\"headerlink\" title=\"1.高性能\"></a>1.<strong>高性能</strong></h2><h3 id=\"1-数据结构\"><a href=\"#1-数据结构\" class=\"headerlink\" title=\"1.数据结构\"></a><strong>1.数据结构</strong></h3><ol>\n<li><p>数据类型及其应用</p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>简介</th>\n<th>特性</th>\n<th>场景</th>\n<th>大小</th>\n<th>底层数据结构</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>String</td>\n<td>二进制安全</td>\n<td>可以包含任何数据（字符串、整数、浮点数、图片的base64编码、序列化后的对象）</td>\n<td>1.存储数据；2.计数（单位时间请求数，单位时间访问数）</td>\n<td>一个键最大能存储 512MB</td>\n<td>SDS（简单动态字符串）</td>\n</tr>\n<tr>\n<td>Hash</td>\n<td>键值对集合,即编程语言中的Map类型</td>\n<td>适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)</td>\n<td>1.存储、读取、修改用户属性；2.对象数据存储（用户信息、文章信息、购物车信息）</td>\n<td>每个 hash 可以存储 2^32 -1 键值对（4294967295）</td>\n<td>LinkedLIst ZipList</td>\n</tr>\n<tr>\n<td>List</td>\n<td>链表(双向链表)，按照插入顺序排序</td>\n<td>增删快，提供了操作某一段元素的API（没法用来做排行榜，分页显示时会有串行的问题，使用Sorted Set的score可以解决）</td>\n<td>1、最新消息排行等功能(比如朋友圈的时间线) 2、消息队列</td>\n<td>列表最多可存储 2^32 - 1 元素（4294967295）</td>\n<td>ZipList HashTable；3.2后使用QuickList</td>\n</tr>\n<tr>\n<td>Set</td>\n<td>哈希表实现，元素不重复，可以求交集、并集、差集</td>\n<td>1、添加、删除、查找的复杂度都是O(1) ；2、为集合提供了求交集、并集、差集等操作；3、数据量大时可以选择一个从库</td>\n<td>1、共同好友 2、利用唯一性，统计访问网站的所有独立ip 3、好友推荐时，根据tag求交集，大于某个阈值就可以推荐</td>\n<td>集合中最大的成员数为 2^32 - 1（4294967295）</td>\n<td>ZipList Intset</td>\n</tr>\n<tr>\n<td>ZSet（Sorted Set）</td>\n<td>将Set中的元素增加一个权重参数score,元素按score有序排列</td>\n<td>数据插入集合时，已经进行天然排序。类似于Set，但是多了一个权重参数score，使得集合中的元素能够按score进行有序排列，还可以通过score的范围来获取元素的列表</td>\n<td>1、排行榜 2、带权重的消息队列</td>\n<td>—</td>\n<td>ZipList SkipList</td>\n</tr>\n<tr>\n<td>Bitmap</td>\n<td>位存储，支持按位与、或、异或</td>\n<td>存储连续的二进制数字，可以看成是存储0/1的数组，数组下标称为offset（活跃用户统计）</td>\n<td>1、用来做二值统计（元素的取值只有0和1），如签到统计</td>\n<td>GETBIT、SETBIT、BITCOUNT</td>\n<td>String（底层为二进制字节数组）</td>\n</tr>\n<tr>\n<td>HyperLogLogs</td>\n<td>基数统计，元素数量多时仍可保证消耗的空间是固定的</td>\n<td>基数计数概率算法为了节省内存并不会直接存储元数据，而是通过一定的概率统计方法预估基数值（集合中包含元素的个数）</td>\n<td>主要用于数据量巨大的计数场景（热门网站每日访问ip数统计），只存估计值</td>\n<td>HyperLogLogs只需要12KB内存，可以计算接近 2^64 个元素的基数</td>\n<td>基于概率进行统计，给出的结果有偏差</td>\n</tr>\n<tr>\n<td>Geospatial</td>\n<td>地理位置</td>\n<td>基于Sorted Set实现，将经纬度信息通过GeoHash算法转换成一个整数，将这个整数作为Sorted Set的score使用（实现附近的人功能）</td>\n<td>主要用于存储地理位置信息</td>\n<td>GEOADD、GEORADIUS（根据输入的经纬度，查找以这个经纬度为中心的一定范围内的其他元素）</td>\n<td>Sorted Set + GeoHash编码（二分区间、区间编码）</td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>Hash 类型底层结构什么时候使用压缩列表</p>\n<ul>\n<li>Hash 集合中写入的元素个数超过了<code>hash-max-ziplist-entries</code>，或者写入的单个元素大小超过了<code>hash-max-ziplist-value</code>，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表</li>\n<li>一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了</li>\n</ul>\n</li>\n<li><p>补充数据结构</p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>简介</th>\n<th>特性</th>\n<th>API</th>\n<th>底层原理</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RedisTimeSeries</td>\n<td>记录时间序列数据</td>\n<td>支持直接在Redis实例上进行聚合计算（求平均、最值、和），其它方案都需要传输数据到客户端上进行聚合计算</td>\n<td>TS.CREATE；TS.ADD；TS.GET；TS.MGET；TS.RANGE（av g、max/min、sum）</td>\n<td>Redis的扩展模块，使用前需要编译成动态链接库 redistimeseries.so，再使用 loadmodule 命令进行加载</td>\n</tr>\n<tr>\n<td>Streams</td>\n<td>专门为消息队列设计的数据类型</td>\n<td>消息格式是键值对形式，插入的每一条消息自动生成一个全局唯一ID，读取时可以指定读取起始位置。支持创建消费组</td>\n<td>XADD、XREAD、XREADGROUP、SPENDING、XACK</td>\n<td>自动使用内部队列留存消费者读取的消息直到消费者使用SACK命令，重启时使用命令XPENDING继续处理</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>自定义数据类型</p>\n<ul>\n<li>RedisObject<ul>\n<li>type：表示值的类型，涵盖了前面学习的五大基本类型</li>\n<li>encoding：是值的编码方式，用来表示 Redis 中实现各个基本类型的底层数据结构，例如 SDS、压缩列表、哈希表、跳表等</li>\n<li>lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对</li>\n<li>refcount：记录了对象的引用计数</li>\n<li>*ptr：是指向数据的指针，借助*ptr指针，就可以指向不同的数据类型</li>\n</ul>\n</li>\n<li>定义一个新的数据类型的步骤（未完待续）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>数据结构对应命令</p>\n<ul>\n<li><p>命令行方式（<a href=\"https://www.runoob.com/redis/redis-tutorial.html%E3%80%81https://redis.io/commands/%EF%BC%89\">https://www.runoob.com/redis/redis-tutorial.html、https://redis.io/commands/）</a></p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>命令</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>string</td>\n<td>SET、GET、EXIST、STRLEN、DEL、MSET、MGET、INCR、DECR、EXPIRE、SETNX、TTL</td>\n</tr>\n<tr>\n<td>list</td>\n<td>LPUSH、LPOP、RPUSH、RPOP、LRANGE（实现分页）、LLEN</td>\n</tr>\n<tr>\n<td>hash</td>\n<td>HSET、HSETNX、HMSET、HGET、HMGET、HGETALL（所有）、HEXIXTS、HDEL、HLEN、HINCRBY（增加多少）</td>\n</tr>\n<tr>\n<td>set</td>\n<td>SADD、SMEMBERS（内容）、SCARD（数量）、SISMEMBER（有无）、求交/并/差集（SINTER、SUNION、SDIFF）、SPOP key count、SRANDMEMBER key count</td>\n</tr>\n<tr>\n<td>zset</td>\n<td>ZADD、ZCARD、ZSCORE、ZINTERSTORE（一共三个）、ZRANGE、ZREVRANGE、ZREVRANK</td>\n</tr>\n<tr>\n<td>key</td>\n<td>SET key value、DEL key、EXISTS key（seconds）、TTL key、TYPE key</td>\n</tr>\n<tr>\n<td>pub/sub</td>\n<td>PUBLISH channel message、SUBSCRIBE channel、UNSUBSCRIBE channel</td>\n</tr>\n<tr>\n<td>事务</td>\n<td>MULTI（开始）、EXEC（执行）、DISCARD（取消）、WATCH、UNWATCH</td>\n</tr>\n<tr>\n<td>其它</td>\n<td>PING、PONG、QUIT、AUTH password、INFO、FLUSHALL、BGSAVE、BGREWRITEAOF</td>\n</tr>\n</tbody></table>\n</li>\n<li><p>使用批量操作减少网络传输</p>\n<ul>\n<li>Redis每条命令都会通过网络与服务器交互，可以使用批量操作命令（mget、hmget），但是在Redis Cluster下无法保证所有key都在同一个hash slot上，但仍个减少网络交互耗时</li>\n<li>对于不支持批量操作的命令，可以用pipeline将一批Redis命令封装成一组（非原子操作），但是需要控制批量传输的元素个数，避免网络传输的数据量大，同前一点一样，在Redis Cluster会有问题</li>\n</ul>\n</li>\n<li><p>Jedis方式（<a href=\"https://redis.io/commands/%EF%BC%89\">https://redis.io/commands/）</a></p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">import redis.clients.jedis.Jedis;\n \n import java.util.List;\n import java.util.Set;\n \n public class redisDemo &#123;\n     public static void main(String[] args) &#123;\n         Jedis jedis &#x3D; new Jedis(&quot;localhost&quot;,6379);\n         &#x2F;&#x2F;ping下，看看是否通的\n &#x2F;&#x2F;        System.out.println(&quot;Server is running: &quot; + jedis.ping());\n         &#x2F;&#x2F;String\n         jedis.set(&quot;foo&quot;, &quot;bar&quot;);\n         String value &#x3D; jedis.get(&quot;foo&quot;);\n         &#x2F;&#x2F;List，双端队列可设置为阻塞获取，可返回&#x2F;删除一个范围内的元素，可通过索引设置元素\n         jedis.lpush(&quot;mylist&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         jedis.rpush(&quot;mylist&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         List&lt;String&gt; mylist &#x3D; jedis.lrange(&quot;mylist&quot;, 0, -1);&#x2F;&#x2F;0表示第一个，-1表示最后一个\n         System.out.println(mylist);\n         &#x2F;&#x2F;Set\n         jedis.sadd(&quot;myset&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\n         jedis.sadd(&quot;myset2&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;);\n         Set&lt;String&gt; setdiff &#x3D; jedis.sdiff(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;差集\n         Set&lt;String&gt; setinter &#x3D; jedis.sinter(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;交集\n         Set&lt;String&gt; sunion &#x3D; jedis.sunion(&quot;myset&quot;, &quot;myset2&quot;);&#x2F;&#x2F;并集\n         &#x2F;&#x2F;Hash\n         jedis.hset(&quot;myhash&quot;, &quot;a&quot;, &quot;b&quot;);\n &#x2F;&#x2F;        jedis.hincrBy(&quot;myhash&quot;, &quot;a&quot;, 1);&#x2F;&#x2F;a的值加1\n         &#x2F;&#x2F;Sorted Set\n         jedis.zadd(&quot;myzset&quot;, 1, &quot;a&quot;);\n         jedis.zadd(&quot;myzset&quot;, 2, &quot;b&quot;);\n         jedis.zadd(&quot;myzset&quot;, 3, &quot;c&quot;);\n         jedis.zlexcount(&quot;myzset&quot;, &quot;-&quot;, &quot;+&quot;);&#x2F;&#x2F;返回有序集合中指定区间内成员的数量\n         jedis.zlexcount(&quot;myzset&quot;, &quot;[b&quot;, &quot;[c&quot;);&#x2F;&#x2F;返回有序集合中指定区间(b到c)内成员的数量\n \n     &#125;\n &#125;</code></pre></li>\n</ul>\n</li>\n<li><p>底层原理</p>\n<ol>\n<li><p>全局哈希：实现从键到值的访问，具体的数据再根据值的类型不同进行不同的查找（默认使用两个全局哈希表）</p>\n<ul>\n<li>哈希冲突解决方法：拉链法，增加next指针，缺点是冲突越多在链上的查找越慢</li>\n<li><code>rehash</code>：增加hash表长度，减少单个桶中的元素数量，rehash的过程包括以下三步<ul>\n<li>给hash表2分配更大的空间</li>\n<li>把hash表1的数据重新映射到hash表2，会产生大量的数据拷贝，导致Redis的线程阻塞，所以使用渐进式rehash<ul>\n<li>Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries</li>\n<li>处理请求：渐进式rehash过程中，使用两个hash表，t1和t2。针对查找操作，先在t1里面查找，如果没找到就去t2里查找；针对插入操作，一律保存到t2里，保证t1数据只减不增</li>\n</ul>\n</li>\n<li>释放hash表1的空间，表1留作下一次rehash使用<ul>\n<li>每个 hash table 都有存着一个 used 字段，每次单步 rehash 完成的时候，最后都会检查老表即  ht[0].used 是否变成了 0，变成 0 后，就说明老的哈希表里已经没有数据了，此时就会去 free 掉老表，交换老表新表的指针，rehashidx 置为 -1，然后就完成了整个 rehash</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/1cc8eaed5d1ca4e3cdbaa5a3d48dfb5f.jpg\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/1cc8eaed5d1ca4e3cdbaa5a3d48dfb5f.jpg\"></p>\n</li>\n<li><p>压缩列表：基于压缩列表实现了List、Hash、Set、Sorted Set，节省了dictEntry数量，好多个值共用一个dictEntry</p>\n<ul>\n<li><p>类似于一个数组，不同之处是在表头有三个字段lbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束</p>\n<ul>\n<li>查找：查找头尾元素复杂度是O(1)，查找其它元素复杂度是O(N)</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230504190132095.png\" alt=\"image-20230504190132095\"></p>\n</li>\n<li><p>节省内存：使用一系列entry保存数据，每个entry包括以下几部分，通过连续存储不使用指针连接来节省指针占用的空间</p>\n<ul>\n<li><p>prev_len，表示前一个 entry 的长度，prev_len 有两种取值情况1 字节或 5 字节</p>\n<ul>\n<li>取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1 字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255 表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时prev_len 取值为 1 字节，否则，就取值为 5 字节</li>\n</ul>\n</li>\n<li><p>len：表示自身长度，4 字节</p>\n</li>\n<li><p>encoding：表示编码方式，1 字节</p>\n</li>\n<li><p>content：保存实际数据</p>\n</li>\n<li><p>代码（byte==B），一个存储Long类型的entry占用1+4+1+8（向上取整为16）字节</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">typedef struct zlentry &#123;\n    unsigned int prevrawlensize; &#x2F;* Bytes used to encode the previous entry len*&#x2F;\n    unsigned int prevrawlen;     &#x2F;* Previous entry len. *&#x2F;\n    unsigned int lensize;        &#x2F;* Bytes used to encode this entry type&#x2F;len.\n                                    For example strings have a 1, 2 or 5 bytes\n                                    header. Integers always use a single byte.*&#x2F;\n    unsigned int len;            &#x2F;* Bytes used to represent the actual entry.\n                                    For strings this is just the string length\n                                    while for integers it is 1, 2, 3, 4, 8 or\n                                    0 (for 4 bit immediate) depending on the\n                                    number range. *&#x2F;\n    unsigned int headersize;     &#x2F;* prevrawlensize + lensize. *&#x2F;\n    unsigned char encoding;      &#x2F;* Set to ZIP_STR_* or ZIP_INT_* depending on\n                                    the entry encoding. However for 4 bits\n                                    immediate integers this can assume a range\n                                    of values and must be range-checked. *&#x2F;\n    unsigned char *p;            &#x2F;* Pointer to the very start of the entry, that\n                                    is, this points to prev-entry-len field. *&#x2F;\n&#125; zlentry;</code></pre></li>\n</ul>\n</li>\n<li><p>二级编码技巧</p>\n<ul>\n<li>使用集合类型保存单值的键值对，把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value</li>\n<li>以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>跳表</p>\n<ul>\n<li><p>在链表的基础上，增加了多级索引，通过索引位置的几个跳转就可以实现数据的快速定位，查找的复杂度是O(logN)</p>\n</li>\n<li><p>如何设计层高的：跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。</p>\n</li>\n<li><p>示例</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230805135931917.png\" alt=\"image-20230805135931917\"></p>\n</li>\n<li><p>时间复杂度：二叉查找树的时间复杂度是O(logn)，空间复杂度是O(n)；跳表的时间复杂度是O(log_{k}n)，k为跳表索引步长，空间复杂度是O(n)</p>\n</li>\n</ul>\n</li>\n<li><p>String的底层实现</p>\n<ul>\n<li><p>相比于c语言的字符串</p>\n<ul>\n<li>拼接时会先考虑内存空间，防止内存溢出</li>\n<li>使用<code>len</code>保存了当前字符串的长度，计算长度的时间复杂度是O(1)的</li>\n<li>减少内存分配次数：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）</li>\n<li>二进制安全：C 语言中的字符串以空字符<code>\\\\\\\\0</code>作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题</li>\n</ul>\n</li>\n<li><p>String 还是 Hash 存储对象数据更好</p>\n<ul>\n<li>String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合</li>\n<li>String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合</li>\n<li>在绝大部分情况，使用 String 来存储对象数据即可</li>\n</ul>\n</li>\n<li><p>String内存占用：以key和value都为10位的整数为例，key16B、value16B、dictEntry32B，合计64B</p>\n<ul>\n<li><p>针对初始化的长度决定用多少字节的struct（支持1、2、4、8），可以减少内存的使用，数据用<code>char buf[]</code>存储</p>\n</li>\n<li><p>String本身空间占用</p>\n<ul>\n<li><p>int编码：当保存的是 Long 类型整数（8B）时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了</p>\n</li>\n<li><p>embstr编码：当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片</p>\n</li>\n<li><p>raw编码模式：当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230504184903361.png\" alt=\"image-20230504184903361\"></p>\n</li>\n</ul>\n</li>\n<li><p>全局哈希的dictEntry结构</p>\n<ul>\n<li><p>dictEntry结构：key指针、value指针、next指针分别为8B</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230504185718448.png\" alt=\"image-20230504185718448\"></p>\n</li>\n<li><p>Redis的内存分配库jemalloc：分配比所需空间大的最小2次幂走位分配空间，减少分配次数，例如上面的dictEntry结构占用24字节空间</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>zset</p>\n<ul>\n<li>底层实现：<ul>\n<li>如果有序集合的元素个数小于 <code>128</code> 个，并且每个元素的值小于 <code>64</code> 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li>\n<li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li>\n</ul>\n</li>\n<li>范围查询：Redis的ZSet的范围查询命令ZRANGE的时间复杂度是O(log(N)+M)，其中N是有序集合的元素数量，M是返回的元素数量。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"2-线程模型\"><a href=\"#2-线程模型\" class=\"headerlink\" title=\"2.线程模型\"></a><strong>2.线程模型</strong></h3><ol>\n<li><p>单线程机制：多线程机制会带来不必要的开销，出现并行变串行的情况；通过优化（内存上进行操作、高效的数据结构、多路复用机制）单线程提高性能</p>\n<ul>\n<li><p>阻塞点</p>\n<ul>\n<li><p>客户端：网络 IO（多路复用机制优化），键值对增删改查操作（O(N)操作会阻塞，如全量查询、聚合统计），数据库操作</p>\n<ul>\n<li><p><strong>查询</strong>：keys * （获取所有的 key 操作）、Hgetall（返回哈希表中所有的字段和）、smembers（返回集合中所有成员）</p>\n<ul>\n<li>优化：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算</li>\n</ul>\n</li>\n<li><p><strong>bigkey删除</strong>：短时释放大量内存，删除操作需要释放内存，将空闲内存插入到空闲内存块链表，内存块过多会影响链表操作时间，从而造成Redis主线程的阻塞。bigkey删除即删除包含大量元素的集合，其不同类型常见耗时如下：</p>\n<ul>\n<li>优化1：从Redis4.0开始，当集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，建议使用 UNLINK 命令</li>\n<li>优化2：4.0之前，先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230505121117235.png\" alt=\"image-20230505121117235\"></p>\n</li>\n<li><p><strong>清空数据库</strong>：如 FLUSHDB 和 FLUSHALL 操作原理同上bigkey删除</p>\n<ul>\n<li>优化：从Redis4.0开始，可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>磁盘：生成 RDB 快照（子进程），记录 AOF 日志，AOF 日志重写（子进程）</p>\n<ul>\n<li><strong>记录 AOF 日志</strong>：会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是 1～2ms，如果有大量的写操作需要记录在 AOF 日志中，并同步写回的话，就会阻塞主线程</li>\n</ul>\n</li>\n<li><p>主从节点：主库生成、传输 RDB 文件，从库接收 RDB 文件、清空数据库、加载 RDB 文件</p>\n<ul>\n<li><strong>接收RDB文件</strong>：主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了 RDB 文件后，需要使用 FLUSHDB 命令清空当前数据库，这会阻塞主线程</li>\n<li><strong>加载RDB文件</strong>：从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和 RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢<ul>\n<li>优化：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>切片集群实例：向其他实例传输哈希槽信息，数据迁移</p>\n<ul>\n<li>Redsi动态扩缩容时，为保证数据一致性，迁移操作都是同步操作，当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程，一旦有bigkey且内存占用过大时，会触发集群内的故障转移，造成不必要的切换</li>\n</ul>\n</li>\n<li><p><strong>异步子线程机制</strong>：除了查询和加载RDB文件这两个读操作，都可以使用异步子线程机制</p>\n<ul>\n<li>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行</li>\n<li><strong>惰性删除</strong>（Redis4.0）：主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成，数据会在子线程获取任务后才开始删除（使用UNLINK而不是DEL）</li>\n<li><strong>AOF日志的everysec选项</strong>：主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>6.0版本的多线程：为了提高网络IO读写性能，这部分时Redis的一个性能瓶颈，多线程默认是禁用的，不建议开启</p>\n</li>\n<li><p>redis性能变慢的检测方法</p>\n<ul>\n<li><p>基于当前环境下的Redis基线性能判定Redis是否真的变慢（<code>./redis-cli --intrinsic-latency 120    </code>）</p>\n</li>\n<li><p>系统排查及应对方案</p>\n<ul>\n<li><p>自身操作特性：看日志是否有慢查询命令、看是否有key集中过期的情况（EXPIREAT、EXPIRE）、是否存在bigkey、是否在进行自动内存整理</p>\n</li>\n<li><p>操作系统：Redis是内存数据库，操作系统的内存机制会直接影响Redis的内存效率，如swap机制、内存大页机制</p>\n<ul>\n<li><p>触发swap的原因：物理机器内存不足，Redis实例使用了大量内存、机器上其它进程进行读写操作占用内存，解决方法为，增加机器的内存或使用Redis集群</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ redis-cli info | grep process_id\nprocess_id: 5332\n$ cd &#x2F;proc&#x2F;5332\n$cat smaps | egrep &#39;^(Swap|Size)&#39;\nSize: 584 kB #一块内存大小\nSwap: 0 kB #有多少内存被swap到磁盘上\nSize: 4 kB\nSwap: 4 kB\nSize: 462044 kB\nSwap: 462008 kB #出现几百MB时，表明Redis实例的内存压力很大，很可能变慢</code></pre></li>\n<li><p>大量短连接请求：Redis处理大量短连接请求，TCP三次握手和四次挥手也会增加耗时，可以使用长连接操作Redis</p>\n</li>\n<li><p>内存大页机制：持久化时通过写时复制机制保证继续响应请求，即使只改小部分数据也需要拷贝整个大页，影响Redis正常的访存操作，所以一般关闭内存大页机制</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">echo never &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled</code></pre></li>\n</ul>\n</li>\n<li><p>文件系统：Redis会持久化到磁盘，文件系统写磁盘的机制会影响Redis持久化的效率，如AOF模式不同的写回策略会导致不同的延迟（检查配置）</p>\n<ul>\n<li>AOF日志提供了三种日志写回策略no、everysec、always，依赖底层的系统调用write和fsync，后两种写回策略都使用了fsync，但是everysec使用了后台子线程异步完成fsync操作而always没有使用，fsync需要等写回磁盘才返回</li>\n<li>AOF重写会进行大量的IO操作，阻塞fsync操作（等待写完磁盘才返回），主线程虽不等待fsync操作，但是会导致主线程的下一次fsync操作被阻塞（等待上一次的fsync），从而阻塞主线程</li>\n<li>是否运行了 Redis 主从集群，如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>基于多路复用的高性能I/O模型（epoll网络框架）</p>\n<ul>\n<li>传统做法：阻塞IO模型<ul>\n<li>为了处理一个 Get 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）</li>\n<li>其中的accept、recv操作都是潜在的阻塞点，如果发生阻塞，Redis就不能再响应其它请求</li>\n</ul>\n</li>\n<li>基于多路复用的高性能I/O模型（select/epoll）<ul>\n<li>Redis向内核注册事件和对应的事件回调函数，由内核来同时保存并监听多个套接字（FD）上的连接请求或数据请求，一旦有请求到达，通过select/epoll提供的基于事件的回调机制（不同事件的不同处理函数）来实现。select/epoll在检测到FD上有请求到达时（事件发生），就将对应事件插入到事件队列中，Redis一直在对事件队列进行处理（如调用epoll_wait函数取事件队列的数据），这样就不会阻塞在某一具体的请求上了</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>事务：不支持原子性、不支持回滚、每条命令都与服务器交互，所以不推荐使用Redis的事务</p>\n<ul>\n<li>Redis 可以通过MULTI（开始事务），EXEC（执行事务），DISCARD（取消事务） 和 WATCH 等命令来实现事务功能<ul>\n<li>WATCH 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行</li>\n<li>通过<code>WATCH</code>命令监听指定的 Key，当调用 <code>EXEC</code>命令执行事务时，如果一个被 <code>WATCH</code>命令监视的 Key 被 其他客户端/Session 修改的话，整个事务都不会被执行</li>\n<li>不过，如果 WATCH与 事务在同一个 Session 里，并且被 WATCH监视的 Key 被修改的操作发生在事务内部，这个事务是可以被执行成功</li>\n</ul>\n</li>\n<li>Redis事务不支持原子性：Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）<ul>\n<li>如果事务中使用的命令语法没问题时，可以保证原子性，所以需要严格按照 Redis 的命令规范进行程序开发，并且通过 code review 确保命令的正确性</li>\n</ul>\n</li>\n<li>一致性（支持）：在命令执行错误或 Redis 发生故障的情况下，Redis 事务机制对一致性属性是有保证的<ul>\n<li>实例发生故障时，如果有RDB则可以保证一致性；如果有AOF也可以保证一致</li>\n</ul>\n</li>\n<li>隔离性（支持）<ul>\n<li>并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证</li>\n<li>并发操作在 EXEC 命令后执行，此时，隔离性可以保证</li>\n</ul>\n</li>\n<li>持久性：AOF的三种配置会导致数据丢失、RDB快照间隙宕机也会丢失数据</li>\n<li>除了不满足原子性之外，事务中的每条命令都会与 Redis 服务器进行网络交互，这是比较浪费资源的行为。明明一次批量执行多个命令就可以了，这种操作实在是看不懂。因此，Redis 事务是不建议在日常开发中使用的</li>\n</ul>\n</li>\n<li><p>并发安全性：针对读-改-写操作</p>\n<ul>\n<li><p>原子操作</p>\n<ul>\n<li>方法一：Redis每个命令是原子性的，可以通过把多个操作在 Redis 中实现成一个操作，实现单命令操作<ul>\n<li>如：数据修改涉及读-改-写三个步骤，可以通过INCR/DECR命令可以对数据进行增值 / 减值操作</li>\n</ul>\n</li>\n<li>方法二：使用Lua脚本，用于Redis没有提供原子命令的情况</li>\n</ul>\n</li>\n<li><p>加分布式锁</p>\n<ul>\n<li><p>缺点：将低并发安全性，分布式锁的实现困难</p>\n</li>\n<li><p>单个Redis实现分布式锁</p>\n<ul>\n<li><p>实现：赋予锁变量一个变量名，把这个变量名作为键值对的键，而锁变量的值，则是键值对的值</p>\n</li>\n<li><p>原子操作</p>\n<ul>\n<li>使用SETNX命令实现加锁操作：执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何设置</li>\n<li>释放锁：可以在执行完业务逻辑后，使用 DEL 命令删除锁变量</li>\n</ul>\n</li>\n<li><p>问题</p>\n<ul>\n<li><p>释放失败：给锁加一个过期时间，即使持有锁的客户端发生了异常，无法主动地释放锁，Redis 也会根据锁变量的过期时间，在锁变量过期后，把它删除</p>\n</li>\n<li><p>加锁后被另一客户端误删再创建新锁：区分来自不同客户端的锁操作，让每个客户端给锁变量设置一个唯一值，这里的唯一值就可以用来标识当前操作的客户端</p>\n</li>\n<li><p>优化后的实现</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 加锁, unique_value作为客户端唯一性的标识\n# 使用了 NX 选项，SET 命令只有在键值对不存在时，才会进行设置，否则不做赋值操作\n# PX 10000 则表示 lock_key 会在 10s 后过期，以免客户端在这期间发生异常而无法释放锁\nSET lock_key unique_value NX PX 10000\n\n\n# 释放锁 比较unique_value是否相等，避免误释放，使用的Lua脚本实现的释放锁操作的伪代码\nif redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then\n    return redis.call(&quot;del&quot;,KEYS[1])\nelse\n    return 0\nend\n## 执行上面的脚本\nredis-cli  --eval  unlock.script lock_key , unique_value </code></pre></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>多个Redis实现分布式锁（Redlock）</p>\n<ul>\n<li>算法思路：让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失</li>\n<li>算法执行步骤<ul>\n<li>客户端获取当前时间</li>\n<li>客户端按顺序依次向 N 个 Redis 实例执行加锁操作<ul>\n<li>使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识</li>\n<li>客户端获取锁的总耗时没有超过锁的有效时间</li>\n</ul>\n</li>\n<li>一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时<ul>\n<li>需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>其它</p>\n</li>\n</ol>\n<h3 id=\"3-内存管理\"><a href=\"#3-内存管理\" class=\"headerlink\" title=\"3.内存管理\"></a><strong>3.内存管理</strong></h3><ol>\n<li><p>内存管理</p>\n<ul>\n<li><p>设置过期时间：内存有限，保存所有数据迟早会OOM</p>\n<ul>\n<li>Redis 中除了字符串类型有自己独有设置过期时间的命令 <code>setex</code> 外，其他方法都需要依靠 <code>expire</code> 命令来设置过期时间 。另外， <code>persist</code> 命令可以移除一个键的过期时间</li>\n<li>很多时候业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效，使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多</li>\n</ul>\n</li>\n<li><p>如何判断数据过期（过期字典）</p>\n<ul>\n<li>通过过期字典（可看作hash表）来保存数据过期的时间，过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）</li>\n<li>过期数据的删除策略：Redis采用定期删除+惰性删除，对于漏掉的过期key使用内存淘汰机制<ul>\n<li><strong>惰性删除</strong> ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。</li>\n<li><strong>定期删除</strong> ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响</li>\n</ul>\n</li>\n<li>大量key集中过期的问题<ul>\n<li>给 key 设置随机过期时间</li>\n<li>开启 lazy-free（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程（不建议使用）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Redis 内存淘汰机制：干净数据直接删除，脏数据需要写回数据库</p>\n<ul>\n<li>不进行数据淘汰<ul>\n<li><strong>no-eviction</strong>：==禁止驱逐数据==，也就是说当内存不足以容纳新写入数据时，新写入操作会报错，很少用</li>\n</ul>\n</li>\n<li>在设置了过期时间（EXPIRE命令）的数据中进行淘汰<ul>\n<li><strong>volatile-lru（least recently used）</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰，LRU策略的实现如下：<ul>\n<li>RedisObject 结构来保存数据的，RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳</li>\n<li>并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如 10 个）的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选</li>\n</ul>\n</li>\n<li><strong>volatile-ttl</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li>\n<li><strong>volatile-random</strong>：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li>\n<li><strong>volatile-lfu（4.0版 least frequently used）</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰<ul>\n<li>缓存污染问题：大量不再访问的数据滞留在缓存中，影响应用的性能；所以需要在写满之前就经常淘汰数据</li>\n<li>LFU策略<ul>\n<li>从两个维度筛选并淘汰数据，数据访问的时效性（访问时间离当前时间的远近）和数据的被访问次数</li>\n<li>LFU 缓存策略的优化：在LRU策略基础上，为每个数据增加一个计数器，来统计这个数据的访问次数。筛选时先淘汰访问次数少的，访问次数相同时再淘汰掉距离上一次访问时间更久的数据</li>\n<li>LFU具体实现：把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分，ldt 值（前 16bit，表示数据的访问时间戳）；counter 值（后 8bit，表示数据的访问次数）</li>\n<li>LFU计数规则：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1，可以减慢counter值达到255的速度</li>\n<li>LFU衰减机制：使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以lfu_decay_time值，所得的结果就是数据 counter 要衰减的值</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>在所有数据中进行淘汰<ul>\n<li><strong>allkeys-lru（least recently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（==这个是最常用的==）</li>\n<li><strong>allkeys-random</strong>：从数据集（server.db[i].dict）中任意选择数据淘汰，适用于没有明显冷热数据的情况</li>\n<li><strong>allkeys-lfu（4.0版 least frequently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>内存碎片</p>\n<ul>\n<li><p>产生的原因</p>\n<ul>\n<li>OS的内存分配机制：默认使用jemalloc内存分配器，其按照2的幂次大小来分配内存空间，减少分配次数的情况下产生了内部碎片</li>\n<li>Redis的负载特征：频繁修改 Redis 中的数据，当 Redis 中的某个数据删除时，Redis 通常不会轻易释放内存给操作系统</li>\n</ul>\n</li>\n<li><p>查看内存碎片率（&gt;1.5才需要清理）</p>\n<ul>\n<li>内存碎片率：mem_fragmentation_ratio = used_memory_rss / used_memory</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">redis-cli -p 6379 info | grep mem_fragmentation_ratio</code></pre></li>\n<li><p>如何清理：Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题（之前版本可以直接重启）</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">config set activedefrag yes #启用了自动清理功能\n\n###具体清理\n# 内存碎片占用空间达到 500mb 的时候开始清理\nconfig set active-defrag-ignore-bytes 500mb\n# 内存碎片率大于 1.5 的时候开始清理\nconfig set active-defrag-threshold-lower 50\n\n###减少对Redis性能的影响\n# 内存碎片清理所占用 CPU 时间的比例不低于 20%\nconfig set active-defrag-cycle-min 20\n# 内存碎片清理所占用 CPU 时间的比例不高于 50%\nconfig set active-defrag-cycle-max 50</code></pre></li>\n</ul>\n</li>\n<li><p>缓冲区</p>\n<ul>\n<li><p>用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题，当缓冲区占用的内存超出了设定的上限阈值时，就会出现缓冲区溢出（bigkey/大RDB、处理慢、缓冲区小）</p>\n</li>\n<li><p>客户端输入和输出缓冲区：输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端</p>\n<ul>\n<li><p>输入缓冲区溢出时</p>\n<ul>\n<li>发生场景：写入bigkey、服务端处理请求慢，通过CLIENT LIST命令可以查看客户端的输入缓冲区（qbuf）使用情况</li>\n<li>解决办法：避免客户端写入bigkey、避免Redis主线程阻塞</li>\n</ul>\n</li>\n<li><p>输出缓冲区溢出时</p>\n<ul>\n<li><p>发生场景：返回bigkey、执行了MONITOR命令、缓冲区大小设置不合理</p>\n</li>\n<li><p>MONITOR 命令是用来监测 Redis 执行的，执行后会持续输出监测到的各个命令操作，持续占用输出缓冲区</p>\n</li>\n<li><p>缓冲区大小：与输入缓冲区不同输出缓冲区可以设置大小（<code>client-output-buffer-limit</code>）</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># normal 表示当前设置的是普通客户端，第 1 个 0 设置的是缓冲区大小限制\n# 第 2 个 0 和第 3 个 0 分别表示缓冲区持续写入量限制和持续写入时间限制\nclient-output-buffer-limit normal 0 0 0</code></pre></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>主从集群中的缓冲区</p>\n<ul>\n<li>全量复制：主节点向从节点传输RDB文件时，持续接受客户端发送的写命令请求，并保存在复制缓冲区中，主节点为每一个客户端维护一个复制缓冲区，RDB传输的慢就会导致复制缓冲区溢出，主节点会结束该连接导致全量复制失败<ul>\n<li>建议把主节点的数据量控制在 2~4GB，这样可以让全量同步执行得更快些，避免复制缓冲区累积过多命令</li>\n<li>使用 client-output-buffer-limit 配置项，来设置合理的复制缓冲区大小</li>\n<li>控制从节点数量：主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和</li>\n</ul>\n</li>\n<li>增量复制：主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区（主从同步中的repl_backlog_buffer）中，读取断连期间主节点接收到的写命令，进而进行增量同步<ul>\n<li>环形缓冲区：一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>三种常用的缓存读写策略：旁路缓存、读写穿透、异步缓存</p>\n<ul>\n<li><p>Cache Aside Pattern（旁路缓存）：同时维护db和cache，并且以db的结果为准</p>\n<ul>\n<li><p>读取数据流程</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150159435.png\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150159435.png\"></p>\n</li>\n<li><p>写数据中的问题</p>\n<ul>\n<li><p>正确方式：先更新db，在直接删除cache</p>\n</li>\n<li><p>问题一：在写数据的过程中，可以先删除 cache ，后更新 db 么？</p>\n<ul>\n<li>回答：会有数据不一致的问题，在删除cache和更新db的过程中，如果有请求从db读取，会读到旧数据</li>\n</ul>\n</li>\n<li><p>问题二：在写数据的过程中，先更新 db，后删除 cache 就没有问题了么？</p>\n<ul>\n<li>在请求读取数据后，将新数据写入到缓存这个过程中，如果有请求更新db，那么读取数据的请求插入到cache中的就是旧数据</li>\n</ul>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230505165440909.png\" alt=\"image-20230505165440909\"></p>\n</li>\n</ul>\n</li>\n<li><p>旁路缓存模式的缺陷：</p>\n<ul>\n<li>首次请求数据一定不在cache中：提前缓存热点数据</li>\n<li>写操作比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率<ul>\n<li>数据库和缓存数据强一致场景 ：更新 db 的时候同样更新 cache，不过需要加一个锁/分布式锁来保证更新 cache 的时候不存在线程安全问题</li>\n<li>可以短暂地允许数据库和缓存数据不一致的场景 ：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小</li>\n</ul>\n</li>\n<li>保证缓存和数据库数据的一致性（更新数据库成功，但删除缓存这一步失败的情况）<ul>\n<li><strong>增加 cache 更新重试机制</strong>： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Read/Write Through Pattern（同步直写）：将cache视为主要数据存储，cache服务负责将数据读取和写入db（很少用），对于首次请求不在cache中的问题，可以提前缓存热点数据</p>\n<ul>\n<li><p>写</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150211551.png\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150211551.png\"></p>\n</li>\n<li><p>读</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150231993.png\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/image-20230420150231993.png\"></p>\n</li>\n</ul>\n</li>\n<li><p>Write Behind Pattern（异步缓存写入）</p>\n<ul>\n<li>与读写穿透类似，都是cache负责db的读写，但是读写穿透是同步更新cache和db，而异步缓存写入更新缓存后，不直接更新db，改为异步批量的方式更新db</li>\n<li>开发中很少见，因为会有数据一致性的问题（没写入db就丢失），应用场景主要是消息队列中消息的异步写入磁盘、MySQL的Innodb Buffer Pool机制</li>\n<li>异步缓存写入下db的写性能非常高，非常适合一些数据经常变化又对数据一致性要求不高的场景，比如浏览量、点赞量</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>缓存相关问题</p>\n<ul>\n<li><p>缓存雪崩</p>\n<ul>\n<li>缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力<ul>\n<li>预防机制：构建Redis缓存高可靠集群，如果Redis缓存的主节点故障宕机了，可以进行主从切换</li>\n</ul>\n</li>\n<li>原因一：缓存中有大量数据同时过期，导致大量请求无法得到处理<ul>\n<li>避免给大量的数据设置相同的过期时间，在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数（例如，随机增加 1~3 分钟）</li>\n<li>通过服务降级，来应对缓存雪崩，即针对不同的数据采取不同的处理方式<ul>\n<li>针对非核心数据请求，停止从缓存中查询这些数据，直接返回预定义的信息、空值或错误信息</li>\n<li>针对核心数据请求，仍然允许查询缓存，缓存缺失时继续通过数据库读取</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>原因二：Redis缓存实例发生故障宕机，无法处理请求<ul>\n<li>服务熔断：为了防止连锁的数据库雪崩，暂停应用对缓存系统的接口访问，会影响整个业务应用的运行</li>\n<li>请求限流：只允许通过一小部分请求，避免大量并发请求压力传递到数据库层</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>缓存击穿</p>\n<ul>\n<li>请求的 key 对应的是热点数据，该数据存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期），这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了<ul>\n<li>如：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力</li>\n</ul>\n</li>\n<li>解决办法<ul>\n<li>设置热点数据永不过期或者过期时间比较长</li>\n<li>针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期</li>\n<li>请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>缓存穿透</p>\n<ul>\n<li><p>大量请求的 key 是不合理的，<strong>根本不存在于缓存中，也不存在于数据库中</strong>。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了</p>\n<ul>\n<li>业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据</li>\n<li>恶意攻击：专门访问数据库中没有的数据</li>\n</ul>\n</li>\n<li><p>解决一：做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等</p>\n</li>\n<li><p>解决二：布隆过滤器，非常方便的判断一个给定的数据是否存在于海量数据中</p>\n<ul>\n<li><p>布隆过滤器原理    </p>\n<ul>\n<li>首先，使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值</li>\n<li>然后，我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置</li>\n<li>最后，我们把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作</li>\n</ul>\n</li>\n<li><p>把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程</p>\n</li>\n<li><p>误判：布隆过滤器说存在，则可能不存；但是说不存在则一定不存在</p>\n<ul>\n<li>计算哈希值，将位数组中对应下标设置为1；判断时检查位数组对应值是否是1（不同字符串可能哈希出来的位置相同）</li>\n</ul>\n</li>\n<li><p>使用**<code>docker redis bloomfilter</code>**</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">➜  ~ docker run -p 6379:6379 --name redis-redisbloom redislabs&#x2F;rebloom:latest\n➜  ~ docker exec -it redis-redisbloom bash\nroot@21396d02c252:&#x2F;data# redis-cli\n127.0.0.1:6379&gt;</code></pre></li>\n</ul>\n</li>\n<li><p>解决三：在请求入口的前端进行请求检测，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"2-高可靠\"><a href=\"#2-高可靠\" class=\"headerlink\" title=\"2.高可靠\"></a><strong>2.高可靠</strong></h2><h3 id=\"1-数据持久化\"><a href=\"#1-数据持久化\" class=\"headerlink\" title=\"1.数据持久化\"></a><strong>1.数据持久化</strong></h3><ol>\n<li>AOF<ul>\n<li>写后日志：首先执行命令写入内存，然后再将命令记录到日志中。与传统数据库的写前（WAL）日志相比，避免了额外的检查开销，并且不会阻塞当前的命令（但会阻塞后一条命令）。但是在写入日之前宕机会丢失日志</li>\n<li>写回策略：控制一个写命令执行完后AOF日志写回磁盘的时机，即appendfsync配置项的三个可选值<ul>\n<li><h2 id=\"Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；可以保证不丢失数据，但是回影响主线程性能\"><a href=\"#Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；可以保证不丢失数据，但是回影响主线程性能\" class=\"headerlink\" title=\"Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；可以保证不丢失数据，但是回影响主线程性能\"></a>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；可以保证不丢失数据，但是回影响主线程性能</h2></li>\n<li><h2 id=\"Everysec，每秒写回：每个写命令执行完，只是先把日志写到-AOF-文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘\"><a href=\"#Everysec，每秒写回：每个写命令执行完，只是先把日志写到-AOF-文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘\" class=\"headerlink\" title=\"Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘\"></a>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘</h2></li>\n<li><h2 id=\"No，操作系统控制的写回：每个写命令执行完，只是先把日志写到-AOF-文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘，会有数据丢失的风险\"><a href=\"#No，操作系统控制的写回：每个写命令执行完，只是先把日志写到-AOF-文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘，会有数据丢失的风险\" class=\"headerlink\" title=\"No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘，会有数据丢失的风险\"></a>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘，会有数据丢失的风险</h2></li>\n</ul>\n</li>\n<li>AOF重写机制：防止AOF文件过大，故障恢复时恢复过程缓慢<ul>\n<li>Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入（将多个命令合并成一个命令）</li>\n<li>AOF使用后台子线程bgrewriteaof来完成，避免阻塞主线程：重写时fork出后台bgrewriteaof子线程，通过拷贝父进程的页表的方式共享父进程的内存数据的方式来共享父进程的数据<ul>\n<li>写时复制：避免一次性大量拷贝给子进程造成的长时间阻塞问题，在父进程写入操作是一个已经存在的key时，父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间（否则子进程读完，父进程修改，就会丢失这一次修改的数据）</li>\n</ul>\n</li>\n<li>两次日志写入：在重写过程中，新请求会先写入到原AOF文件的缓冲区中，然后写入到重写日志的缓冲区，在重写机制结束后再合并到AOF重写日志中（但是需要上面的写时复制来保证数据不会丢失修改）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>RDB<ul>\n<li>AOF在故障恢复的时候需要逐一执行命令，恢复时间长，所以提出了RDB内存快照的方式来高效的恢复，提供了两个命令<ul>\n<li>save：在主线程中执行，会导致阻塞</li>\n<li>bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置</li>\n</ul>\n</li>\n<li>写时复制：在执行快照的同时，正常处理写操作<ul>\n<li>由父进程fork出bgsave子进程，然后开始读取主线程的内存数据，并写入到RDB文件中，在主线程有写入请求时，这块数据会被复制一份，然后主线程在数据副本上进行修改，bgsave子进程继续将原来的数据写入RDB文件</li>\n</ul>\n</li>\n<li>优化<ul>\n<li>增量快照：一直做全量快照，虽然bgsave执行时不阻塞主线程，但是会对磁盘造成压力，而且fork操作本身也会阻塞主线程。通过记录修改的元数据信息来做增量快照，但是又会产生大量的额外空间开销</li>\n<li>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照：内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>如何选择 RDB 和 AOF？<ul>\n<li>RDB 比 AOF 优秀的地方<ul>\n<li>RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会必 RDB 文件大很多。当 AOF 变得太大时，Redis 能够在后台自动重写 AOF。新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。不过， Redis 7.0 版本之前，如果在重写期间有写入命令，AOF 可能会使用大量内存，重写期间到达的所有写入命令都会写入磁盘两次。</li>\n<li>使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。</li>\n</ul>\n</li>\n<li>AOF 比 RDB 优秀的地方<ul>\n<li>RDB 的数据安全性不如 AOF，没有办法实时或者秒级持久化数据。生成 RDB 文件的过程是比较繁重的， 虽然 BGSAVE 子进程写入 RDB 文件的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。AOF 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，操作轻量。</li>\n<li>RDB 文件是以特定的二进制格式保存的，并且在 Redis 版本演进中有多个版本的 RDB，所以存在老版本的 Redis 服务不兼容新版本的 RDB 格式的问题。</li>\n<li>AOF 以一种易于理解和解析的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。比如，如果执行<code>FLUSHALL</code>命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态</li>\n</ul>\n</li>\n<li>由于 RDB 和 AOF 各有优势，于是，Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 <code>aof-use-rdb-preamble</code> 开启）。如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"2-主从复制\"><a href=\"#2-主从复制\" class=\"headerlink\" title=\"2.主从复制\"></a><strong>2.主从复制</strong></h3><ol>\n<li>使用主从库模式，通过增加副本冗余量，将一份数据同时保存在多个实例上。主从库之间采用读写分离的方式，主库和从库同时支持读操作，写操作通过主库执行然后同步到从库<ul>\n<li>不采用主从库读写分离：需要加锁或实例间协商的方式完成修改，带来更大的开销</li>\n</ul>\n</li>\n<li>主从库模式的建立<ul>\n<li>启动多个Redis实例时，他们相互之间通过replicaof命令形成主库和从库的关系，按照三个阶段完成第一次同步<ul>\n<li>第一阶段：从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了<ul>\n<li>具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID（实例的随机ID，第一次设置为？）和复制进度offset（-1表示第一次复制）两个参数</li>\n<li>主库收到 psync 命令后，会用 FULLRESYNC 响应命令（全量复制）带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。</li>\n</ul>\n</li>\n<li>第二阶段：主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的RDB文件<ul>\n<li>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空</li>\n<li>在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作</li>\n</ul>\n</li>\n<li>第三阶段：主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>优化<ul>\n<li>主从级联模式分担全量复制时的主库压力：主库需要进行两个耗时操作，生成RDB文件和传输RDB文件，如果从库数量过多就会忙于fork子进程生成RDB文件，通过主-从-从模式将主库的压力分担下去，让一些从库不再和主库交互，只和级联的从库进行写操作同步，减轻主库上的压力</li>\n<li>基于长连接的命令传播：主从库完成全量复制后，会一直维护一个网络连接，主库通过这个连接将后续命令同步给从库</li>\n<li>增量复制：主从库间网络断了，2.8之前进行全量复制，2.8之后采用部分增量复制仍需全量同步，4.0版本后进行增量同步<ul>\n<li>repl_backlog_buffer缓冲区：repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置<ul>\n<li>当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区</li>\n<li>主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距</li>\n</ul>\n</li>\n<li>注意事项<ul>\n<li>通过reolid和replid2来判断主从切换的时候，新的master和slave是否曾经属于同一个主库，如果属于可进行增量同步的尝试</li>\n<li>master同步速度必须比slave快，且不能超过环形缓冲区大小，否则还是要进行全量同步操作</li>\n<li>repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致，可以通过调整 repl_backlog_size 这个参数来避免</li>\n<li>一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制</li>\n<li>每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"3-哨兵机制\"><a href=\"#3-哨兵机制\" class=\"headerlink\" title=\"3.哨兵机制\"></a><strong>3.哨兵机制</strong></h3><ol>\n<li><p>哨兵机制：在Redis主从集群中，实现主从库自动切换的机制，有效地解决了三个问题（主库判活、从库升级为主库、新主库同步消息到从库和客户端），即监控、选主和通知三个任务</p>\n<ul>\n<li>监控：哨兵在运行时周期性的给所有的主从库发送PING命令，检测他们是否仍在运行，如果从库规定时间内没响应，则标记为下线状态（主观下线）；如果主库规定时间内也没有响应，则开始自动切换主库的流程（主观下线）<ul>\n<li>客观下线：主观下线如果是误判（网络压力大、主库压力大），会产生额外的通信和计算开销，所以选择多哨兵实例的哨兵集群的方式来减少误判率</li>\n<li>客观下线的标准：当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”，但是这个数量标准可以通过设置来指定</li>\n<li>哨兵领导者：哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换</li>\n</ul>\n</li>\n<li>选主：在已有从库中，通过一定的规则（筛选+打分）选择一个从库实例，将其升级为主库<ul>\n<li>筛选<ul>\n<li>判断从库的当前在线状态：从库仍在运行</li>\n<li>判断之前的网络状态：使用配置项down-after-milliseconds * 10，down-after-milliseconds是从库断连的最大连接超时时间，如果down-after-milliseconds内从库都没有连接上则认为主从节点断连，如果从库从运行到现在一共断连次数超过10次，则认为从库网络状况不好（在sentinel.conf中配置）</li>\n</ul>\n</li>\n<li>打分：按照三个规则依次打分（从库优先级、从库复制进度以及从库 ID 号），只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。<ul>\n<li>第一轮：优先级最高的从库得分高，通过 slave-priority 配置项配置</li>\n<li>第二轮：和旧主库同步程度最接近的从库得分高，repl_backlog_buffer缓冲区的位置，主为master_repl_offset，副为slave_repl_offset，选择复制最快的（选slave_repl_offset最大的）</li>\n<li>第三轮：ID 号小的从库得分高，每个实例都会有一个 ID，类似于从库的编号</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>通知：在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让他们执行repliicaof命令，和新主库建立连接并进行数据复制。同时，哨兵还会把新主库的连接信息发送给客户端，让它们把请求操作发到新主库上<ul>\n<li>通知客户端：哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端</li>\n<li>如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。 所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>哨兵集群</p>\n<ul>\n<li><p>基于 pub/sub 机制的哨兵集群组成：不同哨兵通过___sentine__:hello频道来相互发现、实现互相通信</p>\n<ul>\n<li>主库和哨兵：哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口</li>\n<li>从库和哨兵：哨兵向主库发送 INFO 命令后可以知道从库的IP地址和端口</li>\n</ul>\n</li>\n<li><p>基于 pub/sub 机制的客户端事件通知</p>\n<ul>\n<li><p>从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件</p>\n</li>\n<li><p>重要频道使用：客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，可以在客户端执行订阅命令（SUBSCRIBE [下面的频道]），来获取不同的事件消息</p>\n<p><img src=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/4e9665694a9565abbce1a63cf111f725.jpg\" alt=\"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/4e9665694a9565abbce1a63cf111f725.jpg\"></p>\n</li>\n</ul>\n</li>\n<li><p>由哪个哨兵执行主从切换</p>\n<ul>\n<li>任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票<ul>\n<li>要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds</li>\n</ul>\n</li>\n<li>一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的<ul>\n<li>需要同时满足：拿到半数以上的赞成票（选举Leader），并且票数需要大于quorum值（判读客观下线）</li>\n</ul>\n</li>\n<li>此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader<ul>\n<li>如果一轮投票没选出来Leader，哨兵集群就等待一段时间（哨兵故障转移超时时间的2倍），再重新选举</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>相关问题：</p>\n<ul>\n<li>哨兵机制能防止脑裂吗<ul>\n<li>master和两个slave节点因网络问题被隔离时，所有写入到master的数据都会丢失（网络恢复后master节点会变为新master的slave）</li>\n<li>解决办法<ul>\n<li>min-replicas-to-write 1：配置写master至少写入的slave数量，0表示关闭此功能，3个节点的情况下，可以配置为1</li>\n<li>min-replicas-max-lag 10：配制master多长时间无法得到从节点的响应，就认为这个节点失联，失联则停止新的写入命令请求</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Raft协议</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-高可扩展\"><a href=\"#3-高可扩展\" class=\"headerlink\" title=\"3.高可扩展\"></a><strong>3.高可扩展</strong></h2><h3 id=\"1-数据分片\"><a href=\"#1-数据分片\" class=\"headerlink\" title=\"1.数据分片\"></a><strong>1.数据分片</strong></h3><ol>\n<li><p>单实例：使用RDB进行持久化时，fork子进程的用时与Redis数据量是正相关的，所以采用切片/分片集群，同时启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分为多份，每一份用一份实例来保存</p>\n<ul>\n<li>Redis在单机情况下支持多个数据库（同一个访问密码，FLUSHALL可以同时清空所有数据），每个数据库对外都是一个从0开始的递增数字命名，Redis默认支持16个数据库。并且可以随时使用SELECT命令更换数据库</li>\n</ul>\n</li>\n<li><p>Redis Cluster：用于实现切片集群的方案，方案中规定了数据分片和实例的对应关系</p>\n<ul>\n<li><p>哈希槽：一个切片集群共有16384个哈希槽，根据键值对的key，按照CEC16算法计算一个16bit的值，然后与16384取模确定对应的哈希槽。哈希槽默认被均分到Redis实例上，也可以通过命令来配置（cluster meet、cluster addslots）</p>\n<ul>\n<li>为什么Redis Cluster的哈希槽是16384个：CRC16算法可以产生16位（65536），但是只用了14位（16384）<ul>\n<li>通过bitmap来维护哈希槽信息，如果该位为1，则表示这个哈希槽属于这个节点，哈希槽长度为2048（16384/8）。哈希槽总数越少，bitmap填充率越小，压缩效果越好</li>\n<li>正常的心跳包会携带一个节点的完整配置，也就是说会包含当前节点负责的哈希槽的信息，如果是65536则需要8k的空间，内存占用过高</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>客户端如何定位数据所在实例</p>\n<ul>\n<li><p>Redis会把自己的哈希槽发给和他相连接的其他实例，来完成哈希槽分配信息的扩散，客户端会把哈希槽信息缓存在本地</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">127.0.0.1:6379&gt; cluster slots\n1) 1) (integer) 0\n   2) (integer) 4095\n   3) 1) &quot;192.168.10.3&quot;\n      2) (integer) 6379\n2) 1) (integer) 12288\n   2) (integer) 16383\n   3) 1) &quot;192.168.10.5&quot;\n      2) (integer) 6379</code></pre></li>\n<li><p>变化：集群中增减Redis实例、为了负载均衡重新划分，重新划分完后实例间使用上面的方式扩散信息</p>\n<ul>\n<li><p>CLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置 Slot 要迁入的目标实例，Slot 要迁出的源实例，以及 Slot 所属的实例</p>\n</li>\n<li><p>CLUSTER GETKEYSINSLOT：获取某个 Slot 中一定数量的 key</p>\n</li>\n<li><p>MIGRATE：把一个 key 从源实例实际迁移到目标实例</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">#假设要把 Slot 300 从源实例（ID 为 3）迁移到目标实例（ID 为 5）\n#第 1 步，我们先在目标实例 5 上执行下面的命令，将 Slot 300 的源实例设置为实例 3，表示要从实例 3 上迁入 Slot 300\nCLUSTER SETSLOT 300 IMPORTING 3\n#第 2 步，在源实例 3 上，我们把 Slot 300 的目标实例设置为 5，这表示，Slot 300 要迁出到实例 5 上，如下所示：\nCLUSTER SETSLOT 300 MIGRATING 5\n#第 3 步，从 Slot 300 中获取 100 个 key。因为 Slot 中的 key 数量可能很多，所以我们需要在客户端上多次执行下面的这条命令，分批次获得并迁移 key。\nCLUSTER GETKEYSINSLOT 300 100\n#第 4 步，我们把刚才获取的 100 个 key 中的 key1 迁移到目标实例 5 上（IP 为 192.168.10.5），同时把要迁入的数据库设置为 0 号数据库，把迁移的超时时间设置为 timeout。我们重复执行 MIGRATE 命令，把 100 个 key 都迁移完。\nMIGRATE 192.168.10.5 6379 key1 0 timeout\n#最后，我们重复执行第 3 和第 4 步，直到 Slot 中的所有 key 都迁移完成。\n\n#从 Redis 3.0.6 开始，你也可以使用 KEYS 选项，一次迁移多个 key（key1、2、3），这样可以提升迁移效率。\nMIGRATE 192.168.10.5 6379 &quot;&quot; 0 timeout KEYS key1 key2 key3</code></pre></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>重定向</p>\n<ul>\n<li>当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回MOVED命令响应结果，这个结果中就包含了新实例的访问地址</li>\n<li>数据迁移过程中的请求：如果不在本地，则返回ASK报错信息返回新地址，客户端给新地址发送ASKING命令在发送数据请求命令（如果不发ASKING直接请求则会报错，因为新实例上还没有管理这个槽位）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Gossip协议：Redis Cluster中的节点的通信方式，cluster.h定义了所有消息类型和消息结构</p>\n<ul>\n<li><p>Gossip 协议的工作原理可以概括成两点</p>\n<ul>\n<li>每个实例之间会按照一定的频率，从集群中随机挑选一些实例，把 PING 消息发送给挑选出来的实例，用来检测这些实例是否在线，并交换彼此的状态信息。PING 消息中封装了发送消息的实例自身的状态信息、部分其它实例的状态信息，以及 Slot 映射表</li>\n<li>一个实例在接收到 PING 消息后，会给发送 PING 消息的实例，发送一个 PONG 消息。PONG 消息包含的内容和 PING 消息一样</li>\n</ul>\n</li>\n<li><p>Gossip 消息大小：clusterMsgDataGossip * 集群中实例个数 + 16384bit的Bitmap（slot信息）</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">typedef struct &#123;\n    char nodename[CLUSTER_NAMELEN];  &#x2F;&#x2F;40字节\n    uint32_t ping_sent; &#x2F;&#x2F;4字节\n    uint32_t pong_received; &#x2F;&#x2F;4字节\n    char ip[NET_IP_STR_LEN]; &#x2F;&#x2F;46字节\n    uint16_t port;  &#x2F;&#x2F;2字节\n    uint16_t cport;  &#x2F;&#x2F;2字节\n    uint16_t flags;  &#x2F;&#x2F;2字节\n    uint32_t notused1; &#x2F;&#x2F;4字节\n&#125; clusterMsgDataGossip; &#x2F;&#x2F;104字节 一个实例状态信息大小</code></pre></li>\n<li><p>实例间通信频率</p>\n<ul>\n<li>Redis Cluster 的实例启动后，默认会每秒从本地的实例列表中随机选出 5 个实例，再从这 5 个实例中找出一个最久没有通信的实例，把 PING 消息发送给该实例。这是实例周期性发送 PING 消息的基本做法</li>\n<li>为了避免有实例一直没有被发送PING信息：Redis Cluster 的实例会按照每 100ms 一次的频率，扫描本地的实例列表，如果发现有实例最近一次接收 PONG 消息的时间，已经大于配置项 cluster-node-timeout 的一半了（cluster-node-timeout/2），就会立刻给该实例发送 PING 消息，更新这个实例上的集群状态信息</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"2-负载均衡\"><a href=\"#2-负载均衡\" class=\"headerlink\" title=\"2.负载均衡\"></a><strong>2.负载均衡</strong></h3><h2 id=\"附录\"><a href=\"#附录\" class=\"headerlink\" title=\"附录\"></a>附录</h2><ol>\n<li><p>如何使用慢查询日志和 latency monitor 排查执行慢的操作（也可以使用监控工具latency monitor）</p>\n<ul>\n<li><p>设置参数</p>\n<ul>\n<li>slowlog-log-slower-than：慢查询日志对执行时间大于多少微秒的命令进行记录</li>\n<li>slowlog-max-len：慢查询日志最多能记录多少条命令记录（队列）</li>\n</ul>\n</li>\n<li><p>使用SLOWLOG GET命令查看慢查询日志中记录的命令操作</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">SLOWLOG GET 1\n1) 1) (integer) 33           &#x2F;&#x2F;每条日志的唯一ID编号\n   2) (integer) 1600990583   &#x2F;&#x2F;命令执行时的时间戳\n   3) (integer) 20906        &#x2F;&#x2F;命令执行的时长，单位是微秒\n   4) 1) &quot;keys&quot;               &#x2F;&#x2F;具体的执行命令和参数\n      2) &quot;abc*&quot;\n   5) &quot;127.0.0.1:54793&quot;      &#x2F;&#x2F;客户端的IP和端口号\n   6) &quot;&quot;                     &#x2F;&#x2F;客户端的名称，此处为空</code></pre></li>\n</ul>\n</li>\n<li><p>如何排查Redis的bigkey：<code>./redis-cli  --bigkeys</code></p>\n<ul>\n<li>在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行</li>\n<li>可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能</li>\n<li>缺点：只能返回最大的那个bigkey，只统计个数不统计实际占用的内存量</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ .&#x2F;redis-cli  --bigkeys\n\n-------- summary -------\nSampled 32 keys in the keyspace!\nTotal key length in bytes is 184 (avg len 5.75)\n\n&#x2F;&#x2F;统计每种数据类型中元素个数最多的bigkey\nBiggest   list found &#39;product1&#39; has 8 items\nBiggest   hash found &#39;dtemp&#39; has 5 fields\nBiggest string found &#39;page2&#39; has 28 bytes\nBiggest stream found &#39;mqstream&#39; has 4 entries\nBiggest    set found &#39;userid&#39; has 5 members\nBiggest   zset found &#39;device:temperature&#39; has 6 members\n\n&#x2F;&#x2F;统计每种数据类型的总键值个数，占所有键值个数的比例，以及平均大小\n4 lists with 15 items (12.50% of keys, avg size 3.75)\n5 hashs with 14 fields (15.62% of keys, avg size 2.80)\n10 strings with 68 bytes (31.25% of keys, avg size 6.80)\n1 streams with 4 entries (03.12% of keys, avg size 4.00)\n7 sets with 19 members (21.88% of keys, avg size 2.71)\n5 zsets with 17 members (15.62% of keys, avg size 3.40)</code></pre></li>\n<li><p>bigkey如何解决</p>\n<ul>\n<li><strong>对大Key进行拆分：</strong>例如将含有数万成员的一个HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围</li>\n<li><strong>对大Key进行清理：</strong>将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。注意，要使用异步删除。<ul>\n<li>优化1：从Redis4.0开始，当集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，建议使用 UNLINK 命令</li>\n<li>优化2：4.0之前，先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞</li>\n</ul>\n</li>\n<li><strong>监控Redis的内存水位：</strong>可以通过监控系统设置合理的Redis内存报警阈值进行提醒，例如Redis内存使用率超过70%、Redis的内存在1小时内增长率超过20%等</li>\n<li><strong>对过期数据进行定期清：</strong>堆积大量过期数据会造成大Key的产生，例如在HASH数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。可以通过定时任务的方式对失效数据进行清理</li>\n</ul>\n</li>\n<li><p>hotkey：</p>\n<ul>\n<li>定义<ul>\n<li>QPS集中在特定的Key：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。</li>\n<li>带宽使用率集中在特定的Key：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的<strong>HGETALL</strong>操作请求。</li>\n<li>CPU使用时间占比集中在特定的Key：对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的<strong>ZRANGE</strong>操作请求。</li>\n</ul>\n</li>\n<li>如何解决<ul>\n<li>在Redis集群架构中对热Key进行复制。在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力</li>\n<li>使用读写分离架构。如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>整合Spring</p>\n<ol>\n<li><p>添加依赖、新增Spring下Redis的配置文件</p>\n<pre class=\"line-numbers language-markup\" data-language=\"markup\"><code class=\"language-markup\"># Spring节点下\nredis:\n    host: localhost # Redis服务器地址\n    database: 0 # Redis数据库索引（默认为0）\n    port: 6379 # Redis服务器连接端口\n    password: # Redis服务器连接密码（默认为空）\n    jedis: #Redis的Java客户端\n      pool:\n        max-active: 8 # 连接池最大连接数（使用负值表示没有限制）\n        max-wait: -1ms # 连接池最大阻塞等待时间（使用负值表示没有限制）\n        max-idle: 8 # 连接池中的最大空闲连接\n        min-idle: 0 # 连接池中的最小空闲连接\n    timeout: 3000ms # 连接超时时间（毫秒）</code></pre></li>\n<li><p>添加<code>RedisService</code>和<code>RedisServiceImpl</code>（注入<code>StringRedisTemplate</code>（继承自<code>RedisTemplate</code>））</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">public interface RedisService &#123;\n    &#x2F;**\n     * 存储数据\n     *&#x2F;\n    void set(String key, String value);\n\n    &#x2F;**\n     * 获取数据\n     *&#x2F;\n    String get(String key);\n\n    &#x2F;**\n     * 设置超期时间\n     *&#x2F;\n    boolean expire(String key, long expire);\n\n    &#x2F;**\n     * 删除数据\n     *&#x2F;\n    void remove(String key);\n\n    &#x2F;**\n     * 自增操作\n     * @param delta 自增步长\n     *&#x2F;\n    Long increment(String key, long delta);\n\n&#125;\n\n@Service\npublic class RedisServiceImpl implements RedisService &#123;\n    @Autowired\n    private StringRedisTemplate stringRedisTemplate;\n\n    @Override\n    public void set(String key, String value) &#123;\n        stringRedisTemplate.opsForValue().set(key, value);\n    &#125;\n\n    @Override\n    public String get(String key) &#123;\n        return stringRedisTemplate.opsForValue().get(key);\n    &#125;\n\n    @Override\n    public boolean expire(String key, long expire) &#123;\n        return stringRedisTemplate.expire(key, expire, TimeUnit.SECONDS);\n    &#125;\n\n    @Override\n    public void remove(String key) &#123;\n        stringRedisTemplate.delete(key);\n    &#125;\n\n    @Override\n    public Long increment(String key, long delta) &#123;\n        return stringRedisTemplate.opsForValue().increment(key,delta);\n    &#125;\n&#125;</code></pre></li>\n<li><p>在CRUD代码中，通过注入<code>redisService</code>，来实现缓存功能</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">@Service\npublic class UmsMemberServiceImpl implements UmsMemberService &#123;\n    @Autowired\n    private RedisService redisService;\n    @Value(&quot;$&#123;redis.key.prefix.authCode&#125;&quot;)\n    private String REDIS_KEY_PREFIX_AUTH_CODE;\n    @Value(&quot;$&#123;redis.key.expire.authCode&#125;&quot;)\n    private Long AUTH_CODE_EXPIRE_SECONDS;\n\n    @Override\n    public CommonResult generateAuthCode(String telephone) &#123;\n        StringBuilder sb &#x3D; new StringBuilder();\n        Random random &#x3D; new Random();\n        for (int i &#x3D; 0; i &lt; 6; i++) &#123;\n            sb.append(random.nextInt(10));\n        &#125;\n        &#x2F;&#x2F;验证码绑定手机号并存储到redis\n        redisService.set(REDIS_KEY_PREFIX_AUTH_CODE + telephone, sb.toString());\n        redisService.expire(REDIS_KEY_PREFIX_AUTH_CODE + telephone, AUTH_CODE_EXPIRE_SECONDS);\n        return CommonResult.success(sb.toString(), &quot;获取验证码成功&quot;);\n    &#125;\n\n\n    &#x2F;&#x2F;对输入的验证码进行校验\n    @Override\n    public CommonResult verifyAuthCode(String telephone, String authCode) &#123;\n        if (StringUtils.isEmpty(authCode)) &#123;\n            return CommonResult.failed(&quot;请输入验证码&quot;);\n        &#125;\n        String realAuthCode &#x3D; redisService.get(REDIS_KEY_PREFIX_AUTH_CODE + telephone);\n        boolean result &#x3D; authCode.equals(realAuthCode);\n        if (result) &#123;\n            return CommonResult.success(null, &quot;验证码校验成功&quot;);\n        &#125; else &#123;\n            return CommonResult.failed(&quot;验证码不正确&quot;);\n        &#125;\n    &#125;\n\n&#125;</code></pre></li>\n</ol>\n</li>\n<li><p>分布式锁</p>\n<ol>\n<li><p>四个特性</p>\n<ul>\n<li><strong>互斥性</strong>：锁的目的是获取资源的使用权，所以只让一个竞争者持有锁，这一点要尽可能保证；</li>\n<li><strong>安全性</strong>：避免死锁情况发生。当一个竞争者在持有锁期间内，由于意外崩溃而导致未能主动解锁，其持有的锁也能够被正常释放，并保证后续其它竞争者也能加锁；</li>\n<li><strong>对称性</strong>：同一个锁，加锁和解锁必须是同一个竞争者。不能把其他竞争者持有的锁给释放了，这又称为锁的可重入性。</li>\n<li><strong>可靠性</strong>：需要有一定程度的异常处理能力、容灾能力。</li>\n</ul>\n</li>\n<li><p>实现</p>\n<ul>\n<li><p>Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：</p>\n<ul>\n<li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</li>\n<li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</li>\n</ul>\n</li>\n<li><p>基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。</p>\n<ul>\n<li>加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以<strong>原子操作</strong>的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；</li>\n<li>锁变量需要设置<strong>过期时间</strong>，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；</li>\n<li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个<strong>唯一值</strong>，用于标识客户端；</li>\n</ul>\n</li>\n<li><p>满足这三个条件的分布式命令如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">SET lock_key unique_value NX PX 10000 </code></pre>\n\n<ul>\n<li>lock_key 就是 key 键；</li>\n<li>unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；</li>\n<li>NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；</li>\n<li>PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。</li>\n</ul>\n</li>\n<li><p>解锁操作</p>\n<ul>\n<li><p>将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除</p>\n</li>\n<li><p>因为有两个操作，所以需要保证原子性，可以通过Lua脚本实现</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">&#x2F;&#x2F; 释放锁时，先比较 unique_value 是否相等，避免锁的误释放\nif redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then\n    return redis.call(&quot;del&quot;,KEYS[1])\nelse\n    return 0\nend</code></pre></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>守护线程</p>\n<ul>\n<li>用途：防止锁在业务没有执行完成后就释放掉了,开启一个线程来定期对这把锁进行延期操作</li>\n<li>业务线程挂掉了，然后守护线程一直还在更新这把锁的延期时间，会怎么样<ul>\n<li>业务线程挂了分情况。一种是整个程序被干掉了，比如掉线了。一个情况是程序出现 bug 了，导致业务线程在执行解锁逻辑之前被干掉了，或者说业务线程死循环了、忘记解锁了这类情况，都归属于 bug<ul>\n<li>第一种情况，程序被干掉了，那么守护线程也没了，所以不会续期了，时间到了就释放锁，这个没问题</li>\n<li>第二种情况，根据看门狗机制，它就是会无线续期。相当于变成了一个死锁。这是由它的工作原理决定的，无解。但是可以自己魔改一下看门狗机制，比如设定为续期 1000 次后还要续期，就有可能出问题了，那就释放锁。但是这个方案，聊胜于无。还不如设置一个较长的过期时间。</li>\n</ul>\n</li>\n<li>我觉得这种情况不应该考虑怎么改进看门狗机制，而是应该考虑怎么监控它是否在正常运行。比如续期了 1000 次还在续期，就发个预警出来，人工看看啥情况，然后具体情况具体分析，是 bug 就修 bug，是正常运行就先不管。人工一介入，就没有啥不能解决的。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n</li>\n<li></li>\n</ol>\n","text":"Redis Redis是一个高性能（内存+Reactor+优化的数据结构）的开源键值数据库，其value支持丰富的数据类型（string、hash、set、list、zset「有序集合」），具有数据可持久化（AOF+RDB）、支持master-slave备份、读写性能高（MySQ...","link":"","photos":[],"count_time":{"symbolsCount":"40k","symbolsTime":"36 mins."},"categories":[],"tags":[{"name":"database","slug":"database","count":2,"path":"api/tags/database.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Redis\"><span class=\"toc-text\">Redis</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E9%AB%98%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">1.高性能</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">1.数据结构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">2.线程模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86\"><span class=\"toc-text\">3.内存管理</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-%E9%AB%98%E5%8F%AF%E9%9D%A0\"><span class=\"toc-text\">2.高可靠</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96\"><span class=\"toc-text\">1.数据持久化</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Always%EF%BC%8C%E5%90%8C%E6%AD%A5%E5%86%99%E5%9B%9E%EF%BC%9A%E6%AF%8F%E4%B8%AA%E5%86%99%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E5%AE%8C%EF%BC%8C%E7%AB%8B%E9%A9%AC%E5%90%8C%E6%AD%A5%E5%9C%B0%E5%B0%86%E6%97%A5%E5%BF%97%E5%86%99%E5%9B%9E%E7%A3%81%E7%9B%98%EF%BC%9B%E5%8F%AF%E4%BB%A5%E4%BF%9D%E8%AF%81%E4%B8%8D%E4%B8%A2%E5%A4%B1%E6%95%B0%E6%8D%AE%EF%BC%8C%E4%BD%86%E6%98%AF%E5%9B%9E%E5%BD%B1%E5%93%8D%E4%B8%BB%E7%BA%BF%E7%A8%8B%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；可以保证不丢失数据，但是回影响主线程性能</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Everysec%EF%BC%8C%E6%AF%8F%E7%A7%92%E5%86%99%E5%9B%9E%EF%BC%9A%E6%AF%8F%E4%B8%AA%E5%86%99%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E5%AE%8C%EF%BC%8C%E5%8F%AA%E6%98%AF%E5%85%88%E6%8A%8A%E6%97%A5%E5%BF%97%E5%86%99%E5%88%B0-AOF-%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%85%E5%AD%98%E7%BC%93%E5%86%B2%E5%8C%BA%EF%BC%8C%E6%AF%8F%E9%9A%94%E4%B8%80%E7%A7%92%E6%8A%8A%E7%BC%93%E5%86%B2%E5%8C%BA%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%E5%86%99%E5%85%A5%E7%A3%81%E7%9B%98\"><span class=\"toc-text\">Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#No%EF%BC%8C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6%E7%9A%84%E5%86%99%E5%9B%9E%EF%BC%9A%E6%AF%8F%E4%B8%AA%E5%86%99%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E5%AE%8C%EF%BC%8C%E5%8F%AA%E6%98%AF%E5%85%88%E6%8A%8A%E6%97%A5%E5%BF%97%E5%86%99%E5%88%B0-AOF-%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%85%E5%AD%98%E7%BC%93%E5%86%B2%E5%8C%BA%EF%BC%8C%E7%94%B1%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%B3%E5%AE%9A%E4%BD%95%E6%97%B6%E5%B0%86%E7%BC%93%E5%86%B2%E5%8C%BA%E5%86%85%E5%AE%B9%E5%86%99%E5%9B%9E%E7%A3%81%E7%9B%98%EF%BC%8C%E4%BC%9A%E6%9C%89%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E7%9A%84%E9%A3%8E%E9%99%A9\"><span class=\"toc-text\">No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘，会有数据丢失的风险</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6\"><span class=\"toc-text\">2.主从复制</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">3.哨兵机制</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-%E9%AB%98%E5%8F%AF%E6%89%A9%E5%B1%95\"><span class=\"toc-text\">3.高可扩展</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87\"><span class=\"toc-text\">1.数据分片</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1\"><span class=\"toc-text\">2.负载均衡</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%99%84%E5%BD%95\"><span class=\"toc-text\">附录</span></a></li></ol></li></ol>","author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Spring Family","uid":"0eecce2180060832c1ffa34a76f3eb3b","slug":"Spring","date":"2023-05-06T05:09:43.000Z","updated":"2023-08-05T13:23:19.915Z","comments":true,"path":"api/articles/Spring.json","keywords":null,"cover":[],"text":"Spring 1.IOC1.基础知识 BeanFactory：提供了一种高级配置，能够管理任何类型对象，BeanFactory是ApplicationContext的父接口，ApplicationContext接口的实现类主要有ClassPathXmlApplicationCon...","link":"","photos":[],"count_time":{"symbolsCount":"98k","symbolsTime":"1:29"},"categories":[],"tags":[{"name":"tools","slug":"tools","count":2,"path":"api/tags/tools.json"}],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Go","uid":"8aa9bb0438939ce2b4a00f1a6ea1e9e5","slug":"Go","date":"2023-05-04T04:42:41.000Z","updated":"2023-05-04T06:50:29.873Z","comments":true,"path":"api/articles/Go.json","keywords":null,"cover":[],"text":"GO1.运行前准备 源码结构 GOROOT：Go 语言安装根目录的路径，也就是 GO 语言的安装路径 GOPATH：若干工作区目录的路径。是我们自己定义的工作空间（workspace），go源码文件（.go）、归档文件（.a）、可执行文件都存在此处 go源码文件需要保存在GOPA...","link":"","photos":[],"count_time":{"symbolsCount":"25k","symbolsTime":"23 mins."},"categories":[],"tags":[{"name":"language","slug":"language","count":3,"path":"api/tags/language.json"}],"author":{"name":"Dajunnnnnn","slug":"blog-author","avatar":"https://macro---oss2.oss-cn-beijing.aliyuncs.com/img/dajunnnnnn_psychedelic_eagle_neon_colors_comic_illustration_1ca2dde3-db58-4c04-b835-42e21feffbe8.PNG","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}